<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Watchmen1992&#39;s Blog</title>
  
  <subtitle>锦瑟年华当与书香为度，是为不负天地人生。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-28T08:41:14.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>XiaoHua WANG</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>zabbix trapper方式监控</title>
    <link href="http://yoursite.com/2019/07/28/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/zabbix/zabbix-trapper%E6%96%B9%E5%BC%8F%E7%9B%91%E6%8E%A7/"/>
    <id>http://yoursite.com/2019/07/28/IT科学技术知识体系结构-Linux运维方向/运维监控体系/zabbix/zabbix-trapper方式监控/</id>
    <published>2019-07-28T08:41:14.000Z</published>
    <updated>2019-07-28T08:41:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p> zabbix获取数据时有时会出现超时，如果一些数据需要执行比较长的时间才能获取的话，那么zabbix会出现异常，考虑到这种情况，zabbix增加了Trapper功能，客户端自己提交数据给zabbix。</p><p>使用场景：</p><ul><li>例如自定义的网络监控。需要添加ping丢包、延迟、抖动等情况的监控，如果通过server去获取数据，因为存在ping的时间，所以很容易就会导致超时，从而拿不到数据</li><li>监控项比较多，并且比较耗时的情况。例如zk的数据、es的数据等，使用trapper的方式，会比server去获取的效率高很多。</li></ul><h1 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h1><h2 id="实现逻辑"><a href="#实现逻辑" class="headerlink" title="实现逻辑"></a>实现逻辑</h2><ol><li>客户端自己实现获取获取数据的方式，可以是shell脚本、python程序等</li><li>通过zabbix_sender，把数据推送到zabbix server</li><li>客户端上配置定时任务，控制发送的频率</li></ol><h2 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a>配置流程</h2><p>具体到配置，流程是：</p><ol><li>zabbix server添加客户端，客户端的配置文件中要配置主机名</li><li>配置监控项，设置监控类型为：zabbix trapper</li><li>item的key是</li></ol><h2 id="zabbix-sender语法"><a href="#zabbix-sender语法" class="headerlink" title="zabbix_sender语法"></a>zabbix_sender语法</h2><p>语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zabbix_sender -z &lt;server IP address&gt; -p 10051 -s &quot;New host&quot; -k trap -o &quot;test value&quot;</span><br></pre></td></tr></table></figure><p>参数说明：</p><ul><li><p>-z  to specify Zabbix server IP address</p></li><li><p>-p  to specify Zabbix server port number (10051 by default)</p></li><li><p>-s  to specify the host (make sure to use the ‘technical’ <a href="https://www.zabbix.com/documentation/3.0/manual/config/hosts/host#configuration" target="_blank" rel="noopener">host name</a> here, instead of the ‘visible’ name)</p></li></ul><ul><li>-k to specify the key of the item we just defined</li></ul><ul><li>-o to specify the actual value to send</li></ul><p>执行的命令是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./zabbix_sender  -s common010-dev.novalocal -c /usr/local/zabbix/etc/zabbix_agentd.conf  -k trapper-test -o &quot;5&quot;  -p 10051</span><br></pre></td></tr></table></figure><p>或者直接指定zabbix server的地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./zabbix_sender  -s common010-dev.novalocal -z 192.168.1.82  -k trapper-test -o &quot;6&quot;</span><br></pre></td></tr></table></figure><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li><p>trapper是被监控主机主动发送数据给zabbix server，与主动模式的区别是可以不需要安装客户端；</p></li><li><p>trapper方式发送数据是以主机名处理，不是IP地址，所以主机名要唯一。</p></li><li><p>接上面一点，-s 后面加的必须是主机名，而不是ip地址</p></li><li><p>指定server地址，可以使用配置文件，也可以直接使用ip</p></li><li>如果使用的是默认端口，那么端口参数可以省略</li></ul><h2 id="实际案例-es监控"><a href="#实际案例-es监控" class="headerlink" title="实际案例-es监控"></a>实际案例-es监控</h2><p>使用zabbix来做，整体步骤如下：</p><ol><li><p>zabbix上创建模板</p></li><li><p>主机上使用zabbix_send定时发送数据-上传脚本</p></li><li><p>设置定时任务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@es042.ecs.east1-e ~]# crontab  -l</span><br><span class="line"># send es monitor data every 30s</span><br><span class="line">* * * * * for i in 30 30;do sleep $i; /application/python/bin/python /usr/local/zabbix/scripts/es_status_monitor.py 9200;done</span><br></pre></td></tr></table></figure></li></ol><h1 id="discovery-自动发现"><a href="#discovery-自动发现" class="headerlink" title="discovery-自动发现"></a>discovery-自动发现</h1><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>分为2个部分</p><ol><li>动态发现要监控的对象</li><li>根据上一步输出的对象，添加预先设置好的监控项和触发器</li></ol><p>也就是说，分为2个逻辑</p><ol><li>获取监控对象的逻辑</li><li>根据上面输出变量的值，添加监控项和触发器</li></ol><p>官方说明：</p><p>首先，用户在“配置”→“模板”→“发现”列中创建一个发现规则。发现规则包括（1）发现必要实体（例如，文件系统或网络接口）的项目和（2）应该根据该项目的值创建的监控项，触发器和图形的原型</p><p>发现必要实体的项目就像其他地方所看到的常规项目：服务器向该项目的值询问Zabbix agent（或者该项目的任何类型的设置），agent以文本值进行响应。区别在于agent响应的值应该包含特定JSON格式的发现实体的列表。这种格式的自定义检查者发现的细节才是最重要的，因为返回值必须包含宏→值对。例如，项目“net.if.discovery”可能会返回两对键值：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“&#123;#IFNAME&#125;”→“lo”和“&#123;#IFNAME&#125;”→“eth0”。</span><br></pre></td></tr></table></figure><p>这些宏用于名称，键值和其他原型字段中，然后用接收到的值为每个发现的实体创建实际的监控项，触发器，图形甚至主机。请参阅使用LLD宏的<a href="https://www.zabbix.com/documentation/3.4/manual/config/macros/lld_macros" target="_blank" rel="noopener">选项</a>的完整列表。</p><p>当服务器接收到发现项目的值时，它会查看宏→值对，每对都根据原型生成实际监控项，触发器和图形。在上面的“net.if.discovery”示例中，服务器将生成环路接口“lo”的一组监控项，触发器和图表，另一组用于界面“eth0”。</p><p>以下部分将详细说明上述过程，并作为一个指导上述类型的所有发现。最后一节描述了发现项目的JSON格式，并给出了文件系统发现实现的Perl脚本的示例。</p><h2 id="具体实现-1"><a href="#具体实现-1" class="headerlink" title="具体实现"></a>具体实现</h2><h3 id="创建模板和应用集"><a href="#创建模板和应用集" class="headerlink" title="创建模板和应用集"></a>创建模板和应用集</h3><h3 id="创建discovery-rules"><a href="#创建discovery-rules" class="headerlink" title="创建discovery rules"></a>创建discovery rules</h3><h2 id="实例案例-zookeeper"><a href="#实例案例-zookeeper" class="headerlink" title="实例案例-zookeeper"></a>实例案例-zookeeper</h2><p>根据端口号，定位pid，然后根据pid去获取相应的jvm信息</p><h3 id="监控脚本"><a href="#监控脚本" class="headerlink" title="监控脚本"></a>监控脚本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">#!/application/python/bin/python</span><br><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">import subprocess,json,sys</span><br><span class="line">#base_path=os.path.dirname(os.path.dirname(os.path.abspath(__file__)))</span><br><span class="line">#sys.path.append(base_path)</span><br><span class="line">args = sys.argv[1:]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def get_zk_node_path():</span><br><span class="line">    get_path_cmd = &quot;&quot;&quot;sudo /bin/ps -elf | grep zookeeper| grep -E -v &apos;grep|sleep|sugar_java|scripts|sudo&apos; | awk &apos;&#123;print $NF&#125;&apos; | awk -F &quot;/&quot; &apos;&#123;print &quot;/&quot;$2&quot;/&quot;$3&quot;/&quot;$4&#125;&apos;&quot;&quot;&quot;</span><br><span class="line">    zk_node_path_list=subprocess.Popen(get_path_cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE)</span><br><span class="line">    macros_keys = &#123;&quot;data&quot;: []&#125;</span><br><span class="line">    for zk_node_path in zk_node_path_list.stdout.readlines():</span><br><span class="line">        zk_node_path = zk_node_path.strip()</span><br><span class="line">        macros_keys[&apos;data&apos;].append(&#123;&apos;&#123;&amp;#35ZK_NODE&#125;&apos;:zk_node_path&#125;)</span><br><span class="line">    return json.dumps(macros_keys)</span><br><span class="line"></span><br><span class="line">def get_zk_value(zk_node_path,key):</span><br><span class="line">    get_pid_cmd = &quot;&quot;&quot;sudo /bin/ps -elf | grep %s | grep -Ev &quot;grep|python&quot;  | awk &apos;&#123;print $4&#125;&apos;&quot;&quot;&quot; % (zk_node_path)</span><br><span class="line">    zk_pid_tmp = subprocess.Popen(get_pid_cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE)</span><br><span class="line">    zk_pid = zk_pid_tmp.stdout.read().strip()</span><br><span class="line">    values=subprocess.Popen(&apos;sudo /usr/local/jdk/bin/jstat -gcutil &#123;&#125;&apos;.format(zk_pid),shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE)</span><br><span class="line">    jstat_keys = values.stdout.readline().strip().split()</span><br><span class="line">    jstat_values = values.stdout.readline().strip().split()</span><br><span class="line">    try:</span><br><span class="line">        index_num=jstat_keys.index(key)</span><br><span class="line">    except ValueError:</span><br><span class="line">        pass</span><br><span class="line">    else:</span><br><span class="line">        return jstat_values[index_num]</span><br><span class="line"></span><br><span class="line">if __name__==&apos;__main__&apos;:</span><br><span class="line">    result=None</span><br><span class="line">    if len(args)==1:</span><br><span class="line">        if args[0]==&apos;discovery&apos;:</span><br><span class="line">            result = get_zk_node_path()</span><br><span class="line">    if len(args)==2:</span><br><span class="line">        result = get_zk_value(args[0],args[1])</span><br><span class="line">    if result:</span><br><span class="line">        print (result)</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>zabbix上创建模板</p><p>修改sudo</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@common001-dev.novalocal ~]# cat /etc/sudoers </span><br><span class="line">在文件末尾添加</span><br><span class="line">zabbix  ALL = (ALL)     NOPASSWD: /usr/local/jdk/bin/jps, /usr/local/jdk/bin/jstat, /sbin/blockdev, /bin/ps</span><br></pre></td></tr></table></figure><p>脚本上传</p><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@common001-dev.novalocal zabbix_agentd.conf.d]# pwd</span><br><span class="line">/usr/local/zabbix/etc/zabbix_agentd.conf.d</span><br><span class="line"></span><br><span class="line">[root@common001-dev.novalocal zabbix_agentd.conf.d]# cat zk_jvm.conf</span><br><span class="line">UserParameter=zkjvm.discovery, /usr/local/zabbix/scripts/get_zk_jvm.py discovery</span><br><span class="line">UserParameter=zkjvm.status[*], /usr/local/zabbix/scripts/get_zk_jvm.py $1 $2</span><br></pre></td></tr></table></figure><p>重启agent</p>]]></content>
    
    <summary type="html">
    
      zabbix trapper方式监控
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维监控体系" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/"/>
    
      <category term="zabbix" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/zabbix/"/>
    
    
      <category term="zabbix" scheme="http://yoursite.com/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>python从入门到实践</title>
    <link href="http://yoursite.com/2019/06/18/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/python%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5/"/>
    <id>http://yoursite.com/2019/06/18/IT科学技术知识体系结构-Linux运维方向/编程开发/Python/python从入门到实践/</id>
    <published>2019-06-18T12:35:45.000Z</published>
    <updated>2019-06-18T12:35:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考文献：</p><ul><li><a href="https://wiki.python.org/moin/BeginnersGuide/Overview" target="_blank" rel="noopener">https://wiki.python.org/moin/BeginnersGuide/Overview</a></li></ul><h1 id="学习编程的方法"><a href="#学习编程的方法" class="headerlink" title="学习编程的方法"></a>学习编程的方法</h1><p>人学习东西，天然有一种特性，就是学到的知识不马上应用的话，就会很快忘记。因此采集学习大量的知识，再去应用的方式是不可取的，比较浪费时间，而实际情况是，很多人往往就会陷入这种误区。</p><p>特别是现在的IT培训机构，在短时间内，灌输大量的知识，只是做一些简单的案例练习，这样是无法真正掌握这些知识的，只是走马观花的看一遍。</p><p>看了网上的，以及结合自身的实际情况来看，比较合适的一个学习方式是：项目驱动式去学习。</p><p>也就是，由输出来决定输入。实现一个项目，在实现这个项目中，会涉及很多需要学习的知识，在这个时候，再去学习这些知识，学完之后马上就能得到应用。</p><p>把项目驱动式的方式进程拆解，其实就是一种从上到下的树形图。</p><p>根节点是项目，也就是要解决或者要实现的问题或者需求。往下的每一个部分都代表了学习过程中遇到的问题，每个问题其实就是单独的需要去学习的知识点。</p><p>它的好处就是让你知道了你应该去学什么，而不是先学一大堆有用的或者没用的知识，然后再来做项目。</p><p><strong>存在的问题</strong></p><blockquote><p>这种学些方式，存在一个天然的问题，就是学习到的知识都是分散的，可能也就是只是学习了这个项目需要要就好了。每一个部分的知识都是非常零碎的，不成体系和结构。</p></blockquote><h1 id="python特性"><a href="#python特性" class="headerlink" title="python特性"></a>python特性</h1><p>Some programming-language features of Python are:</p><ul><li>A variety of basic data types are available: numbers (floating point, complex, and unlimited-length long integers), strings (both ASCII and Unicode), lists, and dictionaries.</li><li>Python supports object-oriented programming with classes and multiple inheritance.</li><li>Code can be grouped into modules and packages.</li><li>The language supports raising and catching exceptions, resulting in cleaner error handling.</li><li>Data types are strongly and dynamically typed. Mixing incompatible types (e.g. attempting to add a string and a number) causes an exception to be raised, so errors are caught sooner.</li><li>Python contains advanced programming features such as generators and list comprehensions.</li><li>Python’s automatic memory management frees you from having to manually allocate and free memory in your code.</li></ul><p>下面我们会把一些重要的知识点单独拿出来详细说明</p><h2 id="强数据类型以及动态类型"><a href="#强数据类型以及动态类型" class="headerlink" title="强数据类型以及动态类型"></a>强数据类型以及动态类型</h2><p>官方描述：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Data types are strongly and dynamically typed. Mixing incompatible types (e.g. attempting to add a string and a number) causes an exception to be raised, so errors are caught sooner.</span><br></pre></td></tr></table></figure><p><strong>Python是一个强数据类型以及动态类型的编程语言。</strong></p><p><strong>强数据类型</strong>：</p><p>一个变量在被赋值时会获得一个数据类型，如果不经过强制转换，那么它将永远会是这个类型、</p><p>测试代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = 1</span><br><span class="line">b = &quot;2&quot;</span><br><span class="line">print (a+b)</span><br></pre></td></tr></table></figure><p>执行后输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 152, in &lt;module&gt;</span><br><span class="line">    print (a+b)</span><br><span class="line">TypeError: unsupported operand type(s) for +: &apos;int&apos; and &apos;str&apos;</span><br></pre></td></tr></table></figure><p><strong>弱数据类型：</strong></p><p>不允许隐式转换的是强类型，允许隐式转换的是弱类型。</p><p>有强就有弱，弱语言类型的编程语言在执行时，数据类型可以被忽略，我们直接看一个例子</p><p>测试代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜  script cat test.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">a=1</span><br><span class="line">c=ddd</span><br><span class="line">echo $a+$c</span><br><span class="line">➜  script sh test.sh</span><br><span class="line">1+ddd</span><br></pre></td></tr></table></figure><p>也就是说，它与强类型定义语言相反, 一个变量可以赋不同数据类型的值。</p><p><strong>常见的强弱数据类型编程语言</strong></p><ul><li>强数据类型语言：Java/C#/python</li><li>弱数据类型语言：C/C++/PHP/Perl/JavaScript/Unix Shell</li></ul><p><strong>动态类型：</strong></p><p>运行期间才会做数据类型检查。也就是说只会在程序运行时，执行到变量赋值的代码时，才将该变量的数据类型进行记录。</p><p>因此不用在变量定义的时候指定变量的数据类型</p><p><strong>静态类型：</strong></p><p>同样的，有静就有动，静态类型的编程语言，在编译期间就知道变量的类型，例如在C语言中要使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int age = 18;</span><br></pre></td></tr></table></figure><p>这样的方式来定义变量</p><p><strong>总结</strong></p><p>下图是常见的语言类型的划分：<br><img src="http://picture.watchmen.xin//python/base/base.png" alt=""></p><p>由于强类型语言一般需要在运行时运行一套类型检查系统，因此强类型语言的速度一般比弱类型要慢，动态类型也比静态类型慢，因此常见的四种语言中执行的速度应该是 C &gt; Java &gt; JavaScript &gt; Python。</p><p>强类型，静态类型的语言写起来往往是最安全的。</p><h2 id="生成器及列表解析"><a href="#生成器及列表解析" class="headerlink" title="生成器及列表解析"></a>生成器及列表解析</h2><p>官方描述</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python contains advanced programming features such as generators and list comprehensions.</span><br></pre></td></tr></table></figure><h1 id="unicode问题"><a href="#unicode问题" class="headerlink" title="unicode问题"></a>unicode问题</h1><h1 id="常用模块"><a href="#常用模块" class="headerlink" title="常用模块"></a>常用模块</h1><h2 id="re-正则匹配模块"><a href="#re-正则匹配模块" class="headerlink" title="re-正则匹配模块"></a>re-正则匹配模块</h2><p>正则表达式是一个特殊的字符序列，它能帮助你方便的检查一个字符串是否与某种模式匹配。</p><p>Python 自1.5版本起增加了re 模块，它提供 Perl 风格的正则表达式模式。</p><h3 id="re-match函数"><a href="#re-match函数" class="headerlink" title="re.match函数"></a>re.match函数</h3><p>re.match 尝试从字符串的<strong>起始位置匹配</strong>一个模式</p><ul><li>如果没有匹配成功的话，match()就返回none。</li><li>如果匹配成功的话，返回匹配对象</li></ul><p><strong>函数语法</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.match(pattern, string, flags=0)</span><br></pre></td></tr></table></figure><p>函数参数说明：</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>pattern</td><td>匹配的正则表达式</td></tr><tr><td>string</td><td>要匹配的字符串。</td></tr><tr><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：<a href="http://www.runoob.com/python/python-reg-expressions.html#flags" target="_blank" rel="noopener">正则表达式修饰符 - 可选标志</a></td></tr></tbody></table><p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p><table><thead><tr><th>匹配对象方法</th><th>描述</th></tr></thead><tbody><tr><td>group(num=0)</td><td>匹配的整个表达式的字符串，group() 可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组。</td></tr><tr><td>groups()</td><td>返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。</td></tr></tbody></table><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">test_str = &quot;wo shi wangxiaohua,wangxiaohua shi wo&quot;</span><br><span class="line"></span><br><span class="line">a = re.match(&apos;wangxiaohua&apos;,test_str)</span><br><span class="line">b = re.match(&apos;w&apos;,test_str)</span><br><span class="line">print (a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><p>执行后的结果是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">None</span><br><span class="line">&lt;re.Match object; span=(0, 1), match=&apos;w&apos;&gt;</span><br></pre></td></tr></table></figure><p>当执行group方法是，会表现为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print (a.group())</span><br><span class="line">输出为：</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/learn_python/module-re.py&quot;, line 12, in &lt;module&gt;</span><br><span class="line">    print (a.group())</span><br><span class="line">AttributeError: &apos;NoneType&apos; object has no attribute &apos;group&apos;</span><br><span class="line"></span><br><span class="line">print (b.group())</span><br><span class="line">输出为：</span><br><span class="line">w</span><br></pre></td></tr></table></figure><h3 id="re-search方法"><a href="#re-search方法" class="headerlink" title="re.search方法"></a>re.search方法</h3><p>re.search 扫描整个字符串并返回第一个成功的匹配。</p><p>函数语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.search(pattern, string, flags=0)</span><br></pre></td></tr></table></figure><p>函数参数说明：</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>pattern</td><td>匹配的正则表达式</td></tr><tr><td>string</td><td>要匹配的字符串。</td></tr><tr><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。</td></tr></tbody></table><p>匹配成功re.search方法返回一个匹配的对象，否则返回None。</p><p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p><table><thead><tr><th>匹配对象方法</th><th>描述</th></tr></thead><tbody><tr><td>group(num=0)</td><td>匹配的整个表达式的字符串，group() 可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组。</td></tr><tr><td>groups()</td><td>返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。</td></tr></tbody></table><h3 id="re-match与re-search的区别"><a href="#re-match与re-search的区别" class="headerlink" title="re.match与re.search的区别"></a>re.match与re.search的区别</h3><p>re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。</p><h3 id="检索和替换"><a href="#检索和替换" class="headerlink" title="检索和替换"></a>检索和替换</h3><p>Python 的 re 模块提供了re.sub用于替换字符串中的匹配项。</p><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(pattern, repl, string, count=0, flags=0)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>pattern : 正则中的模式字符串。</li><li>repl : 替换的字符串，也可为一个函数。</li><li>string : 要被查找替换的原始字符串。</li><li>count : 模式匹配后替换的最大次数，默认 0 表示替换所有的匹配。</li></ul><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"> </span><br><span class="line">import re</span><br><span class="line"> </span><br><span class="line">phone = &quot;2004-959-559 # 这是一个国外电话号码&quot;</span><br><span class="line"> </span><br><span class="line"># 删除字符串中的 Python注释 </span><br><span class="line">num = re.sub(r&apos;#.*$&apos;, &quot;&quot;, phone)</span><br><span class="line">print &quot;电话号码是: &quot;, num</span><br><span class="line"> </span><br><span class="line"># 删除非数字(-)的字符串 </span><br><span class="line">num = re.sub(r&apos;\D&apos;, &quot;&quot;, phone)</span><br><span class="line">print &quot;电话号码是 : &quot;, num</span><br></pre></td></tr></table></figure><p>执行后输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">电话号码是:  2004-959-559 </span><br><span class="line">电话号码是 :  2004959559</span><br></pre></td></tr></table></figure><h3 id="findall"><a href="#findall" class="headerlink" title="findall"></a>findall</h3><p>在字符串中找到正则表达式所匹配的所有子串，并<strong>返回一个列表</strong>，如果没有找到匹配的，则返回空列表。</p><p><strong>注意：</strong> match 和 search 是匹配一次，而 findall是匹配所有。</p><p>语法格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">findall(string[, pos[, endpos]])</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>string : 待匹配的字符串。</li><li>pos : 可选参数，指定字符串的起始位置，默认为 0。</li><li>endpos : 可选参数，指定字符串的结束位置，默认为字符串的长度。</li></ul><h3 id="re-finditer"><a href="#re-finditer" class="headerlink" title="re.finditer"></a>re.finditer</h3><p>和 findall 类似，在字符串中找到正则表达式所匹配的所有子串，并把它们作为<strong>一个迭代器返回</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.finditer(pattern, string, flags=0)</span><br></pre></td></tr></table></figure><p>参数：</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>pattern</td><td>匹配的正则表达式</td></tr><tr><td>string</td><td>要匹配的字符串。</td></tr><tr><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：<a href="http://www.runoob.com/python/python-reg-expressions.html#flags" target="_blank" rel="noopener">正则表达式修饰符 - 可选标志</a></td></tr></tbody></table><h3 id="re-split"><a href="#re-split" class="headerlink" title="re.split"></a>re.split</h3><p>split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.split(pattern, string[, maxsplit=0, flags=0])</span><br></pre></td></tr></table></figure><p>参数：</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>pattern</td><td>匹配的正则表达式</td></tr><tr><td>string</td><td>要匹配的字符串。</td></tr><tr><td>maxsplit</td><td>分隔次数，maxsplit=1 分隔一次，默认为 0，不限制次数。</td></tr><tr><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：<a href="http://www.runoob.com/python/python-reg-expressions.html#flags" target="_blank" rel="noopener">正则表达式修饰符 - 可选标志</a></td></tr></tbody></table><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;import re</span><br><span class="line">&gt;&gt;&gt; re.split(&apos;\W+&apos;, &apos;runoob, runoob, runoob.&apos;)</span><br><span class="line">[&apos;runoob&apos;, &apos;runoob&apos;, &apos;runoob&apos;, &apos;&apos;]</span><br><span class="line">&gt;&gt;&gt; re.split(&apos;(\W+)&apos;, &apos; runoob, runoob, runoob.&apos;) </span><br><span class="line">[&apos;&apos;, &apos; &apos;, &apos;runoob&apos;, &apos;, &apos;, &apos;runoob&apos;, &apos;, &apos;, &apos;runoob&apos;, &apos;.&apos;, &apos;&apos;]</span><br><span class="line">&gt;&gt;&gt; re.split(&apos;\W+&apos;, &apos; runoob, runoob, runoob.&apos;, 1) </span><br><span class="line">[&apos;&apos;, &apos;runoob, runoob, runoob.&apos;]</span><br><span class="line"> </span><br><span class="line">&gt;&gt;&gt; re.split(&apos;a*&apos;, &apos;hello world&apos;)   # 对于一个找不到匹配的字符串而言，split 不会对其作出分割</span><br><span class="line">[&apos;hello world&apos;]</span><br></pre></td></tr></table></figure><h3 id="正则表达式修饰符-可选标志"><a href="#正则表达式修饰符-可选标志" class="headerlink" title="正则表达式修饰符 - 可选标志"></a>正则表达式修饰符 - 可选标志</h3><p>正则表达式可以包含一些可选标志修饰符（属性）来控制匹配的模式。修饰符被指定为一个可选的标志。多个标志可以通过按位 OR(|) 它们来指定。如 re.I | re.M 被设置成 I 和 M 标志：</p><table><thead><tr><th>修饰符</th><th>描述</th></tr></thead><tbody><tr><td>re.I</td><td>大小写不敏感</td></tr><tr><td>re.L</td><td>做本地化识别（locale-aware）匹配</td></tr><tr><td>re.M</td><td>多行匹配，影响 ^ 和 $</td></tr><tr><td>re.S</td><td>使 . 匹配包括换行在内的所有字符</td></tr><tr><td>re.U</td><td>根据Unicode字符集解析字符。这个标志影响 \w, \W, \b, \B.</td></tr><tr><td>re.X</td><td>该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解。</td></tr></tbody></table><h3 id="正则表达式模式"><a href="#正则表达式模式" class="headerlink" title="正则表达式模式"></a>正则表达式模式</h3><p>模式字符串使用特殊的语法来表示一个正则表达式：</p><p>字母和数字表示他们自身。一个正则表达式模式中的字母和数字匹配同样的字符串。</p><p>多数字母和数字前加一个反斜杠时会拥有不同的含义。</p><p>标点符号只有被转义时才匹配自身，否则它们表示特殊的含义。</p><p>反斜杠本身需要使用反斜杠转义。</p><p>由于正则表达式通常都包含反斜杠，所以你最好使用原始字符串来表示它们。模式元素(如 r’\t’，等价于 ‘\t’)匹配相应的特殊字符。</p><p>下表列出了正则表达式模式语法中的特殊元素。如果你使用模式的同时提供了可选的标志参数，某些模式元素的含义会改变。</p><table><thead><tr><th>模式</th><th>描述</th></tr></thead><tbody><tr><td>^</td><td>匹配字符串的开头</td></tr><tr><td>$</td><td>匹配字符串的末尾。</td></tr><tr><td>.</td><td>匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。</td></tr><tr><td>[…]</td><td>用来表示一组字符,单独列出：[amk] 匹配 ‘a’，’m’或’k’</td></tr><tr><td>[^…]</td><td>不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。</td></tr><tr><td>re*</td><td>匹配0个或多个的表达式。</td></tr><tr><td>re+</td><td>匹配1个或多个的表达式。</td></tr><tr><td>re?</td><td>匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式</td></tr><tr><td>re{ n}</td><td>精确匹配 n 个前面表达式。例如， o{2} 不能匹配 “Bob” 中的 “o”，但是能匹配 “food” 中的两个 o。</td></tr><tr><td>re{ n,}</td><td>匹配 n 个前面表达式。例如， o{2,} 不能匹配”Bob”中的”o”，但能匹配 “foooood”中的所有 o。”o{1,}” 等价于 “o+”。”o{0,}” 则等价于 “o*”。</td></tr><tr><td>re{ n, m}</td><td>匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式</td></tr><tr><td>a\</td><td>b</td><td>匹配a或b</td></tr><tr><td>(re)</td><td>匹配括号内的表达式，也表示一个组</td></tr><tr><td>(?imx)</td><td>正则表达式包含三种可选标志：i, m, 或 x 。只影响括号中的区域。</td></tr><tr><td>(?-imx)</td><td>正则表达式关闭 i, m, 或 x 可选标志。只影响括号中的区域。</td></tr><tr><td>(?: re)</td><td>类似 (…), 但是不表示一个组</td></tr><tr><td>(?imx: re)</td><td>在括号中使用i, m, 或 x 可选标志</td></tr><tr><td>(?-imx: re)</td><td>在括号中不使用i, m, 或 x 可选标志</td></tr><tr><td>(?#…)</td><td>注释.</td></tr><tr><td>(?= re)</td><td>前向肯定界定符。如果所含正则表达式，以 … 表示，在当前位置成功匹配时成功，否则失败。但一旦所含表达式已经尝试，匹配引擎根本没有提高；模式的剩余部分还要尝试界定符的右边。</td></tr><tr><td>(?! re)</td><td>前向否定界定符。与肯定界定符相反；当所含表达式不能在字符串当前位置匹配时成功</td></tr><tr><td>(?&gt; re)</td><td>匹配的独立模式，省去回溯。</td></tr><tr><td>\w</td><td>匹配字母数字及下划线</td></tr><tr><td>\W</td><td>匹配非字母数字及下划线</td></tr><tr><td>\s</td><td>匹配任意空白字符，等价于 [\t\n\r\f].</td></tr><tr><td>\S</td><td>匹配任意非空字符</td></tr><tr><td>\d</td><td>匹配任意数字，等价于 [0-9].</td></tr><tr><td>\D</td><td>匹配任意非数字</td></tr><tr><td>\A</td><td>匹配字符串开始</td></tr><tr><td>\Z</td><td>匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串。</td></tr><tr><td>\z</td><td>匹配字符串结束</td></tr><tr><td>\G</td><td>匹配最后匹配完成的位置。</td></tr><tr><td>\b</td><td>匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。</td></tr><tr><td>\B</td><td>匹配非单词边界。’er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。</td></tr><tr><td>\n, \t, 等.</td><td>匹配一个换行符。匹配一个制表符。等</td></tr><tr><td>\1…\9</td><td>匹配第n个分组的内容。</td></tr><tr><td>\10</td><td>匹配第n个分组的内容，如果它经匹配。否则指的是八进制字符码的表达式。</td></tr></tbody></table><hr><h4 id="正则表达式实例"><a href="#正则表达式实例" class="headerlink" title="正则表达式实例"></a>正则表达式实例</h4><h4 id="字符匹配"><a href="#字符匹配" class="headerlink" title="字符匹配"></a>字符匹配</h4><table><thead><tr><th>实例</th><th>描述</th></tr></thead><tbody><tr><td>python</td><td>匹配 “python”.</td></tr></tbody></table><h4 id="字符类"><a href="#字符类" class="headerlink" title="字符类"></a>字符类</h4><table><thead><tr><th>实例</th><th>描述</th></tr></thead><tbody><tr><td>[Pp]ython</td><td>匹配 “Python” 或 “python”</td></tr><tr><td>rub[ye]</td><td>匹配 “ruby” 或 “rube”</td></tr><tr><td>[aeiou]</td><td>匹配中括号内的任意一个字母</td></tr><tr><td>[0-9]</td><td>匹配任何数字。类似于 [0123456789]</td></tr><tr><td>[a-z]</td><td>匹配任何小写字母</td></tr><tr><td>[A-Z]</td><td>匹配任何大写字母</td></tr><tr><td>[a-zA-Z0-9]</td><td>匹配任何字母及数字</td></tr><tr><td>[^aeiou]</td><td>除了aeiou字母以外的所有字符</td></tr><tr><td>[^0-9]</td><td>匹配除了数字外的字符</td></tr></tbody></table><h4 id="特殊字符类"><a href="#特殊字符类" class="headerlink" title="特殊字符类"></a>特殊字符类</h4><table><thead><tr><th>实例</th><th>描述</th></tr></thead><tbody><tr><td>.</td><td>匹配除 “\n” 之外的任何单个字符。要匹配包括 ‘\n’ 在内的任何字符，请使用象 ‘[.\n]’ 的模式。</td></tr><tr><td>\d</td><td>匹配一个数字字符。等价于 [0-9]。</td></tr><tr><td>\D</td><td>匹配一个非数字字符。等价于 [^0-9]。</td></tr><tr><td>\s</td><td>匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。</td></tr><tr><td>\S</td><td>匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。</td></tr><tr><td>\w</td><td>匹配包括下划线的任何单词字符。等价于’[A-Za-z0-9_]’。</td></tr><tr><td>\W</td><td>匹配任何非单词字符。等价于 ‘[^A-Za-z0-9_]’。</td></tr></tbody></table><h2 id="json模块"><a href="#json模块" class="headerlink" title="json模块"></a>json模块</h2><p>JSON(JavaScript Object Notation) 是一种基于文本的轻量级数据交换格式，易于人阅读和编写。</p><p>主谓宾重点：json是一种数据的描述表达和使用的格式、规范。</p><h3 id="json模块的功能作用"><a href="#json模块的功能作用" class="headerlink" title="json模块的功能作用"></a>json模块的功能作用</h3><p>使用该模块，实现：</p><ol><li>解码：解释json字符串数据以供程序使用。将字符串或者文件中的数据内容（内容格式必须是json规范)，转换为python对象</li><li>编码：生成json格式数据。将json对象（字典、列表等）转换成为字符串</li></ol><table><thead><tr><th>函数</th><th>描述</th></tr></thead><tbody><tr><td>json.dumps</td><td>将 Python 对象编码成 JSON 字符串</td></tr><tr><td>json.loads</td><td>将已编码的 JSON 字符串解码为 Python 对象</td></tr></tbody></table><p>码：数据、信息</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><p>JSON 文本格式在语法上与创建 JavaScript 对象的代码相同。</p><p>由于这种相似性，无需解析器，JavaScript 程序能够使用内建的 <a href="http://www.w3school.com.cn/jsref/jsref_eval.asp" target="_blank" rel="noopener">eval() 函数</a>，用 JSON 数据来生成原生的 JavaScript 对象。</p><h3 id="json-dumps-编码"><a href="#json-dumps-编码" class="headerlink" title="json.dumps-编码"></a>json.dumps-编码</h3><p>json.dumps 用于将 Python 对象编码成 JSON 字符串。</p><p><strong>语法</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json.dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, encoding=&quot;utf-8&quot;, default=None, sort_keys=False, **kw)</span><br></pre></td></tr></table></figure><p>示例代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 编码</span><br><span class="line">data_list = [ &#123; &apos;a&apos; : 1, &apos;b&apos; : 2, &apos;c&apos; : 3, &apos;d&apos; : 4, &apos;e&apos; : 5 &#125; ]</span><br><span class="line">data_dict =  &#123; &apos;a&apos; : 1, &apos;b&apos; : 2, &apos;c&apos; : 3, &apos;d&apos; : 4, &apos;e&apos; : 5 &#125;</span><br><span class="line"></span><br><span class="line">a = json.dumps(data_list)</span><br><span class="line">b = json.dumps(data_dict)</span><br><span class="line">print (type(a),a)</span><br><span class="line">print (type(b),b)</span><br><span class="line"></span><br><span class="line">执行后输出为：</span><br><span class="line">&lt;class &apos;str&apos;&gt; [&#123;&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3, &quot;d&quot;: 4, &quot;e&quot;: 5&#125;]</span><br><span class="line">&lt;class &apos;str&apos;&gt; &#123;&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: 3, &quot;d&quot;: 4, &quot;e&quot;: 5&#125;</span><br></pre></td></tr></table></figure><p>python 原始类型向 json 类型的转化对照表：</p><table><thead><tr><th>Python</th><th>JSON</th></tr></thead><tbody><tr><td>dict</td><td>object</td></tr><tr><td>list, tuple</td><td>array</td></tr><tr><td>str, unicode</td><td>string</td></tr><tr><td>int, long, float</td><td>number</td></tr><tr><td>True</td><td>true</td></tr><tr><td>False</td><td>false</td></tr><tr><td>None</td><td>null</td></tr></tbody></table><h3 id="json-loads-解码"><a href="#json-loads-解码" class="headerlink" title="json.loads-解码"></a>json.loads-解码</h3><p>json.loads 用于解码 JSON 数据。该函数返回 Python 字段的数据类型。</p><p><strong>语法</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">json.loads(s[, encoding[, cls[, object_hook[, parse_float[, parse_int[, parse_constant[, object_pairs_hook[, **kw]]]]]]]])</span><br></pre></td></tr></table></figure><p>示例代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 解码</span><br><span class="line">data = &apos;[ &#123;&quot;a&quot;:1,&quot;b&quot;:2&#125;]&apos;</span><br><span class="line">a = json.loads(data)</span><br><span class="line">print (type(a),a)</span><br><span class="line"></span><br><span class="line">执行后输出如下：</span><br><span class="line">&lt;class &apos;list&apos;&gt; [&#123;&apos;a&apos;: 1, &apos;b&apos;: 2&#125;]</span><br><span class="line">&lt;class &apos;list&apos;&gt;</span><br></pre></td></tr></table></figure><p>json 类型转换到 python 的类型对照表：</p><table><thead><tr><th>JSON</th><th>Python</th></tr></thead><tbody><tr><td>object</td><td>dict</td></tr><tr><td>array</td><td>list</td></tr><tr><td>string</td><td>unicode</td></tr><tr><td>number (int)</td><td>int, long</td></tr><tr><td>number (real)</td><td>float</td></tr><tr><td>true</td><td>True</td></tr><tr><td>false</td><td>False</td></tr><tr><td>null</td><td>None</td></tr></tbody></table><h3 id="json对象"><a href="#json对象" class="headerlink" title="json对象"></a>json对象</h3><p>json格式的字符串需要转换成为一个对象之后，才可以被调用。这个步骤也就是loads解码</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">json_string = &apos;&#123;&quot;first_name&quot;: &quot;Guido&quot;, &quot;last_name&quot;:&quot;Rossum&quot;&#125;&apos;</span><br><span class="line">json_string = json.loads(json_string)</span><br><span class="line">print (json_string[&apos;first_name&apos;])</span><br></pre></td></tr></table></figure><p>如果没有使用json.loads进行实例化对象，那么print是会报错的，报错为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/dnamed/lib/error.py&quot;, line 18, in &lt;module&gt;</span><br><span class="line">    print (json_string[&apos;first_name&apos;])</span><br><span class="line">TypeError: string indices must be integers</span><br></pre></td></tr></table></figure><h3 id="dumps-和dump-等的区别"><a href="#dumps-和dump-等的区别" class="headerlink" title="dumps() 和dump()等的区别"></a>dumps() 和dump()等的区别</h3><p>通过前面的内容，我们知道dumps是json编码的过程，将python对象编码成为字符串，loads是解码过程，将字符串编程python对象，但是上面的例子都是的数据来源全都是变量，也就是将结果写到变量里面或者从变量里面获取信息。</p><p>但是在实际情况中，我们可能会涉及到文件的操作，例如将编码后的数据写入到文件当中，或者从文件当中获取数据去生产python对象，这个时候就涉及到dump和load。</p><p>dump和load也是类似的功能，只是与文件操作结合起来了。在使用的时候，要多加一个文件对象参数</p><h2 id="requests模块"><a href="#requests模块" class="headerlink" title="requests模块"></a>requests模块</h2><h3 id="实现功能及解决问题"><a href="#实现功能及解决问题" class="headerlink" title="实现功能及解决问题"></a>实现功能及解决问题</h3><p>request为python的内置模块，实现功能：</p><ul><li>发送HTTP请求（get、post、delete等等）</li><li>获取一个返回对象，然后针对这个对象做一系列的操作，例如获取参数及数据等</li></ul><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><p>语法部分也就是使用这个语法的逻辑思路和规则</p><p>我们先看一个案例：</p><p>一开始要导入 Requests 模块：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import requests</span><br></pre></td></tr></table></figure><p>然后，尝试获取某个网页。本例子中，我们来获取 Github 的公共时间线：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;)</span><br></pre></td></tr></table></figure><p>现在，我们有一个名为 <code>r</code> 的 <a href="http://docs.python-requests.org/zh_CN/latest/api.html#requests.Response" target="_blank" rel="noopener"><code>Response</code></a> 对象。我们可以从这个对象中获取所有我们想要的信息。</p><p>Requests 简便的 API 意味着所有 HTTP 请求类型都是显而易见的。例如，你可以这样发送一个 HTTP POST 请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.post(&apos;http://httpbin.org/post&apos;, data = &#123;&apos;key&apos;:&apos;value&apos;&#125;)</span><br></pre></td></tr></table></figure><p>那么其他 HTTP 请求类型：PUT，DELETE，HEAD 以及 OPTIONS 又是如何的呢？都是一样的简单：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.put(&apos;http://httpbin.org/put&apos;, data = &#123;&apos;key&apos;:&apos;value&apos;&#125;)</span><br><span class="line">&gt;&gt;&gt; r = requests.delete(&apos;http://httpbin.org/delete&apos;)</span><br><span class="line">&gt;&gt;&gt; r = requests.head(&apos;http://httpbin.org/get&apos;)</span><br><span class="line">&gt;&gt;&gt; r = requests.options(&apos;http://httpbin.org/get&apos;)</span><br></pre></td></tr></table></figure><h3 id="传递URL参数"><a href="#传递URL参数" class="headerlink" title="传递URL参数"></a>传递URL参数</h3><p>你也许经常想为 URL 的查询字符串(query string)传递某种数据。如果你是手工构建 URL，那么数据会以键/值对的形式置于 URL 中，跟在一个问号的后面。例如， <code>httpbin.org/get?key=val</code>。 Requests 允许你使用 <code>params</code> 关键字参数，以一个字符串字典来提供这些参数。举例来说，如果你想传递 <code>key1=value1</code> 和 <code>key2=value2</code> 到 <code>httpbin.org/get</code> ，那么你可以使用如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; payload = &#123;&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;&#125;</span><br><span class="line">&gt;&gt;&gt; r = requests.get(&quot;http://httpbin.org/get&quot;, params=payload)</span><br></pre></td></tr></table></figure><p>通过打印输出该 URL，你能看到 URL 已被正确编码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; print(r.url)</span><br><span class="line">http://httpbin.org/get?key2=value2&amp;key1=value1</span><br></pre></td></tr></table></figure><p>注意字典里值为 <code>None</code> 的键都不会被添加到 URL 的查询字符串里。</p><p>你还可以将一个列表作为值传入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; payload = &#123;&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: [&apos;value2&apos;, &apos;value3&apos;]&#125;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; r = requests.get(&apos;http://httpbin.org/get&apos;, params=payload)</span><br><span class="line">&gt;&gt;&gt; print(r.url)</span><br><span class="line">http://httpbin.org/get?key1=value1&amp;key2=value2&amp;key2=value3</span><br></pre></td></tr></table></figure><h3 id="响应内容"><a href="#响应内容" class="headerlink" title="响应内容"></a>响应内容</h3><p>我们能读取服务器响应的内容。再次以 GitHub 时间线为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import requests</span><br><span class="line">&gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;)</span><br><span class="line">&gt;&gt;&gt; r.text</span><br><span class="line">u&apos;[&#123;&quot;repository&quot;:&#123;&quot;open_issues&quot;:0,&quot;url&quot;:&quot;https://github.com/...</span><br></pre></td></tr></table></figure><p>Requests 会自动解码来自服务器的内容。大多数 unicode 字符集都能被无缝地解码。</p><p>请求发出后，Requests 会基于 HTTP 头部对响应的编码作出有根据的推测。当你访问 <code>r.text</code> 之时，Requests 会使用其推测的文本编码。你可以找出 Requests 使用了什么编码，并且能够使用<code>r.encoding</code> 属性来改变它：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r.encoding</span><br><span class="line">&apos;utf-8&apos;</span><br><span class="line">&gt;&gt;&gt; r.encoding = &apos;ISO-8859-1&apos;</span><br></pre></td></tr></table></figure><p>如果你改变了编码，每当你访问 <code>r.text</code> ，Request 都将会使用 <code>r.encoding</code> 的新值。你可能希望在使用特殊逻辑计算出文本的编码的情况下来修改编码。比如 HTTP 和 XML 自身可以指定编码。这样的话，你应该使用 <code>r.content</code> 来找到编码，然后设置 <code>r.encoding</code> 为相应的编码。这样就能使用正确的编码解析 <code>r.text</code> 了。</p><p>在你需要的情况下，Requests 也可以使用定制的编码。如果你创建了自己的编码，并使用 <code>codecs</code>模块进行注册，你就可以轻松地使用这个解码器名称作为 <code>r.encoding</code> 的值， 然后由 Requests 来为你处理编码。</p><h3 id="二进制响应内容"><a href="#二进制响应内容" class="headerlink" title="二进制响应内容"></a>二进制响应内容</h3><p>你也能以字节的方式访问请求响应体，对于非文本请求：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r.content</span><br><span class="line">b&apos;[&#123;&quot;repository&quot;:&#123;&quot;open_issues&quot;:0,&quot;url&quot;:&quot;https://github.com/...</span><br></pre></td></tr></table></figure><p>Requests 会自动为你解码 <code>gzip</code> 和 <code>deflate</code> 传输编码的响应数据。</p><p>例如，以请求返回的二进制数据创建一张图片，你可以使用如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; from PIL import Image</span><br><span class="line">&gt;&gt;&gt; from io import BytesIO</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; i = Image.open(BytesIO(r.content))</span><br></pre></td></tr></table></figure><h3 id="JSON-响应内容"><a href="#JSON-响应内容" class="headerlink" title="JSON 响应内容"></a>JSON 响应内容</h3><p>Requests 中也有一个内置的 JSON 解码器，助你处理 JSON 数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import requests</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;)</span><br><span class="line">&gt;&gt;&gt; r.json()</span><br><span class="line">[&#123;u&apos;repository&apos;: &#123;u&apos;open_issues&apos;: 0, u&apos;url&apos;: &apos;https://github.com/...</span><br></pre></td></tr></table></figure><p>如果 JSON 解码失败， <code>r.json()</code> 就会抛出一个异常。例如，响应内容是 401 (Unauthorized)，尝试访问 <code>r.json()</code> 将会抛出 <code>ValueError: No JSON object could be decoded</code> 异常。</p><p>需要注意的是，成功调用 <code>r.json()</code> 并<strong>不</strong>意味着响应的成功。有的服务器会在失败的响应中包含一个 JSON 对象（比如 HTTP 500 的错误细节）。这种 JSON 会被解码返回。要检查请求是否成功，请使用 <code>r.raise_for_status()</code> 或者检查 <code>r.status_code</code> 是否和你的期望相同。</p><h3 id="原始响应内容"><a href="#原始响应内容" class="headerlink" title="原始响应内容"></a>原始响应内容</h3><p>在罕见的情况下，你可能想获取来自服务器的原始套接字响应，那么你可以访问 <code>r.raw</code>。 如果你确实想这么干，那请你确保在初始请求中设置了 <code>stream=True</code>。具体你可以这么做：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; r = requests.get(&apos;https://api.github.com/events&apos;, stream=True)</span><br><span class="line">&gt;&gt;&gt; r.raw</span><br><span class="line">&lt;requests.packages.urllib3.response.HTTPResponse object at 0x101194810&gt;</span><br><span class="line">&gt;&gt;&gt; r.raw.read(10)</span><br><span class="line">&apos;\x1f\x8b\x08\x00\x00\x00\x00\x00\x00\x03&apos;</span><br></pre></td></tr></table></figure><p>但一般情况下，你应该以下面的模式将文本流保存到文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">with open(filename, &apos;wb&apos;) as fd:</span><br><span class="line">    for chunk in r.iter_content(chunk_size):</span><br><span class="line">        fd.write(chunk)</span><br></pre></td></tr></table></figure><p>使用 <code>Response.iter_content</code> 将会处理大量你直接使用 <code>Response.raw</code> 不得不处理的。 当流下载时，上面是优先推荐的获取内容方式。 Note that <code>chunk_size</code> can be freely adjusted to a number that may better fit your use cases.</p><h3 id="定制请求头"><a href="#定制请求头" class="headerlink" title="定制请求头"></a>定制请求头</h3><p>如果你想为请求添加 HTTP 头部，只要简单地传递一个 <code>dict</code> 给 <code>headers</code> 参数就可以了。</p><p>例如，在前一个示例中我们没有指定 content-type:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; url = &apos;https://api.github.com/some/endpoint&apos;</span><br><span class="line">&gt;&gt;&gt; headers = &#123;&apos;user-agent&apos;: &apos;my-app/0.0.1&apos;&#125;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; r = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure><p>注意: 定制 header 的优先级低于某些特定的信息源，例如：</p><ul><li>如果在 <code>.netrc</code> 中设置了用户认证信息，使用 headers= 设置的授权就不会生效。而如果设置了 <code>auth=</code> 参数，<code>.netrc</code> 的设置就无效了。</li><li>如果被重定向到别的主机，授权 header 就会被删除。</li><li>代理授权 header 会被 URL 中提供的代理身份覆盖掉。</li><li>在我们能判断内容长度的情况下，header 的 Content-Length 会被改写。</li></ul><p>更进一步讲，Requests 不会基于定制 header 的具体情况改变自己的行为。只不过在最后的请求中，所有的 header 信息都会被传递进去。</p><p>注意: 所有的 header 值必须是 <code>string</code>、bytestring 或者 unicode。尽管传递 unicode header 也是允许的，但不建议这样做。</p><h3 id="更加复杂的-POST-请求"><a href="#更加复杂的-POST-请求" class="headerlink" title="更加复杂的 POST 请求"></a>更加复杂的 POST 请求</h3><p>通常，你想要发送一些编码为表单形式的数据——非常像一个 HTML 表单。要实现这个，只需简单地传递一个字典给 data 参数。你的数据字典在发出请求时会自动编码为表单形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; payload = &#123;&apos;key1&apos;: &apos;value1&apos;, &apos;key2&apos;: &apos;value2&apos;&#125;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; r = requests.post(&quot;http://httpbin.org/post&quot;, data=payload)</span><br><span class="line">&gt;&gt;&gt; print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  &quot;form&quot;: &#123;</span><br><span class="line">    &quot;key2&quot;: &quot;value2&quot;,</span><br><span class="line">    &quot;key1&quot;: &quot;value1&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你还可以为 <code>data</code> 参数传入一个元组列表。在表单中多个元素使用同一 key 的时候，这种方式尤其有效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; payload = ((&apos;key1&apos;, &apos;value1&apos;), (&apos;key1&apos;, &apos;value2&apos;))</span><br><span class="line">&gt;&gt;&gt; r = requests.post(&apos;http://httpbin.org/post&apos;, data=payload)</span><br><span class="line">&gt;&gt;&gt; print(r.text)</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  &quot;form&quot;: &#123;</span><br><span class="line">    &quot;key1&quot;: [</span><br><span class="line">      &quot;value1&quot;,</span><br><span class="line">      &quot;value2&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很多时候你想要发送的数据并非编码为表单形式的。如果你传递一个 <code>string</code> 而不是一个 <code>dict</code>，那么数据会被直接发布出去。</p><p>例如，Github API v3 接受编码为 JSON 的 POST/PATCH 数据：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import json</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; url = &apos;https://api.github.com/some/endpoint&apos;</span><br><span class="line">&gt;&gt;&gt; payload = &#123;&apos;some&apos;: &apos;data&apos;&#125;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; r = requests.post(url, data=json.dumps(payload))</span><br></pre></td></tr></table></figure><p>此处除了可以自行对 <code>dict</code> 进行编码，你还可以使用 <code>json</code> 参数直接传递，然后它就会被自动编码。这是 2.4.2 版的新加功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; url = &apos;https://api.github.com/some/endpoint&apos;</span><br><span class="line">&gt;&gt;&gt; payload = &#123;&apos;some&apos;: &apos;data&apos;&#125;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; r = requests.post(url, json=payload)</span><br></pre></td></tr></table></figure><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>在request中向服务端传入参数及数据时，数据主体部分的数据类型根据服务端的要求进行转化，如果服务端接收字典，那么直接传输字典即可，如果是为json，那么使用json.dumps(data)进行转化。将字典进行转换成为json字符串的形式。由于发送json格式数据太常见了，所以在Requests模块的高版本中，又加入了json这个关键字参数，可以直接发送json数据给post请求而不用再使用json模块了，直接使用json=upload_data_dict，它会自动转换</li><li>在向服务端传输参数及数据时，get等请求的参数关键字是params；POST的关键字是data</li></ul><h2 id="time模块"><a href="#time模块" class="headerlink" title="time模块"></a>time模块</h2><p>在平常的代码中，我们常常需要与时间打交道。在Python中，与时间处理有关的模块包括：time，datetime以及calendar。</p><p>在开始之前，首先要说明这几点：</p><ol><li><p>在Python中，通常有这几种方式来表示时间：</p><p>1）时间戳 </p><p>2）格式化的时间字符串 </p><p>3）元组（struct_time）共九个元素。由于Python的time模块实现主要调用C库，所以各个平台可能有所不同。</p></li><li><p>UTC（Coordinated Universal Time，世界协调时）亦即格林威治天文时间，世界标准时间。在中国为UTC+8。DST（Daylight Saving Time）即夏令时。</p></li><li><p>时间戳（timestamp）的方式：通常来说，时间戳表示的是从<strong>1970年1月1日00:00:00</strong>开始按秒计算的偏移量。我们运行“type(time.time())”，返回的是float类型。返回时间戳方式的函数主要有time()，clock()等。</p></li><li><p>元组（struct_time）方式：struct_time元组共有9个元素，返回struct_time的函数主要有gmtime()，localtime()，strptime()。下面列出这种方式元组中的几个元素：</p></li></ol><table><thead><tr><th>索引（Index）</th><th>属性（Attribute）</th><th>值（Values）</th></tr></thead><tbody><tr><td>0</td><td>tm_year（年）</td><td>比如2011</td></tr><tr><td>1</td><td>tm_mon（月）</td><td>1 - 12</td></tr><tr><td>2</td><td>tm_mday（日）</td><td>1 - 31</td></tr><tr><td>3</td><td>tm_hour（时）</td><td>0 - 23</td></tr><tr><td>4</td><td>tm_min（分）</td><td>0 - 59</td></tr><tr><td>5</td><td>tm_sec（秒）</td><td>0 - 61</td></tr><tr><td>6</td><td>tm_wday（weekday）</td><td>0 - 6（0表示周日）</td></tr><tr><td>7</td><td>tm_yday（一年中的第几天）</td><td>1 - 366</td></tr><tr><td>8</td><td>tm_isdst（是否是夏令时）</td><td>默认为-1</td></tr></tbody></table><h3 id="获取当前时间戳"><a href="#获取当前时间戳" class="headerlink" title="获取当前时间戳"></a>获取当前时间戳</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print (time.time())</span><br><span class="line">输出如下：</span><br><span class="line">1531317129.0039742</span><br></pre></td></tr></table></figure><h3 id="时间元祖"><a href="#时间元祖" class="headerlink" title="时间元祖"></a>时间元祖</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print (time.localtime())</span><br><span class="line">输出如下：</span><br><span class="line">time.struct_time(tm_year=2018, tm_mon=7, tm_mday=11, tm_hour=22, tm_min=4, tm_sec=18, tm_wday=2, tm_yday=192, tm_isdst=0)</span><br></pre></td></tr></table></figure><h3 id="格式化时间"><a href="#格式化时间" class="headerlink" title="格式化时间"></a>格式化时间</h3><p>最简单的获取可读模式的方法是asctime()</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print (time.asctime())</span><br><span class="line">输出如下：</span><br><span class="line">Wed Jul 11 21:52:09 2018</span><br></pre></td></tr></table></figure><p><strong>使用指定的格式输出</strong>，使用strftime方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print (time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;,time.localtime()))</span><br><span class="line">输入如下：</span><br><span class="line">2018-07-11 22:02:27</span><br></pre></td></tr></table></figure><h3 id="python中时间日期格式化符号"><a href="#python中时间日期格式化符号" class="headerlink" title="python中时间日期格式化符号"></a>python中时间日期格式化符号</h3><ul><li>%y 两位数的年份表示（00-99）</li><li>%Y 四位数的年份表示（000-9999）</li><li>%m 月份（01-12）</li><li>%d 月内中的一天（0-31）</li><li>%H 24小时制小时数（0-23）</li><li>%I 12小时制小时数（01-12）</li><li>%M 分钟数（00=59）</li><li>%S 秒（00-59）</li><li>%a 本地简化星期名称</li><li>%A 本地完整星期名称</li><li>%b 本地简化的月份名称</li><li>%B 本地完整的月份名称</li><li>%c 本地相应的日期表示和时间表示</li><li>%j 年内的一天（001-366）</li><li>%p 本地A.M.或P.M.的等价符</li><li>%U 一年中的星期数（00-53）星期天为星期的开始</li><li>%w 星期（0-6），星期天为星期的开始</li><li>%W 一年中的星期数（00-53）星期一为星期的开始</li><li>%x 本地相应的日期表示</li><li>%X 本地相应的时间表示</li><li>%Z 当前时区的名称</li><li>%% %号本身</li></ul><h3 id="sleep"><a href="#sleep" class="headerlink" title="sleep"></a>sleep</h3><p>Python time sleep() 方法推迟调用线程的运行，可通过参数secs指秒数，表示进程挂起的时间。 </p><p>语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">time.sleep(t)</span><br></pre></td></tr></table></figure><h2 id="commands模块-3-x已废弃"><a href="#commands模块-3-x已废弃" class="headerlink" title="commands模块-3.x已废弃"></a>commands模块-3.x已废弃</h2><p>用Python写运维脚本时，经常需要执行linux shell的命令，Python中的commands模块专门用于调用Linux shell命令，并返回状态和结果。</p><p>下面是commands模块的几个主要方法： </p><h3 id="commands-getoutput-‘shell-command’"><a href="#commands-getoutput-‘shell-command’" class="headerlink" title="commands.getoutput(‘shell command’)"></a>commands.getoutput(‘shell command’)</h3><p>执行shell命令，返回结果（string类型）</p><p>案例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">输出指定进程的pid</span><br><span class="line"></span><br><span class="line">wxh@wxh-virtual-machine:~/python_files$ cat tt.py</span><br><span class="line">#!/usr/bin/env python2</span><br><span class="line">import sys,commands</span><br><span class="line">cmdline = sys.argv[1]</span><br><span class="line">cmdline1 = sys.argv[2]</span><br><span class="line"></span><br><span class="line">cmd = &quot;ps -ef|grep &quot; + cmdline + &quot;|grep &quot; + cmdline1 + &quot;|grep -v grep|grep -v python|awk &apos;&#123;print $2&#125;&apos;&quot;</span><br><span class="line"></span><br><span class="line">c1 = commands.getoutput(cmd)</span><br><span class="line">print (c1)</span><br><span class="line">print (type(c1))</span><br></pre></td></tr></table></figure><p>执行后输出如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wxh@wxh-virtual-machine:~/python_files$ python2 ./tt.py unity-panel-service lockscreen-mode</span><br><span class="line"></span><br><span class="line">126263</span><br><span class="line">&lt;type &apos;str&apos;&gt;</span><br></pre></td></tr></table></figure><h3 id="commands-getstatusoutput-‘shell-command’"><a href="#commands-getstatusoutput-‘shell-command’" class="headerlink" title="commands.getstatusoutput(‘shell command’)"></a>commands.getstatusoutput(‘shell command’)</h3><p>执行shell命令, 返回两个元素的元组tuple(status, result)，status为int类型，result为string类型。</p><p>因为cmd的执行方式是{ cmd ; } 2&gt;&amp;1, 故返回结果包含标准输出和标准错误.</p><ul><li>第一个值为命令执行的返回状态码，执行成功则返回的是0，不成功则返回的是非0</li></ul><p>案例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">wxh@wxh-virtual-machine:~/python_files$ cat tt.py </span><br><span class="line">#!/usr/bin/env python2</span><br><span class="line">import sys,commands</span><br><span class="line">cmdline = sys.argv[1]</span><br><span class="line">cmdline1 = sys.argv[2]</span><br><span class="line"></span><br><span class="line">cmd = &quot;ps -ef|grep &quot; + cmdline + &quot;|grep &quot; + cmdline1 + &quot;|grep -v grep|grep -v python|awk &apos;&#123;print $2&#125;&apos;&quot;</span><br><span class="line">res = commands.getstatusoutput(cmd)</span><br><span class="line">print (res)</span><br></pre></td></tr></table></figure><p>执行后输出如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wxh@wxh-virtual-machine:~/python_files$ python2 ./tt.py unity-panel-service lockscreen-mode</span><br><span class="line">(0, &apos;126263&apos;)</span><br></pre></td></tr></table></figure><h2 id="subprocess模块"><a href="#subprocess模块" class="headerlink" title="subprocess模块"></a>subprocess模块</h2><p>从Python 2.4开始，Python引入subprocess模块来管理子进程，以取代一些旧模块的方法：如 os.system、<code>os.spawn*</code>、<code>os.popen*</code>、<code>popen2.*</code>、<code>commands.*</code>等不但可以调用外部的命令作为子进程，而且可以连接到子进程的input/output/error管道，获取相关的返回信息。</p><p>运行python的时候，我们都是在创建并运行一个进程。像Linux进程那样，一个进程可以fork一个子进程，并让这个子进程exec另外一个程序。在Python中，我们通过标准库中的subprocess包来fork一个子进程，并运行一个外部的程序。</p><p>subprocess包中定义有<strong>数个创建子进程的函数</strong>，这些函数分别以不同的方式创建子进程，所以我们可以根据需要来从中选取一个使用。另外subprocess还提供了一些管理标准流(standard stream)和管道(pipe)的工具，从而在进程间使用文本通信。</p><h3 id="shell命令格式"><a href="#shell命令格式" class="headerlink" title="shell命令格式"></a>shell命令格式</h3><p>默认情况下，我们传入的参数（一般是shell命令）是需要使用列表的方式，以空格分开的每一个单独的命令或者参数，是列表的每一个元素</p><p>因为subprocess模块中的各个类和函数的shell参数默认为False，在Linux下，shell=False时, Popen调用os.execvp()执行args指定的程序；</p><p>shell=True时，如果args是字符串，Popen直接调用系统的Shell来执行args指定的程序，如果args是一个序列，则args的第一项是定义程序命令字符串，其它项是调用系统Shell时的附加参数。</p><h3 id="call-check-call-和check-output-函数"><a href="#call-check-call-和check-output-函数" class="headerlink" title="call(),check_call()和check_output()函数"></a>call(),check_call()和check_output()函数</h3><p><strong>subprocess.call()</strong></p><p>父进程等待子进程完成</p><p>返回退出信息(returncode，相当于Linux exit code)</p><p><strong>subprocess.check_call()</strong></p><p>父进程等待子进程完成</p><p>返回0</p><p>检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性，可用try…except…来检查</p><p><strong>subprocess.check_output()</strong></p><p>父进程等待子进程完成</p><p>返回子进程向标准输出的输出结果</p><p>检查退出信息，如果returncode不为0，则举出错误subprocess.CalledProcessError，该对象包含有returncode属性和output属性，output属性为标准输出的输出结果，可用try…except…来检查。</p><p>这三个函数的使用方法相类似，下面来举例说明:</p><ul><li>call()函数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">p = subprocess.call(&apos;pdd&apos;,shell=True)</span><br><span class="line">print (p)</span><br><span class="line"></span><br><span class="line">执行后输出如下：</span><br><span class="line">127</span><br></pre></td></tr></table></figure><ul><li>check_call函数</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">p = subprocess.check_call(&apos;pdd&apos;,shell=True)</span><br><span class="line">print (p)</span><br><span class="line"></span><br><span class="line">执行后输出如下：</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 31, in &lt;module&gt;</span><br><span class="line">    p = subprocess.check_call(&apos;pdd&apos;,shell=True)</span><br><span class="line">  File &quot;/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py&quot;, line 328, in check_call</span><br><span class="line">    raise CalledProcessError(retcode, cmd)</span><br><span class="line">subprocess.CalledProcessError: Command &apos;pdd&apos; returned non-zero exit status 127.</span><br></pre></td></tr></table></figure><ul><li>check_output()</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">p = subprocess.check_output(&apos;pdd&apos;,shell=True)</span><br><span class="line">print (p)</span><br><span class="line"></span><br><span class="line">执行后输出如下：</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 31, in &lt;module&gt;</span><br><span class="line">    p = subprocess.check_output(&apos;pdd&apos;,shell=True)</span><br><span class="line">  File &quot;/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py&quot;, line 376, in check_output</span><br><span class="line">    **kwargs).stdout</span><br><span class="line">  File &quot;/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py&quot;, line 468, in run</span><br><span class="line">    output=stdout, stderr=stderr)</span><br><span class="line">subprocess.CalledProcessError: Command &apos;pdd&apos; returned non-zero exit status 127.</span><br></pre></td></tr></table></figure><h3 id="subprocess-Popen类"><a href="#subprocess-Popen类" class="headerlink" title="subprocess.Popen类"></a>subprocess.Popen类</h3><p>上面的几个函数都是基于Popen()的封装(wrapper)。这些封装的目的在于让我们容易使用子进程，也就是说，我们不需要关心父子进程通信和回收等问题。当我们想要更个性化我们的需求的时候，就要转向Popen类，该类生成的对象用来代表子进程。</p><p>与上面的封装不同，Popen对象创建后，主程序不会自动等待子进程完成。我们必须调用对象的wait()方法，父进程才会等待 (也就是阻塞block)，举例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">child = subprocess.Popen(&quot;ping -c4 www.baidu.com&quot;,shell=True)</span><br><span class="line"># child.wait()</span><br><span class="line">print (111)</span><br></pre></td></tr></table></figure><p>添加注释和不添加的2次结果分别为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">111</span><br><span class="line"></span><br><span class="line">和</span><br><span class="line"></span><br><span class="line">PING www.baidu.com (115.239.211.112): 56 data bytes</span><br><span class="line">64 bytes from 115.239.211.112: icmp_seq=0 ttl=54 time=49.593 ms</span><br><span class="line">64 bytes from 115.239.211.112: icmp_seq=1 ttl=54 time=20.527 ms</span><br><span class="line">64 bytes from 115.239.211.112: icmp_seq=2 ttl=54 time=30.277 ms</span><br><span class="line">64 bytes from 115.239.211.112: icmp_seq=3 ttl=54 time=12.728 ms</span><br><span class="line"></span><br><span class="line">--- www.baidu.com ping statistics ---</span><br><span class="line">4 packets transmitted, 4 packets received, 0.0% packet loss</span><br><span class="line">round-trip min/avg/max/stddev = 12.728/28.281/49.593/13.786 ms</span><br><span class="line">111</span><br></pre></td></tr></table></figure><p>一些方法和属性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">child.wait()   # 等待子进程执行完毕</span><br><span class="line">child.poll()           # 检查子进程状态</span><br><span class="line">child.kill()           # 终止子进程</span><br><span class="line">child.send_signal()    # 向子进程发送信号</span><br><span class="line">child.terminate()      # 终止子进程</span><br><span class="line">child.pid      # 子进程的pid</span><br></pre></td></tr></table></figure><h3 id="子进程的文本流控制"><a href="#子进程的文本流控制" class="headerlink" title="子进程的文本流控制"></a>子进程的文本流控制</h3><p>子进程的标准输入、标准输出和标准错误如下属性分别表示:</p><ol><li>child.stdin</li><li>child.stdout</li><li>child.stderr</li></ol><p>在pycharm中可以看到</p><p><img src="http://picture.watchmen.xin/python/python_modules/subprocess/std.png" alt="std"></p><p>可以在Popen()建立子进程的时候改变标准输入、标准输出和标准错误，并可以利用<strong>subprocess.PIPE</strong>将多个子进程的输入和输出连接在一起，构成管道(pipe)，如下2个例子：</p><p>案例1：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import subprocess</span><br><span class="line">child1 = subprocess.Popen([&quot;ls&quot;,&quot;-l&quot;], stdout=subprocess.PIPE)</span><br><span class="line">print (child1.stdout.read())</span><br><span class="line">#或者child1.communicate()</span><br><span class="line"></span><br><span class="line">执行后输出如下：</span><br><span class="line">b&apos;total 16\ndrwxr-xr-x  3 wangxiaohua  staff    96 12 10 16:35 __pycache__\n-rw-r--r--  1 wangxiaohua  staff   185 12 10 16:33 custom_except.py\n-rw-r--r--  1 wangxiaohua  staff  1028  1  5 17:54 test.py\n&apos;</span><br><span class="line">可以看到，输出的是byte类型</span><br></pre></td></tr></table></figure><p>案例2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import subprocess</span><br><span class="line">child1 = subprocess.Popen([&quot;cat&quot;,&quot;/etc/passwd&quot;], stdout=subprocess.PIPE)</span><br><span class="line">child2 = subprocess.Popen([&quot;grep&quot;,&quot;0:0&quot;],stdin=child1.stdout, stdout=subprocess.PIPE)</span><br><span class="line">out = child2.communicate()</span><br><span class="line"></span><br><span class="line">注意:</span><br><span class="line">最终的输出是从child2中获取的。</span><br><span class="line">默认的输出是byte类型，如果要转换成为字符串类型，使用下面这种方式实现。</span><br><span class="line">out_str = str(out[0],encoding=&quot;utf-8&quot;)</span><br></pre></td></tr></table></figure><p>subprocess.PIPE实际上为文本流提供一个缓存区。child1的stdout将文本输出到缓存区，随后child2的stdin从该PIPE中将文本读取走。child2的输出文本也被存放在PIPE中，直到communicate()方法从PIPE中读取出PIPE中的文本。</p><p>注意：</p><ul><li>communicate()是Popen对象的一个方法，该方法会阻塞父进程，直到子进程完成。</li><li>communicate()函数返回一个<code>tuple</code>(标准输出和错误)。所以当你只是标准输出的时候就需要使用[0]获取</li></ul><h3 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h3><h4 id="检测linux进程的状态"><a href="#检测linux进程的状态" class="headerlink" title="检测linux进程的状态"></a>检测linux进程的状态</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def redis_status(new_port):</span><br><span class="line">    p = subprocess.Popen([&quot;netstat&quot;, &quot;-unptl&quot;], stdout=subprocess.PIPE)</span><br><span class="line">    out, err = p.communicate()</span><br><span class="line">    if (new_port in str(out) ):</span><br><span class="line">        print (&quot;redis &#123;PORT&#125; instance is running...&quot;.format(PORT=new_port))</span><br><span class="line">    else:</span><br><span class="line">        print (&quot;start redis &#123;PORT&#125; faild.please check again...&quot;.format(PORT=new_port))</span><br></pre></td></tr></table></figure><h2 id="os模块"><a href="#os模块" class="headerlink" title="os模块"></a>os模块</h2><h1 id="python文件处理"><a href="#python文件处理" class="headerlink" title="python文件处理"></a>python文件处理</h1><p>Python open() 方法用于打开一个文件，并返回文件对象，在对文件进行处理过程都需要使用到这个函数，如果该文件无法被打开，会抛出 OSError。</p><p><strong>注意：</strong></p><p>使用 open() 方法一定要保证关闭文件对象，即调用 close() 方法。</p><p>open() 函数常用形式是接收两个参数：文件名(file)和模式(mode)。</p><h2 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h2><p><strong>open()</strong></p><p>Python open() 方法用于打开一个文件，并返回文件对象，在对文件进行处理过程都需要使用到这个函数，如果该文件无法被打开，会抛出 OSError。</p><p><strong>注意：</strong></p><p>使用 open() 方法一定要保证关闭文件对象，即调用 close() 方法。</p><p>open() 函数常用形式是接收两个参数：文件名(file)和模式(mode)。</p><p>语法格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open(file, mode=&apos;r&apos;)</span><br></pre></td></tr></table></figure><p>完整的语法格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open(file, mode=&apos;r&apos;, buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)</span><br></pre></td></tr></table></figure><p>参数说明:</p><ul><li>file: 必需，文件路径（相对或者绝对路径）。</li><li>mode: 可选，文件打开模式</li><li>buffering: 设置缓冲</li><li>encoding: 一般使用utf8</li><li>errors: 报错级别</li><li>newline: 区分换行符</li><li>closefd: 传入的file参数类型</li><li>opener:</li></ul><p>mode模式一共有一下几种：</p><table><thead><tr><th>模式</th><th>描述</th></tr></thead><tbody><tr><td>t</td><td>文本模式 (默认)。</td></tr><tr><td>x</td><td>写模式，新建一个文件，如果该文件已存在则会报错。</td></tr><tr><td>b</td><td>二进制模式。</td></tr><tr><td>+</td><td>打开一个文件进行更新(可读可写)。</td></tr><tr><td>U</td><td>通用换行模式（不推荐）。</td></tr><tr><td>r</td><td>以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。</td></tr><tr><td>rb</td><td>以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。</td></tr><tr><td>r+</td><td>打开一个文件用于读写。文件指针将会放在文件的开头。</td></tr><tr><td>rb+</td><td>以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。</td></tr><tr><td>w</td><td>打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。</td></tr><tr><td>wb</td><td>以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。</td></tr><tr><td>w+</td><td>打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。</td></tr><tr><td>wb+</td><td>以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。</td></tr><tr><td>a</td><td>打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</td></tr><tr><td>ab</td><td>以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</td></tr><tr><td>a+</td><td>打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。</td></tr><tr><td>ab+</td><td>以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。</td></tr></tbody></table><p>默认为文本模式，如果要以二进制模式打开，加上 b 。</p><h2 id="file-对象"><a href="#file-对象" class="headerlink" title="file 对象"></a>file 对象</h2><p>file 对象使用 open 函数来创建，下表列出了 file 对象常用的函数：</p><table><thead><tr><th>序号</th><th>方法及描述</th></tr></thead><tbody><tr><td>1</td><td><a href="http://www.runoob.com/python/file-close.html" target="_blank" rel="noopener">file.close()</a>关闭文件。关闭后文件不能再进行读写操作。</td></tr><tr><td>2</td><td><a href="http://www.runoob.com/python/file-flush.html" target="_blank" rel="noopener">file.flush()</a>刷新文件内部缓冲，直接把内部缓冲区的数据立刻写入文件, 而不是被动的等待输出缓冲区写入。</td></tr><tr><td>3</td><td><a href="http://www.runoob.com/python/file-fileno.html" target="_blank" rel="noopener">file.fileno()</a>返回一个整型的文件描述符(file descriptor FD 整型), 可以用在如os模块的read方法等一些底层操作上。</td></tr><tr><td>4</td><td><a href="http://www.runoob.com/python/file-isatty.html" target="_blank" rel="noopener">file.isatty()</a>如果文件连接到一个终端设备返回 True，否则返回 False。</td></tr><tr><td>5</td><td><a href="http://www.runoob.com/python/file-next.html" target="_blank" rel="noopener">file.next()</a>返回文件下一行。</td></tr><tr><td>6</td><td><a href="http://www.runoob.com/python/python-file-read.html" target="_blank" rel="noopener">file.read([size])</a>从文件读取指定的字节数，如果未给定或为负则读取所有。</td></tr><tr><td>7</td><td><a href="http://www.runoob.com/python/file-readline.html" target="_blank" rel="noopener">file.readline([size])</a>读取整行，包括 “\n” 字符。</td></tr><tr><td>8</td><td><a href="http://www.runoob.com/python/file-readlines.html" target="_blank" rel="noopener">file.readlines([sizeint])</a>读取所有行并返回列表，若给定sizeint&gt;0，则是设置一次读多少字节，这是为了减轻读取压力。</td></tr><tr><td>9</td><td><a href="http://www.runoob.com/python/file-seek.html" target="_blank" rel="noopener">file.seek(offset[, whence])</a>设置文件当前位置</td></tr><tr><td>10</td><td><a href="http://www.runoob.com/python/file-tell.html" target="_blank" rel="noopener">file.tell()</a>返回文件当前位置。</td></tr><tr><td>11</td><td><a href="http://www.runoob.com/python/file-truncate.html" target="_blank" rel="noopener">file.truncate([size])</a>截取文件，截取的字节通过size指定，默认为当前文件位置。</td></tr><tr><td>12</td><td><a href="http://www.runoob.com/python/python-file-write.html" target="_blank" rel="noopener">file.write(str)</a>将字符串写入文件，返回的是写入的字符长度。</td></tr><tr><td>13</td><td><a href="http://www.runoob.com/python/file-writelines.html" target="_blank" rel="noopener">file.writelines(sequence)</a>向文件写入一个序列字符串列表，如果需要换行则要自己加入每行的换行符。</td></tr></tbody></table><h2 id="关于-Buffering"><a href="#关于-Buffering" class="headerlink" title="关于 Buffering"></a>关于 Buffering</h2><p>官方解释如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The optional buffering argument specifies the file’s desired buffer size: 0 means unbuffered, 1 means line buffered, any other positive value means use a buffer of (approximately) that size. A negative buffering means to use the system default, which is usually line buffered for tty devices and fully buffered for other files. If omitted, the system default is used.</span><br></pre></td></tr></table></figure><p>缓冲的目的：是为了减少系统的io调用。只有当符合一定条件(比如缓冲数量)时才调用io。</p><p>缓冲分以下几种： </p><ul><li><p>全缓冲 : open函数的buffering设置大于1的整数n,n为缓冲区大小，linux默认为page的大小4096 满了n 个字节才会写入磁盘 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=open(“demo.txt”,’w’,buffering=10)</span><br></pre></td></tr></table></figure></li><li><p>行缓冲 : open 函数的buffering设置为1, 每写一行就会将缓冲区写入磁盘。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=open(“demo.txt”,’w’,buffering=1)</span><br></pre></td></tr></table></figure></li><li><p>无缓冲 : open 函数的buffering设置为0 有输入就写入磁盘。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=open(“demo.txt”,’w,’,buffering=0)</span><br></pre></td></tr></table></figure></li><li><p>系统缓存：open 函数的buffering设置小于0，由操作系统决定何时写入磁盘</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=open(“demo.txt”,’w,’,buffering=-1)</span><br></pre></td></tr></table></figure></li></ul><p>如果没有设置，那么默认值就是使用系统缓存</p><h1 id="python异常处理"><a href="#python异常处理" class="headerlink" title="python异常处理"></a>python异常处理</h1><p>python提供了两个非常重要的功能来<strong><code>处理python程序在运行中出现的异常和错误</code></strong>。你可以使用它们来调试python程序。</p><ul><li>异常处理</li><li>断言(Assertions)</li></ul><h2 id="方式-功能1-异常处理"><a href="#方式-功能1-异常处理" class="headerlink" title="方式/功能1-异常处理"></a>方式/功能1-异常处理</h2><h3 id="使用python自带异常进行处理"><a href="#使用python自带异常进行处理" class="headerlink" title="使用python自带异常进行处理"></a>使用python自带异常进行处理</h3><h3 id="python标准异常"><a href="#python标准异常" class="headerlink" title="python标准异常"></a>python标准异常</h3><p>我们先了解下python定义了哪些标准异常</p><table><thead><tr><th>异常名称</th><th>描述</th></tr></thead><tbody><tr><td>BaseException</td><td>所有异常的基类</td></tr><tr><td>SystemExit</td><td>解释器请求退出</td></tr><tr><td>KeyboardInterrupt</td><td>用户中断执行(通常是输入^C)</td></tr><tr><td>Exception</td><td><strong>常规错误的基类</strong></td></tr><tr><td>StopIteration</td><td>迭代器没有更多的值</td></tr><tr><td>GeneratorExit</td><td>生成器(generator)发生异常来通知退出</td></tr><tr><td>StandardError</td><td>所有的内建标准异常的基类</td></tr><tr><td>ArithmeticError</td><td>所有数值计算错误的基类</td></tr><tr><td>FloatingPointError</td><td>浮点计算错误</td></tr><tr><td>OverflowError</td><td>数值运算超出最大限制</td></tr><tr><td>ZeroDivisionError</td><td>除(或取模)零 (所有数据类型)</td></tr><tr><td>AssertionError</td><td>断言语句失败</td></tr><tr><td>AttributeError</td><td>对象没有这个属性</td></tr><tr><td>EOFError</td><td>没有内建输入,到达EOF 标记</td></tr><tr><td>EnvironmentError</td><td>操作系统错误的基类</td></tr><tr><td>IOError</td><td>输入/输出操作失败</td></tr><tr><td>OSError</td><td>操作系统错误</td></tr><tr><td>WindowsError</td><td>系统调用失败</td></tr><tr><td>ImportError</td><td>导入模块/对象失败</td></tr><tr><td>LookupError</td><td>无效数据查询的基类</td></tr><tr><td>IndexError</td><td>序列中没有此索引(index)</td></tr><tr><td>KeyError</td><td>映射中没有这个键</td></tr><tr><td>MemoryError</td><td>内存溢出错误(对于Python 解释器不是致命的)</td></tr><tr><td>NameError</td><td>未声明/初始化对象 (没有属性)</td></tr><tr><td>UnboundLocalError</td><td>访问未初始化的本地变量</td></tr><tr><td>ReferenceError</td><td>弱引用(Weak reference)试图访问已经垃圾回收了的对象</td></tr><tr><td>RuntimeError</td><td>一般的运行时错误</td></tr><tr><td>NotImplementedError</td><td>尚未实现的方法</td></tr><tr><td>SyntaxError</td><td>Python 语法错误</td></tr><tr><td>IndentationError</td><td>缩进错误</td></tr><tr><td>TabError</td><td>Tab 和空格混用</td></tr><tr><td>SystemError</td><td>一般的解释器系统错误</td></tr><tr><td>TypeError</td><td>对类型无效的操作</td></tr><tr><td>ValueError</td><td>传入无效的参数</td></tr><tr><td>UnicodeError</td><td>Unicode 相关的错误</td></tr><tr><td>UnicodeDecodeError</td><td>Unicode 解码时的错误</td></tr><tr><td>UnicodeEncodeError</td><td>Unicode 编码时错误</td></tr><tr><td>UnicodeTranslateError</td><td>Unicode 转换时错误</td></tr><tr><td>Warning</td><td>警告的基类</td></tr><tr><td>DeprecationWarning</td><td>关于被弃用的特征的警告</td></tr><tr><td>FutureWarning</td><td>关于构造将来语义会有改变的警告</td></tr><tr><td>OverflowWarning</td><td>旧的关于自动提升为长整型(long)的警告</td></tr><tr><td>PendingDeprecationWarning</td><td>关于特性将会被废弃的警告</td></tr><tr><td>RuntimeWarning</td><td>可疑的运行时行为(runtime behavior)的警告</td></tr><tr><td>SyntaxWarning</td><td>可疑的语法的警告</td></tr><tr><td>UserWarning</td><td>用户代码生成的警告</td></tr></tbody></table><h3 id="try-except-else-finally语法"><a href="#try-except-else-finally语法" class="headerlink" title="try/except/else/finally语法"></a>try/except/else/finally语法</h3><p>首先说明下语法</p><ul><li>try: 需要检测异常的代码块放在try中</li><li>except &lt;异常名称&gt;：匹配之后，指定该段中的代码。可以定义多个抓取异常的语句</li><li>except Exception：用户捕获我们没有发现的异常，这段需要放在except语句块的最后</li><li>else: 语句执行正常时执行的代码</li><li>finally：语句无论是否发生异常都将执行最后的代码</li></ul><p>实际组合：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">&lt;语句&gt;        #运行代码</span><br><span class="line">except &lt;名字1&gt;：</span><br><span class="line">&lt;语句&gt;        #如果在try部份引发了&apos;name1&apos;异常，则执行这段代码</span><br><span class="line">except &lt;名字2&gt;:</span><br><span class="line">&lt;语句&gt;        #如果在try部份引发了&apos;name2&apos;异常，则执行这段代码</span><br><span class="line">except Exception：</span><br><span class="line">&lt;语句&gt;# 匹配到未知异常时执行，也就是没有被&quot;except &lt;名字&gt;&quot;定义的异常</span><br><span class="line">else:</span><br><span class="line">&lt;语句&gt;        #如果没有异常发生执行这段代码</span><br><span class="line">finally:</span><br><span class="line">&lt;语句&gt;# 无论异常与否都执行</span><br></pre></td></tr></table></figure><p>光说没案例是理解不了的，下面我们看一个案例</p><h3 id="实际案例-1"><a href="#实际案例-1" class="headerlink" title="实际案例"></a>实际案例</h3><p>我们先看一段会导致异常的代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def test(par1,par2):</span><br><span class="line">    print (par1,par2)</span><br><span class="line"></span><br><span class="line">test(1)</span><br></pre></td></tr></table></figure><p>运行之后的结果是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/bin/python3 /Users/wangxiaohua/PycharmProjects/private_project/test/test.py</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 6, in &lt;module&gt;</span><br><span class="line">    test(1)</span><br><span class="line">TypeError: test() missing 1 required positional argument: &apos;par2&apos;</span><br><span class="line"></span><br><span class="line">Process finished with exit code 1</span><br></pre></td></tr></table></figure><p>可以很明显的看到，因为我们少输入的一个参数，这里产生了TypeError这个异常，并且还给出了异常的相关信息</p><p><strong>—— 分割线 ——</strong></p><p>接下来我们对这段代码进行一下改造，添加上异常处理功能</p><p>修改之后的代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def test(par1,par2):</span><br><span class="line">    print (par1,par2)</span><br><span class="line">try:</span><br><span class="line">    test(1)</span><br><span class="line">except TypeError as e:</span><br><span class="line">    print (&quot;位置参数错误，详细信息为：&quot;,e)</span><br><span class="line">except Exception as e:</span><br><span class="line">    print (&quot;未知错误：&quot;,e)</span><br><span class="line">else:</span><br><span class="line">    print (&quot;执行正常时输出这段话&quot;)</span><br><span class="line">finally:</span><br><span class="line">    print (&quot;不管成功与否，都会执行的代码段，可以不定义&quot;)</span><br></pre></td></tr></table></figure><p>我们开始运行程序</p><ul><li><p>第一次（错误案例，调用方式为：test(1)），结果如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/bin/python3 /Users/wangxiaohua/PycharmProjects/private_project/test/test.py</span><br><span class="line">位置参数错误，详细信息为： test() missing 1 required positional argument: &apos;par2&apos;</span><br><span class="line">不管成功与否，都会执行的代码段，可以不定义</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></li><li><p>第二次（成功案例，调用方式为：test(1,2)），结果如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/bin/python3 /Users/wangxiaohua/PycharmProjects/private_project/test/test.py</span><br><span class="line">1 2</span><br><span class="line">执行正常时输出这段话</span><br><span class="line">不管成功与否，都会执行的代码段，可以不定义</span><br><span class="line"></span><br><span class="line">Process finished with exit code 0</span><br></pre></td></tr></table></figure></li></ul><p><strong>注意：</strong></p><ul><li>如果代码本身有错误，都没办法执行的话，是抓不到错误异常的，因为上面抓取错误异常指的是在代码执行时出现的异常</li></ul><h3 id="工作流"><a href="#工作流" class="headerlink" title="工作流"></a><strong>工作流</strong></h3><p>try的工作原理是，当开始一个try语句后，python就在当前程序的上下文中作标记，这样当异常出现时就可以回到这里，try子句先执行，接下来会发生什么依赖于执行时是否出现异常。</p><ul><li>如果当try后的语句执行时发生异常，python就<strong><code>跳回到try</code></strong>并执行<strong>第一个</strong>匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。</li><li>如果在try后的语句里发生了异常，却没有匹配的except子句，异常将被递交到上层的try，或者到程序的最上层（这样将结束程序，并打印缺省的出错信息）。</li><li>如果在try子句执行时没有发生异常，python将执行else语句后的语句（如果有else的话），然后控制流通过整个try语句。</li></ul><h2 id="自定义触发异常"><a href="#自定义触发异常" class="headerlink" title="自定义触发异常"></a>自定义触发异常</h2><p>在我们定义一些代码逻辑的时候，可能程序并不是产生异常，但是已经不符合我们定义的逻辑，这个时候，我们需要使用raise语句来强制引发抛出异常</p><h3 id="语法-2"><a href="#语法-2" class="headerlink" title="语法"></a>语法</h3><p><strong>raise语法格式</strong>如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">raise Exception(&quot;message&quot;, args)</span><br></pre></td></tr></table></figure><p>语句中 Exception 是异常的类型（例如，NameError、IOError）参数，标准异常中任一种，args 是自已提供的参数。两个参数都可以省略</p><h3 id="实例案例"><a href="#实例案例" class="headerlink" title="实例案例"></a>实例案例</h3><p>代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def test (num):</span><br><span class="line">    if num &lt; 10:</span><br><span class="line">        raise ValueError(&quot;Invaild num:&quot;,num)</span><br><span class="line">try:</span><br><span class="line">    test(8)</span><br><span class="line">except ValueError as e:</span><br><span class="line">    print (e)</span><br><span class="line">except Exception as e:</span><br><span class="line">    print (&quot;异常错误&quot;,e)</span><br><span class="line">else:</span><br><span class="line">    print (&quot;ok&quot;)</span><br></pre></td></tr></table></figure><p>执行后输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(&apos;Invaild num:&apos;, 8)</span><br></pre></td></tr></table></figure><h3 id="自定义异常类"><a href="#自定义异常类" class="headerlink" title="自定义异常类"></a>自定义异常类</h3><p>有些时候，我们需要使用我们自己定义的异常类去做一些处理</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class wxherror(Exception):</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">def test (num):</span><br><span class="line">    if num &lt; 10:</span><br><span class="line">        raise wxherror(num)</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    test(8)</span><br><span class="line">except wxherror as e:</span><br><span class="line">    print (&quot;错误,参数为：&#123;e&#125;&quot;.format(e=e))</span><br><span class="line">except Exception as e:</span><br><span class="line">    print (&quot;异常错误&quot;,e)</span><br><span class="line">else:</span><br><span class="line">    print (&quot;ok&quot;)</span><br></pre></td></tr></table></figure><p>执行后输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">错误,参数为：8</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>通过上面的案例，我们可以总结一下使用方式</p><ul><li>和python自带的异常处理不同，在使用自定义异常的时候，我们在具体的实现代码块中就要事先定义好，当出现某种情况时，需要抛出指定的异常（需要人为定义异常的内容）</li><li>其实自带异常处理，也是在实现代码中定义了这些异常，只不过已经内部集成，不为外部所见</li><li>自己写的异常，系统不知道它的存在，也就是说系统不知道走到哪一步应该触发它，因为所有的逻辑都是我们认为的去判断的，因此自己写的异常需要我们自己去触发，否则它不会自动触发，会自动触发的异常只有标准异常</li></ul><h2 id="方式-功能2-断言-Assertions"><a href="#方式-功能2-断言-Assertions" class="headerlink" title="方式/功能2-断言(Assertions)"></a>方式/功能2-断言(Assertions)</h2><h3 id="语法-3"><a href="#语法-3" class="headerlink" title="语法"></a>语法</h3><p><strong>assert断言语句用来声明某个条件是真的，其作用是判断一个条件(condition)是否成立，如果不成立，则抛出异常。</strong></p><p>assert一般用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assert condition</span><br></pre></td></tr></table></figure><p>如果condition为false，就raise一个AssertionError出来。逻辑上等同于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if not condition:</span><br><span class="line">    raise AssertionError()</span><br></pre></td></tr></table></figure><p>另一种使用方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assert condition，expression</span><br></pre></td></tr></table></figure><p>如果condition为false，就raise一个描述为 expression 的AssertionError出来。逻辑上等同于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if not condition:</span><br><span class="line">        raise AssertionError(expression)</span><br></pre></td></tr></table></figure><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p>assert使用示例：</p><ul><li>案例1</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assert isinstance(11,str)</span><br></pre></td></tr></table></figure><p>执行后输出为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 26, in &lt;module&gt;</span><br><span class="line">    assert isinstance(11,str)</span><br><span class="line">AssertionError</span><br></pre></td></tr></table></figure><p>知道会抛出AssertionError之后，我们就可以做一些判断处理</p><ul><li>案例2</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def test (num):</span><br><span class="line">    if not (num &lt; 10):</span><br><span class="line">        raise AssertionError(&quot;&#123;num&#125; &gt;= 10&quot;.format(num=num))</span><br><span class="line"></span><br><span class="line">try:</span><br><span class="line">    test(11)</span><br><span class="line">except AssertionError as e:</span><br><span class="line">    print (&quot;输入数字错误&quot;,e)</span><br><span class="line">except Exception as e:</span><br><span class="line">    print (&quot;异常错误&quot;,e)</span><br></pre></td></tr></table></figure><p>执行后输出为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">输入数字错误 11 &gt;= 10</span><br></pre></td></tr></table></figure><ul><li>案例3</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">assert (1&gt;2),&quot;异常信息：1&gt;2&quot;</span><br></pre></td></tr></table></figure><p>执行后输出为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 18, in &lt;module&gt;</span><br><span class="line">    assert (1&gt;2),&quot;异常信息：1&gt;2&quot;</span><br><span class="line">AssertionError: 异常信息：1&gt;2</span><br></pre></td></tr></table></figure><h2 id="断言跟异常的区别"><a href="#断言跟异常的区别" class="headerlink" title="断言跟异常的区别"></a>断言跟异常的区别</h2><p>断言是用来检查非法情况而不是错误情况的，用来帮开发者快速定位问题的位置。<br>异常处理用于对程序发生异常情况的处理，增强程序的健壮性和容错性。</p><p>对一个函数而言，一般情况下，断言用于检查函数输入的合法性，要求输入满足一定的条件才能继续执行;</p><p>在函数执行过程中出现的异常情况使用异常来捕获。</p><h1 id="python日志处理"><a href="#python日志处理" class="headerlink" title="python日志处理"></a>python日志处理</h1><p><strong>参考文献</strong></p><ul><li><a href="https://www.cnblogs.com/yyds/p/6901864.html" target="_blank" rel="noopener">Python之日志处理（logging模块）</a></li><li><a href="https://docs.python.org/3/library/logging.html?highlight=logging#module-logging" target="_blank" rel="noopener">官方文档</a></li></ul><h2 id="日志相关概念"><a href="#日志相关概念" class="headerlink" title="日志相关概念"></a>日志相关概念</h2><p>日志是一种可以追踪某些软件运行时所发生事件的方法。软件开发人员可以向他们的代码中调用日志记录相关的方法来表明发生了某些事情。一个事件可以用一个可包含可选变量数据的消息来描述。此外，事件也有重要性的概念，这个重要性也可以被称为严重性级别（level）。</p><p><strong>总结重点：</strong></p><ul><li>追踪记录程序运行时发生的事件</li><li>实现：在代码中调用日志处理方法</li><li>事件有严重性级别</li></ul><h3 id="日志作用"><a href="#日志作用" class="headerlink" title="日志作用"></a>日志作用</h3><p>通过对log进行分析，可以</p><ol><li>方便用户了解系统或软件、应用的运行情况；</li><li>如果你的应用log足够丰富，也可以分析以往用户的操作行为、类型喜好、地域分布或其他更多信息；</li><li>如果一个应用的log同时也分了多个级别，那么可以很轻易地分析得到该应用的健康状况，及时发现问题并快速定位、解决问题，补救损失。</li></ol><p>简单来讲就是：我们通过记录和分析日志可以了解一个系统或软件程序运行情况是否正常，也可以在应用程序出现故障时快速定位问题。</p><p>比如，做运维的同学，在接收到报警或各种问题反馈后，进行问题排查时通常都会先去看各种日志，大部分问题都可以在日志中找到答案。</p><p>再比如，做开发的同学，可以通过IDE控制台上输出的各种日志进行程序调试。</p><p>对于运维老司机或者有经验的开发人员，可以快速的通过日志定位到问题的根源。可见，日志的重要性不可小觑。</p><p>如果应用的日志信息足够详细和丰富，还可以用来做用户行为分析，如：分析用户的操作行为、类型洗好、地域分布以及其它更多的信息，由此可以实现改进业务、提高商业利益。</p><p><strong>日志作用简单总结：</strong></p><ul><li>程序调试</li><li>了解软件程序<strong><code>运行状况</code></strong>是否正常</li><li>软件程序运行故障时<strong><code>定位问题及分析问题</code></strong></li><li>用户行为分析，并以此改进业务等</li></ul><h3 id="日志等级"><a href="#日志等级" class="headerlink" title="日志等级"></a>日志等级</h3><p>在软件开发阶段或部署开发环境时，为了尽可能详细的查看应用程序的运行状态来保证上线后的稳定性，我们需要把该应用程序所有的运行日志全部记录下来进行分析，这是非常耗费机器性能的。当应用程序在生产环境正式部署时，我们通常只记录应用程序的异常信息、错误信息等，这样既可以减小服务器的I/O压力，也可以避免我们在排查故障时被淹没在日志的海洋里。</p><p>那么，怎样才能在不改动应用程序代码的情况下实现在不同的环境记录不同详细程度的日志呢？这就是日志等级的作用了，我们通过配置文件指定我们需要的日志等级就可以了。</p><p>不同的应用程序所定义的日志等级可能会有所差别，分的详细点的会包含以下几个等级：</p><ul><li>DEBUG</li><li>INFO</li><li>NOTICE</li><li>WARNING</li><li>ERROR</li><li>CRITICAL</li><li>ALERT</li><li>EMERGENCY</li></ul><h3 id="日志字段信息与日志格式"><a href="#日志字段信息与日志格式" class="headerlink" title="日志字段信息与日志格式"></a>日志字段信息与日志格式</h3><p>一条日志信息对应的是一个<strong><code>需要关注的事件</code></strong>的发生，因此通常需要包括以下几个内容：</p><ul><li>事件的严重程度（日志级别）</li><li>事件发生时间</li><li>事件发生位置</li><li>事件内容</li></ul><p>上面这些都是一条日志记录中可能包含的字段信息，当然还可以包括一些其他信息，如进程ID、进程名称、线程ID、线程名称等。</p><p><strong>日志格式</strong>就是用来<strong>定义</strong>一条日志记录中<strong>包含哪些字段</strong>及其组合顺序及方式，且日志格式通常都是可以自定义的。</p><p><strong>注意：</strong>输出一条日志时，日志内容和日志级别是需要开发人员明确指定的。对于而其它字段信息，只需要是否显示在日志中就可以了。</p><h3 id="日志功能实现"><a href="#日志功能实现" class="headerlink" title="日志功能实现"></a>日志功能实现</h3><p>几乎所有开发语言都会内置日志相关功能，或者会有比较优秀的第三方库来提供日志操作功能，比如：log4j，log4php等。它们功能强大、使用简单。Python自身也提供了一个用于记录日志的标准库模块-logging。</p><p>我们在Python中一般使用logging模块实现日志功能，因此我们在这里说的python日志处理实际上是logging模块相关内容。</p><p>logging模块是Python的一个标准库模块，由标准库模块提供日志记录API的关键好处是所有Python模块都可以使用这个日志记录功能。所以，你的应用日志可以将你自己的日志信息与来自第三方模块的信息整合起来。</p><h2 id="logging模块"><a href="#logging模块" class="headerlink" title="logging模块"></a>logging模块</h2><p><strong>logging模块支持日志级别</strong></p><p>logging模块并不支持我们上面说的所有级别，它默认定义了以下几个日志等级</p><table><thead><tr><th>日志等级（level）</th><th>描述</th></tr></thead><tbody><tr><td>DEBUG</td><td>最详细的日志信息，典型应用场景是 问题诊断</td></tr><tr><td>INFO</td><td>信息详细程度仅次于DEBUG，通常只记录关键节点信息，用于确认一切都是按照我们预期的那样进行工作</td></tr><tr><td>WARNING</td><td>当某些不期望的事情发生时记录的信息（如，磁盘可用空间较低），但是此时应用程序还是正常运行的</td></tr><tr><td>ERROR</td><td>由于一个更严重的问题导致某些功能不能正常运行时记录的信息</td></tr><tr><td>CRITICAL</td><td>当发生严重错误，导致应用程序不能继续运行时记录的信息</td></tr></tbody></table><p>开发应用程序或部署开发环境时，可以使用DEBUG或INFO级别的日志获取尽可能详细的日志信息来进行开发或部署调试；</p><p>应用上线或部署生产环境时，应该使用WARNING或ERROR或CRITICAL级别的日志来降低机器的I/O压力和提高获取错误日志信息的效率。日志级别的指定通常都是在应用程序的配置文件中进行指定的。</p><p><strong>说明：</strong></p><ul><li>上面列表中的日志等级是从上到下依次升高的，即：DEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; CRITICAL，而日志的信息量是依次减少的；</li><li>当为某个应用程序指定一个日志级别后，应用程序会记录所有日志级别<strong><code>大于或等于</code></strong>指定日志级别的日志信息，而不是仅仅记录指定级别的日志信息，nginx、php等应用程序以及这里python的logging模块都是这样的。同样，logging模块也可以指定日志记录器的日志级别，只有级别大于或等于该指定日志级别的日志记录才会被输出，小于该等级的日志记录将会被丢弃。</li></ul><p><strong>logging模块的两种实现方式</strong></p><p>logging模块提供了两种记录日志的方式：</p><ul><li>第一种方式是使用logging提供的<strong><code>模块级别的函数</code></strong></li><li>第二种方式是使用Logging日志系统的<strong><code>四大组件</code></strong></li></ul><p><strong>logging模块定义的模块级别常用函数</strong></p><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td>logging.debug(msg, <em>args, *</em>kwargs)</td><td>创建一条严重级别为DEBUG的日志记录</td></tr><tr><td>logging.info(msg, <em>args, *</em>kwargs)</td><td>创建一条严重级别为INFO的日志记录</td></tr><tr><td>logging.warning(msg, <em>args, *</em>kwargs)</td><td>创建一条严重级别为WARNING的日志记录</td></tr><tr><td>logging.error(msg, <em>args, *</em>kwargs)</td><td>创建一条严重级别为ERROR的日志记录</td></tr><tr><td>logging.critical(msg, <em>args, *</em>kwargs)</td><td>创建一条严重级别为CRITICAL的日志记录</td></tr><tr><td>logging.log(level, <em>args, *</em>kwargs)</td><td>创建一条严重级别为level的日志记录</td></tr><tr><td>logging.basicConfig(**kwargs)</td><td>对root logger进行一次性配置</td></tr></tbody></table><p>其中<code>logging.basicConfig(**kwargs)</code>函数用于指定“要记录的日志级别”、“日志格式”、“日志输出位置”、“日志文件的打开模式”等信息，其他几个都是用于记录各个级别日志的函数。</p><p>使用这个模块提供的这些函数，不需要进行额外的相关配置（其中涉及到配置的，其实也就是一个logging.basicConfig(**kwargs)  方法）就可以使用日志功能，其实就是相当于在linux中的立即生效以及永久生效。这些函数其实底层也是调用的四大组件去实现功能，只不过使用了一些默认值。</p><p><strong>logging模块日志系统的四大组件</strong></p><table><thead><tr><th>组件</th><th>说明</th></tr></thead><tbody><tr><td>loggers</td><td>提供应用程序代码直接使用的接口，可以理解为入口，最外层的代理层</td></tr><tr><td>handlers</td><td>用于将日志记录发送到指定的目的位置进行输出</td></tr><tr><td>filters</td><td>提供更细粒度的日志过滤功能，用于决定哪些日志记录将会被输出（其它的日志记录将会被忽略）</td></tr><tr><td>formatters</td><td>用于控制日志信息的最终输出格式</td></tr></tbody></table><p><strong>说明：</strong> logging模块提供的模块级别的那些函数实际上也是通过这几个组件的相关实现类来记录日志的，只是在创建这些类的实例时设置了一些默认值。</p><h3 id="实现方式1-使用logging提供的模块级别函数记录日志"><a href="#实现方式1-使用logging提供的模块级别函数记录日志" class="headerlink" title="实现方式1-使用logging提供的模块级别函数记录日志"></a>实现方式1-使用logging提供的模块级别函数记录日志</h3><p>代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">logging.debug(&quot;debug log&quot;)</span><br><span class="line">logging.info(&quot;info log&quot;)</span><br><span class="line">logging.warning(&quot;warning log&quot;)</span><br><span class="line">logging.error(&quot;error log&quot;)</span><br><span class="line">logging.critical(&quot;critical log&quot;)</span><br></pre></td></tr></table></figure><p>执行后输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WARNING:root:warning log</span><br><span class="line">ERROR:root:error log</span><br><span class="line">CRITICAL:root:critical log</span><br></pre></td></tr></table></figure><p>这里需要注意的是：logging模块提供的<strong><code>日志记录函数</code></strong>所使用的日志器设置的日志级别是<code>WARNING</code>，因此只有<code>WARNING</code>级别的日志记录以及大于它的<code>ERROR</code>和<code>CRITICAL</code>级别的日志记录被输出了，而小于它的<code>DEBUG</code>和<code>INFO</code>级别的日志记录被丢弃了。</p><p>几个注意事项：</p><ul><li><p>默认的输出格式为：<strong><code>日志级别:日志器名称:日志内容</code></strong></p><p>之所以会这样输出，是因为logging模块提供的日志记录函数所使用的日志器设置的日志格式默认是BASIC_FORMAT，其值为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&quot;%(levelname)s:%(name)s:%(message)s&quot;</span><br></pre></td></tr></table></figure></li><li><p>日志记录函数所使用的<strong>日志器</strong>设置的<strong>处理器</strong>所指定的日志输出位置默认为:<code>sys.stderr</code></p></li><li><p>日志器（Logger）是有层级关系的，上面调用的logging模块级别的函数所使用的日志器是<code>RootLogger</code>类的实例，其名称为’root’，它是处于日志器层级关系最顶层的日志器，且该实例是以单例模式存在的。</p></li><li><p>源码实现：</p><p>查看这些日志记录函数的实现代码，可以发现：当我们没有提供任何配置信息的时候，这些函数都会去调用<code>logging.basicConfig(**kwargs)</code>方法，且不会向该方法传递任何参数。继续查看<code>basicConfig()</code>方法的代码就可以找到上面这些问题的答案了。</p></li><li><p>如何修改默认配置</p><p>在我们调用上面这些日志记录函数之前，手动调用一下basicConfig()方法，把我们想设置的内容以参数的形式传递进去就可以了</p><p>在我们需要将日志内容从控制台输出重定向到文件时需要修改配置</p></li></ul><h4 id="logging-basicConfig-函数"><a href="#logging-basicConfig-函数" class="headerlink" title="logging.basicConfig()函数"></a>logging.basicConfig()函数</h4><p>该方法用于为logging日志系统做一些基本配置，方法定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logging.basicConfig(**kwargs)</span><br></pre></td></tr></table></figure><p>该函数可接收的关键字参数如下：</p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>filename</td><td>指定日志输出目标文件的文件名，指定该设置项后日志就不会被输出到控制台了</td></tr><tr><td>filemode</td><td>指定日志文件的打开模式，默认为’a’。需要注意的是，该选项要在filename指定时才有效</td></tr><tr><td>format</td><td>指定日志格式字符串，即指定日志输出时所包含的字段信息以及它们的顺序。logging模块定义的格式字段下面会列出。</td></tr><tr><td>datefmt</td><td>指定日期/时间格式。需要注意的是，该选项要在format中包含时间字段%(asctime)s时才有效</td></tr><tr><td>level</td><td>指定日志器的日志级别</td></tr><tr><td>stream</td><td>指定日志输出目标stream，如sys.stdout、sys.stderr以及网络stream。需要说明的是，stream和filename不能同时提供，否则会引发 <code>ValueError</code>异常</td></tr><tr><td>style</td><td>Python 3.2中新添加的配置项。指定format格式字符串的风格，可取值为’%’、’{‘和’$’，默认为’%’</td></tr><tr><td>handlers</td><td>Python 3.3中新添加的配置项。该选项如果被指定，它应该是一个创建了多个Handler的可迭代对象，这些handler将会被添加到root logger。需要说明的是：filename、stream和handlers这三个配置项只能有一个存在，不能同时出现2个或3个，否则会引发ValueError异常。</td></tr></tbody></table><p>logging模块中定义好的可以用于format格式字符串中的字段：</p><table><thead><tr><th>字段/属性名称</th><th>使用格式</th><th>描述</th></tr></thead><tbody><tr><td>asctime</td><td>%(asctime)s</td><td>日志事件发生的时间–人类可读时间，如：2003-07-08 16:49:45,896</td></tr><tr><td>created</td><td>%(created)f</td><td>日志事件发生的时间–时间戳，就是当时调用time.time()函数返回的值</td></tr><tr><td>relativeCreated</td><td>%(relativeCreated)d</td><td>日志事件发生的时间相对于logging模块加载时间的相对毫秒数（目前还不知道干嘛用的）</td></tr><tr><td>msecs</td><td>%(msecs)d</td><td>日志事件发生事件的毫秒部分</td></tr><tr><td>levelname</td><td>%(levelname)s</td><td>该日志记录的文字形式的日志级别（’DEBUG’, ‘INFO’, ‘WARNING’, ‘ERROR’, ‘CRITICAL’）</td></tr><tr><td>levelno</td><td>%(levelno)s</td><td>该日志记录的数字形式的日志级别（10, 20, 30, 40, 50）</td></tr><tr><td>name</td><td>%(name)s</td><td>所使用的<strong>日志器名称</strong>，默认是’root’，因为默认使用的是 rootLogger</td></tr><tr><td>message</td><td>%(message)s</td><td>日志记录的文本内容，通过 <code>msg % args</code>计算得到的</td></tr><tr><td>pathname</td><td>%(pathname)s</td><td>调用日志记录函数的源码文件的全路径</td></tr><tr><td>filename</td><td>%(filename)s</td><td>pathname的文件名部分，包含文件后缀</td></tr><tr><td>module</td><td>%(module)s</td><td>filename的名称部分，不包含后缀</td></tr><tr><td>lineno</td><td>%(lineno)d</td><td>调用日志记录函数的源代码所在的行号</td></tr><tr><td>funcName</td><td>%(funcName)s</td><td>调用日志记录函数的函数名</td></tr><tr><td>process</td><td>%(process)d</td><td>进程ID</td></tr><tr><td>processName</td><td>%(processName)s</td><td>进程名称，Python 3.1新增</td></tr><tr><td>thread</td><td>%(thread)d</td><td>线程ID</td></tr><tr><td>threadName</td><td>%(thread)s</td><td>线程名称</td></tr></tbody></table><h4 id="实际配置案例"><a href="#实际配置案例" class="headerlink" title="实际配置案例"></a>实际配置案例</h4><p>代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import logging</span><br><span class="line">import time</span><br><span class="line">from os import path</span><br><span class="line"></span><br><span class="line"># 定义日志文件名称格式</span><br><span class="line">base_log_name = path.abspath(path.dirname(path.dirname(__file__))) + &apos;/logs/&apos; + &quot;dcache.log&quot; + &quot;-&quot;</span><br><span class="line">info_log_filename = base_log_name + time.strftime(&apos;%Y-%m-%d-%H&apos;) + &quot;-&quot; + time.strftime(&apos;%H&apos;)</span><br><span class="line">error_log_filename = base_log_name + &quot;error.log&quot;</span><br><span class="line">warn_log_filename = base_log_name + &quot;warn.log&quot;</span><br><span class="line"></span><br><span class="line"># 定义日志的输出格式</span><br><span class="line">log_format = &quot;%(asctime)s - %(levelname)s - %(pathname)s[line:%(lineno)d] - %(message)s&quot;</span><br><span class="line">logging.basicConfig(filename=info_log_filename,level=logging.DEBUG,format=log_format)</span><br><span class="line"></span><br><span class="line"># 日志记录，第一种方式来源方式2，下面会将</span><br><span class="line">log = logging.getLogger(&apos;root&apos;)</span><br><span class="line">log.info(&quot;info log&quot;)</span><br><span class="line">或者</span><br><span class="line">logging.info(&quot;info log&quot;)</span><br></pre></td></tr></table></figure><p>在这里使用了以下字段：</p><ul><li>asctime    事件发生的时间</li><li>levelname 事件的等级</li><li>pathname 产生事件的文件的绝对路径</li><li>lineno 调用日志记录函数的源代码所在的行号</li><li>message 日志记录的文本内容</li></ul><p>日志的输出格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2018-12-07 11:10:33,546 - INFO - /Users/wangxiaohua/PycharmProjects/dcache/lib/logger.py[line:35] - info log</span><br></pre></td></tr></table></figure><h3 id="实现方式2-使用四大组件记录日志"><a href="#实现方式2-使用四大组件记录日志" class="headerlink" title="实现方式2-使用四大组件记录日志"></a>实现方式2-使用四大组件记录日志</h3><h4 id="logging模块的四大组件"><a href="#logging模块的四大组件" class="headerlink" title="logging模块的四大组件"></a>logging模块的四大组件</h4><table><thead><tr><th>组件名称</th><th>对应类名</th><th>功能描述</th></tr></thead><tbody><tr><td>日志器</td><td>Logger</td><td>提供了应用程序可一直使用的接口</td></tr><tr><td>处理器</td><td>Handler</td><td>将logger创建的日志记录发送到合适的目的输出</td></tr><tr><td>过滤器</td><td>Filter</td><td>提供了更细粒度的控制工具来决定输出哪条日志记录，丢弃哪条日志记录</td></tr><tr><td>格式器</td><td>Formatter</td><td>决定日志记录的最终输出格式</td></tr></tbody></table><p>logging模块就是通过这些组件来完成日志处理的，上面所使用的logging模块级别的函数也是通过这些组件对应的类来实现的。 </p><p><strong>这些组件之间的关系描述：</strong></p><ul><li>日志器/记录器（logger）需要通过处理器（handler）将日志信息输出到目标位置，如：文件、sys.stdout、网络等；</li><li>不同的处理器（handler）可以将日志输出到不同的位置；</li><li>日志器（logger）可以设置多个处理器（handler）将同一条日志记录输出到不同的位置；这里的意思也就是说，当日志器接收到一个请求之后，会把这个日志信息发送给所有的处理器，至于具体的输出情况则是由处理器去控制</li><li>每个处理器（handler）都可以设置自己的过滤器（filter）实现日志过滤，从而只保留感兴趣的日志；</li><li>每个处理器（handler）都可以设置自己的格式器（formatter）实现同一条日志以不同的格式输出到不同的地方。</li></ul><p>简单点说就是：<strong>日志器（logger）是入口</strong>，真正干活儿的是处理器（handler），处理器（handler）还可以通过过滤器（filter）和格式器（formatter）对要输出的日志内容做过滤和格式化等处理操作。</p><p>总结：日志器logger是一个入口，它本身不处理任何的请求，只是将接受到的请求转发给后端的所有处理器，可以类比为4层转发的机制（它所能做的一些设置只是例如设置最低日志等级这种）。真正实现灵活控制的是处理器(handler)，handler接受到日志之后，根据自身的过滤规则和格式器，决定是否要记录，以及按照什么格式进行记录。</p><h4 id="四大组件相关类及其常用方法"><a href="#四大组件相关类及其常用方法" class="headerlink" title="四大组件相关类及其常用方法"></a>四大组件相关类及其常用方法</h4><p>下面介绍下与logging四大组件相关的类：Logger, Handler, Filter, Formatter。</p><h5 id="logger类"><a href="#logger类" class="headerlink" title="logger类"></a>logger类</h5><p>Logger对象，也就是日志器有3个任务要做：</p><ul><li><p>向应用程序代码暴露几个方法，使应用程序可以在运行时记录日志消息；</p></li><li><p>基于日志严重等级（默认的过滤设施）或filter对象来决定要对哪些日志进行后续处理；</p><p>也就是说logger日志器这一层就会对日志做初步的过滤</p></li><li><p>将日志消息传送给所有感兴趣的日志handlers。</p></li></ul><p>Logger对象最常用的方法分为两类：<strong><code>配置方法 和 消息发送方法</code></strong></p><p><strong>常用配置方法：</strong></p><table><thead><tr><th>方法</th><th>描述</th></tr></thead><tbody><tr><td>Logger.setLevel()</td><td>设置日志器将会处理的日志消息的最低严重级别</td></tr><tr><td>Logger.addHandler() 和 Logger.removeHandler()</td><td>为该logger对象添加 和 移除一个handler对象</td></tr><tr><td>Logger.addFilter() 和 Logger.removeFilter()</td><td>为该logger对象添加 和 移除一个filter对象</td></tr></tbody></table><p>关于Logger.setLevel()方法的说明：</p><blockquote><p>内建等级中，级别最低的是DEBUG，级别最高的是CRITICAL。例如setLevel(logging.INFO)，此时函数参数为INFO，那么该logger将只会处理INFO、WARNING、ERROR和CRITICAL级别的日志，而DEBUG级别的消息将会被忽略/丢弃。</p></blockquote><p>logger对象配置完成后，可以使用下面的方法来创建日志记录：</p><p><strong>常用消息发送方法</strong></p><table><thead><tr><th>方法</th><th>描述</th></tr></thead><tbody><tr><td>Logger.debug(), Logger.info(), Logger.warning(), Logger.error(), Logger.critical()</td><td>创建一个与它们的方法名对应等级的日志记录</td></tr><tr><td>Logger.exception()</td><td>创建一个类似于Logger.error()的日志消息</td></tr><tr><td>Logger.log()</td><td>需要获取一个明确的日志level参数来创建一个日志记录</td></tr></tbody></table><p>说明：</p><blockquote><ul><li>Logger.exception()与Logger.error()的区别在于：Logger.exception()将会输出堆栈追踪信息，另外通常只是在一个exception handler中调用该方法。</li><li>Logger.log()的用法为：logging.log(logging.ERROR,”log message”)</li><li>Logger.log()与Logger.debug()、Logger.info()等方法相比，虽然需要多传一个level参数，显得不是那么方便，但是当需要记录自定义level的日志时还是需要该方法来完成。</li></ul></blockquote><p>如何得到一个Logger对象呢？一种方式是通过Logger类的实例化方法创建一个Logger类的实例，但是我们通常都是用第二种方式–logging.getLogger()方法。</p><p>logging.getLogger()方法有一个可选参数name，该参数表示将要返回的日志器的名称标识，如果不提供该参数，则其值为’root’。若以相同的name参数值多次调用getLogger()方法，将会返回指向同一个logger对象的引用。</p><h5 id="关于logger的层级结构与有效等级的说明"><a href="#关于logger的层级结构与有效等级的说明" class="headerlink" title="关于logger的层级结构与有效等级的说明"></a>关于logger的层级结构与有效等级的说明</h5><ul><li>logger的名称是一个以’.’分割的层级结构，每个’.’后面的logger都是’.’前面的logger的children，例如，有一个名称为 foo 的logger，其它名称分别为 foo.bar, foo.bar.baz 和 foo.bam都是 foo 的后代。</li><li>logger有一个”有效等级（effective level）”的概念。如果一个logger上没有被明确设置一个level，那么该logger就是使用它parent的level;如果它的parent也没有明确设置level则继续向上查找parent的parent的有效level，依次类推，直到找到个一个明确设置了level的祖先为止。需要说明的是，root logger总是会有一个明确的level设置（默认为 WARNING）。当决定是否去处理一个已发生的事件时，logger的有效等级将会被用来决定是否将该事件传递给该logger的handlers进行处理。</li><li>child loggers在完成对日志消息的处理后，默认会将日志消息传递给与它们的祖先loggers相关的handlers。因此，我们不必为一个应用程序中所使用的所有loggers定义和配置handlers，只需要为一个顶层的logger配置handlers，然后按照需要创建child loggers就可足够了。我们也可以通过将一个logger的propagate属性设置为False来关闭这种传递机制。</li></ul><p>也就是说：四大组件是一种分层的架构，不管是父logger还是子logger，只要是logger，都是在handler层级之上的，所以child logger处理之后，会把消息传递给父logger的handler</p><h5 id="Handler类"><a href="#Handler类" class="headerlink" title="Handler类"></a>Handler类</h5><p>Handler对象的作用是（基于日志消息的level）将消息分发到handler指定的位置（文件、网络、邮件等）。Logger对象可以通过addHandler()方法为自己添加0个或者更多个handler对象。比如，一个应用程序可能想要实现以下几个日志需求：</p><ul><li>1）把所有日志都发送到一个日志文件中；</li><li>2）把所有严重级别大于等于error的日志发送到stdout（标准输出）；</li><li>3）把所有严重级别为critical的日志发送到一个email邮件地址。<br>这种场景就需要3个不同的handlers，每个handler负责发送一个特定严重级别的日志到一个特定的位置。</li></ul><p>一个handler中只有非常少数的方法是需要应用开发人员去关心的。对于使用内建handler对象的应用开发人员来说，似乎唯一相关的handler方法就是下面这几个配置方法：</p><table><thead><tr><th>方法</th><th>描述</th></tr></thead><tbody><tr><td>Handler.setLevel()</td><td>设置handler将会处理的日志消息的最低严重级别</td></tr><tr><td>Handler.setFormatter()</td><td>为handler设置一个格式器对象</td></tr><tr><td>Handler.addFilter() 和 Handler.removeFilter()</td><td>为handler添加 和 删除一个过滤器对象</td></tr></tbody></table><p>需要说明的是，应用程序代码不应该直接实例化和使用Handler实例。因为Handler是一个基类，它只定义了所有handlers都应该有的接口，同时提供了一些子类可以直接使用或覆盖的默认行为。下面是一些常用的Handler：</p><table><thead><tr><th>Handler</th><th>描述</th></tr></thead><tbody><tr><td>logging.StreamHandler</td><td>将日志消息发送到输出到Stream，如std.out, std.err或任何file-like对象。</td></tr><tr><td>logging.FileHandler</td><td>将日志消息发送到磁盘文件，默认情况下文件大小会无限增长</td></tr><tr><td>logging.handlers.RotatingFileHandler</td><td>将日志消息发送到磁盘文件，并支持日志文件按大小切割</td></tr><tr><td>logging.hanlders.TimedRotatingFileHandler</td><td>将日志消息发送到磁盘文件，并支持日志文件按时间切割</td></tr><tr><td>logging.handlers.HTTPHandler</td><td>将日志消息以GET或POST的方式发送给一个HTTP服务器</td></tr><tr><td>logging.handlers.SMTPHandler</td><td>将日志消息发送给一个指定的email地址</td></tr><tr><td>logging.NullHandler</td><td>该Handler实例会忽略error messages，通常被想使用logging的library开发者使用来避免’No handlers could be found for logger XXX’信息的出现。</td></tr></tbody></table><h5 id="Formater类"><a href="#Formater类" class="headerlink" title="Formater类"></a>Formater类</h5><p>Formater对象用于配置日志信息的顺序、结构和内容。</p><p>与logging.Handler基类不同的是，应用代码可以直接实例化Formatter类。另外，如果你的应用程序需要一些特殊的处理行为，也可以实现一个Formatter的子类来完成。</p><p>Formatter类的构造方法定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logging.Formatter.__init__(fmt=None, datefmt=None, style=&apos;%&apos;)</span><br></pre></td></tr></table></figure><p>可见，该构造方法接收3个可选参数：</p><ul><li>fmt：指定消息格式化字符串，如果不指定该参数则默认使用message的原始值</li><li>datefmt：指定日期格式字符串，如果不指定该参数则默认使用”%Y-%m-%d %H:%M:%S”</li><li>style：Python 3.2新增的参数，可取值为 ‘%’, ‘{‘和 ‘$’，如果不指定该参数则默认使用’%’</li></ul><h5 id="Filter类"><a href="#Filter类" class="headerlink" title="Filter类"></a>Filter类</h5><p>Filter可以被Handler和Logger用来做比level更细粒度的、更复杂的过滤功能。Filter是一个过滤器基类，它只允许某个logger层级下的日志事件通过过滤。该类定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">class logging.Filter(name=&apos;&apos;)</span><br><span class="line">    filter(record)</span><br></pre></td></tr></table></figure><p>比如，一个filter实例化时传递的name参数值为’A.B’，那么该filter实例将只允许名称为类似如下规则的loggers产生的日志记录通过过滤：’A.B’，’A.B,C’，’A.B.C.D’，’A.B.D’，而名称为’A.BB’, ‘B.A.B’的loggers产生的日志则会被过滤掉。如果name的值为空字符串，则允许所有的日志事件通过过滤。</p><p>filter方法用于具体控制传递的record记录是否能通过过滤，如果该方法返回值为0表示不能通过过滤，返回值为非0表示可以通过过滤。</p><p><strong>说明：</strong></p><blockquote><ul><li>如果有需要，也可以在filter(record)方法内部改变该record，比如添加、删除或修改一些属性。</li><li>我们还可以通过filter做一些统计工作，比如可以计算下被一个特殊的logger或handler所处理的record数量等。</li></ul></blockquote><h2 id="案例演示"><a href="#案例演示" class="headerlink" title="案例演示"></a>案例演示</h2><p><strong>需求：</strong></p><p>生成2个日志文件</p><ol><li>普通日志文件：<ul><li>日志级别：INFO及以上级别</li><li>格式：dcache.log | 之前文件：dcache.log.2018-12-09</li><li>日志轮询：所有级别的日志相对来说会比较大，因此按天分割，每天输出一个日志文件，保留30天</li></ul></li><li>error日志：<ul><li>日志级别：Error及CRITICAL级别</li><li>格式：dcache-error.log | 之前文件：dcache-error.log.2018-12-09</li><li>日志轮询：error日志不会太大，因此每7天生成一个新的文件，保留4个文件</li></ul></li></ol><p><strong>分析：</strong></p><ul><li>要记录INFO级别机器以上的日志，因此日志器的有效level需要设置为最低级别–INFO;</li><li>日志需要被发送到2个不同的目的地，因此需要为日志器设置2个handler，并且这3个目的地都是磁盘文件，因此这3个handler都是与FileHandler相关的</li><li>这里使用统一的内容格式，因此handler分别格式器设置一致，不需要额外区分</li><li>日志按照时间进行分割，因此需要用logging.handlers.TimedRotatingFileHandler; 而不是使用FileHandler;</li></ul><p><strong>代码实现：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">import logging</span><br><span class="line">import logging.handlers</span><br><span class="line">from os import path</span><br><span class="line">import datetime</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">生成2个日志文件</span><br><span class="line">1. 普通日志文件：</span><br><span class="line">    - 日志级别：INFO及以上级别</span><br><span class="line">    - 格式：dcache.log | 之前文件：dcache.log.2018-12-09</span><br><span class="line">    - 日志轮询：按天分割，每天输出一个日志文件，保留30天</span><br><span class="line"></span><br><span class="line">2. error日志：</span><br><span class="line">    - 日志级别：Error及CRITICAL级别</span><br><span class="line">    - 格式：dcache-error.log | 之前文件：dcache-error.log.2018-12-09</span><br><span class="line">    - 日志轮询：为防止文件过大，每7天生成一个新的文件，保留7个文件</span><br><span class="line">    </span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">## 定义日志文件名称格式</span><br><span class="line">base_log_name = path.abspath(path.dirname(path.dirname(__file__))) + &apos;/logs/&apos; + &quot;dcache&quot;</span><br><span class="line">info_log_filename = base_log_name + &quot;.log&quot;</span><br><span class="line">error_log_filename = base_log_name + &quot;-error.log&quot;</span><br><span class="line"></span><br><span class="line"># 定义日志内容的输出格式</span><br><span class="line">log_format = &quot;%(asctime)s - %(levelname)s - %(pathname)s[line:%(lineno)d] - %(message)s&quot;</span><br><span class="line"></span><br><span class="line"># 定义日志处理器(实例化一个日志处理器对象)</span><br><span class="line">logger = logging.getLogger(&apos;root&apos;)</span><br><span class="line">logger.setLevel(logging.INFO)</span><br><span class="line"></span><br><span class="line"># 定义handlers</span><br><span class="line">info_handler = logging.handlers.TimedRotatingFileHandler(info_log_filename, when=&apos;midnight&apos;, interval=1,backupCount=30, atTime=datetime.time(0, 0, 0, 0))</span><br><span class="line">info_handler.suffix = &quot;%Y-%m-%d&quot;</span><br><span class="line">info_handler.setLevel(logging.INFO)</span><br><span class="line">info_handler.setFormatter(logging.Formatter(log_format))</span><br><span class="line"></span><br><span class="line">error_handler = logging.handlers.TimedRotatingFileHandler(error_log_filename, when=&apos;midnight&apos;, interval=7,backupCount=4, atTime=datetime.time(0, 0, 0, 0))</span><br><span class="line">error_handler.suffix = &quot;%Y-%m-%d&quot;</span><br><span class="line">error_handler.setLevel(logging.ERROR)</span><br><span class="line">error_handler.setFormatter(logging.Formatter(log_format))</span><br><span class="line"></span><br><span class="line"># 日志器添加handlers</span><br><span class="line">logger.addHandler(info_handler)</span><br><span class="line">logger.addHandler(error_handler)</span><br><span class="line"></span><br><span class="line"># test</span><br><span class="line">logger.debug(&apos;debug message&apos;)</span><br><span class="line">logger.info(&apos;info message&apos;)</span><br><span class="line">logger.warning(&apos;warning message&apos;)</span><br><span class="line">logger.error(&apos;error message&apos;)</span><br><span class="line">logger.critical(&apos;critical message&apos;)</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>interval表示的是：多少个指定时间内，当前的日志文件没有新的内容被写入进来，再去创建新文件，而不是时间一到就去创建新文件。每次每隔一小时输出一个文件的功能使用TimedRotatingFileHandler的方式实现不了。</li><li>因此要每小时一个文件的这种功能，需要我们想其他办法去实现</li></ul><h1 id="补充-零碎知识记录"><a href="#补充-零碎知识记录" class="headerlink" title="补充-零碎知识记录"></a>补充-零碎知识记录</h1><h2 id="python中方法与函数的区别"><a href="#python中方法与函数的区别" class="headerlink" title="python中方法与函数的区别"></a>python中方法与函数的区别</h2><p>定义:</p><ul><li><p>function(函数) —— A series of statements which returns some value toa caller. It can also be passed zero or more arguments which may beused in the execution of the body.</p></li><li><p>method(方法) —— A function which is defined inside a class body. Ifcalled as an attribute of an instance of that class, the methodwill get the instance object as its first argument (which isusually called self).</p></li></ul><blockquote><p>Function包含一个函数头和一个函数体, 支持0到n个形参</p><p>而Method则是在function的基础上, 多了一层类的关系, 正因为这一层类, 所以区分了 function 和 method.而这个过程是通过 PyMethod_New实现的</p></blockquote><p>也就是说，函数可以脱离于类单独存在，在使用的时候，需要往函数中传入参数（实参）</p><p>而方法是与某个对象紧密联系的，不能脱离于类而存在方法的作用域只是在一个类中，只能在该类实例化后被该类使用</p><p>方法的绑定, 肯定是伴随着class的实例化而发生,我们都知道, 在class里定义方法, 需要显示传入self参数, 因为这个self是代表即将被实例化的对象。</p><p><strong>定义角度：</strong></p><p>从定义的角度上看，我们知道函数(function)就相当于一个数学公式，它理论上不与其它东西关系，它只需要相关的参数就可以。所以普通的在module中定义的称谓函数是很有道理的。</p><p>那么方法的意思就很明确了，它是与某个对象相互关联的，也就是说它的实现与某个对象有关联关系。这就是方法。虽然它的定义方式和函数是一样的。也就是说，在Class定义的函数就是方法。</p><p><strong>总结：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">函数是一段代码，通过名字来进行调用。它能将一些数据（参数）传递进去进行处理，然后返回一些数据（返回值），也可以没有返回值。所有传递给函数的数据都是显式传递的。</span><br><span class="line"></span><br><span class="line">方法也是一段代码，也通过名字来进行调用，但它跟一个对象相关联。方法和函数大致上是相同的，但有两个主要的不同之处：</span><br><span class="line"></span><br><span class="line">方法中的数据是隐式传递的；</span><br><span class="line">方法可以操作类内部的数据（请记住，对象是类的实例化–类定义了一个数据类型，而对象是该数据类型的一个实例化）</span><br></pre></td></tr></table></figure><h2 id="可变参数args"><a href="#可变参数args" class="headerlink" title="可变参数args"></a>可变参数args</h2><h3 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h3><p>如果我们在函数被调用前并不知道也不限制将来函数可以接收的参数数量。在这种情况下我们可以使用<code>*args</code>和<code>**kwargs</code>来进行定义函数</p><p><code>*args</code>和<code>**kwargs</code>这两个是python中的可变参数。</p><ul><li>args表示任何多个无名参数，它是一个tuple</li><li>kwargs表示关键字参数，它是一个dict</li></ul><p><strong>特别注意：</strong></p><ul><li>同时使用<code>*args</code>和<code>**kwargs</code>时，<code>*args</code>参数要列在<code>**kwargs</code><strong>前</strong>。</li><li>因此像foo(a=1, b=’2’, c=3, a’, 1, None, )这样调用的话，会提示语法错误“SyntaxError: non-keyword arg after keyword arg”。</li><li>当两者同时存在时，正确的调用方式应该像是：foo(‘a’,1,a=1,b=2)</li><li>实际上真正的Python参数传递语法是<code>*</code>和<code>**</code>。<code>*args</code>和<code>**kwargs</code>只是一种约定俗成的编程实践。我们也可以写成<code>*vars</code>和<code>**kvars</code>。</li></ul><h3 id="实际案例-2"><a href="#实际案例-2" class="headerlink" title="实际案例"></a>实际案例</h3><p>代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def test(*args,**kwargs):</span><br><span class="line">    print (&quot;args = &quot;,args)</span><br><span class="line">    print (&quot;kwargs = &quot;,kwargs)</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line">test(1,2,3,4)</span><br><span class="line">test(&quot;11&quot;,&quot;2&quot;,a=1,b=2)</span><br></pre></td></tr></table></figure><p>执行后输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">args =  (1, 2, 3, 4)</span><br><span class="line">kwargs =  &#123;&#125;</span><br><span class="line">args =  (&apos;11&apos;, &apos;2&apos;)</span><br><span class="line">kwargs =  &#123;&apos;a&apos;: 1, &apos;b&apos;: 2&#125;</span><br></pre></td></tr></table></figure><h2 id="python-import相关问题"><a href="#python-import相关问题" class="headerlink" title="python import相关问题"></a>python import相关问题</h2><p>参考文献：</p><ul><li><a href="https://www.kancloud.cn/st_afei/python_info_ylf/344146" target="_blank" rel="noopener">关于python——import问题</a></li><li><a href="http://codingpy.com/article/python-import-101/" target="_blank" rel="noopener">python导入模块的几种姿势</a></li></ul><p>在python中，每个py文件被称之为模块，每个具有<code>__init__.py</code>文件的目录被称为包。只要模块或者包所在的目录在sys.path中，就可以使用import 模块或import 包来使用。</p><p>作为一名新手Python程序员，你首先需要学习的内容之一就是如何导入模块或包。但是我注意到，那些许多年来不时使用Python的人并不是都知道Python的导入机制其实非常灵活。在本文中，我们将探讨以下话题：</p><ul><li>常规导入（regular imports）</li><li>使用from语句导入</li><li>相对导入（relative imports）</li><li>可选导入（optional imports）</li><li>本地导入（local imports）</li><li>导入注意事项</li></ul><h3 id="常规导入"><a href="#常规导入" class="headerlink" title="常规导入"></a>常规导入</h3><p>常规导入应该是最常使用的导入方式，大概是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br></pre></td></tr></table></figure><p>你只需要使用<code>import</code>一词，然后指定你希望导入的模块或包即可。通过这种方式导入的好处是可以一次性导入多个包或模块：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import os, sys, time</span><br></pre></td></tr></table></figure><p>虽然这节省了空间，但是却违背了Python风格指南。<strong>Python风格指南建议将每个导入语句单独成行</strong>。</p><p>有时在导入模块时，你想要重命名这个模块。这个功能很容易实现：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import sys as system</span><br><span class="line"></span><br><span class="line">print(system.platform)</span><br></pre></td></tr></table></figure><p>上面的代码将我们导入的<code>sys</code>模块重命名为<code>system</code>。我们可以按照和以前一样的方式调用模块的方法，但是可以用一个新的模块名。也有某些子模块必须要使用点标记法才能导入。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import urllib.error</span><br></pre></td></tr></table></figure><p>这个情况不常见，但是对此有所了解总是没有坏处的。</p><p>注意：</p><ul><li>import导入为绝对导入</li><li>import 只能导入模块，不能导入模块中的对象（类、函数、变量等)</li></ul><blockquote><p>Python 中所有加载到内存的模块都放在 sys.modules 。当 import 一个模块时首先会在这个列表中查找是否已经加载了此模块，如果没有加载则从 sys.path 目录中按照模块名称查找模块文件，找到后将模块载入内存，并加到 sys.modules 中。只有存在sys.path中的模块才会被正确导入。 </p><p>一个模块不会重复载入。多个不同的模块都可以用 import 引入同一个模块到自己的 Local 名字空间，其实背后的 PyModuleObject 对象只有一个。 </p><p>一个容易忽略的问题：import 只能导入模块，不能导入模块中的对象（类、函数、变量等）。例如：模块 A（A.py）中有个函数 getName，另一个模块不能通过 import A.getName 将 getName导入到本模块，只能用 from A import getName。 </p><p>同级目录下，可以使用import直接导入所需模块</p></blockquote><h3 id="使用from语句导入"><a href="#使用from语句导入" class="headerlink" title="使用from语句导入"></a>使用from语句导入</h3><p>很多时候你只想要导入一个模块或库中的某个部分。我们来看看在Python中如何实现这点：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from functools import lru_cache</span><br></pre></td></tr></table></figure><p>上面这行代码可以让你直接调用<code>lru_cache</code>。如果你按常规的import方式导入<code>functools</code>，那么你就必须像这样调用<code>lru_cache</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">functools.lru_cache(*args)</span><br></pre></td></tr></table></figure><p>根据你实际的使用场景，上面的做法可能是更好的。在复杂的代码库中，能够看出某个函数是从哪里导入的这点很有用的。不过，如果你的代码维护的很好，模块化程度高，那么只从某个模块中导入一部分内容也是非常方便和简洁的。</p><p>当然，你还可以使用from方法导入模块的全部内容，就像这样：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from os import *</span><br></pre></td></tr></table></figure><p>这种做法在少数情况下是挺方便的，但是这样也会打乱你的命名空间。问题在于，你可能定义了一个与导入模块中名称相同的变量或函数，这时如果你试图使用<code>os</code>模块中的同名变量或函数，实际使用的将是你自己定义的内容。因此，你最后可能会碰到一个相当让人困惑的逻辑错误。<strong>标准库中我唯一推荐全盘导入的模块只有Tkinter</strong>。</p><p>如果你正好要写自己的模块或包，有人会建议你在<code>__init__.py</code>文件中导入所有内容，让模块或者包使用起来更方便。我个人更喜欢显示地导入，而非隐式地导入。</p><p>你也可以采取折中方案，从一个包中导入多个项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from os import path, walk, unlink</span><br><span class="line">from os import uname, remove</span><br></pre></td></tr></table></figure><p>在上述代码中，我们从<code>os</code>模块中导入了5个函数。你可能注意到了，我们是通过多次从同一个模块中导入实现的。当然，如果你愿意的话，你也可以使用圆括号一次性导入多个项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from os import (path, walk, unlink, uname, </span><br><span class="line">                remove, rename)</span><br></pre></td></tr></table></figure><p>这是一个有用的技巧，不过你也可以换一种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from os import path, walk, unlink, uname, \</span><br><span class="line">                remove, rename</span><br></pre></td></tr></table></figure><p>上面的反斜杠是Python中的续行符，告诉解释器这行代码延续至下一行。</p><h3 id="相对导入"><a href="#相对导入" class="headerlink" title="相对导入"></a>相对导入</h3><p><a href="https://www.python.org/dev/peps/pep-0328/" target="_blank" rel="noopener">PEP 328</a>介绍了引入相对导入的原因，以及选择了哪种语法。具体来说，是使用句点来决定如何相对导入其他包或模块。这么做的原因是为了避免偶然情况下导入标准库中的模块产生冲突。这里我们以PEP 328中给出的文件夹结构为例，看看相对导入是如何工作的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">my_package/</span><br><span class="line">    __init__.py</span><br><span class="line">    subpackage1/</span><br><span class="line">        __init__.py</span><br><span class="line">        module_x.py</span><br><span class="line">        module_y.py</span><br><span class="line">    subpackage2/</span><br><span class="line">        __init__.py</span><br><span class="line">        module_z.py</span><br><span class="line">    module_a.py</span><br></pre></td></tr></table></figure><p>在本地磁盘上找个地方创建上述文件和文件夹。在顶层的<code>__init__.py</code>文件中，输入以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from . import subpackage1</span><br><span class="line">from . import subpackage2</span><br></pre></td></tr></table></figure><p>接下来进入<code>subpackage1</code>文件夹，编辑其中的<code>__init__.py</code>文件，输入以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from . import module_x</span><br><span class="line">from . import module_y</span><br></pre></td></tr></table></figure><p>现在编辑<code>module_x.py</code>文件，输入以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from .module_y import spam as ham</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    ham()</span><br></pre></td></tr></table></figure><p>最后编辑<code>module_y.py</code>文件，输入以下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def spam():</span><br><span class="line">    print(&apos;spam &apos; * 3)</span><br></pre></td></tr></table></figure><p>打开终端，<code>cd</code>至<code>my_package</code>包所在的文件夹，但不要进入<code>my_package</code>。在这个文件夹下运行Python解释器。我使用的是IPython，因为它的自动补全功能非常方便：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [1]: import my_package</span><br><span class="line"></span><br><span class="line">In [2]: my_package.subpackage1.module_x</span><br><span class="line">Out[2]: &lt;module &apos;my_package.subpackage1.module_x&apos; from &apos;my_package/subpackage1/module_x.py&apos;&gt;</span><br><span class="line"></span><br><span class="line">In [3]: my_package.subpackage1.module_x.main()</span><br><span class="line">spam spam spam</span><br></pre></td></tr></table></figure><p>相对导入适用于你最终要放入包中的代码。如果你编写了很多相关性强的代码，那么应该采用这种导入方式。<strong>你会发现PyPI上有很多流行的包也是采用了相对导入</strong>。还要注意一点，如果你想要跨越多个文件层级进行导入，只需要使用多个句点即可。不过，<strong>PEP 328建议相对导入的层级不要超过两层</strong>。</p><p>还要注意一点，如果你往<code>module_x.py</code>文件中添加了<code>if __name__ == ‘__main__’</code>，然后试图运行这个文件，你会碰到一个很难理解的错误。编辑一下文件，试试看吧！</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from . module_y import spam as ham</span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    ham()</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # This won&apos;t work!</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p>现在从终端进入<code>subpackage1</code>文件夹，执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python module_x.py</span><br></pre></td></tr></table></figure><p>如果你使用的是Python 2，你应该会看到下面的错误信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;module_x.py&quot;, line 1, in &lt;module&gt;</span><br><span class="line">    from . module_y import spam as ham</span><br><span class="line">ValueError: Attempted relative import in non-package</span><br></pre></td></tr></table></figure><p>如果你使用的是Python 3，错误信息大概是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;module_x.py&quot;, line 1, in &lt;module&gt;</span><br><span class="line">    from . module_y import spam as ham</span><br><span class="line">SystemError: Parent module &apos;&apos; not loaded, cannot perform relative import</span><br></pre></td></tr></table></figure><p>这指的是，<code>module_x.py</code>是某个包中的一个模块，而你试图以脚本模式执行，但是<strong>这种模式不支持相对导入</strong>。</p><p>如果你想在自己的代码中使用这个模块，那么你必须将其添加至Python的导入检索路径（import search path）。最简单的做法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">sys.path.append(&apos;/path/to/folder/containing/my_package&apos;)</span><br><span class="line">import my_package</span><br></pre></td></tr></table></figure><p>注意，你需要添加的是<code>my_package</code>的上一层文件夹路径，而不是<code>my_package</code>本身。原因是<code>my_package</code>就是我们想要使用的包，所以如果你添加它的路径，那么将无法使用这个包。</p><p>我们接下来谈谈可选导入。</p><h3 id="可选导入（Optional-imports）"><a href="#可选导入（Optional-imports）" class="headerlink" title="可选导入（Optional imports）"></a>可选导入（Optional imports）</h3><p>如果你希望优先使用某个模块或包，但是同时也想在没有这个模块或包的情况下有备选，你就可以使用可选导入这种方式。这样做可以导入支持某个软件的多种版本或者实现性能提升。以<a href="http://pythonhosted.org/github2/_modules/github2/request.html" target="_blank" rel="noopener">github2包</a>中的代码为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    # For Python 3</span><br><span class="line">    from http.client import responses</span><br><span class="line">except ImportError:  # For Python 2.5-2.7</span><br><span class="line">    try:</span><br><span class="line">        from httplib import responses  # NOQA</span><br><span class="line">    except ImportError:  # For Python 2.4</span><br><span class="line">        from BaseHTTPServer import BaseHTTPRequestHandler as _BHRH</span><br><span class="line">        responses = dict([(k, v[0]) for k, v in _BHRH.responses.items()])</span><br></pre></td></tr></table></figure><p><code>lxml</code>包也有使用可选导入方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">try:</span><br><span class="line">    from urlparse import urljoin</span><br><span class="line">    from urllib2 import urlopen</span><br><span class="line">except ImportError:</span><br><span class="line">    # Python 3</span><br><span class="line">    from urllib.parse import urljoin</span><br><span class="line">    from urllib.request import urlopen</span><br></pre></td></tr></table></figure><p>正如以上示例所示，<strong>可选导入的使用很常见，是一个值得掌握的技巧</strong>。</p><h3 id="局部导入"><a href="#局部导入" class="headerlink" title="局部导入"></a>局部导入</h3><p>当你在局部作用域中导入模块时，你执行的就是局部导入。如果你在Python脚本文件的顶部导入一个模块，那么你就是在将该模块导入至全局作用域，这意味着之后的任何函数或方法都可能访问该模块。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import sys  # global scope</span><br><span class="line"></span><br><span class="line">def square_root(a):</span><br><span class="line">    # This import is into the square_root functions local scope</span><br><span class="line">    import math</span><br><span class="line">    return math.sqrt(a)</span><br><span class="line"></span><br><span class="line">def my_pow(base_num, power):</span><br><span class="line">    return math.pow(base_num, power)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    print(square_root(49))</span><br><span class="line">    print(my_pow(2, 3))</span><br></pre></td></tr></table></figure><p>这里，我们将<code>sys</code>模块导入至全局作用域，但我们并没有使用这个模块。然后，在<code>square_root</code>函数中，我们将<code>math</code>模块导入至该函数的局部作用域，这意味着<code>math</code>模块只能在<code>square_root</code>函数内部使用。如果我们试图在<code>my_pow</code>函数中使用<code>math</code>，会引发<code>NameError</code>。试着执行这个脚本，看看会发生什么。</p><p>使用局部作用域的好处之一，是你使用的模块可能需要很长时间才能导入，如果是这样的话，将其放在某个不经常调用的函数中或许更加合理，而不是直接在全局作用域中导入。老实说，我几乎从没有使用过局部导入，主要是因为如果模块内部到处都有导入语句，会很难分辨出这样做的原因和用途。<strong>根据约定，所有的导入语句都应该位于模块的顶部</strong>。</p><h3 id="导入注意事项"><a href="#导入注意事项" class="headerlink" title="导入注意事项"></a>导入注意事项</h3><p>在导入模块方面，有几个程序员常犯的错误。这里我们介绍两个。</p><ul><li>循环导入（circular imports）</li><li>覆盖导入（Shadowed imports，暂时翻译为覆盖导入）</li></ul><p>先来看看循环导入。</p><h4 id="循环导入"><a href="#循环导入" class="headerlink" title="循环导入"></a>循环导入</h4><p>如果你创建两个模块，二者相互导入对方，那么就会出现循环导入。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># a.py</span><br><span class="line">import b</span><br><span class="line"></span><br><span class="line">def a_test():</span><br><span class="line">    print(&quot;in a_test&quot;)</span><br><span class="line">    b.b_test()</span><br><span class="line"></span><br><span class="line">a_test()</span><br></pre></td></tr></table></figure><p>然后在同个文件夹中创建另一个模块，将其命名为<code>b.py</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import a</span><br><span class="line"></span><br><span class="line">def b_test():</span><br><span class="line">    print(&apos;In test_b&quot;&apos;)</span><br><span class="line">    a.a_test()</span><br><span class="line"></span><br><span class="line">b_test()</span><br></pre></td></tr></table></figure><p>如果你运行任意一个模块，都会引发<code>AttributeError</code>。这是因为这两个模块都在试图导入对方。简单来说，模块<code>a</code>想要导入模块<code>b</code>，但是因为模块<code>b</code>也在试图导入模块<code>a</code>（这时正在执行），模块<code>a</code>将无法完成模块<code>b</code>的导入。我看过一些解决这个问题的破解方法（hack），但是<strong>一般来说，你应该做的是重构代码，避免发生这种情况</strong>。</p><h4 id="覆盖导入"><a href="#覆盖导入" class="headerlink" title="覆盖导入"></a>覆盖导入</h4><p>当你创建的模块与标准库中的模块同名时，如果你导入这个模块，就会出现覆盖导入。举个例子，创建一个名叫<code>math.py</code>的文件，在其中写入如下代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import math</span><br><span class="line"></span><br><span class="line">def square_root(number):</span><br><span class="line">    return math.sqrt(number)</span><br><span class="line"></span><br><span class="line">square_root(72)</span><br></pre></td></tr></table></figure><p>现在打开终端，试着运行这个文件，你会得到以下回溯信息（traceback）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;math.py&quot;, line 1, in &lt;module&gt;</span><br><span class="line">    import math</span><br><span class="line">  File &quot;/Users/michael/Desktop/math.py&quot;, line 6, in &lt;module&gt;</span><br><span class="line">    square_root(72)</span><br><span class="line">  File &quot;/Users/michael/Desktop/math.py&quot;, line 4, in square_root</span><br><span class="line">    return math.sqrt(number)</span><br><span class="line">AttributeError: module &apos;math&apos; has no attribute &apos;sqrt&apos;</span><br></pre></td></tr></table></figure><p>这到底是怎么回事？其实，你运行这个文件的时候，Python解释器首先在当前运行脚本所处的的文件夹中查找名叫<code>math</code>的模块。在这个例子中，解释器找到了我们正在执行的模块，试图导入它。但是我们的模块中并没有叫<code>sqrt</code>的函数或属性，所以就抛出了<code>AttributeError</code>。</p><h3 id="import总结"><a href="#import总结" class="headerlink" title="import总结"></a>import总结</h3><p>在本文中，我们讲了很多有关导入的内容，但是还有部分内容没有涉及。<a href="https://www.python.org/dev/peps/pep-0302/" target="_blank" rel="noopener">PEP 302</a>中介绍了导入钩子（import hooks），支持实现一些非常酷的功能，比如说直接从github导入。Python标准库中还有一个<a href="https://docs.python.org/3/library/importlib.html" target="_blank" rel="noopener">importlib</a>模块，值得查看学习。当然，你还可以多看看别人写的代码，不断挖掘更多好用的妙招。</p><h2 id="删除字符串中指定符号"><a href="#删除字符串中指定符号" class="headerlink" title="删除字符串中指定符号"></a>删除字符串中指定符号</h2><p>源文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wxh:wxh123</span><br><span class="line"></span><br><span class="line">wsy:wsy123</span><br><span class="line"></span><br><span class="line">badou:badou123</span><br><span class="line"></span><br><span class="line">dabadou:dabadou123</span><br></pre></td></tr></table></figure><p>此时我要根据冒号（:）将两边的内容都截取出来</p><p>传统的字符串截取方式是根据索引进行区分的，这种事不能实现这种需求，这个时候需要使用函数split() </p><p>Python中有split()和os.path.split()两个函数，具体作用如下： </p><p>split()：拆分字符串。通过指定分隔符对字符串进行切片，并返回分割后的字符串列表（list） </p><p>os.path.split()：按照路径将文件名和路径分割开 </p><p>如下方代码所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with open (r&apos;C:\Users\Administrator\PycharmProjects\files\login.txt&apos;,&apos;r&apos;) as file_object:</span><br><span class="line">    for lines in file_object:</span><br><span class="line">      lines = lines.strip(&apos;\n&apos;)</span><br><span class="line">      file_username = lines.split(&apos;:&apos;, 1)[0]</span><br><span class="line">      file_password = lines.split(&apos;:&apos;, 1)[1]</span><br></pre></td></tr></table></figure><h2 id="查看python执行过程-类似sh-x"><a href="#查看python执行过程-类似sh-x" class="headerlink" title="查看python执行过程-类似sh -x"></a>查看python执行过程-类似sh -x</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#详细追踪 python -m trace --trace script.py </span><br><span class="line"></span><br><span class="line">#显示调用了哪些函数 python -m trace --trackcalls script.py</span><br></pre></td></tr></table></figure><h2 id="版本变化"><a href="#版本变化" class="headerlink" title="版本变化"></a>版本变化</h2><p>##django##</p><p><strong>外键：</strong></p><p>Django2.0版本之后，创建外键时需要在后面加上on_delete</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">topic = models.ForeignKey(Topic)</span><br></pre></td></tr></table></figure><p>应该修改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">topic = models.ForeignKey(Topic,on_delete=models.CASCADE)</span><br></pre></td></tr></table></figure><p><strong>django.core.urlresolvers变化</strong></p><p>Django 2.0 removes the django.core.urlresolvers module, which was moved to django.urls in version 1.10. You should change any import to use django.urls instead.</p><h2 id="pycharm使用"><a href="#pycharm使用" class="headerlink" title="pycharm使用"></a>pycharm使用</h2><p>解决pycharm问题：module ‘pip’ has no attribute ‘main’</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">更新pip之后，Pycharm安装package出现报错：module &apos;pip&apos; has no attribute &apos;main&apos;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">找到安装目录下 helpers/packaging_tool.py文件，找到如下代码：</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def do_install(pkgs):</span><br><span class="line">    try:</span><br><span class="line">        import pip</span><br><span class="line">    except ImportError:</span><br><span class="line">        error_no_pip()</span><br><span class="line">    return pip.main([&apos;install&apos;] + pkgs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def do_uninstall(pkgs):</span><br><span class="line">    try:</span><br><span class="line">        import pip</span><br><span class="line">    except ImportError:</span><br><span class="line">        error_no_pip()</span><br><span class="line">    return pip.main([&apos;uninstall&apos;, &apos;-y&apos;] + pkgs)</span><br></pre></td></tr></table></figure><p>修改为如下，保存即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def do_install(pkgs):</span><br><span class="line">    try:</span><br><span class="line">        # import pip</span><br><span class="line">        try:</span><br><span class="line">            from pip._internal import main</span><br><span class="line">        except Exception:</span><br><span class="line">            from pip import main</span><br><span class="line">    except ImportError:</span><br><span class="line">        error_no_pip()</span><br><span class="line">    return main([&apos;install&apos;] + pkgs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def do_uninstall(pkgs):</span><br><span class="line">    try:</span><br><span class="line">        # import pip</span><br><span class="line">        try:</span><br><span class="line">            from pip._internal import main</span><br><span class="line">        except Exception:</span><br><span class="line">            from pip import main</span><br><span class="line">    except ImportError:</span><br><span class="line">        error_no_pip()</span><br><span class="line">    return main([&apos;uninstall&apos;, &apos;-y&apos;] + pkgs)</span><br></pre></td></tr></table></figure><h2 id="创建directory和python-package的区别"><a href="#创建directory和python-package的区别" class="headerlink" title="创建directory和python package的区别"></a>创建directory和python package的区别</h2><p>对于python而言，有一点是要认识明确的，python作为一个相对而言轻量级的，易用的脚本语言（当然其功能并不仅限于此，在此只是讨论该特点），随着程序的增长，可能想要把它分成几个文件，以便逻辑更加清晰，更好维护，亦或想要在几个程序中均使用某个函数，而不必将其复制粘贴到所有程序中。</p><p>为了支持这一点，Python有一种方法将定义函数放在一个文件中，并在脚本中使用它们，这样的文件叫做模块，一个模块中的定义可以被导入到其他模块，或者主模块中。</p><p>简单来说在python中模块就是指一个py文件，如果我们将所有相关的代码都放在一个py文件中，则该py文件既是程序由是模块，但是程序和模块的设计目的是不同的，程序的目的是为了运行，而模块的目的是为了其他程序进行引</p><ul><li><p><strong>Dictionary</strong></p><p>Dictionary在pycharm中就是一个文件夹，放置资源文件，对应于在进行JavaWeb开发时用于放置css/<a href="http://lib.csdn.net/base/javascript" target="_blank" rel="noopener">js</a>文件的目录，或者说在进行物体识别时，用来存储背景图像的文件夹。该文件夹其中并不包含<em> </em> init.py<em> </em>文件</p></li><li><p><strong>Python package</strong></p><p>对于Python package 文件夹而言，与Dictionary不同之处在于其会自动创建<em> </em> init.py<em> </em>文件。  简单的说，python package就是一个目录，其中包括一组模块和一个<em> </em> init.py<em> </em>文件。</p><ul><li><p>Image/</p><p><em>_init</em> _.py</p><p>jpg.py</p><p>tiff.py</p><p>bmp.py</p></li></ul><p>只要image目录是我们程序目录的子目录，我们就可以导入image目录下的任意模块来为我们所用，使用时可如下：</p></li><li><p><strong><em> </em> init<em> </em>.py</strong></p></li></ul><p>该文件与Python的import机制有关，这关乎到你的哪些.py文件是对外可访问的。有些时候，如果<strong>一个包下有很多模块</strong>，在调用方import如此多模块是很费事，且不优雅的，此时可以通过修改<em> </em> init<em> </em>.py来完成该任务。<br>在<em> </em> init_ .py中定义特殊变量<code>_all_</code>,将要包含的模块复制给该变量。</p><p>例如在Image/<em> init</em> .py中定义 <code>_all_</code>=[‘tiff’,’bmp’,’jpg’],这里的all 对应的就是 from …import  中代指的模块，此时在引用方使用如下语句： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from image import *</span><br><span class="line">tool = tiff.read(&apos;a.tiff&apos;)</span><br></pre></td></tr></table></figure><p>其实<em> </em> init_ .py可以为空，当其为空时，from Image import *将Image包下<strong>所有的模块都进行引用</strong>，如果想要控制引用的模块，则可以自行定义 <em>all</em></p><h2 id="python的dict和json的区别"><a href="#python的dict和json的区别" class="headerlink" title="python的dict和json的区别"></a>python的dict和json的区别</h2><p>工作中和其他语言的工程师交流，合作与联调中经常会涉及到数据的传输，这个数据的传输通常为json字符串，这个json格式数据和python自身的dict数据对象非常像，所以很自然的会思考这两者究竟区别在哪里？</p><p><strong>首先，两者不一样</strong></p><h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ul><li>Python 的字典是一种数据结构，JSON 是一种数据格式。</li></ul><p>json 就是一个根据某种约定格式编写的纯字符串，不具备任何数据结构的特征。而 python 的字典的字符串表现形式的规则看上去和 json 类似，但是字典本身是一个完整的数据结构，实现了一切自身该有的算法。</p><ul><li>Python的字典key可以是任意可hash对象，json只能是字符串。</li></ul><p>形式上有些相像，但JSON是纯文本的，无法直接操作。</p><ul><li>1.python dict 字符串用单引号，<strong>json强制规定双引号。</strong></li><li>2.python dict 里可以嵌套tuple,json里只有array。 json.dumps({1:2}) 的结果是 ｛”1”:2}； json.dumps((1,2)) 的结果是[1,2]</li><li>3.json key name 必须是字符串,   python 是hashable,  {(1,2):1} 在python里是合法的,因为tuple是hashable type；{[1,2]:1} 在python里TypeError: unhashable “list”</li><li>4.json: true false null ；  python:True False None</li><li><ol><li>python {“me”: “我”} 是合法的；    json 必须是 {“me”: “\u6211”}</li></ol></li></ul><h3 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h3><p>dict 存在于内存中，可以被序列化成 json 格式的数据（string），之后这些数据就可以传输或者存储了。<br> JSON 是一种数据传输格式。<br> 也就是说，这些字符串以 JSON 这样的格式来传输，至于你怎么 parse 这些信息，甚至是是否 parse，是否储存，都不是 JSON 的事情。<br> 用 Python 举个例子: 某段程序可以把字符串 <code>&quot;{A:1, B:2}&quot;</code> parse 成 一对 tuple<code>( (&quot;A&quot;, 1), (&quot;B&quot;, 2) )</code>而不是 dictionary <code>{&quot;A&quot;: 1, &quot;B&quot;: 2}</code>。Python 的 dictionary 是对 Hash Table 这一数据结构的一种实现。它使用其内置的哈希函数来规划键对应的内容的储存位置，从而获得 O(1) 的数据读取速度。所以 JSON 是一种数据传输格式，它能被解析成 Python 的 Dictionary 或者其他形式，但解析成什么内容是和 JSON 这种格式无关的。Python 的 Dictionary 则是 Python 对 Hash Table 的实现，一套从存储到提取都封装好了的方案。</p><h2 id="Python-2-7-12-源码安装pip"><a href="#Python-2-7-12-源码安装pip" class="headerlink" title="Python 2.7.12 源码安装pip"></a>Python 2.7.12 源码安装pip</h2><p>wget  <a href="https://bootstrap.pypa.io/get-pip.py" target="_blank" rel="noopener">https://bootstrap.pypa.io/get-pip.py</a></p><p>./python get-pip.py</p><h2 id="if-name-‘main‘-如何正确理解"><a href="#if-name-‘main‘-如何正确理解" class="headerlink" title="if __name__ == ‘main‘ 如何正确理解?"></a>if <code>__name__</code> == ‘<strong>main</strong>‘ 如何正确理解?</h2><p>这里的作用主要是作为整个程序的一个入口</p><p>对于很多编程语言来说，程序都必须要有一个入口，比如 C，C++，以及完全面向对象的编程语言 Java，C# 等。如果你接触过这些语言，对于程序入口这个概念应该很好理解，C 和 C++ 都需要有一个 main 函数来作为程序的入口，也就是程序的运行会从 main 函数开始。同样，Java 和 C# 必须要有一个包含 Main 方法的主类来作为程序入口。</p><p>而 Python 则有不同，它属于脚本语言，不像编译型语言那样先将程序编译成二进制再运行，而是动态的逐行解释运行。也就是从脚本第一行开始运行，没有统一的入口。</p><p>一个 Python 源码文件除了可以被直接运行外，还可以作为模块（也就是库）被导入。不管是导入还是直接运行，最顶层的代码都会被运行（Python 用缩进来区分代码层次）。而实际上在导入的时候，有一部分代码我们是不希望被运行的。</p><p>详细内容可以看这篇文章：<a href="http://blog.konghy.cn/2017/04/24/python-entry-program/" target="_blank" rel="noopener">http://blog.konghy.cn/2017/04/24/python-entry-program/</a></p><h2 id="获取当前py文件目录"><a href="#获取当前py文件目录" class="headerlink" title="获取当前py文件目录"></a>获取当前py文件目录</h2><ul><li><p>当前目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">path.dirname(__file__)</span><br></pre></td></tr></table></figure></li><li><p>上级目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">path.abspath(path.dirname(path.dirname(__file__)))</span><br></pre></td></tr></table></figure></li></ul><h2 id="byte类型和str类型之间的转换"><a href="#byte类型和str类型之间的转换" class="headerlink" title="byte类型和str类型之间的转换"></a>byte类型和str类型之间的转换</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># bytes object</span><br><span class="line">b = b&quot;example&quot;</span><br><span class="line"> </span><br><span class="line"># str object</span><br><span class="line">s = &quot;example&quot;</span><br><span class="line"></span><br><span class="line"># str to bytes</span><br><span class="line">bytes(s, encoding = &quot;utf8&quot;)</span><br><span class="line"> </span><br><span class="line"># bytes to str</span><br><span class="line">str(b, encoding = &quot;utf-8&quot;)</span><br><span class="line"> </span><br><span class="line"># an alternative method</span><br><span class="line"># str to bytes</span><br><span class="line">str.encode(s)</span><br><span class="line"> </span><br><span class="line"># bytes to str</span><br><span class="line">bytes.decode(b</span><br></pre></td></tr></table></figure><h2 id="时间戳转换"><a href="#时间戳转换" class="headerlink" title="时间戳转换"></a>时间戳转换</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">now_time = time.strftime(&quot;%H:%M:%S&quot;)</span><br><span class="line">today = datetime.date.today()</span><br><span class="line">past_date = today - datetime.timedelta(days=days)</span><br><span class="line">today_time = str(today) + &quot; &quot; + now_time</span><br><span class="line">past_day_time = str(past_date) + &quot; &quot; + now_time</span><br><span class="line"># 将时间转换成为时间戳</span><br><span class="line">start_time = int(time.mktime(time.strptime(today_time, &quot;%Y-%m-%d %H:%M:%S&quot;)))</span><br><span class="line">end_time = int(time.mktime(time.strptime(past_day_time, &quot;%Y-%m-%d %H:%M:%S&quot;)))</span><br></pre></td></tr></table></figure><h2 id="Python-requests-post方法中data与json参数区别"><a href="#Python-requests-post方法中data与json参数区别" class="headerlink" title="Python requests.post方法中data与json参数区别"></a>Python requests.post方法中data与json参数区别</h2><p>在通过requests.post()进行POST请求时，传入报文的参数有两个，一个是data，一个是json。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data与json既可以是str类型，也可以是dict类型。</span><br></pre></td></tr></table></figure><p>区别：</p><p>1、不管<code>json</code>是<code>str</code>还是<code>dict</code>，如果不指定<code>headers</code>中的<code>content-type</code>，默认为<code>application/json</code></p><p>2、<code>data</code>为<code>dict</code>时，如果不指定<code>content-type</code>，默认为<code>application/x-www-form-urlencoded</code>，相当于普通form表单提交的形式</p><p>3、<code>data</code>为<code>str</code>时，如果不指定<code>content-type</code>，默认为<code>application/json</code></p><p>4、用data参数提交数据时，<code>request.body</code>的内容则为<code>a=1&amp;b=2</code>的这种形式，用json参数提交数据时，<code>request.body</code>的内容则为’{“<code>a&quot;: 1, &quot;b&quot;: 2}&#39;</code>的这种形式</p><h2 id="python-添加项目目录"><a href="#python-添加项目目录" class="headerlink" title="python 添加项目目录"></a>python 添加项目目录</h2><p>代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">current_dir = os.path.abspath(os.path.dirname(__file__))</span><br><span class="line">parent_dir = os.path.dirname(current_dir)</span><br><span class="line">sys.path.append(parent_dir)</span><br></pre></td></tr></table></figure><h2 id="python列表-根据值获取索引下标"><a href="#python列表-根据值获取索引下标" class="headerlink" title="python列表-根据值获取索引下标"></a>python列表-根据值获取索引下标</h2><p>代码为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index_num=list_name.index(value)</span><br></pre></td></tr></table></figure><h1 id="补充-git使用"><a href="#补充-git使用" class="headerlink" title="补充-git使用"></a>补充-git使用</h1><h2 id="git输入用户名密码"><a href="#git输入用户名密码" class="headerlink" title="git输入用户名密码"></a>git输入用户名密码</h2><p>使用如下这种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone http://wangxiaohua:密码@192.168.1.66/wangxiaohua/es-monitor.git</span><br><span class="line">或者</span><br><span class="line">git clone http://wangxiaohua:密码@git.nidianwo.com/wangxiaohua/es-monitor.git</span><br></pre></td></tr></table></figure><h2 id="gitignore文件的编写"><a href="#gitignore文件的编写" class="headerlink" title=".gitignore文件的编写"></a>.gitignore文件的编写</h2><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  dnamed git:(master) cat .gitignore</span><br><span class="line">*.pyc</span><br><span class="line">*.log</span><br><span class="line">logs/*</span><br><span class="line">db.sqlite3</span><br></pre></td></tr></table></figure><p><strong>注意：</strong></p><p>.gitignore只能忽略那些原来没有被 track 的文件，如果某些文件已经被纳入了版本管理中，则修改 .gitignore 是无效的。<br>解决方法是先把本地缓存删除，然后再提交。</p><p>执行下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git rm -r --cached .</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;commit content&quot;</span><br><span class="line">git push -u origin master</span><br></pre></td></tr></table></figure><h1 id="补充-python操作mysql"><a href="#补充-python操作mysql" class="headerlink" title="补充-python操作mysql"></a>补充-python操作mysql</h1><p>参考文献</p><ul><li><a href="http://www.runoob.com/python/python-mysql.html" target="_blank" rel="noopener">菜鸟教程</a></li></ul><h2 id="实际案例-3"><a href="#实际案例-3" class="headerlink" title="实际案例"></a>实际案例</h2><p>在py3中，我们一般使用pymysql这个客户端去连接mysql数据库</p><h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><h2 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h2><h2 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h2>]]></content>
    
    <summary type="html">
    
      python从入门到实践
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="编程开发" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>ELK部署</title>
    <link href="http://yoursite.com/2019/06/18/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/ELK%E9%83%A8%E7%BD%B2/ELK%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2019/06/18/IT科学技术知识体系结构-Linux运维方向/大数据/ELK/ELK部署/ELK部署/</id>
    <published>2019-06-18T09:19:33.000Z</published>
    <updated>2019-06-18T09:19:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="实现架构"><a href="#实现架构" class="headerlink" title="实现架构"></a>实现架构</h2><p>传统的ELK是使用elasticsearch+logstash+kibana的方式来部署日志收集系统</p><p>但是在数据量较大下，该架构过于单薄存在各种问题，因此，我们这里所使用的架构是：</p><p>Filebeat—&gt;kafka—&gt;logstash—&gt;[elasticsearch、filesystem、kafka]</p><p>也就是说将客户端收集替换成了filebeat，将日志推送到kafka中，然后在用logstash收集kafaka中的数据，logstash的output可以是es、文件服务器等等</p><h2 id="架构说明"><a href="#架构说明" class="headerlink" title="架构说明"></a>架构说明</h2><h1 id="Filebeat部署"><a href="#Filebeat部署" class="headerlink" title="Filebeat部署"></a>Filebeat部署</h1><h2 id="filebeat工作原理"><a href="#filebeat工作原理" class="headerlink" title="filebeat工作原理"></a>filebeat工作原理</h2><p>Filebeat是本地文件的日志数据采集器，作为服务器上的代理安装。</p><p>Filebeat监视指定的日志目录或特定日志文件，使用tail -f file的机制，收集之后将它们转发给Elasticsearch或Logstash或kafka等进行存储。</p><p><strong>Filebeat由两个主要组件组成：</strong></p><ul><li><p>prospector    探勘器、查找器</p></li><li><p>harvester    采集器</p></li></ul><p><strong>工作过程概述：</strong></p><p>启动Filebeat时，启动<strong>一个或多个</strong>prospector，查看指定的日志文件<strong>目录或者单个文件</strong>。</p><p>对于涉及的每个日志文件，prospector 启动对应数量的harvester， 每个harvester会读取到指定文件的新内容，将新数据发送到libbeat，libbeat将聚合事件并将聚合数据发送到你为Filebeat配置的输出。</p><h3 id="prospector"><a href="#prospector" class="headerlink" title="prospector"></a>prospector</h3><p>prospector有2个职责：负责找到所有需要收集的文件对象，以及管理harvester</p><p>注意：prospector只能读取本地文件， 不能连接到远程主机来读取存储的文件或日志。</p><h3 id="harvester"><a href="#harvester" class="headerlink" title="harvester"></a>harvester</h3><p>harvester只有1个职责：负责读取单个文件的内容，并将内容发送到指定的output</p><p>prospector会为每一个要收集的文件都启动一个harvester<br>harvester 负责打开和关闭文件，这意味着在运行时文件描述符保持打开状态，如果文件在读取时被删除或重命名，Filebeat将继续读取文件。也就是说，这会存在一个问题，就是如果文件被删了了，但是在harvester关闭之前，磁盘上的空间将会被保留无法释放。默认情况下，Filebeat将文件保持打开状态，直到达到close_inactive状态</p><h2 id="Filebeat如何保持文件的状态？"><a href="#Filebeat如何保持文件的状态？" class="headerlink" title="Filebeat如何保持文件的状态？"></a>Filebeat如何保持文件的状态？</h2><p>prospector保存每个文件的状态并经常将状态刷新到磁盘上的注册文件(data/registry)中。</p><p>该状态的作用是用于harvester记住正在读取文件的最后偏移量，并确保发送所有日志行。如果输出（例如Elasticsearch或Logstash）无法访问，Filebeat会检测output，并在oputput再次可用时继续读取文件发送。</p><p>在Filebeat运行时，每个prospector内存中也会保存的文件状态信息，<br>当重新启动Filebeat时，将使用注册文件的数据来重建文件状态，每个harvester基于注册文件中记录的最后偏移量继续读取。</p><p>因为文件可以被重命名或移动，因此文件名和路径不足以识别文件，对于每个文件，Filebeat存储唯一标识符以检测文件是否先前已采集过。</p><p>如果每天会创建大量新文件，注册文件增长可能过大。这个时候参阅注册表文件太大相关问题？</p><h2 id="Filebeat如何确保至少一次分发"><a href="#Filebeat如何确保至少一次分发" class="headerlink" title="Filebeat如何确保至少一次分发"></a>Filebeat如何确保至少一次分发</h2><p>Filebeat保证所有的事件至少会被传送到配置的output一次，并且不会丢失数据。 Filebeat之所以能够实现此行为，因为它将每个事件的传递状态存储在注册文件中。</p><p>如果输出（例如Elasticsearch或Logstash）无法访问，Filebeat会检测output，并在oputput再次可用时继续读取文件发送。</p><p>如果Filebeat在发送事件的过程中关闭，它不会等待output确认所有收到事件。发送到output但未确认的任何事件将会在在重新启动Filebeat后再次发送，这可以确保每个事件至少发送一次，但最终可能会将重复发送事件发送到output</p><p>介于这个特性，我们可以配置shutdown_timeout参数来指定，在手动关闭filebeat时，等待多久才停止进程</p><p>注意：Filebeat的至少一次交付保证在日志轮换和删除旧文件时有限制。如果将日志文件写入磁盘并且写入速度超过Filebeat可以处理的速度，或者在output不可用时删除了文件，则可能会丢失数据。<br>在Linux上，Filebeat也可能因inode重用而跳过行</p><h2 id="filebeat安装配置"><a href="#filebeat安装配置" class="headerlink" title="filebeat安装配置"></a>filebeat安装配置</h2><h3 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h3><p>Before running Filebeat, you need to install and configure the Elastic stack. See <a href="http://www.elastic.co/guide/en/beats/libbeat/6.2/getting-started.html" target="_blank" rel="noopener">Getting Started with Beats and the Elastic Stack</a>.</p><p>A regular <em>Beats setup</em> consists of:</p><ul><li>Elasticsearch for storage and indexing. See <a href="https://www.elastic.co/guide/en/beats/libbeat/6.2/elasticsearch-installation.html" target="_blank" rel="noopener">Install Elasticsearch</a>.</li><li>Logstash (optional) for inserting data into Elasticsearch. See <a href="https://www.elastic.co/guide/en/beats/libbeat/6.2/logstash-installation.html" target="_blank" rel="noopener">Installing Logstash</a>.</li><li>Kibana for the UI. See <a href="https://www.elastic.co/guide/en/beats/libbeat/6.2/kibana-installation.html" target="_blank" rel="noopener">Install Kibana</a>.</li><li>One or more Beats. You install the Beats on your servers to capture operational data. See <a href="https://www.elastic.co/guide/en/beats/libbeat/6.2/installing-beats.html" target="_blank" rel="noopener">Install Beats</a>.</li><li>Kibana dashboards for visualizing the data.</li></ul><p>也就是说，在部署filebeat之前，我们需要ELK环境，相当于说filebeat是在ELK的基础之上的一个组件。</p><p>如果还没有ELK环境的，先跳转到ES部分。</p><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>在这里，我们使用源码包的方式安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.3-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>默认的配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[appdeploy@node001 filebeat6]$ cat filebeat.yml</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  enabled: false</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/*.log</span><br><span class="line">filebeat.config.modules:</span><br><span class="line">  path: $&#123;path.config&#125;/modules.d/*.yml</span><br><span class="line">  reload.enabled: false</span><br><span class="line">setup.template.settings:</span><br><span class="line">  index.number_of_shards: 3</span><br><span class="line">setup.kibana:</span><br><span class="line">output.elasticsearch:</span><br><span class="line">  hosts: [&quot;localhost:9200&quot;]</span><br></pre></td></tr></table></figure><p>一个实际的案例配置文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">filebeat.shutdown_timeout: 10s</span><br><span class="line">filebeat.config.prospectors:</span><br><span class="line">  enabled: true</span><br><span class="line">  path: conf/*.yml</span><br><span class="line">  reload.enabled: true</span><br><span class="line">  reload.period: 10s</span><br><span class="line">output.kafka:</span><br><span class="line">  hosts: [&quot;172.24.48.76:19092&quot;, &quot;172.24.48.77:19092&quot;, &quot;172.24.48.78:19092&quot;]</span><br><span class="line">  topic: &apos;%&#123;[fields.log_topic]&#125;&apos;</span><br><span class="line">  key: &apos;%&#123;[fields.app_name]&#125; %&#123;[beat.hostname]&#125;&apos;</span><br><span class="line">  required_acks: 1</span><br><span class="line">  workers: 6</span><br><span class="line">  timeout: 120</span><br><span class="line">  compression: snappy</span><br><span class="line">  max_message_bytes: 10240000</span><br><span class="line">  codec.format:</span><br><span class="line">     string: &apos;%&#123;[fields.app_name]&#125; %&#123;[beat.hostname]&#125; %&#123;[message]&#125;&apos;</span><br><span class="line">xpack.monitoring:</span><br><span class="line">  enabled: true</span><br><span class="line">  elasticsearch:</span><br><span class="line">    hosts: [&quot;http://172.24.48.76:9200&quot;, &quot;http://172.24.48.77:9200&quot;, &quot;http://172.24.48.78:9200&quot;]</span><br></pre></td></tr></table></figure><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><pre><code>nohup /home/appdeploy/deploy/tools/filebeat6/filebeat -e -c /home/appdeploy/deploy/tools/filebeat6/applogg.yml &gt;&gt;/home/appdeploy/deploy/tools/filebeat6/applogg.log &amp;</code></pre><h2 id="filebeat的模块"><a href="#filebeat的模块" class="headerlink" title="filebeat的模块"></a>filebeat的模块</h2><p>filebeat的模块简化了收集、解析以及可视化例如nginx、Redis、mysql等通用日志格式这一系列操作。</p><p>也就是说，通过使用这些现成的模块，我们可以快速的进行收集，而免去了比较繁琐的自定义设置。</p><h2 id="filebeat的配置详解"><a href="#filebeat的配置详解" class="headerlink" title="filebeat的配置详解"></a>filebeat的配置详解</h2><h3 id="设置prospectors-探勘器、查找器"><a href="#设置prospectors-探勘器、查找器" class="headerlink" title="设置prospectors- 探勘器、查找器"></a>设置prospectors- 探勘器、查找器</h3><p>filebeat使用prospectors去定位和处理文件。</p><p>在yml配置文件中以”filebeat.prospectors:”开头，下面的列表代表每一个prospectors(一个type就是一个prospectors)</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/apache/httpd-*.log</span><br><span class="line"></span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/messages</span><br><span class="line">    - /var/log/*.log</span><br></pre></td></tr></table></figure><p>filebeat将会为每一个文件都启动一个harvester。</p><p>在prospectors这一栏中，有一些参数可以配置：</p><ul><li><p>type。下面是一些常用的二级参数，归属于type下</p><ul><li><p>paths：文件的路径列表</p></li><li><p>exclude_lines</p></li><li><p>Include_lines</p></li><li><p>tags。tags可以用于后面的logstash过滤</p></li><li><p>fileds</p></li><li><p>scan_frequency：在指定的path下，每隔多久去检测是否有新文件</p></li><li><p>harvester_buffer_size</p></li><li><p>max_bytes。这个参数需要关注下。</p></li><li><p>tail_files</p><blockquote><p>如果这个参数被设置为true，</p></blockquote></li></ul></li></ul><h3 id="Multiline-多行合并管理"><a href="#Multiline-多行合并管理" class="headerlink" title="Multiline-多行合并管理"></a>Multiline-多行合并管理</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/beats/filebeat/6.2/multiline-examples.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/6.2/multiline-examples.html</a></p><p>因为在应用的日志输出中，例如java的堆栈信息等，输出是多行的形式，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[beat-logstash-some-name-832-2015.11.28] IndexNotFoundException[no such index]</span><br><span class="line">    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:566)</span><br><span class="line">    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:133)</span><br><span class="line">    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:77)</span><br><span class="line">    at org.elasticsearch.action.admin.indices.delete.TransportDeleteIndexAction.checkBlock(TransportDeleteIndexAction.java:75)</span><br></pre></td></tr></table></figure><p>这几行其实是同一段，我们要放在一起展示，所以需要把这多行的信息进行归纳。这时，就使用到了多行合并的功能</p><p>配置案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /home/appdeploy/deploy/logs/rider-mission-card/rider-mission-card.log</span><br><span class="line">  multiline.pattern: &apos;^[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&apos;</span><br><span class="line">  multiline.negate: true</span><br><span class="line">  multiline.match: after</span><br></pre></td></tr></table></figure><p>上面配置的意思是：不以’^[0-9]{4}-[0-9]{2}-[0-9]{2}’开头的行都合并到上一行的末尾</p><p>配置项说明：</p><ul><li><p>pattern：正则表达式</p></li><li><p>negate：true 或 false；控制是否匹配上面的正则表达式规则</p><p>默认是false，匹配pattern的行，合并到上一行；</p><p>true，匹配到pattern的行，不合并到上一行</p></li><li><p>match：after 或 before，控制如何合并。合并到上一行的末尾或者开头。</p><p>处理java等日志时，我们肯定是合并到上一行的后面。</p></li></ul><h3 id="加载外部的配置文件"><a href="#加载外部的配置文件" class="headerlink" title="加载外部的配置文件"></a>加载外部的配置文件</h3><h4 id="prospector-config"><a href="#prospector-config" class="headerlink" title="prospector config"></a><strong>prospector config</strong></h4><p>探勘器、查找器使用如下的方式去加载外部的配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">filebeat.config.prospectors:</span><br><span class="line">  enabled: true</span><br><span class="line">  path: configs/*.yml</span><br></pre></td></tr></table></figure><p>被加载的外部文件的格式应该是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/mysql.log</span><br><span class="line">  scan_frequency: 10s</span><br><span class="line"></span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/apache.log</span><br><span class="line">  scan_frequency: 5s</span><br></pre></td></tr></table></figure><h4 id="动态重加载"><a href="#动态重加载" class="headerlink" title="动态重加载"></a>动态重加载</h4><p>当配置的，加载外部文件的路径下有文件更新时，filebeat需要能够感知，所以filebeat提供了一个reload的功能。</p><p>配置方式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">filebeat.config.prospectors:</span><br><span class="line">  enabled: true</span><br><span class="line">  path: configs/*.yml</span><br><span class="line">  reload.enabled: true</span><br><span class="line">  reload.period: 10s</span><br></pre></td></tr></table></figure><p>注意：period的值不要设置少于1s，因为修改文件的操作往往在s级左右，</p><h2 id="output配置"><a href="#output配置" class="headerlink" title="output配置"></a>output配置</h2><h3 id="es"><a href="#es" class="headerlink" title="es"></a>es</h3><p>当使用filebeat直接连接es或者kibana时，如果有密码配置，配置文件应该为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">output.elasticsearch:</span><br><span class="line">  hosts: [&quot;myEShost:9200&quot;]</span><br><span class="line">  username: &quot;elastic&quot;</span><br><span class="line">  password: &quot;elastic&quot;</span><br><span class="line">setup.kibana:</span><br><span class="line">  host: &quot;mykibanahost:5601&quot;</span><br><span class="line">  username: &quot;elastic&quot;  </span><br><span class="line">  password: &quot;elastic&quot;</span><br></pre></td></tr></table></figure><h3 id="logstash"><a href="#logstash" class="headerlink" title="logstash"></a>logstash</h3><p>在filebeat的output中指定logstash即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#----------------------------- Logstash output --------------------------------</span><br><span class="line">output.logstash:</span><br><span class="line">  hosts: [&quot;127.0.0.1:5044&quot;]</span><br><span class="line">  loadbalance: true</span><br><span class="line">  worker: 4</span><br></pre></td></tr></table></figure><p>这里有几个比较常用的参数：</p><ul><li>worker：指定为每个主机的工作进程数，例如设置为2，output主机为2，那么总数为4</li><li>loadbalance：当后端有多个logstash主机时，可以设置为true</li></ul><h3 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h3><p>配置格式如下：</p><h2 id="filebeat监控"><a href="#filebeat监控" class="headerlink" title="filebeat监控"></a>filebeat监控</h2><h2 id="配置文件权限问题"><a href="#配置文件权限问题" class="headerlink" title="配置文件权限问题"></a>配置文件权限问题</h2><p>filebeat在启动的时候，可能会出现下面的问题：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019-08-02T15:57:04.027+0800    ERROR   cfgfile/reload.go:237   Error loading config: invalid config: config file (&quot;/home/appdeploy/deploy/tools/filebeat6/conf/httpdns.yml&quot;) can only be writable by the owner but the permissions are &quot;-rw-rw-r--&quot; (to fix the permissions use: &apos;chmod go-w /home/appdeploy/deploy/tools/filebeat6/conf/httpdns.yml&apos;)</span><br></pre></td></tr></table></figure><p>文件的权限需要是644，在创建文件时，默认的权限是664</p><h2 id="系统日志权限问题"><a href="#系统日志权限问题" class="headerlink" title="系统日志权限问题"></a>系统日志权限问题</h2><p>当收集系统日志时，例如cron、secure、message、kern.log等时，如果filebeat使用的时候非root用户启动，那么默认是没有权限读取这些文件的，这个时候，我们就需要对这些日志进行相应的配置，保证启动用户对系统日志有权限。</p><h2 id="filebea案例"><a href="#filebea案例" class="headerlink" title="filebea案例"></a>filebea案例</h2><h3 id="收集终端标准输出"><a href="#收集终端标准输出" class="headerlink" title="收集终端标准输出"></a>收集终端标准输出</h3><h1 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h1><h2 id="logstash概述"><a href="#logstash概述" class="headerlink" title="logstash概述"></a>logstash概述</h2><p>logstash是一个具备实时pipelining流水线能力的数据收集引擎，它能动态的统一来自不同数据源的数据，规范化后发往output，</p><h3 id="logstash工作流"><a href="#logstash工作流" class="headerlink" title="logstash工作流"></a>logstash工作流</h3><p>logstash的工作流非常简单：inputs → filters → outputs</p><ul><li>input：</li></ul><h2 id="logstash术语表-glossary-of-terms"><a href="#logstash术语表-glossary-of-terms" class="headerlink" title="logstash术语表-glossary of terms"></a>logstash术语表-glossary of terms</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/logstash/6.2/glossary.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/glossary.html</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>我们一般使用源码包的安装方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://artifacts.elastic.co/downloads/logstash/logstash-6.2.3.tar.gz</span><br></pre></td></tr></table></figure><p>下载下来之后，解压即可。</p><p>在安装之后，我们可以启动一个最简单的pipeline去测试功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd logstash-6.2.3</span><br><span class="line">bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&apos;</span><br></pre></td></tr></table></figure><p>-e参数可以让我们在命令行直接指定配置，而不是去编辑配置配置，这里的意思是input和output是使用标准输入和标准输出。</p><p>完整的输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[elk@node002 logstash-6.2.3]$ bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&apos;</span><br><span class="line"></span><br><span class="line">Sending Logstash&apos;s logs to /home/elk/logstash-6.2.3/logs which is now configured via log4j2.properties</span><br><span class="line">[2019-07-29T10:53:06,777][INFO ][logstash.modules.scaffold] Initializing module &#123;:module_name=&gt;&quot;fb_apache&quot;, :directory=&gt;&quot;/home/elk/logstash-6.2.3/modules/fb_apache/configuration&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:06,874][INFO ][logstash.modules.scaffold] Initializing module &#123;:module_name=&gt;&quot;netflow&quot;, :directory=&gt;&quot;/home/elk/logstash-6.2.3/modules/netflow/configuration&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:08,037][INFO ][logstash.setting.writabledirectory] Creating directory &#123;:setting=&gt;&quot;path.queue&quot;, :path=&gt;&quot;/home/elk/logstash-6.2.3/data/queue&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:08,088][INFO ][logstash.setting.writabledirectory] Creating directory &#123;:setting=&gt;&quot;path.dead_letter_queue&quot;, :path=&gt;&quot;/home/elk/logstash-6.2.3/data/dead_letter_queue&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:11,772][WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified</span><br><span class="line">[2019-07-29T10:53:12,855][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID &#123;:uuid=&gt;&quot;f9f6fb83-176e-4ba1-8065-ca5699df67fa&quot;, :path=&gt;&quot;/home/elk/logstash-6.2.3/data/uuid&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:25,521][INFO ][logstash.runner          ] Starting Logstash &#123;&quot;logstash.version&quot;=&gt;&quot;6.2.3&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:34,693][INFO ][logstash.agent           ] Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;</span><br><span class="line">[2019-07-29T10:54:13,765][INFO ][logstash.pipeline        ] Starting pipeline &#123;:pipeline_id=&gt;&quot;main&quot;, &quot;pipeline.workers&quot;=&gt;4, &quot;pipeline.batch.size&quot;=&gt;125, &quot;pipeline.batch.delay&quot;=&gt;50&#125;</span><br><span class="line">[2019-07-29T10:54:16,628][INFO ][logstash.pipeline        ] Pipeline started succesfully &#123;:pipeline_id=&gt;&quot;main&quot;, :thread=&gt;&quot;#&lt;Thread:0x7028647c run&gt;&quot;&#125;</span><br><span class="line">The stdin plugin is now waiting for input:</span><br><span class="line">[2019-07-29T10:54:19,144][INFO ][logstash.agent           ] Pipelines running &#123;:count=&gt;1, :pipelines=&gt;[&quot;main&quot;]&#125;</span><br><span class="line">2019-07-29T02:54:20.429Z node002</span><br><span class="line">2019-07-29T02:54:20.463Z node002</span><br><span class="line">2019-07-29T02:54:34.399Z node002</span><br><span class="line">hello world</span><br><span class="line">2019-07-29T02:54:39.357Z node002 hello world</span><br></pre></td></tr></table></figure><h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><h3 id="filebeat-logstash配置案例"><a href="#filebeat-logstash配置案例" class="headerlink" title="filebeat+logstash配置案例"></a>filebeat+logstash配置案例</h3><p>filebeat端配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[appdeploy@node001 filebeat6]$ cat filebeat.yml</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /home/appdeploy/logstash-tutorial.log</span><br><span class="line">output.logstash:</span><br><span class="line">  hosts: [&quot;192.168.101.172:5144&quot;]</span><br><span class="line">[appdeploy@node001 filebeat6]$</span><br></pre></td></tr></table></figure><p>启动filebeat：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./filebeat -e -c filebeat.yml -d "publish"</span><br></pre></td></tr></table></figure><p>logstash端配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[elk@node002 logstash-6.2.3]$ cat config/first-pipeline.conf</span><br><span class="line">input &#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; &quot;5144&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编辑完配置文件之后，我们可以检测一下配置文件的正确性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[elk@node002 logstash-6.2.3]$ ./bin/logstash -f config/first-pipeline.conf --config.test_and_exit</span><br></pre></td></tr></table></figure><p>执行后的输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Sending Logstash&apos;s logs to /home/elk/logstash-6.2.3/logs which is now configured via log4j2.properties</span><br><span class="line">[2019-07-29T11:22:44,111][INFO ][logstash.modules.scaffold] Initializing module &#123;:module_name=&gt;&quot;fb_apache&quot;, :directory=&gt;&quot;/home/elk/logstash-6.2.3/modules/fb_apache/configuration&quot;&#125;</span><br><span class="line">[2019-07-29T11:22:44,199][INFO ][logstash.modules.scaffold] Initializing module &#123;:module_name=&gt;&quot;netflow&quot;, :directory=&gt;&quot;/home/elk/logstash-6.2.3/modules/netflow/configuration&quot;&#125;</span><br><span class="line">[2019-07-29T11:22:49,059][WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified</span><br><span class="line">Configuration OK</span><br><span class="line">[2019-07-29T11:23:29,319][INFO ][logstash.runner          ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash</span><br><span class="line">[elk@node002 logstash-6.2.3]$</span><br></pre></td></tr></table></figure><p>检测通过之后，我们可以启动logsatsh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/logstash -f config/first-pipeline.conf --config.reload.automatic</span><br></pre></td></tr></table></figure><p>—config.reload.automatic参数的作用是，当我们修改了配置文件之后，进程能够自动的reload</p><h3 id="grok过滤"><a href="#grok过滤" class="headerlink" title="grok过滤"></a>grok过滤</h3><p>查看当前logstash已安装的所有插件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 logstash-6.2.3]$ bin/logstash-plugin list</span><br></pre></td></tr></table></figure><p>grok插件能够帮助你解析结构凌乱的日志，转变成有结构的以及可查询的。</p><p>从源数据中拆分出我们需要的字段进行展示。</p><p>grok使用正则表达式去匹配源的数据</p><p>一个简单的案例：</p><p>我们使用logstash内置的%{COMBINEDAPACHELOG}进行匹配</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 config]$ cat first-pipeline.conf</span><br><span class="line">input &#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; &quot;5144&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>reload或者重启后，在filebeat节点上删除注册文件之后，在重新启动filebeat，logstash端的显示为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">     &quot;@timestamp&quot; =&gt; 2019-07-29T08:53:35.835Z,</span><br><span class="line">        &quot;message&quot; =&gt; &quot;192.1.76.62 - - [04/Jan/2015:05:30:37 +0000] \&quot;GET /style2.css HTTP/1.1\&quot; 200 4877 \&quot;http://www.semicomplete.com/projects/xdotool/\&quot; \&quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\&quot;&quot;,</span><br><span class="line">          &quot;ident&quot; =&gt; &quot;-&quot;,</span><br><span class="line">     &quot;prospector&quot; =&gt; &#123;</span><br><span class="line">        &quot;type&quot; =&gt; &quot;log&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">      &quot;timestamp&quot; =&gt; &quot;04/Jan/2015:05:30:37 +0000&quot;,</span><br><span class="line">       &quot;clientip&quot; =&gt; &quot;192.1.76.62&quot;,</span><br><span class="line">       &quot;referrer&quot; =&gt; &quot;\&quot;http://www.semicomplete.com/projects/xdotool/\&quot;&quot;,</span><br><span class="line">           &quot;verb&quot; =&gt; &quot;GET&quot;,</span><br><span class="line">         &quot;source&quot; =&gt; &quot;/home/appdeploy/logstash-tutorial.log&quot;,</span><br><span class="line">           &quot;beat&quot; =&gt; &#123;</span><br><span class="line">        &quot;hostname&quot; =&gt; &quot;node001&quot;,</span><br><span class="line">         &quot;version&quot; =&gt; &quot;6.2.3&quot;,</span><br><span class="line">            &quot;name&quot; =&gt; &quot;node001&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">       &quot;@version&quot; =&gt; &quot;1&quot;,</span><br><span class="line">           &quot;host&quot; =&gt; &quot;node001&quot;,</span><br><span class="line">       &quot;response&quot; =&gt; &quot;200&quot;,</span><br><span class="line">          &quot;bytes&quot; =&gt; &quot;4877&quot;,</span><br><span class="line">          &quot;agent&quot; =&gt; &quot;\&quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\&quot;&quot;,</span><br><span class="line">        &quot;request&quot; =&gt; &quot;/style2.css&quot;,</span><br><span class="line">         &quot;offset&quot; =&gt; 24898,</span><br><span class="line">           &quot;tags&quot; =&gt; [</span><br><span class="line">        [0] &quot;beats_input_codec_plain_applied&quot;</span><br><span class="line">    ],</span><br><span class="line">           &quot;auth&quot; =&gt; &quot;-&quot;,</span><br><span class="line">    &quot;httpversion&quot; =&gt; &quot;1.1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>%{COMBINEDAPACHELOG}包含的格式是：</p><table><thead><tr><th><strong>Information</strong></th><th><strong>Field Name</strong></th></tr></thead><tbody><tr><td>IP Address</td><td><code>clientip</code></td></tr><tr><td>User ID</td><td><code>ident</code></td></tr><tr><td>User Authentication</td><td><code>auth</code></td></tr><tr><td>timestamp</td><td><code>timestamp</code></td></tr><tr><td>HTTP Verb</td><td><code>verb</code></td></tr><tr><td>Request body</td><td><code>request</code></td></tr><tr><td>HTTP Version</td><td><code>httpversion</code></td></tr><tr><td>HTTP Status Code</td><td><code>response</code></td></tr><tr><td>Bytes served</td><td><code>bytes</code></td></tr><tr><td>Referrer URL</td><td><code>referrer</code></td></tr><tr><td>User agent</td><td><code>agent</code></td></tr></tbody></table><p>注意：</p><ul><li>使用了grok之后，生成了我们需要的自定义字段之后，发往output的这个event依旧包含这个原始的未被拆分的message</li></ul><h3 id="设置output为es"><a href="#设置output为es" class="headerlink" title="设置output为es"></a>设置output为es</h3><p>在配置文件中，配置输出为es:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [ &quot;localhost:9200&quot; ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在整体的配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 logstash-6.2.3]$ cat config/first-pipeline.conf</span><br><span class="line">input &#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; &quot;5144&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;</span><br><span class="line">&#125;</span><br><span class="line">    geoip &#123;</span><br><span class="line">        source =&gt; &quot;clientip&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [ &quot;192.168.100.113:9500&quot; ]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="启动参数"><a href="#启动参数" class="headerlink" title="启动参数"></a>启动参数</h3><p>主要需要关注的参数有：</p><ul><li>-f：指定配置文件</li><li>-w：指定pipeline的工作进程数量。</li><li>-b：指定每个工作线程最大处理的event数量，默认是125。调大这个数量也就以为着更大的内存消耗，这个需要参考JVM参数进行配置。</li><li><p>—pipeline.unsafe_shutdown：强制logstash在还有event没有处理完成的情况下就退出。</p></li><li><p>-r, —config.reload.automatic：在配置文件修改之后，自动reload配置文件</p></li></ul><h3 id="提取字段已经转变数据"><a href="#提取字段已经转变数据" class="headerlink" title="提取字段已经转变数据"></a>提取字段已经转变数据</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/logstash/6.2/field-extraction.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/field-extraction.html</a></p><p>当输入是通用的日志格式时，我们可以使用grok去进行拆解</p><p>当输出是不规则的日志格式时，我们可以使用dissect去自定义我们的字段</p><h2 id="logstash的-metadata字段"><a href="#logstash的-metadata字段" class="headerlink" title="logstash的@metadata字段"></a>logstash的@metadata字段</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/logstash/6.2/event-dependent-configuration.html#metadata" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/event-dependent-configuration.html#metadata</a></p><p>每一种类型的input，logstash都会生成对应的@metadata字段，具体的信息在input部分会有记录</p><p>默认情况下，如果不进行特殊设置，我们是看不到@metadata的内容的：</p><p>添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123; metadata =&gt; true &#125;</span><br></pre></td></tr></table></figure><p>在调试模式下，output的设置是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    stdout &#123; codec =&gt; rubydebug &#123; metadata =&gt; true &#125; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在input为filebeat时，输出为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  &quot;@metadata&quot; =&gt; &#123;</span><br><span class="line">          &quot;beat&quot; =&gt; &quot;filebeat&quot;,</span><br><span class="line">       &quot;version&quot; =&gt; &quot;6.2.3&quot;,</span><br><span class="line">          &quot;type&quot; =&gt; &quot;doc&quot;,</span><br><span class="line">    &quot;ip_address&quot; =&gt; &quot;192.168.100.113&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><h2 id="input部分"><a href="#input部分" class="headerlink" title="input部分"></a>input部分</h2><h3 id="Common-option"><a href="#Common-option" class="headerlink" title="Common option"></a>Common option</h3><p>下面这些是通用配置，在所有的input中都支持</p><table><thead><tr><th>Setting</th><th>Input type</th><th>Required</th></tr></thead><tbody><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-add_field" target="_blank" rel="noopener"><code>add_field</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#hash" target="_blank" rel="noopener">hash</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-codec" target="_blank" rel="noopener"><code>codec</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#codec" target="_blank" rel="noopener">codec</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-enable_metric" target="_blank" rel="noopener"><code>enable_metric</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#boolean" target="_blank" rel="noopener">boolean</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-id" target="_blank" rel="noopener"><code>id</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#string" target="_blank" rel="noopener">string</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-tags" target="_blank" rel="noopener"><code>tags</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#array" target="_blank" rel="noopener">array</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-type" target="_blank" rel="noopener"><code>type</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#string" target="_blank" rel="noopener">string</a></td><td>No</td></tr></tbody></table><h3 id="beats"><a href="#beats" class="headerlink" title="beats"></a>beats</h3><p>参考配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  beats &#123;</span><br><span class="line">    port =&gt; 5044</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; &quot;localhost:9200&quot;</span><br><span class="line">    manage_template =&gt; false</span><br><span class="line">    index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">    document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="kafka-1"><a href="#kafka-1" class="headerlink" title="kafka"></a>kafka</h3><p>本质上是logstash启动一个kafka的客户端，因为存在一定的版本兼容性问题，这里需要注意</p><p>在kafka中，主要关注这些参数：</p><ul><li><p>auto_offset_reset</p><blockquote><p>当没有最初始的偏移量或者偏移量超出范围了，这个时候，做什么操作</p><ul><li>earliest：reset偏移量为最早的</li><li>latest：reset偏移量为最晚的，也就是最新的。</li></ul></blockquote></li><li><p>bootstrap_servers</p><blockquote><p>kafka集群的地址。格式是：host1:port1,host2:port2</p></blockquote></li><li><p>group_id</p><blockquote><p>默认值是logstash。设置消费组的名称。</p></blockquote></li><li><p>session_timeout_ms</p><blockquote><p>如果poll_timeout_ms时间（等待kafka推送消息的超时时间，默认是100ms）超时，过多长时间之后，这个消费者将会被标记为dead。</p></blockquote></li><li><p>request_timeout_ms</p><blockquote><p>logstash上的kafka客户端等待响应的超时时间。</p></blockquote></li><li><p>max_poll_records</p><blockquote><p>单次调用的最大值</p></blockquote></li><li><p>consumer_threads</p><blockquote><p>默认值为1。最理想的情况是线程总数与topic的partition总数相同。如果大于partition总数，则会产生线程空闲，导致资源浪费。</p></blockquote></li><li><p>topics</p><blockquote><p>监听的topic列表，默认值是logstash。</p></blockquote></li></ul><h2 id="filter部分"><a href="#filter部分" class="headerlink" title="filter部分"></a>filter部分</h2><h3 id="grok"><a href="#grok" class="headerlink" title="grok"></a>grok</h3><p>解析非结构化的日志，将日志拆分成为结构化的可查询的字段数据。</p><p>grok中预先定义了很多的正则表达式，在使用的时候只需要调用即可。</p><p>grok 表达式的打印复制格式的完整语法是下面这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%&#123;PATTERN_NAME:capture_name:data_type&#125;</span><br></pre></td></tr></table></figure><ul><li>PATTERN_NAME。代表匹配值的类型,例如3.44可以用NUMBER类型所匹配,127.0.0.1可以使用IP类型匹配。 </li><li>capture_name。代表存储该值的一个变量名称,例如 3.44 可能是一个事件的持续时间,127.0.0.1可能是请求的client地址。所以这两个值可以用 %{NUMBER:duration} %{IP:client_ip} 来匹配。</li></ul><p>案例1:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input &#123;stdin&#123;&#125;&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;%&#123;WORD&#125; %&#123;NUMBER:request_time:float&#125; %&#123;WORD&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;stdout&#123;&#125;&#125;</span><br></pre></td></tr></table></figure><p>运行如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">         &quot;message&quot; =&gt; &quot;begin 123.456 end&quot;,</span><br><span class="line">        &quot;@version&quot; =&gt; &quot;1&quot;,</span><br><span class="line">      &quot;@timestamp&quot; =&gt; &quot;2014-08-09T12:23:36.634Z&quot;,</span><br><span class="line">            &quot;host&quot; =&gt; &quot;raochenlindeMacBook-Air.local&quot;,</span><br><span class="line">    &quot;request_time&quot; =&gt; 123.456</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把 request_time 变成数值类型。如果不使用这个，使用下面这种，那么将会拆分为字符串</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input &#123;stdin&#123;&#125;&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;\s+(?&lt;request_time&gt;\d+(?:\.\d+)?)\s+&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;stdout&#123;&#125;&#125;</span><br></pre></td></tr></table></figure><p>注意：</p><p>grok match本质是一个正则匹配,默认出来的数据都是String.有些时候我们知道某个值其实是个数据类型,这时候可以直接指定数据类型. 不过match中仅支持直接转换成int ,float,语法是 %{NUMBER:response_time:int}</p><p>案例2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  grok &#123;</span><br><span class="line">    match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下是filter结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">● client: <span class="number">55.3</span><span class="number">.244</span><span class="number">.1</span></span><br><span class="line">● method: GET</span><br><span class="line">● request: /index.html</span><br><span class="line">● bytes: <span class="number">15824</span></span><br><span class="line">● duration: <span class="number">0.043</span></span><br></pre></td></tr></table></figure><h4 id="自定义pattern"><a href="#自定义pattern" class="headerlink" title="自定义pattern"></a>自定义pattern</h4><p><strong>引入文件方法</strong></p><p>很多时候logstash grok没办法提供你所需要的匹配类型，这个时候我们可以使用自定义</p><p>grok里面的match的message，其实是定义在<a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns" target="_blank" rel="noopener">这里</a>的各种pattern。<br>我们可以自定义pattern。</p><p>形式如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">USERNAME [a-zA-Z0-9._-]+</span><br><span class="line">USER %&#123;USERNAME&#125;</span><br><span class="line">EMAILLOCALPART [a-zA-Z][a-zA-Z0-9_.+-=:]+</span><br><span class="line">EMAILADDRESS %&#123;EMAILLOCALPART&#125;@%&#123;HOSTNAME&#125;</span><br><span class="line">INT (?:[+-]?(?:[0-9]+))</span><br></pre></td></tr></table></figure><p>将这些pattern保存在文件中，然后在logstash的config中制定读取pattern的目录即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  grok &#123;</span><br><span class="line">    patterns_dir =&gt; [&quot;/usr/local/logstash/patterns&quot;]</span><br><span class="line">match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;USER: user&#125; %&#123;INT: age&#125; %&#123;EMAILADDRESS: email&#125;&quot;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，我们输出的时候可以获得到message,user,age,email这几个field。</p><p>配置文件内即时配置方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">语法：(?&lt;field_name&gt;the pattern here)</span><br></pre></td></tr></table></figure><p>就是上面的这个案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input &#123;stdin&#123;&#125;&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;\s+(?&lt;request_time&gt;\d+(?:\.\d+)?)\s+&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;stdout&#123;&#125;&#125;</span><br></pre></td></tr></table></figure><p>拆分出来，就是这个：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">?&lt;request_time&gt;\d+(?:\.\d+)?</span><br><span class="line"></span><br><span class="line">\d+(?:\.\d+)? 这个就是这个字段的匹配规则</span><br></pre></td></tr></table></figure><p>\s：匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。+表示匹配次数为1次或者多次</p><p>(?<request_time>  )：这个是grok语法,request_time表示要将捕获的字符定义成的字段名</request_time></p><p>\d+：匹配一个或者多个数字</p><p>(?:.\d+)：为正则表达式，</p><p>(?: pattern):非获取匹配，匹配pattern但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。</p><p>.\d+：表示点后面跟一个或者多个 数字，(?:.\d+)?表示点后面跟一个或多个数字这种情况出现0次或者多次，如果为0次，则request_time为一个整数。所以匹配到的结果可能为123.456或者123或者123.4.5.6，这些都满足条件</p><p>注意：</p><p>()表示捕获分组，()会把每个分组里的匹配的值保存起来，使用$n(n是一个数字，表示第n个捕获组的内容)<br>(?:)表示非捕获分组，和捕获分组唯一的区别在于，非捕获分组匹配的值不会保存起来</p><h4 id="overwrite"><a href="#overwrite" class="headerlink" title="overwrite"></a>overwrite</h4><p>如果原本的字段需要重写掉，那么：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  grok &#123;</span><br><span class="line">    match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGBASE&#125; %&#123;DATA:message&#125;&quot; &#125;</span><br><span class="line">    overwrite =&gt; [ &quot;message&quot; ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="add-field"><a href="#add-field" class="headerlink" title="add_field"></a>add_field</h4><h4 id="remove-field"><a href="#remove-field" class="headerlink" title="remove_field"></a>remove_field</h4><p>#### </p><h3 id="dissect"><a href="#dissect" class="headerlink" title="dissect"></a>dissect</h3><p>dissect主要用于切割操作。dissect不使用正则表达式去进行匹配，因此，它的处理速度是非常快的。</p><p>如果你的内容每一行都是比较规则的，那么grok是更合适的。</p><p>分隔字段的这个动作，我们叫做解刨<strong>dissection</strong></p><p>语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%&#123;a&#125; - %&#123;b&#125; - %&#123;c&#125;</span><br></pre></td></tr></table></figure><p>{}内的是拆分之后的字段名称</p><p>一个案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  dissect &#123;</span><br><span class="line">    mapping =&gt; &#123;</span><br><span class="line">      &quot;message&quot; =&gt; &quot;%&#123;ts&#125; %&#123;+ts&#125; %&#123;+ts&#125; %&#123;src&#125; %&#123;&#125; %&#123;prog&#125;[%&#123;pid&#125;]: %&#123;msg&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="字段追加"><a href="#字段追加" class="headerlink" title="字段追加"></a>字段追加</h4><p>使用+号</p><h3 id="mutate"><a href="#mutate" class="headerlink" title="mutate"></a>mutate</h3><p>mutate过滤器能够允许你修改、优化你的event。包括：rename、remove、replace、modify字段</p><h4 id="replace"><a href="#replace" class="headerlink" title="replace"></a>replace</h4><p>案例为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">    mutate &#123;</span><br><span class="line">        replace =&gt; &#123; &quot;type&quot; =&gt; &quot;nginx&quot;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通用参数"><a href="#通用参数" class="headerlink" title="通用参数"></a>通用参数</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-grok.html#plugins-filters-grok-common-options" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-grok.html#plugins-filters-grok-common-options</a></p><p>The following configuration options are supported by all filter plugins:</p><table><thead><tr><th>Setting</th><th>Input type</th><th>Required</th></tr></thead><tbody><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-add_field" target="_blank" rel="noopener"><code>add_field</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#hash" target="_blank" rel="noopener">hash</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-add_tag" target="_blank" rel="noopener"><code>add_tag</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#array" target="_blank" rel="noopener">array</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-enable_metric" target="_blank" rel="noopener"><code>enable_metric</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#boolean" target="_blank" rel="noopener">boolean</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-id" target="_blank" rel="noopener"><code>id</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#string" target="_blank" rel="noopener">string</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-periodic_flush" target="_blank" rel="noopener"><code>periodic_flush</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#boolean" target="_blank" rel="noopener">boolean</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-remove_field" target="_blank" rel="noopener"><code>remove_field</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#array" target="_blank" rel="noopener">array</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-remove_tag" target="_blank" rel="noopener"><code>remove_tag</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#array" target="_blank" rel="noopener">array</a></td><td>No</td></tr></tbody></table><h3 id="if条件判断"><a href="#if条件判断" class="headerlink" title="if条件判断"></a>if条件判断</h3><p>参考链接：</p><p><a href="https://www.elastic.co/guide/en/logstash/6.2/event-dependent-configuration.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/event-dependent-configuration.html</a></p><h2 id="output部分"><a href="#output部分" class="headerlink" title="output部分"></a>output部分</h2><h3 id="kafka-2"><a href="#kafka-2" class="headerlink" title="kafka"></a>kafka</h3><p>只要关注的参数有：</p><ul><li><p>bootstrap_servers</p><blockquote><p>kafka集群的地址。格式是：host1:port1,host2:port2</p></blockquote></li><li><p>topic_id</p><blockquote><p>topic的名称</p></blockquote></li><li><p>compression_type</p><blockquote><p>默认值为none。取值范围为：none、gzip、snappy、lz4</p><p>在logstash向后端kafka传输数据时，可以对数据进行压缩。这里定义使用压缩的算法</p></blockquote></li><li><p>codec</p><blockquote><p>定义输出的编码，默认是明文plain。</p></blockquote></li></ul><p>一个案例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;172.24.48.63:19092,172.24.48.64:19092,172.24.48.65:19092&quot;</span><br><span class="line">        topic_id =&gt; &quot;%&#123;topicname&#125;&quot;</span><br><span class="line">        compression_type =&gt; &quot;lz4&quot;</span><br><span class="line">        codec =&gt; plain &#123;</span><br><span class="line">           format =&gt; &quot;%&#123;topicinfo&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h3 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h3><p>一个实际的案例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        codec =&gt; &quot;plain&quot;</span><br><span class="line">        group_id =&gt; &quot;kafkatoes&quot;</span><br><span class="line">        bootstrap_servers =&gt; &quot;172.24.48.76:19092,172.24.48.77:19092,172.24.48.78:19092&quot;</span><br><span class="line">        auto_offset_reset =&gt; &quot;earliest&quot;</span><br><span class="line">        consumer_threads =&gt; 4</span><br><span class="line">        topics =&gt; &quot;applog6&quot;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">filter  &#123;</span><br><span class="line">    dissect &#123;</span><br><span class="line">        mapping =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;%&#123;type&#125; %&#123;host&#125; %&#123;logtime&#125; %&#123;+logtime&#125; %&#123;level&#125; %&#123;content&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if &quot;_dissectfailure&quot; in [tags] &#123;</span><br><span class="line">      drop &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if [type] !~ &quot;^[A-Za-z]&quot; &#123;</span><br><span class="line">             drop &#123;&#125;</span><br><span class="line">          &#125;</span><br><span class="line">    if [logtime] !~ &quot;^[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&quot; &#123;</span><br><span class="line">             drop &#123;&#125;</span><br><span class="line">          &#125;</span><br><span class="line">    mutate &#123;</span><br><span class="line">        add_field =&gt; &#123;</span><br><span class="line">            &quot;[@metadata][type]&quot; =&gt; &quot;%&#123;type&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        remove_field =&gt; [&quot;type&quot;]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">       date  &#123;</span><br><span class="line">        match =&gt; [&quot;logtime&quot;, &quot;yyyy-MM-dd HH:mm:ss,SSS&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;yyyy-MM-dd HH:mm:ss:SSS&quot;, &quot;ISO8601&quot;]</span><br><span class="line">        #timezone =&gt; &quot;+08:00&quot;</span><br><span class="line">        remove_field =&gt; [&quot;message&quot;,&quot;logtime&quot;,&quot;@version&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">     elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;10.10.10.86:9200&quot;,&quot;10.10.10.87:9200&quot;,&quot;10.10.10.88:9200&quot;]</span><br><span class="line">        index =&gt; &quot;%&#123;[@metadata][type]&#125;-logstash-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        template_overwrite =&gt; true</span><br><span class="line">        document_type =&gt; &quot;doc&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一些参数说明：</p><ul><li><p>template_overwrite</p><blockquote><p>布尔类型，取值为true|false。</p><p>The template_overwrite option will always overwrite the indicated template in Elasticsearch with either the one indicated by template or the included one. This option is set to false by default. If you always want to stay up to date with the template provided by Logstash, this option could be very useful to you. Likewise, if you have your own template file managed by puppet, for example, and you wanted to be able to update it regularly, this option could help there as well.</p><p>Please note that if you are using your own customized version of the Logstash template (logstash), setting this to true will make Logstash to overwrite the “logstash” template (i.e. removing all customized settings)</p></blockquote></li><li><p>document_type</p></li></ul><h3 id="file"><a href="#file" class="headerlink" title="file"></a>file</h3><p>官网的案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line"> file &#123;</span><br><span class="line">   path =&gt; ...</span><br><span class="line">   codec =&gt; line &#123; format =&gt; &quot;custom format: %&#123;message&#125;&quot;&#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个实际的案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">  if [logdate] =~ &quot;^[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&quot; and [loghour] =~ &quot;^[0-9]&#123;2&#125;&quot;  &#123;</span><br><span class="line">    file &#123;</span><br><span class="line">        path =&gt; &quot;/nas/logs/%&#123;type&#125;/%&#123;logdate&#125;/%&#123;host&#125;/%&#123;type&#125;.log-%&#123;logdate&#125;-%&#123;loghour&#125;&quot;</span><br><span class="line">        codec =&gt; line &#123;</span><br><span class="line">            format =&gt; &quot;%&#123;logdate&#125; %&#123;loghour&#125;:%&#123;logms&#125; %&#123;content&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="codec部分"><a href="#codec部分" class="headerlink" title="codec部分"></a>codec部分</h2><p>codec插件，改变了event中的数据展示方式/格式，codecs本质上也是一个过滤器，可以作用在input和output阶段</p><p>Codec 是 logstash 从 1.3.0 版开始新引入的概念(<em>Codec</em> 来自 <em>Co</em>der/<em>dec</em>oder 两个单词的首字母缩写)。</p><p>在此之前，logstash 只支持纯文本形式输入，然后以<em>过滤器</em>处理它。但现在，我们可以在<em>输入</em> 期处理不同类型的数据，这全是因为有了 <strong>codec</strong> 设置。</p><p>Logstash 不只是一个<code>input | filter | output</code> 的数据流，而是一个 <code>input | decode | filter | encode | output</code> 的数据流！<em>codec</em> 就是用来 decode、encode 事件的。</p><p>简单说，就是在logstash读入的时候，通过codec编码解析日志为相应格式，从logstash输出的时候，通过codec解码成相应格式。</p><p>codec 的引入，使得 logstash 可以更好更方便的与其他有自定义数据格式的运维产品共存，比如 graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等。</p><p>事实上，我们在第一个 “hello world” 用例中就已经用过 <em>codec</em> 了 —— <em>rubydebug</em> 就是一种 <em>codec</em>！虽然它一般只会用在 stdout 插件中，作为配置测试或者调试的工具。</p><h3 id="plain"><a href="#plain" class="headerlink" title="plain"></a>plain</h3><p>用于event之间没有分隔的文本</p><p>在消息队列时，例如kafka，input一般都是plain</p><p>format设置，指定输出的内容，例如在output是kafka时：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;172.24.48.63:19092,172.24.48.64:19092,172.24.48.65:19092&quot;</span><br><span class="line">        topic_id =&gt; &quot;%&#123;topicname&#125;&quot;</span><br><span class="line">        compression_type =&gt; &quot;lz4&quot;</span><br><span class="line">        codec =&gt; plain &#123;</span><br><span class="line">           format =&gt; &quot;%&#123;topicinfo&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="line"><a href="#line" class="headerlink" title="line"></a>line</h3><h2 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h2><h3 id="公网服务器日志收集"><a href="#公网服务器日志收集" class="headerlink" title="公网服务器日志收集"></a>公网服务器日志收集</h3><p>公网服务器的filebeat，将日志发送到有对外IP的logstash，然后由logstash去处理数据，获取到数据之后，再将数据写入到kafka集群中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 config]$ grep -v &apos;#&apos; httpdns.conf</span><br><span class="line">input &#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; &quot;5144&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    if [source] == &quot;/home/appdeploy/deploy/logs/httpdns/httpdns.log&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            add_field =&gt; &#123;</span><br><span class="line">                &quot;[@metadata][topic_name]&quot; =&gt; &quot;applog8&quot;</span><br><span class="line">                &quot;[@metadata][app_name]&quot; =&gt; &quot;httpdns&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    if [source] == &quot;/home/appdeploy/deploy/logs/httpdns/httpdns_error.log&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            add_field =&gt; &#123;</span><br><span class="line">                &quot;[@metadata][topic_name]&quot; =&gt; &quot;errorlog&quot;</span><br><span class="line">                &quot;[@metadata][app_name]&quot; =&gt; &quot;httpdns&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    if [source] == &quot;/home/appdeploy/deploy/logs/monitor/httpdns_monitor.log&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            add_field =&gt; &#123;</span><br><span class="line">                &quot;[@metadata][topic_name]&quot; =&gt; &quot;monitor&quot;</span><br><span class="line">                &quot;[@metadata][app_name]&quot; =&gt; &quot;monitor&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    if [source] == &quot;/var/log/secure&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            add_field =&gt; &#123;</span><br><span class="line">                &quot;[@metadata][topic_name]&quot; =&gt; &quot;oslog&quot;</span><br><span class="line">                &quot;[@metadata][app_name]&quot; =&gt; &quot;secure&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    if [source] == &quot;/var/log/messages&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            add_field =&gt; &#123;</span><br><span class="line">                &quot;[@metadata][topic_name]&quot; =&gt; &quot;oslog&quot;</span><br><span class="line">                &quot;[@metadata][app_name]&quot; =&gt; &quot;messages&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    if [source] == &quot;/var/log/cron&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            add_field =&gt; &#123;</span><br><span class="line">                &quot;[@metadata][topic_name]&quot; =&gt; &quot;oslog&quot;</span><br><span class="line">                &quot;[@metadata][app_name]&quot; =&gt; &quot;cron&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    if [source] == &quot;/var/log/maillog&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            add_field =&gt; &#123;</span><br><span class="line">                &quot;[@metadata][topic_name]&quot; =&gt; &quot;oslog&quot;</span><br><span class="line">                &quot;[@metadata][app_name]&quot; =&gt; &quot;maillog&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    if [source] == &quot;/var/log/kern.log&quot; &#123;</span><br><span class="line">        mutate &#123;</span><br><span class="line">            add_field =&gt; &#123;</span><br><span class="line">                &quot;[@metadata][topic_name]&quot; =&gt; &quot;oslog&quot;</span><br><span class="line">                &quot;[@metadata][app_name]&quot; =&gt; &quot;kern&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  stdout &#123; codec =&gt; rubydebug &#123; metadata =&gt; true &#125; &#125;</span><br><span class="line">  file &#123;</span><br><span class="line">    path =&gt; &quot;/home/elk/filebeat-to-file&quot;</span><br><span class="line">    codec =&gt; line &#123; format =&gt; &quot;%&#123;[@metadata][topic_name]&#125; %&#123;[@metadata][app_name]&#125; %&#123;[beat][hostname]&#125; %&#123;message&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    bootstrap_servers =&gt; &quot;172.16.1.132:9092&quot;</span><br><span class="line">    topic_id =&gt; &quot;%&#123;[@metadata][topic_name]&#125;&quot;</span><br><span class="line">    compression_type =&gt; &quot;lz4&quot;</span><br><span class="line">    codec =&gt; plain &#123;</span><br><span class="line">       format =&gt; &quot;%&#123;[@metadata][app_name]&#125; %&#123;[beat][hostname]&#125; %&#123;message&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="nginx错误日志收集"><a href="#nginx错误日志收集" class="headerlink" title="nginx错误日志收集"></a>nginx错误日志收集</h3><p><strong>filebeat端配置：</strong></p><p>主配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[appdeploy@node001 filebeat6]$ grep -v &apos;#&apos; applogg.yml</span><br><span class="line">filebeat.shutdown_timeout: 10s</span><br><span class="line">filebeat.config.prospectors:</span><br><span class="line">  enabled: true</span><br><span class="line">  path: conf/*.yml</span><br><span class="line">  reload.enabled: true</span><br><span class="line">  reload.period: 10s</span><br><span class="line">output.kafka:</span><br><span class="line">  hosts: [&quot;172.16.1.132:9092&quot;]</span><br><span class="line">  topic: &apos;%&#123;[fields.log_topic]&#125;&apos;</span><br><span class="line">  key: &apos;%&#123;[fields.app_name]&#125; %&#123;[beat.hostname]&#125;&apos;</span><br><span class="line">  required_acks: 1</span><br><span class="line">  workers: 6</span><br><span class="line">  timeout: 120</span><br><span class="line">  compression: snappy</span><br><span class="line">  max_message_bytes: 10240000</span><br><span class="line">  codec.format:</span><br><span class="line">     string: &apos;%&#123;[fields.app_name]&#125; %&#123;[beat.hostname]&#125; %&#123;[message]&#125;&apos;</span><br></pre></td></tr></table></figure><p>子配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[appdeploy@node001 conf]$ cat nginx.yml</span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /data1/logs/nginx/access-*.log</span><br><span class="line">  fields:</span><br><span class="line">    log_topic: nginx</span><br><span class="line">    app_name: nginx</span><br><span class="line">  scan_frequency: 5s</span><br><span class="line">  tail_files: true</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">[appdeploy@node001 conf]$ cat nginx_error.yml</span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /usr/local/tengine/logs/error.log</span><br><span class="line">    - /data1/logs/nginx/error.log</span><br><span class="line">  fields:</span><br><span class="line">    log_topic: nginx_error</span><br><span class="line">    app_name: nginx_error</span><br><span class="line">  scan_frequency: 5s</span><br><span class="line">  tail_files: true</span><br></pre></td></tr></table></figure><p>启动命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ./filebeat -e -c applogg.yml &gt; start.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p><strong>logstash端配置</strong></p><p>落地到文件的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 config]$ cat nginx_errortofile.yml</span><br><span class="line">input&#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        codec =&gt; &quot;plain&quot;</span><br><span class="line">        group_id =&gt; &quot;kafkatofile&quot;</span><br><span class="line">        bootstrap_servers =&gt; &quot;172.16.1.132:9092&quot;</span><br><span class="line">        auto_offset_reset =&gt; &quot;latest&quot;</span><br><span class="line">        consumer_threads =&gt; 5</span><br><span class="line">        topics =&gt; &quot;nginx_error&quot;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    dissect &#123;</span><br><span class="line">        mapping =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;%&#123;type&#125; %&#123;host&#125; %&#123;content&#125;&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">    mutate &#123;</span><br><span class="line">        replace =&gt; &#123; &quot;type&quot; =&gt; &quot;nginx&quot;&#125;</span><br><span class="line">&#125;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123; &quot;content&quot; =&gt; &quot;%&#123;YEAR:logyear&#125;/%&#123;MONTHNUM2:logmonth&#125;/%&#123;MONTHDAY:logday&#125; %&#123;HOUR:loghour&#125;:%&#123;MINUTE:logmin&#125;:%&#123;SECOND:logsec&#125; (?&lt;content1&gt;.+)&quot; &#125;</span><br><span class="line">&#125;</span><br><span class="line">    if &quot;_dissectfailure&quot; in [tags] &#123;</span><br><span class="line">          drop &#123; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    if &quot;_grokparsefailure&quot; in [tags] &#123;</span><br><span class="line">          drop &#123; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    if [type] == &quot;nginx&quot; &#123;</span><br><span class="line">        file &#123;</span><br><span class="line">            path =&gt; &quot;/nas/logs/%&#123;type&#125;/%&#123;logyear&#125;-%&#123;logmonth&#125;-%&#123;logday&#125;/%&#123;host&#125;/error.log-%&#123;logyear&#125;-%&#123;logmonth&#125;-%&#123;logday&#125;-%&#123;loghour&#125;&quot;</span><br><span class="line">            codec =&gt; line &#123;</span><br><span class="line">                format =&gt; &quot;%&#123;content&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>落地的文件的时候，和nginx的access放在同一个目录下，所以把type转变成为nginx</p><p>写入到es的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 config]$ cat nginx_errortoes.yml</span><br><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        codec =&gt; &quot;plain&quot;</span><br><span class="line">        group_id =&gt; &quot;kafkatoes&quot;</span><br><span class="line">        bootstrap_servers =&gt; &quot;172.16.1.132:9092&quot;</span><br><span class="line">        auto_offset_reset =&gt; &quot;latest&quot;</span><br><span class="line">        consumer_threads =&gt; 5</span><br><span class="line">        topics =&gt; &quot;nginx_error&quot;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter  &#123;</span><br><span class="line">    dissect &#123;</span><br><span class="line">        mapping =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;type&#125; %&#123;host&#125; %&#123;logtime&#125; %&#123;+logtime&#125; %&#123;content&#125;&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    mutate &#123;</span><br><span class="line">        add_field =&gt; &#123;</span><br><span class="line">            &quot;[@metadata][type]&quot; =&gt; &quot;%&#123;type&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        remove_field =&gt; [&quot;type&quot;,&quot;@version&quot;,&quot;message&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">    date &#123;</span><br><span class="line">        match =&gt; [&quot;logtime&quot;, &quot;yyyy/MM/dd HH:mm:ss&quot;]</span><br><span class="line">        remove_field =&gt; [&quot;logtime&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">    if &quot;_dissectfailure&quot; in [tags] &#123;</span><br><span class="line">      drop &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if &quot;_dateparsefailure&quot; in [tags] &#123;</span><br><span class="line">      drop &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">     stdout &#123; codec =&gt; rubydebug &#123; metadata =&gt; true &#125; &#125;</span><br><span class="line">     elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;172.16.1.128:9500&quot;]</span><br><span class="line">        index =&gt; &quot;%&#123;[@metadata][type]&#125;-logstash-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        template_overwrite =&gt; true</span><br><span class="line">        document_type =&gt; &quot;doc&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>索引的名称是：nginx_error-logstash-年月日</p><p>在es中创建索引模板：</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">PUT  _template/nginx_error</span><br><span class="line">&#123;</span><br><span class="line"> &quot;order&quot;: 0,</span><br><span class="line">    &quot;template&quot;: &quot;nginx_error-logstash*&quot;,</span><br><span class="line">    &quot;settings&quot;:&#123;</span><br><span class="line">    &quot;index&quot; : &#123;</span><br><span class="line">      &quot;refresh_interval&quot;: &quot;5s&quot;,</span><br><span class="line">      &quot;number_of_shards&quot;: &quot;5&quot;,</span><br><span class="line">      &quot;number_of_replicas&quot;: &quot;1&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;mappings&quot;:&#123;</span><br><span class="line">  &quot;doc&quot;: &#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">          &quot;host&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;content&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line">GET _template/nginxlog</span><br><span class="line">&#123;</span><br><span class="line">  &quot;nginxlog&quot; : &#123;</span><br><span class="line">    &quot;order&quot; : 0,</span><br><span class="line">    &quot;index_patterns&quot; : [</span><br><span class="line">      &quot;nginx*-logstash-*&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">      &quot;index&quot; : &#123;</span><br><span class="line">        &quot;mapping&quot; : &#123;</span><br><span class="line">          &quot;total_fields&quot; : &#123;</span><br><span class="line">            &quot;limit&quot; : &quot;2000&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;refresh_interval&quot; : &quot;60s&quot;,</span><br><span class="line">        &quot;number_of_shards&quot; : &quot;6&quot;,</span><br><span class="line">        &quot;translog&quot; : &#123;</span><br><span class="line">          &quot;sync_interval&quot; : &quot;10s&quot;,</span><br><span class="line">          &quot;durability&quot; : &quot;async&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;number_of_replicas&quot; : &quot;0&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">      &quot;doc&quot; : &#123;</span><br><span class="line">        &quot;dynamic_templates&quot; : [</span><br><span class="line">          &#123;</span><br><span class="line">            &quot;strings_as_keywords&quot; : &#123;</span><br><span class="line">              &quot;match_mapping_type&quot; : &quot;string&quot;,</span><br><span class="line">              &quot;mapping&quot; : &#123;</span><br><span class="line">                &quot;type&quot; : &quot;keyword&quot;,</span><br><span class="line">                &quot;doc_values&quot; : &quot;false&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        ],</span><br><span class="line">        &quot;properties&quot; : &#123;</span><br><span class="line">          &quot;geoip&quot; : &#123;</span><br><span class="line">            &quot;properties&quot; : &#123;</span><br><span class="line">              &quot;city_name&quot; : &#123;</span><br><span class="line">                &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">              &#125;,</span><br><span class="line">              &quot;country_name&quot; : &#123;</span><br><span class="line">                &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">              &#125;,</span><br><span class="line">              &quot;latitude&quot; : &#123;</span><br><span class="line">                &quot;type&quot; : &quot;float&quot;</span><br><span class="line">              &#125;,</span><br><span class="line">              &quot;location&quot; : &#123;</span><br><span class="line">                &quot;type&quot; : &quot;geo_point&quot;</span><br><span class="line">              &#125;,</span><br><span class="line">              &quot;longitude&quot; : &#123;</span><br><span class="line">                &quot;type&quot; : &quot;float&quot;</span><br><span class="line">              &#125;,</span><br><span class="line">              &quot;region_name&quot; : &#123;</span><br><span class="line">                &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;remote_user&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;request_time&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;status&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;tags&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;,</span><br><span class="line">            &quot;index&quot; : false</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;type&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;upstream&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;upstream_response_time&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;url_path&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;user_agent&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;verb&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;,</span><br><span class="line">            &quot;index&quot; : false</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;host&quot; : &#123;</span><br><span class="line">            &quot;index&quot; : &quot;true&quot;,</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;client&quot; : &#123;</span><br><span class="line">            &quot;index&quot; : &quot;true&quot;,</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;parameters.day&quot; : &#123;</span><br><span class="line">            &quot;fielddata&quot; : true,</span><br><span class="line">            &quot;type&quot; : &quot;text&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;parameters.shopId&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;parameters.cityId&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;parameters.userId&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;parameters.riderId&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;http_host&quot; : &#123;</span><br><span class="line">            &quot;type&quot; : &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;parameters.createTimeEnd&quot; : &#123;</span><br><span class="line">            &quot;fielddata&quot; : true,</span><br><span class="line">            &quot;type&quot; : &quot;text&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;parameters.createTimeStart&quot; : &#123;</span><br><span class="line">            &quot;fielddata&quot; : true,</span><br><span class="line">            &quot;type&quot; : &quot;text&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;aliases&quot; : &#123; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>启动命令为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ./bin/logstash -f config/nginxtofile.yml --config.reload.automatic  &gt; start.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>也可以不输出到start.log中，直接输出到/dev/null</p><h1 id="Elasticsearch部署"><a href="#Elasticsearch部署" class="headerlink" title="Elasticsearch部署"></a>Elasticsearch部署</h1><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/getting-started.html#getting-started" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/getting-started.html#getting-started</a></p><h2 id="ES工作原理"><a href="#ES工作原理" class="headerlink" title="ES工作原理"></a>ES工作原理</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p><strong>Near Realtime (NRT)</strong></p><blockquote><p>ES是一个接近实时的搜索平台，也就是说有些许的延迟，从索引文件到能够检索出结果的延迟一般在秒内</p></blockquote><p><strong>Cluser</strong></p><blockquote><p>集群由一个或多个node节点组成，这些节点协同存储所有的条目数据，并且都支持检索的功能以提高性能。</p><p>一个集群由一个唯一的名称标识，<strong>默认为：elasticsearch</strong>。一个节点只能够属于一个集群</p></blockquote><p><strong>Node</strong></p><blockquote><p>集群中的每一个服务器/服务节点叫做node。在一个集群中，每一个node都通过一个唯一的名称去标识(默认是一个随机的UUID)。每一个node会加到一个es集群当中，默认的集群名称是elasticsearch，可以指定集群的名称以创建多个不同的es集群。</p><p>一个集群可以只有一个node节点</p></blockquote><p><strong>Index</strong></p><blockquote><p>索引是一批收集的拥有相似特征的<strong>文件集合</strong>。</p><p>索引通过不同的名称去标识(必须为小写)，这个索引名称用于后续的检索、更新、删除文件内容等操作</p></blockquote><p><strong>Type</strong></p><blockquote><p>在一个索引中，可以定义一个或多个type类型，type就相当于是索引数据的分类字段。例如你的索引内容一个博客系统，你可以分别定义用户字段、评论字段、内容字段。</p><p>在5版本中有，6版本中只能设置一个，7版本中废弃。</p><p>index相当于是一个数据库，type相当于是表。</p></blockquote><p><strong>Document</strong></p><blockquote><p>document是存储信息以及创建索引的基本单元。document通常是以JSON的方式存在的。document其实也可以理解是一段内容</p><p>注意：document在索引中存在时，必须被分配或者说指定给某一个type</p><p>document是一条记录，其中包含各个字段。</p></blockquote><p><strong>Shard &amp; Replicas</strong></p><blockquote><p>每一个索引可以存储大量的数据。这些数据在落地到物理磁盘上时，很有可能超出单个node的限制。为了解决这个问题，ES提供了把索引分割的功能，每一个被分割出来的部分我们叫做shard分片。</p><p>在创建index的时候，我们可以指定分片的数量。</p><p>副本是为了提供分片的高可用，并且在查询的时候可以并行执行</p><p>这一部分比较核心，我们会有单独的篇幅讲解。</p></blockquote><h3 id="集群状态"><a href="#集群状态" class="headerlink" title="集群状态"></a>集群状态</h3><p>ES集群有3种状态：green，yellow，red。其中green状态表明集群是健康的。yellow表示集群可用，但是有部分索引的shard有异常。red状态表示集群有索引异常。</p><h2 id="ES安装配置"><a href="#ES安装配置" class="headerlink" title="ES安装配置"></a>ES安装配置</h2><h3 id="基础环境配置"><a href="#基础环境配置" class="headerlink" title="基础环境配置"></a>基础环境配置</h3><p><strong>JAVA配置</strong></p><p>ES的运行需要java作为基础，最低版本要求为java 8。</p><p>根据以下命令操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# tar -zxvf jdk1.8.0_77.tar.gz  -C /usr/local/</span><br><span class="line">[root@node001 ~]# ln -s /usr/local/jdk1.8.0_77 /usr/local/jdk</span><br><span class="line">[root@node001 ~]# vim /etc/profile# 在文件末尾添加一下内容</span><br><span class="line">JAVA_HOME=/usr/local/jdk</span><br><span class="line">PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">CLASSPATH=.:$JAVA_HOME/lib</span><br><span class="line">JRE_HOME=$JAVA_HOME/jre</span><br><span class="line">export JAVA_HOME PATH CLASSPATH JRE_HOME</span><br><span class="line"></span><br><span class="line">[root@node001 ~]# source /etc/profile</span><br><span class="line">[root@node001 ~]# java -version</span><br><span class="line">java version &quot;1.8.0_77&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_77-b03)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.77-b03, mixed mode)</span><br></pre></td></tr></table></figure><p><strong>系统环境配置</strong></p><ol><li>打开服务器的/etc/sysctl.conf文件，增加下面内容：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# vim /etc/sysctl.conf</span><br><span class="line">vm.max_map_count=655360</span><br><span class="line">vm.zone_reclaim_mode=0</span><br></pre></td></tr></table></figure><p>保存后，执行命令: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# sysctl  -p</span><br></pre></td></tr></table></figure><ol><li>创建elk用户，创建数据目录，设置数据目录的权限</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# useradd  elk</span><br><span class="line">[root@node001 ~]# su - elk</span><br><span class="line">[elk@node001 ~]$ mkdir data</span><br></pre></td></tr></table></figure><p>注意，一般我们会将数据目录放在其他盘中，这个时候需要注意权限问题，此时的操作类型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# mkdir  -p /data1/elk</span><br><span class="line">[root@node001 ~]# chown -R elk:elk /data1/elk</span><br></pre></td></tr></table></figure><ol><li>配置/etc/security/limits.conf，修改文件描述符以及进程数限制</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# vim /etc/security/limits.conf</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 655360</span><br><span class="line">elk soft memlock unlimited</span><br><span class="line">elk hard memlock unlimited</span><br><span class="line"></span><br><span class="line">[root@node001 ~]# vim  /etc/security/limits.d/90-nproc.conf</span><br><span class="line">*       soft    nproc   65536</span><br><span class="line">root       soft    nproc     unlimited</span><br><span class="line"></span><br><span class="line"># *       hard    nproc   65536这个可选</span><br></pre></td></tr></table></figure><p>注意：在limits.conf文件中的nproc的设置和/etc/security/limits.d/90-nproc.conf中proc设置有关</p><ul><li><p>当在limits.conf中使用*号让全局用户生效的时候，生效的nproc的值大小受后者制约</p><p>因为，Linux系统默认先读取<code>/etc/security/limits.conf</code> 中的信息, 如果<code>/etc/security/limits.d/</code>目录下还有配置文件的话, 也会依次遍历读取, 最终, <code>/etc/security/limits.d/</code>中的配置会覆盖<code>/etc/security/limits.conf</code> 中的配置.</p></li><li><p>当在limits.conf中指定用户时，生效的nproc值不受该文件制约</p></li></ul><h3 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h3><p>执行以下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.1.2.tar.gz</span><br><span class="line">[elk@node001 ~]$ tar -xvf elasticsearch-5.1.2.tar.gz</span><br></pre></td></tr></table></figure><p>在做测试时，我们可以不经过任何配置直接启动，执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ cd elasticsearch-5.1.2/bin</span><br><span class="line">[elk@node001 bin]$ ./elasticsearch</span><br></pre></td></tr></table></figure><p>如果需要使用守护进程方式启动，执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 bin]$ ./elasticsearch -d -p pid.file</span><br><span class="line">[elk@node001 bin]$ cat pid.file</span><br><span class="line">3104</span><br><span class="line">注：-p可以指定将pid记录到某一个文件中</span><br></pre></td></tr></table></figure><h3 id="ES配置及配置文件详解"><a href="#ES配置及配置文件详解" class="headerlink" title="ES配置及配置文件详解"></a>ES配置及配置文件详解</h3><p>Elasticsearch loads its configuration from the <code>$ES_HOME/config/elasticsearch.yml</code> file by default. The format of this config file is explained in <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/settings.html" target="_blank" rel="noopener"><em>Configuring Elasticsearch</em></a>.</p><p>Any settings that can be specified in the config file can also be specified on the command line, using the <code>-E</code> syntax as follows:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch -d -Ecluster.name=my_cluster -Enode.name=node_1</span><br></pre></td></tr></table></figure><p>ES在启动的时候，默认会从ES目录下的config目录下，读取elasticsearch.yml文件。</p><p>但是，除了从配置文件读取之外，也可以在启动的时候，手动的指定一些配置。</p><p>注意：</p><ul><li>建议都从elasticsearch.yml配置文件中读取，不建议命令行指定。</li><li>建议将配置文件目录、数据目录、日志目录进行分离。</li></ul><h4 id="ES目录结构"><a href="#ES目录结构" class="headerlink" title="ES目录结构"></a>ES目录结构</h4><p>解压出来的es目录结构如下所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 elasticsearch-5.1.2]$ pwd</span><br><span class="line">/home/elk/elasticsearch-5.1.2</span><br><span class="line">[elk@node001 elasticsearch-5.1.2]$ ll</span><br><span class="line">total 56</span><br><span class="line">drwxr-xr-x.  2 elk elk  4096 Jun 28 15:56 bin</span><br><span class="line">drwxr-xr-x.  3 elk elk  4096 Jun 20 17:16 config</span><br><span class="line">drwxrwxr-x.  3 elk elk  4096 Jun 20 17:16 data</span><br><span class="line">drwxr-xr-x.  2 elk elk  4096 Jan 12  2017 lib</span><br><span class="line">-rw-r--r--.  1 elk elk 11358 Jan 12  2017 LICENSE.txt</span><br><span class="line">drwxrwxr-x.  2 elk elk  4096 Jun 28 15:20 logs</span><br><span class="line">drwxr-xr-x. 12 elk elk  4096 Jan 12  2017 modules</span><br><span class="line">-rw-r--r--.  1 elk elk   150 Jan 12  2017 NOTICE.txt</span><br><span class="line">drwxr-xr-x.  2 elk elk  4096 Jan 12  2017 plugins</span><br><span class="line">-rw-r--r--.  1 elk elk  9108 Jan 12  2017 README.textile</span><br></pre></td></tr></table></figure><p>下面是官方的定义：</p><table><thead><tr><th style="text-align:left">Type</th><th style="text-align:left">Description</th><th style="text-align:left">Default Location</th><th style="text-align:left">Setting</th></tr></thead><tbody><tr><td style="text-align:left"><strong>home</strong></td><td style="text-align:left">Elasticsearch home directory or <code>$ES_HOME</code></td><td style="text-align:left">Directory created by unpacking the archive</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><strong>bin</strong></td><td style="text-align:left">Binary scripts including <code>elasticsearch</code> to start a node and <code>elasticsearch-plugin</code> to install plugins</td><td style="text-align:left"><code>$ES_HOME/bin</code></td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><strong>conf</strong></td><td style="text-align:left">Configuration files including <code>elasticsearch.yml</code></td><td style="text-align:left"><code>$ES_HOME/config</code></td><td style="text-align:left"><code>path.conf</code></td></tr><tr><td style="text-align:left"><strong>data</strong></td><td style="text-align:left">The location of the data files of each index / shard allocated on the node. Can hold multiple locations.</td><td style="text-align:left"><code>$ES_HOME/data</code></td><td style="text-align:left"><code>path.data</code></td></tr><tr><td style="text-align:left"><strong>logs</strong></td><td style="text-align:left">Log files location.</td><td style="text-align:left"><code>$ES_HOME/logs</code></td><td style="text-align:left"><code>path.logs</code></td></tr><tr><td style="text-align:left"><strong>plugins</strong></td><td style="text-align:left">Plugin files location. Each plugin will be contained in a subdirectory.</td><td style="text-align:left"><code>$ES_HOME/plugins</code></td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><strong>repo</strong></td><td style="text-align:left">Shared file system repository locations. Can hold multiple locations. A file system repository can be placed in to any subdirectory of any directory specified here.</td><td style="text-align:left">Not configured</td><td style="text-align:left"><code>path.repo</code></td></tr><tr><td style="text-align:left"><strong>script</strong></td><td style="text-align:left">Location of script files.</td><td style="text-align:left"><code>$ES_HOME/scripts</code></td><td style="text-align:left"><code>path.scripts</code></td></tr></tbody></table><h4 id="如何配置ES"><a href="#如何配置ES" class="headerlink" title="如何配置ES"></a>如何配置ES</h4><p>Elasticsearch ships with good defaults and requires very little configuration. Most settings can be changed on a running cluster using the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/cluster-update-settings.html" target="_blank" rel="noopener"><em>Cluster Update Settings</em></a> API.</p><p>The configuration files should contain settings which are node-specific (such as <code>node.name</code> and paths), or settings which a node requires in order to be able to join a cluster, such as <code>cluster.name</code>and <code>network.host</code>.</p><p>注意：</p><ul><li>ES的大部分配置可以使用ES提供的接口在集群运行过程中动态的修改。</li><li>配置文件中应该要包含node节点相关的配置(例如node.name和path)，如果要加入es集群的话还需要添加集群相关的配置</li></ul><p><strong>配置文件：</strong></p><p>ES需要关注的配置文件有一下2个：</p><ul><li>elasticsearch.yml    # ES的主配置文件</li><li>log4j2.properties    # ES的日志相关配置</li></ul><p>默认这两个配置文件在$ES_HOME/config/路径下，但是，我们也可以在启动的时候手动指定配置文件的加载路径，启动命令为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch -Epath.conf=/path/to/my/config/</span><br></pre></td></tr></table></figure><p><strong>配置格式：</strong></p><p>ES的相关配置都是使用YAML语法格式，下面是两种配置方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path:</span><br><span class="line">    data: /var/lib/elasticsearch</span><br><span class="line">    logs: /var/log/elasticsearch</span><br></pre></td></tr></table></figure><p>等价于</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path.data: /var/lib/elasticsearch</span><br><span class="line">path.logs: /var/log/elasticsearch</span><br></pre></td></tr></table></figure><p><strong>环境变量引用</strong></p><p>如果需要在配置文件中引入系统的环境变量，可以使用下面这种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node.name:    $&#123;HOSTNAME&#125;</span><br><span class="line">network.host: $&#123;ES_NETWORK_HOST&#125;</span><br></pre></td></tr></table></figure><p><strong>根据提示输入配置</strong></p><p>ES的配置文件支持交互式的输入配置，可以配置在启动的时候手动输入对应的配置，配置方式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node:</span><br><span class="line">  name: $&#123;prompt.text&#125;</span><br></pre></td></tr></table></figure><p>放前台启动es的时候，会有下面这种提示信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Enter value for [node.name]:</span><br></pre></td></tr></table></figure><p>注意：这种方式在启动方式为后台守护进程启动时是无效的。</p><p><strong>设置默认配置</strong></p><p>一些默认配置如果不想让es自动生成，那么我们可以进行自定义，命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch -Edefault.node.name=My_Node</span><br></pre></td></tr></table></figure><p>注意：默认值只是在配置文件中没有配置，并且没有在命令行手动指定时生效。</p><p><strong>日志相关配置</strong></p><p>Elasticsearch uses <a href="http://logging.apache.org/log4j/2.x/" target="_blank" rel="noopener">Log4j 2</a> for logging. Log4j 2 can be configured using the log4j2.properties file. Elasticsearch exposes a single property <code>${sys:es.logs}</code> that can be referenced in the configuration file to determine the location of the log files; this will resolve to a prefix for the Elasticsearch log file at runtime.</p><p>For example, if your log directory (<code>path.logs</code>) is <code>/var/log/elasticsearch</code> and your cluster is named <code>production</code> then <code>${sys:es.logs}</code> will resolve to <code>/var/log/elasticsearch/production</code>.</p><p>ES使用java的log4J 2日志框架。ES在内部维护了一个变量：${sys:es.logs}，该变量记录的是es的集群名称</p><p>在输出日志时，这个日志框架将会调用这个变量生成对应的文件。</p><p>例如：</p><p>log4j2.properties配置文件是这个内容时</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appender.rolling.type = RollingFile </span><br><span class="line">appender.rolling.name = rolling</span><br><span class="line">appender.rolling.fileName = $&#123;sys:es.logs&#125;.log</span><br></pre></td></tr></table></figure><p>例如es集群名称为：testes，那么生成的日志文件名称将会是：testes.log</p><p>下面拿配置文件中的一段配置进行举例说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">appender.rolling.type = RollingFile</span><br><span class="line">appender.rolling.name = rolling</span><br><span class="line">appender.rolling.fileName = $&#123;sys:es.logs&#125;.log</span><br><span class="line">appender.rolling.layout.type = PatternLayout</span><br><span class="line">appender.rolling.layout.pattern = [%d&#123;ISO8601&#125;][%-5p][%-25c&#123;1.&#125;] %marker%.-10000m%n</span><br><span class="line">appender.rolling.filePattern = $&#123;sys:es.logs&#125;-%d&#123;yyyy-MM-dd&#125;.log</span><br><span class="line">appender.rolling.policies.type = Policies</span><br><span class="line">appender.rolling.policies.time.type = TimeBasedTriggeringPolicy</span><br><span class="line">appender.rolling.policies.time.interval = 1</span><br><span class="line">appender.rolling.policies.time.modulate = true</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>appender.rolling.filePattern。给这个配置参数赋值时，如果添加：.gz或者.zip这种后缀，那么在进行日志轮转的时候将会自动被压缩</li></ul><p><strong>deprecation log </strong></p><p>In addition to regular logging, Elasticsearch allows you to enable logging of deprecated actions. For example this allows you to determine early, if you need to migrate certain functionality in the future. By default, deprecation logging is enabled at the WARN level, the level at which all deprecation log messages will be emitted.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logger.deprecation.level = warn</span><br></pre></td></tr></table></figure><p>This will create a daily rolling deprecation log file in your log directory. Check this file regularly, especially when you intend to upgrade to a new major version.</p><p>The default logging configuration has set the roll policy for the deprecation logs to roll and compress after 1 GB, and to preserve a maximum of five log files (four rolled logs, and the active log).</p><p>You can disable it in the <code>config/log4j2.properties</code> file by setting the deprecation log level to <code>error</code>.</p><p>在ES中，还专门定义了这么一个日志文件：查看被废弃或者被修改的功能的调用日志</p><p>当你在调用ES时，如果涉及到一些在后续版本中要废弃或者要修改的配置项时，ES将会将该内容，以便管理员知悉并判断是否需要升级<br>例如 _all 即将被废弃，如果你某一个索引启用了 _all，则可能会有一条 deprecation log；<br>通过这个日志的内容，可以指导你决定是否迁移到新的版本</p><h4 id="重要配置参数说明"><a href="#重要配置参数说明" class="headerlink" title="重要配置参数说明"></a>重要配置参数说明</h4><h5 id="path-data和path-logs"><a href="#path-data和path-logs" class="headerlink" title="path.data和path.logs"></a><strong>path.data和path.logs</strong></h5><p>在默认情况下，数据目录和日志目录在es的主目录下，如果我们修改了路径，那么在升级es版本的时候，这些目录可能被删除</p><p>但是，实际情况是，我们一般都会把这两个目录自定义出来</p><p>如果数据目录只需要一个，那么可以是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path:</span><br><span class="line">  logs: /var/log/elasticsearch</span><br><span class="line">  data: /var/data/elasticsearch</span><br></pre></td></tr></table></figure><p>但是，es的数据目录可以设置为多个，如果我们有这方面的需求，我们可以设置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">path:</span><br><span class="line">  data:</span><br><span class="line">    - /mnt/elasticsearch_1</span><br><span class="line">    - /mnt/elasticsearch_2</span><br><span class="line">    - /mnt/elasticsearch_3</span><br></pre></td></tr></table></figure><p>注意：一个索引的分片只会存储在某一个目录中，不会分散存储。</p><h5 id="cluster-name"><a href="#cluster-name" class="headerlink" title="cluster.name"></a><strong>cluster.name</strong></h5><p>一个es节点只能加入到一个es集群当中，es集群的默认名称为：elasticsearch。在实际使用时，你应该将它修改为符合用途的名称</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster.name: logging-prod</span><br></pre></td></tr></table></figure><h5 id="node-name"><a href="#node-name" class="headerlink" title="node.name"></a><strong>node.name</strong></h5><p>如果在配置文件中没有配置，es默认将会分配一个随机的7个字符对节点进行标识。</p><p>注意，一旦分配，在这个node后续重启时，也将使用这个字符串，不会再重新生成。</p><p>这个配置参数建议是最好进行配置，配置方式例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node.name: prod-data-2</span><br></pre></td></tr></table></figure><p>如果想把node的名称定义为系统的主机名，es也提供了这个功能，使用这种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node.name: $&#123;HOSTNAME&#125;</span><br></pre></td></tr></table></figure><h5 id="bootstrap-memory-lock"><a href="#bootstrap-memory-lock" class="headerlink" title="bootstrap.memory_lock"></a><strong>bootstrap.memory_lock</strong></h5><p>It is vitally important to the health of your node that none of the JVM is ever swapped out to disk. One way of achieving that is set the <code>bootstrap.memory_lock</code> setting to <code>true</code>.</p><p>For this setting to have effect, other system settings need to be configured first. See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/setup-configuration-memory.html#mlockall" target="_blank" rel="noopener">Enable <code>bootstrap.memory_lock</code></a> for more details about how to set up memory locking correctly.</p><p>我们一般称之为锁内存配置。这个在ES中是及其重要的一个参数，开启了该参数后，能够保证，JVM内存被锁定在内存中，其中的数据永远不会被添加到swap交换分区中。</p><p>注意：如要要正确的开启这个参数，对系统的一些配置有要求。可以点击这个链接进行查看</p><p>开启配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.memory_lock: true</span><br></pre></td></tr></table></figure><p>在es启动之后，我们可以通过下面的接口来确认是否正确开启：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _nodes?filter_path=**.mlockall</span><br></pre></td></tr></table></figure><p>If you see that <code>mlockall</code> is <code>false</code>, then it means that the <code>mlockall</code> request has failed. You will also see a line with more information in the logs with the words <code>Unable to lock JVM Memory</code>.</p><p>The most probable reason, on Linux/Unix systems, is that the user running Elasticsearch doesn’t have permission to lock memory. This can be granted as follows:</p><p>如果接口的返回结果是false，那么，我们可以在日志文件中根据关键字：”Unable to lock JVM Memory”进行搜索，查看具体原因</p><p>有许多原因会导致开启失败，罗列为：</p><ul><li><p>Set <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/setting-system-settings.html#ulimit" target="_blank" rel="noopener"><code>ulimit -l unlimited</code></a> as root before starting Elasticsearch, or set <code>memlock</code> to <code>unlimited</code> in<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/setting-system-settings.html#limits.conf" target="_blank" rel="noopener"><code>/etc/security/limits.conf</code></a>.</p><p>需要打开涉及用户对内存的限制，如果没有配置，需要按照下方格式配置，这一部分我们在上面的基础环境配置时有记录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">elk soft memlock unlimited</span><br><span class="line">elk hard memlock unlimited</span><br></pre></td></tr></table></figure></li><li><p>Another possible reason why <code>mlockall</code> can fail is that the temporary directory (usually <code>/tmp</code>) is mounted with the <code>noexec</code> option. This can be solved by specifying a new temp directory using the <code>ES_JAVA_OPTS</code> environment variable:</p><p>如果系统在挂载临时目录(通常为/tmp)时，添加了noexec（禁止执行二进制文件）参数，也会引起这个问题，我们可以通过自定义临时目录进行解决，配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ES_JAVA_OPTS=&quot;$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir&quot;</span><br><span class="line">./bin/elasticsearch</span><br></pre></td></tr></table></figure><p>如果想永久生效，可以把这个配置记录到<code>jvm.options</code>配置文件中。</p></li></ul><p>注意：因为我们是源码包安装形式，所以这里我们不关注通过rpm包以及yum等管理工具安装的情况</p><p>锁内存问题分析：</p><blockquote><p>大多数操作系统都会将在内存中没有使用的数据转移到swap中，如果没有配置上述的参数，那么在es运行过程中，那么可能就会出现es占用的java堆内存中的数据被转移到swap中，也就是磁盘上。</p><p>我们知道，磁盘的读写性能和内存有非常大的差距，当在执行gc的时候，可能会导致gc时间从ms级别变成min级别，这么长的gc时间是绝对不能接受的，很有可能就会导致这个node节点响应变慢，甚至从集群中脱离。</p></blockquote><p>通过上面的问题分析，我们知道，以下方式也是能杜绝这个问题</p><ul><li>安装系统时不设置swap</li><li>如有swap，关闭swap</li><li>降低使用swap的倾向</li></ul><p>关闭swap的操作如下：</p><ul><li><p>临时生效，执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo swapoff -a</span><br></pre></td></tr></table></figure></li><li><p>永久生效，也就是系统重启后还生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">编辑/etc/fstab文件，将挂载swap的配置注释</span><br></pre></td></tr></table></figure></li></ul><p>降低使用swap的倾向：</p><ul><li><p>临时生效，执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w vm.swappiness=1</span><br></pre></td></tr></table></figure></li><li><p>永久生效，也就是系统重启后还生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;vm.swappiness = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure></li></ul><h5 id="network-host"><a href="#network-host" class="headerlink" title="network.host"></a><strong>network.host</strong></h5><p>默认情况下，es将服务监听在本机的回环地址，我们可以使用下列参数修改监听地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.host: 192.168.1.10</span><br></pre></td></tr></table></figure><p>注意：</p><p>默认情况下，es假定你是工作在开发模式，假如你有一些配置没有配置正确，es也能正常启动，并且将这些配置记录到日志文件中(日志级别为warning)</p><p>但是，一旦你配置了网络相关的配置，例如network.host，那么es将判断你从开发者模式提升为生产模式，这个时候如果有一些配置没有配置正确，那么es将产生异常，并且启动失败。</p><p>这种一种非常重要的安全机制，能够确保你不会因为错误的配置而导致数据丢失。</p><p>下面是当作为生产模式运行时，具体要检测的依赖配置</p><p>Ideally, Elasticsearch should run alone on a server and use all of the resources available to it. In order to do so, you need to configure your operating system to allow the user running Elasticsearch to access more resources than allowed by default.</p><p>The following settings <strong>must</strong> be addressed before going to production:</p><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/heap-size.html" target="_blank" rel="noopener">Set JVM heap size</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/setup-configuration-memory.html" target="_blank" rel="noopener">Disable swapping</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/file-descriptors.html" target="_blank" rel="noopener">Increase file descriptors</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/vm-max-map-count.html" target="_blank" rel="noopener">Ensure sufficient virtual memory</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/max-number-of-threads.html" target="_blank" rel="noopener">Ensure sufficient threads</a></li></ul><p>网络相关的配置，除了这个常见的监听地址的配置，还有很多，我们在下面会进行汇总讲解</p><h5 id="discovery-zen-ping-unicast-hosts"><a href="#discovery-zen-ping-unicast-hosts" class="headerlink" title="discovery.zen.ping.unicast.hosts"></a><strong>discovery.zen.ping.unicast.hosts</strong></h5><p>当在组成一个es集群的时候，需要添加其他集群节点，这个时候需要如下的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">discovery.zen.ping.unicast.hosts:</span><br><span class="line">   - 192.168.1.10:9300</span><br><span class="line">   - 192.168.1.11 </span><br><span class="line">   - seeds.mydomain.com</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>如果没有指定端口，则默认为：transport.profiles.default.port和transport.tcp.port(这里指的是TCP端口)</li><li>如果一个主机名映射了多个ip，那么会把解析出来的所有ip都添加进来</li></ul><h5 id="discovery-zen-minimum-master-nodes"><a href="#discovery-zen-minimum-master-nodes" class="headerlink" title="discovery.zen.minimum_master_nodes"></a><strong>discovery.zen.minimum_master_nodes</strong></h5><p>为了防止数据的丢失，需要确保每一个主节点都知晓：组成一个集群最少可以有几个主节点</p><p>如果没有这个配置，当集群遭遇到网络问题导致各个集群节点之间的通信出现问题时，整个集群可能会变成2个独立的集群，这个现象我们称之为：a split brain(脑裂)，这会导致数据的丢失。</p><p>配置规则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(master_eligible_nodes / 2) + 1</span><br></pre></td></tr></table></figure><p>举例说明，例如当前集群有3个节点，那么配置就应该是(3 / 2) + 1或者2(注意，我们是取整数)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">discovery.zen.minimum_master_nodes: 2</span><br></pre></td></tr></table></figure><p>除了在配置文件中配置，在运行过程中，我们可以通过接口临时修改</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;transient&quot;: &#123;</span><br><span class="line">    &quot;discovery.zen.minimum_master_nodes&quot;: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>a split brain详解：</p><blockquote><p>假定集群有2个节点，minimum_master_nodes的值设置为1，当网络出现问题时，每个节点都会把自己提升为集群的主节点(认为另一个节点已经终止)，结果就是会产生2个集群。</p><p>当网络恢复时，节点不会重新加入集群。只有当节点重启的时候，才会重新加入集群，但是，重启节点上的数据会丢失。</p><p>也正是因为这个原因，所以，我们的集群主节点最好是3个以上</p></blockquote><h5 id="网络相关配置汇总"><a href="#网络相关配置汇总" class="headerlink" title="网络相关配置汇总"></a>网络相关配置汇总</h5><p>es配置文件中，有以下网络相关配置</p><ul><li><strong>network.host</strong>。略。</li><li><p><strong>discovery.zen.ping.unicast.hosts</strong>。略</p></li><li><p><strong>http.port</strong></p><p>Port to bind to for incoming HTTP requests. Accepts a single value or a range. If a range is specified, the node will bind to the first available port in the range.</p><p>Defaults to <code>9200-9300</code>.</p><p>设置节点的http端口，提供接口处理相对应的请求，可以赋值为单个值或者一个范围，如果是一个范围，那么将会使用第一个值。</p></li><li><p><strong>transport.tcp.port</strong></p><p>Port to bind for communication between nodes. Accepts a single value or a range. If a range is specified, the node will bind to the first available port in the range.</p><p>Defaults to <code>9300-9400</code>.</p><p>设置节点的TCP接口，用于集群之间的通信，和上面类似，可以赋值为单个值或者一个范围，如果是一个范围，那么将会使用第一个值。</p></li></ul><h2 id="ES的启动引导检查"><a href="#ES的启动引导检查" class="headerlink" title="ES的启动引导检查"></a>ES的启动引导检查</h2><p>在ES的早期版本，一些es和系统配置不符合要求时，只是输出到日志文件中，供用户查看，但是考虑到很多用户不去看这些日志文件，因此，在后续版本中，es把这些检查放到了启动过程中，当有配置不符合要求时，就是在启动过程中显示出来(注意，只针对生产模式，开发模式只是记录日志)</p><p>下面是一些检测指标，对应的详细配置会在下面的<strong>重要的系统配置</strong>中说明</p><ul><li><p>Heap size check</p><p>JVM初始值和最大值必须要设置一致。</p></li><li><p>File descriptor check</p><p>ES需要大量的文件描述符(Linux中一切皆文件)，是否&gt;=65535</p></li><li><p>Memory lock check</p><p>锁内存配置是否开启。这个在前面的配置参数中有说明了。</p></li><li><p>Maximum number of threads check</p><p>最大线程数限制。ES将接收到处理请求拆分成为多个步骤，每个步骤都会使用不同的线程池。</p><p>因此，ES需要创建大量的线程，在启动前的check操作能够保证es在运行过程中有足够多的资源。</p><p>系统需要保证用户至少能创建2048个线程。</p><p>这个的配置在/etc/security/limits.conf和/etc/security/limits.d/90-nproc.conf配置文件中，参数是nproc，建议配置&gt;=65536</p></li><li><p>Maximum size virtual memory check</p><p>虚拟内存限制。需要把内存限制打开</p><p>这个的配置在/etc/security/limits.conf配置文件中，参数是memlock，设置为unlimited</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ cat /etc/security/limits.conf</span><br><span class="line">elk soft memlock unlimited</span><br><span class="line">elk hard memlock unlimited</span><br></pre></td></tr></table></figure><p>vm.max_map_count</p></li><li><p>还是内存相关的配置，这个是内存参数配置。</p><p>配置文件：/etc/sysctl.conf，配置参数：vm.max_map_count，默认值是262144，建议配置&gt;=655360</p></li></ul><h2 id="重要的系统配置"><a href="#重要的系统配置" class="headerlink" title="重要的系统配置"></a>重要的系统配置</h2><h3 id="JVM堆内存"><a href="#JVM堆内存" class="headerlink" title="JVM堆内存"></a>JVM堆内存</h3><p>ES的JVM内存配置有以下注意事项</p><ul><li>每个节点的Xms和Xmx设置为相等的值</li><li>更大的内存设置可能会导致gc时间变长，需要考虑一个平衡</li><li>JVM最大内存设置不要超过系统物理内存的一半，需要确保给内核文件系统缓存留有足够的物理内存</li><li>上限不要超过32GB</li><li>26G是一个非常合理设置</li></ul><h3 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h3><p>当文件描述符不足时，造成的后果将会是灾难性的，可以造成数据的丢失。</p><p>这个的配置在/etc/security/limits.conf配置文件中，参数是nofile，建议配置&gt;=65536</p><p>确保为启动es服务的用户设置的值&gt;=65536</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ cat /etc/security/limits.conf</span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 65536</span><br></pre></td></tr></table></figure><p>可以不需要登录服务器，通过以下接口获取当前的配置值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _nodes/stats/process?filter_path=**.max_file_descriptors</span><br></pre></td></tr></table></figure><h3 id="关闭swap"><a href="#关闭swap" class="headerlink" title="关闭swap"></a>关闭swap</h3><p>这部分在es的配置讲解部分（bootstrap.memory_lock部分）记录了</p><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>和ES使用内存映射系统有关，需要我们优化内核参数</p><p>默认值为262144</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ sysctl  -a | grep vm.max_map_count</span><br><span class="line">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure><p>建议配置为&gt;=655360</p><ul><li><p>临时生效，执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w vm.max_map_count=655360</span><br></pre></td></tr></table></figure></li><li><p>永久生效，也就是系统重启后还生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;vm.max_map_count = 655360&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure></li></ul><h3 id="最大线程数"><a href="#最大线程数" class="headerlink" title="最大线程数"></a>最大线程数</h3><p>其实也就是最大进程数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ cat /etc/security/limits.d/90-nproc.conf</span><br><span class="line">*       soft    nproc   65536</span><br><span class="line">*       hard    nproc   65536</span><br></pre></td></tr></table></figure><p>注意：如果设置为所有用户生效，则需要修改90-nproc.conf配置文件，如果是指定某个用户生效，则修改/etc/security/limits.conf即可，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ cat /etc/security/limits.conf</span><br><span class="line">elk       soft    nproc   65536</span><br><span class="line">elk       hard    nproc   65536</span><br></pre></td></tr></table></figure><h2 id="ES集群部署"><a href="#ES集群部署" class="headerlink" title="ES集群部署"></a>ES集群部署</h2><h3 id="ES集群配置"><a href="#ES集群配置" class="headerlink" title="ES集群配置"></a>ES集群配置</h3><p>在使用最简化的3节点时，master和data参数都设置为true</p><p>下面以一个节点的配置为例，每个节点上的配置基本相同，就只有监听的ip不一致。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> cluster.name: testelk</span><br><span class="line">http.port: 9500</span><br><span class="line">transport.tcp.port: 9600-9700</span><br><span class="line">path:</span><br><span class="line"> logs: /home/elk/logs-5.3.0</span><br><span class="line"> data: /home/elk/data-5.3.0</span><br><span class="line">node.master: true</span><br><span class="line">node.data: true</span><br><span class="line">node.name: node001</span><br><span class="line">network.host: 192.168.100.113</span><br><span class="line">bootstrap.memory_lock: true</span><br><span class="line">discovery.zen.ping.unicast.hosts: [&quot;192.168.100.113&quot;, &quot;192.168.101.172&quot;, &quot;192.168.103.133&quot;]</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">transport.tcp.compress: true</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br><span class="line">thread_pool:</span><br><span class="line">  search:</span><br><span class="line">    size: 200</span><br><span class="line">    queue_size: 2000</span><br><span class="line">  bulk:</span><br><span class="line">    queue_size: 2000</span><br></pre></td></tr></table></figure><h3 id="kibana配置"><a href="#kibana配置" class="headerlink" title="kibana配置"></a>kibana配置</h3><h2 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h2><p>mapping的作用是定义document，包括：</p><ul><li>包含哪些字段</li><li>哪些字段需要存储</li><li>哪些字段能被索引</li></ul><p>例如：</p><ul><li>哪一个字符串字段被定义为full text fields</li><li>哪个字段包含数字、日志、地理位置</li><li>是否所有的字段都能被索引(通过<code>_all</code>参数)</li><li>日期格式</li><li>自定义规则</li></ul><p>每一个索引拥有一个或者多个的mapping type，这些mapping通常用于区分不同逻辑组的document，例如：用户相关的document通常type设置为user，博客相关的document通常type设置为blog。每一个type可以定义一个mapping</p><h3 id="mapping-type"><a href="#mapping-type" class="headerlink" title="mapping type"></a>mapping type</h3><p>每一个mapping类型都会有以下的字段：</p><ul><li><p>元类型字段</p><p>mapping的元类型字段，主要是作用于定义document的元字段，例如：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-index-field.html" target="_blank" rel="noopener"><code>_index</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-type-field.html" target="_blank" rel="noopener"><code>_type</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-id-field.html" target="_blank" rel="noopener"><code>_id</code></a>, and <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-source-field.html" target="_blank" rel="noopener"><code>_source</code></a> fields.</p></li><li><p>字段或者自定义属性</p><p>每一个mapping类型都包含一组字段。例如user type包含<code>title</code>, <code>name</code>, and <code>age</code> fields，a <code>blogpost</code> type might contain <code>title</code>, <code>body</code>, <code>user_id</code>and <code>created</code> fields</p></li></ul><p>注意：在一个索引中，两个不同的type中如果有一个同名的字段，那么这个字段必须使用相同的mapping</p><h3 id="字段数据类型"><a href="#字段数据类型" class="headerlink" title="字段数据类型"></a>字段数据类型</h3><p>有以下数据类型可以供字段选择</p><ul><li>基础类型：like text, keyword, date, long, double, boolean or ip.</li><li>json类型： object or nested.</li><li>专门的类型：like geo_point, geo_shape, or completion.</li></ul><h3 id="动态mapping"><a href="#动态mapping" class="headerlink" title="动态mapping"></a>动态mapping</h3><p>mapping type以及具体的字段在使用的时候，可以不需要提前指定配置，而是可以动态自动生成。</p><p>自动发现并且给字段添加相对应的类型我们称之为：”<em>dynamic mapping</em>“</p><p>动态mapping规则可以根据你的需求进行下自定义，有以下几种：</p><ul><li><p><code>_default_</code> mapping</p><p>为新的mapping配置基础的mapping配置。相当于是继承关系</p></li><li><p>Dynamic field mappings</p><p>这个规则管理动态字段发现</p></li><li><p>Dynamic templates</p><p>动态添加字段</p></li></ul><h4 id="default-mapping"><a href="#default-mapping" class="headerlink" title="_default_ mapping"></a><code>_default_</code> mapping</h4><p>default mapping的作用是定义一些全局的配置，在后续的多个mapping定义的时候如果没有手动的指定这个配置，那么会继承这个默认配置。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_default_&quot;: &#123; </span><br><span class="line">      &quot;_all&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;user&quot;: &#123;&#125;, </span><br><span class="line">    &quot;blogpost&quot;: &#123; </span><br><span class="line">      &quot;_all&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>设置全局的配置：将_all字段的标志位设置为false</p><ul><li>user这个type的mapping将会继承这个配置</li><li>blogpost这个type的mapping将会重写这个配置为true</li></ul><p>注意：尽管这个配置可以在索引已经存在的情况下执行，但是执行之后只是影响后来生成的mapping。</p><p>同样的，这个功能也可以用于索引的模板中</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">PUT _template/logging</span><br><span class="line">&#123;</span><br><span class="line">  &quot;template&quot;:   &quot;logs-*&quot;, </span><br><span class="line">  &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1 &#125;, </span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_default_&quot;: &#123;</span><br><span class="line">      &quot;_all&quot;: &#123; </span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;dynamic_templates&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;strings&quot;: &#123; </span><br><span class="line">            &quot;match_mapping_type&quot;: &quot;string&quot;,</span><br><span class="line">            &quot;mapping&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">              &quot;fields&quot;: &#123;</span><br><span class="line">                &quot;raw&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;:  &quot;keyword&quot;,</span><br><span class="line">                  &quot;ignore_above&quot;: 256</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">测试：</span><br><span class="line">PUT logs-2015.10.01/event/1</span><br><span class="line">&#123; &quot;message&quot;: &quot;error:16&quot; &#125;</span><br></pre></td></tr></table></figure><h3 id="明确mapping-Explicit-mappings"><a href="#明确mapping-Explicit-mappings" class="headerlink" title="明确mapping- Explicit mappings"></a>明确mapping- Explicit mappings</h3><p>实际情况下，我们会比es更了解我们的数据，因此，我们可以在创建索引的时候就定义好mapping</p><p>我们可以：</p><ul><li>在创建索引的时候，初始化定义mapping </li><li>当索引已存在时，可以新增字段</li></ul><p>注意：不能更新现有的mapping的字段，更新通过下面的方式</p><h3 id="更新已存在的mapping"><a href="#更新已存在的mapping" class="headerlink" title="更新已存在的mapping"></a>更新已存在的mapping</h3><p>已经存在的mapping中的字段是不能直接被update的，如果修改mapping则意味着现有索引中的document都会成为无效数据，因此，如果我们想要更新mapping：</p><ol><li>新建一个mapping</li><li>重建索引</li><li>reindex：索引数据迁移</li></ol><h3 id="字段共享mapping"><a href="#字段共享mapping" class="headerlink" title="字段共享mapping"></a>字段共享mapping</h3><p>不同的mapping通常用于划分和组织字段组，但是以下的这些字段不会只作用于单个mapping局部</p><ul><li>字段的名称相同</li><li>位于同一个索引中</li><li>在不同的mapping  type中</li><li>mapping内部有相同的字段</li><li>必须拥有相同的mapping</li></ul><p>举例说明：</p><blockquote><p>如果title字段同时存在于user和blogpost这两个mapping type中，那么这个字段在两个mapping type中就必须保持一致的mapping</p><p>但是存在这些例外，直接看官方原文即可：</p><p>The only exceptions to this rule are the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/copy-to.html" target="_blank" rel="noopener"><code>copy_to</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/dynamic.html" target="_blank" rel="noopener"><code>dynamic</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/enabled.html" target="_blank" rel="noopener"><code>enabled</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/ignore-above.html" target="_blank" rel="noopener"><code>ignore_above</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/include-in-all.html" target="_blank" rel="noopener"><code>include_in_all</code></a>, and <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/properties.html" target="_blank" rel="noopener"><code>properties</code></a> parameters, which may have different settings per field.</p></blockquote><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p>下面是一个案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index </span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;user&quot;: &#123; </span><br><span class="line">      &quot;_all&quot;:       &#123; &quot;enabled&quot;: false  &#125;, </span><br><span class="line">      &quot;properties&quot;: &#123; </span><br><span class="line">        &quot;title&quot;:    &#123; &quot;type&quot;: &quot;text&quot;  &#125;, </span><br><span class="line">        &quot;name&quot;:     &#123; &quot;type&quot;: &quot;text&quot;  &#125;, </span><br><span class="line">        &quot;age&quot;:      &#123; &quot;type&quot;: &quot;integer&quot; &#125;  </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;blogpost&quot;: &#123; </span><br><span class="line">      &quot;_all&quot;:       &#123; &quot;enabled&quot;: false  &#125;, </span><br><span class="line">      &quot;properties&quot;: &#123; </span><br><span class="line">        &quot;title&quot;:    &#123; &quot;type&quot;: &quot;text&quot;  &#125;, </span><br><span class="line">        &quot;body&quot;:     &#123; &quot;type&quot;: &quot;text&quot;  &#125;, </span><br><span class="line">        &quot;user_id&quot;:  &#123;</span><br><span class="line">          &quot;type&quot;:   &quot;keyword&quot; </span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;created&quot;:  &#123;</span><br><span class="line">          &quot;type&quot;:   &quot;date&quot;, </span><br><span class="line">          &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="元数据类型字段"><a href="#元数据类型字段" class="headerlink" title="元数据类型字段"></a>元数据类型字段</h3><h3 id="字段数据类型-1"><a href="#字段数据类型-1" class="headerlink" title="字段数据类型"></a>字段数据类型</h3><h4 id="keyword数据类型"><a href="#keyword数据类型" class="headerlink" title="keyword数据类型"></a>keyword数据类型</h4><p>这个数据类型适用于例如：</p><ul><li>email addresses  email地址</li><li>Hostnames 主机名</li><li>Status code  状态码</li><li>zip codes  编码</li><li>tags  指定的标志</li></ul><p>这种数据类型，主要的作用是过滤功能(例如博客文章中可以通过status为<em>published</em>已发布的来进行过滤)、sort排序功能、以及聚合。</p><p>keyword是唯一一种类型：他们的值可以被检索</p><p>下面是一个例子：创建索引的实时设定mapping，mapping中包含一个字段属性，其类型为keyword</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;my_type&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;tags&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;keyword&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>keyword中有以下这些参数，需要重点关注一下：</p><ul><li><p>ignore_above</p><blockquote><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/ignore-above.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/ignore-above.html</a></p></blockquote></li></ul><h4 id="Text数据类型"><a href="#Text数据类型" class="headerlink" title="Text数据类型"></a>Text数据类型</h4><p>顾名思义，这个数据类型主要是作用于例如：邮件内容、产品描述信息等不规则的并且数据量较大的文本内容。</p><p>案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;my_type&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;full_name&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="二级字段类型-fields配置"><a href="#二级字段类型-fields配置" class="headerlink" title="二级字段类型-fields配置"></a>二级字段类型-fields配置</h3><p>参考连接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/multi-fields.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/multi-fields.html</a></p><h2 id="ES-API"><a href="#ES-API" class="headerlink" title="ES API"></a>ES API</h2><h3 id="API约定及惯例"><a href="#API约定及惯例" class="headerlink" title="API约定及惯例"></a>API约定及惯例</h3><h4 id="multiple-indices"><a href="#multiple-indices" class="headerlink" title="multiple indices"></a>multiple indices</h4><p>大部分涉及索引的api都支持匹配多个index操作,有如下这些方式实现</p><ul><li>多个索引：test1,test2,test3</li><li>所有索引：_all</li><li>通配符匹配：例如：<code>test*</code>、<code>*test</code> 、 <code>te*t</code> 、 <code>*test*</code></li><li>加减： “add” (<code>+</code>) and “remove” (<code>-</code>), for example: <code>+test*,-test3</code>.</li></ul><p>All multi indices API support the following url query string parameters:</p><p>使用这种方式的api都有一下参数</p><ul><li><p><strong>ignore_unavailable</strong></p><p>是否忽略不可用(不存在或者异常的)的索引，取值为true|false</p></li><li><p><strong>allow_no_indices</strong></p><p>控制当使用通配符匹配时，如果没有结果，是否返回fail。取值为true|false</p><p>不止针对通配符情况，也支持_all以及不指定任何index的情况</p><p>这个配置同样支持aliases</p></li><li><p><strong>expand_wildcards</strong></p><p>取值为open|closed|(open,closed)</p><p>控制通配符匹配到的索引，当设置为open时，将只会匹配到open的索引，也就是正常的索引，当设置为closed时，将只会匹配到closed的索引。</p><p>也可以设置为open+closed，以匹配所以的索引</p><p>注意：如果设置为none，这个功能将会被disable。如果设置为all，那么等价于open+closed</p></li></ul><p>注意：只作用于单个索引的api（例如document api等等），没有上面这些参数</p><h4 id="Date-math-support-in-index-names"><a href="#Date-math-support-in-index-names" class="headerlink" title="Date math support in index names"></a>Date math support in index names</h4><p>后续涉及时再进行补充。</p><h4 id="Common-option-1"><a href="#Common-option-1" class="headerlink" title="Common option"></a>Common option</h4><p>通用选项。</p><h4 id="URL-based-access-control"><a href="#URL-based-access-control" class="headerlink" title="URL-based access control"></a>URL-based access control</h4><p>后续补充</p><h3 id="Document-APIs"><a href="#Document-APIs" class="headerlink" title="Document APIs"></a>Document APIs</h3><h4 id="Reading-and-Writing-documents-读写document"><a href="#Reading-and-Writing-documents-读写document" class="headerlink" title="Reading and Writing documents-读写document"></a>Reading and Writing documents-读写document</h4><p>链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/docs-replication.html#_introduction" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/docs-replication.html#_introduction</a></p><p>每一个索引在ES中都会被分割成为shard分片，并且每一个shard都会有不等的copies副本。</p><p>当有多个副本的时候，这多个副本，我们就称之为<strong>replication group</strong>-副本组，当document有新增或者删除的时候，我们需要保证这个组中的每个副本的数据和分片是同步的，防止出现数据不一致的情况</p><p>保证分片和副本之间的数据同步的进程，我们称之为：<em>data replication model</em></p><h5 id="基础写模型-Basic-write-model"><a href="#基础写模型-Basic-write-model" class="headerlink" title="基础写模型- Basic write model"></a>基础写模型- Basic write model</h5><p>ES接收索引写请求，首先根据路由服务（根据document为处理依据），将请求转发给副本组。</p><p>副本组收到请求之后，这个请求将会被转发给副本组中的主分片(每个副本组中还会区分主从关系)，这个副本主分片转发请求给其他的副本，</p><p>主分片按照下面的流程处理：</p><ol><li>检验请求是否符合标准，拒绝无效的请求</li><li>在本地执行这个操作(写document的操作)</li><li>转发这个请求给所有的副本，这个过程是同步的，而不是异步</li><li>一旦所有的副本都执行完毕，并且返回结构给主分片，主分片返回ack给客户端。</li></ol><h5 id="写失败处理"><a href="#写失败处理" class="headerlink" title="写失败处理"></a>写失败处理</h5><p>暂时略</p><h5 id="基础读模型"><a href="#基础读模型" class="headerlink" title="基础读模型"></a>基础读模型</h5><p>读操作的时候，可以是非常轻量级的根据document的id进行，也可以是非常重的请求(非常复杂的聚合条件)</p><p>当一个node节点接收到一个读请求时，这个node负责转发这个请求给具有相关分片的node，并且收集响应，然后返回给客户端，我们称这样的node为坐标node(<em>coordinating node</em>)</p><p>这个node的基本的工作流为：</p><ul><li>解析请求，获取这个请求涉及哪些分片，因为很多读请求会涉及到多个索引，他们也就需要读取到多个分片</li><li>从对应分片的副本组中选择一个活跃状态的副本，这个副本可以使主或者从角色，默认情况下，es会轮询调度到这些副本</li><li>发送请求到这个指定的副本</li><li>坐标node，汇总所有副本返回的结果，然后响应客户端。</li></ul><h5 id="读失败处理"><a href="#读失败处理" class="headerlink" title="读失败处理"></a>读失败处理</h5><p>暂时略</p><h4 id="新建document"><a href="#新建document" class="headerlink" title="新建document"></a>新建document</h4><p>案例：</p><p>新建一个document</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT twitter/tweet/1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行之后，es的响应返回为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;_shards&quot; : &#123;</span><br><span class="line">        &quot;total&quot; : 3,</span><br><span class="line">        &quot;failed&quot; : 0,</span><br><span class="line">        &quot;successful&quot; : 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;_index&quot; : &quot;twitter&quot;,</span><br><span class="line">    &quot;_type&quot; : &quot;tweet&quot;,</span><br><span class="line">    &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">    &quot;_version&quot; : 1,</span><br><span class="line">    &quot;created&quot; : true,</span><br><span class="line">    &quot;result&quot; : created</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为，这个索引之前在创建的时候设置为3个分片，所以这里的shard为3，_shards这一个块展示的是复制过程相关的结果信息，success表示所有的副本都是成功状态的。</p><p>分片数量可以根据索引相关的接口的进行查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[elk@node003 ~]$ curl http://192.168.103.133:9500/_cat/indices?v</span><br><span class="line">health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">green  open   twitter         2Gxyl8acRa222-gdYhE4ig   3   2          1            0     14.1kb          4.7kb</span><br><span class="line">green  open   .kibana         JjZFr5NvTXSOUv6DjwyF0w   1   1          1            0      6.3kb          3.1kb</span><br><span class="line">green  open   logs-2015.10.01 Ubo73cz5RRO4ipU33zdCqQ   1   1          0            0       318b           159b</span><br></pre></td></tr></table></figure><p>不手动指定id，使用自动增长的序列号(注意使用POST代替PUT)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST twitter/tweet/</span><br><span class="line">&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回结果为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;twitter&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;tweet&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;AWu2sgI5Rw8iDPJNYgMY&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;result&quot; : &quot;created&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 3,</span><br><span class="line">    &quot;successful&quot; : 3,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，document的为：AWu2sgI5Rw8iDPJNYgMY</p><h4 id="查询document"><a href="#查询document" class="headerlink" title="查询document"></a>查询document</h4><p>根据document的id进行查询</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/tweet/0</span><br><span class="line"></span><br><span class="line">[elk@node003 ~]$ curl http://192.168.103.133:9500/twitter/tweet/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;twitter&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;tweet&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="删除document"><a href="#删除document" class="headerlink" title="删除document"></a>删除document</h4><p>基础document的id进行删除</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">格式例如：curl -XDELETE &apos;http://localhost:9200/twitter/tweet/1&apos;</span><br></pre></td></tr></table></figure><h3 id="Indices-APIs-索引api"><a href="#Indices-APIs-索引api" class="headerlink" title="Indices APIs-索引api"></a>Indices APIs-索引api</h3><h4 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a><strong>创建索引</strong></h4><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">PUT twitter</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;index&quot; : &#123;</span><br><span class="line">            &quot;number_of_shards&quot; : 3, </span><br><span class="line">            &quot;number_of_replicas&quot; : 2 </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">或者可以省略index</span><br><span class="line">PUT twitter</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : 3,</span><br><span class="line">        &quot;number_of_replicas&quot; : 2</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建索引并指定mapping</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PUT test</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">        &quot;type1&quot; : &#123;</span><br><span class="line">            &quot;properties&quot; : &#123;</span><br><span class="line">                &quot;field1&quot; : &#123; &quot;type&quot; : &quot;text&quot; &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建索引并设置alias</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT test</span><br><span class="line">&#123;</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">        &quot;alias_1&quot; : &#123;&#125;,</span><br><span class="line">        &quot;alias_2&quot; : &#123;</span><br><span class="line">            &quot;filter&quot; : &#123;</span><br><span class="line">                &quot;term&quot; : &#123;&quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;routing&quot; : &quot;kimchy&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a><strong>删除索引</strong></h4><p>执行下面的接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /twitter</span><br></pre></td></tr></table></figure><p>索引可以是：</p><ul><li>单个索引</li><li>_all 所有索引</li><li>通配符表达式，例如添加*等</li></ul><p>因为可以批量的删除，所以存在一定的风险，当我们希望关闭这个功能的时候，设置action.destructive_requires_name的值为true。这个配置也可以在集群运行过程中被修改。</p><h4 id="查看索引"><a href="#查看索引" class="headerlink" title="查看索引"></a><strong>查看索引</strong></h4><p>接口为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET twitter</span><br></pre></td></tr></table></figure><p>查看twitter索引，注意可以使用通配符、alias、_all等匹配多个索引</p><p>过滤索引的特殊配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/_settings</span><br><span class="line">GET twitter/_mappings</span><br><span class="line">GET twitter/_aliases</span><br></pre></td></tr></table></figure><h4 id="索引是否存在"><a href="#索引是否存在" class="headerlink" title="索引是否存在"></a><strong>索引是否存在</strong></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HEAD twitter</span><br></pre></td></tr></table></figure><p>接口返回404为不存在，200则为存在。</p><h4 id="put-mapping-mapping的新增"><a href="#put-mapping-mapping的新增" class="headerlink" title="put mapping-mapping的新增"></a><strong>put mapping-mapping的新增</strong></h4><p>我们可以实现：</p><ul><li><p>在现有的索引上新增type的mapping</p></li><li><p>创建索引时指定mapping</p></li><li>在现有的mapping基础上新增字段</li></ul><p>案例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># 创建索引时指定mapping</span><br><span class="line">PUT twitter </span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;tweet&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;message&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 在现有索引上新增mapping type</span><br><span class="line">PUT twitter/_mapping/user </span><br><span class="line">&#123;</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: &quot;text&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 现有mapping上新增字段</span><br><span class="line">PUT twitter/_mapping/tweet </span><br><span class="line">&#123;</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;user_name&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: &quot;text&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="get-mapping"><a href="#get-mapping" class="headerlink" title="get mapping"></a><strong>get mapping</strong></h4><p>语法格式为：host:port/{index}/_mapping/{type}</p><p>案例为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GET /_mapping/tweet,kimchy</span><br><span class="line">=</span><br><span class="line">GET /_all/_mapping/tweet,book</span><br><span class="line"></span><br><span class="line">GET /_all/_mapping</span><br><span class="line">=</span><br><span class="line">GET /_mapping</span><br></pre></td></tr></table></figure><h4 id="获取具体字段的mapping"><a href="#获取具体字段的mapping" class="headerlink" title="获取具体字段的mapping"></a><strong>获取具体字段的mapping</strong></h4><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/_mapping/tweet/field/field1,field2,...</span><br></pre></td></tr></table></figure><h4 id="判断mapping-type是否存在"><a href="#判断mapping-type是否存在" class="headerlink" title="判断mapping type是否存在"></a><strong>判断mapping type是否存在</strong></h4><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HEAD twitter/_mapping/tweet</span><br></pre></td></tr></table></figure><p>返回值为404或者200</p><h4 id="索引别名-index-aliases"><a href="#索引别名-index-aliases" class="headerlink" title="索引别名-index aliases"></a><strong>索引别名-index aliases</strong></h4><p>索引别名允许给索引重新定义一个名称，当在调用这个alias的时候，es会自动的把这个alias转换为真实的index,</p><p>一个alias可以被映射到多个index上，</p><p>添加alias:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;test1&quot;, &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;test2&quot;, &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">或者</span><br><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;indices&quot; : [&quot;test1&quot;, &quot;test2&quot;], &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">或者</span><br><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;test*&quot;, &quot;alias&quot; : &quot;all_test_indices&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="获取索引alias"><a href="#获取索引alias" class="headerlink" title="获取索引alias"></a><strong>获取索引alias</strong></h4><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">语法格式：/&#123;index&#125;/_alias/&#123;alias&#125;</span><br><span class="line">例如：GET /logs_20162801/_alias/*</span><br></pre></td></tr></table></figure><p>在所有index中搜索alias为2016</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_alias/2016</span><br></pre></td></tr></table></figure><p>下面的方式可以检查alias是否存在：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HEAD /_alias/2016</span><br><span class="line">HEAD /_alias/20*</span><br><span class="line">HEAD /logs_20162801/_alias/*</span><br></pre></td></tr></table></figure><h4 id="索引模板"><a href="#索引模板" class="headerlink" title="索引模板"></a><strong>索引模板</strong></h4><p>作用：新建的index能够继承这一套的配置</p><p>模板中包括setting、mapping等配置，以及控制哪些index可以继承这个模板配置。</p><p>例如：</p><p>新建索引模板：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">PUT _template/template_1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;template&quot;: &quot;te*&quot;,</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;number_of_shards&quot;: 1</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;type1&quot;: &#123;</span><br><span class="line">      &quot;_source&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;host_name&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;created_at&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">          &quot;format&quot;: &quot;EEE MMM dd HH:mm:ss Z YYYY&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个生产案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">PUT _template/realtime_baobei_order</span><br><span class="line">&#123;</span><br><span class="line">  &quot;order&quot;: 0,</span><br><span class="line">  &quot;template&quot;: &quot;realtime_baobei_order-*&quot;,</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &#123;</span><br><span class="line">        &quot;max_result_window&quot;: &quot;30000&quot;,</span><br><span class="line">        &quot;codec&quot;: &quot;best_compression&quot;,</span><br><span class="line">        &quot;refresh_interval&quot;: &quot;-1&quot;,</span><br><span class="line">        &quot;number_of_shards&quot;: &quot;6&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot;: &quot;0&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;aliases&quot;: &#123;&#125;,</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">      &quot;order&quot;:&#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;cancel_reason&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;cook_tm&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">          &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;customer_name&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;customer_tel&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;expect_send_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;finish_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;food_agg&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;join_expire_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;leave_shop_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;location_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;location_name&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;order_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;package_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;pay_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;place_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;pt&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;remark&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;serial_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_1&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_2&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_4&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_5&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_6&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_7&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_998&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_999&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;shop_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;shop_name&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;shop_tel&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;status&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;user_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p>删除索引模板：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /_template/template_1</span><br></pre></td></tr></table></figure><p>查看索引模板信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_template/template_1</span><br><span class="line">GET /_template/temp*</span><br><span class="line">GET /_template/template_1,template_2</span><br><span class="line">获取所有的模板：</span><br><span class="line">GET /_template</span><br></pre></td></tr></table></figure><p>判断索引模板是否存在：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HEAD _template/template_1</span><br></pre></td></tr></table></figure><h4 id="索引状态"><a href="#索引状态" class="headerlink" title="索引状态"></a><strong>索引状态</strong></h4><p>语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看所有的索引的状态</span><br><span class="line">GET /_stats</span><br><span class="line"></span><br><span class="line"># 查看指定索引的状态</span><br><span class="line">GET /index1,index2/_stats</span><br></pre></td></tr></table></figure><h4 id="refresh"><a href="#refresh" class="headerlink" title="refresh"></a><strong>refresh</strong></h4><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 刷新一个index</span><br><span class="line">POST /twitter/_refresh</span><br><span class="line"># 刷新多个index</span><br><span class="line">POST /kimchy,elasticsearch/_refresh</span><br><span class="line"># 刷新所有的index</span><br><span class="line">POST /_refresh</span><br></pre></td></tr></table></figure><h3 id="cat-apis"><a href="#cat-apis" class="headerlink" title="cat apis"></a>cat apis</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>尽管json格式是一种非常好的数据格式，但是在shh终端上，不利于人类的可读，在终端界面，我们需要线性的显示。那么cat api就是干这个的，它可以把输出转换为方便人类查看的格式</p><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p>在cat api中，支持一下参数</p><ul><li><p>verbose。输出全量信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 无参数</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/master</span><br><span class="line">Mb1156xHRuSYgSZ3RG1n8Q 192.168.101.172 192.168.101.172 node002</span><br><span class="line"></span><br><span class="line"># 有参数</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/master?v</span><br><span class="line">id                     host            ip              node</span><br><span class="line">Mb1156xHRuSYgSZ3RG1n8Q 192.168.101.172 192.168.101.172 node002</span><br></pre></td></tr></table></figure></li><li><p>help，每一个方法都可以使用help查看可以获得哪些输出信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/master?help</span><br><span class="line">id   |   | node id</span><br><span class="line">host | h | host name</span><br><span class="line">ip   |   | ip address</span><br><span class="line">node | n | node name</span><br></pre></td></tr></table></figure></li><li><p>Headers，可以指定要输出的字段，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 获取支持的字段信息</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/nodes?help</span><br><span class="line"></span><br><span class="line"># 默认的全量输出</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/nodes?v</span><br><span class="line">ip              heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name</span><br><span class="line">192.168.103.133           12          97   0    0.39    0.37     0.26 mdi       -      node003</span><br><span class="line">192.168.100.113           12          96   0    0.16    0.29     0.22 mdi       -      node001</span><br><span class="line">192.168.101.172           14          96   1    0.40    0.37     0.25 mdi       *      node002</span><br><span class="line"></span><br><span class="line"># 指定字段输出</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/nodes?h=ip,port,heapPercent,name</span><br><span class="line">192.168.103.133 9600 12 node003</span><br><span class="line">192.168.100.113 9600 12 node001</span><br><span class="line">192.168.101.172 9600 14 node002</span><br></pre></td></tr></table></figure></li></ul><h4 id="具体接口"><a href="#具体接口" class="headerlink" title="具体接口"></a>具体接口</h4><p>链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/cat.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/cat.html</a></p><h3 id="ES常用API"><a href="#ES常用API" class="headerlink" title="ES常用API"></a>ES常用API</h3><ul><li><p>集群健康状态：GET /_cat/health?v</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl http://127.0.0.1:9200/_cat/health?v</span><br><span class="line">epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent</span><br><span class="line">1561023164 17:32:44  elasticsearch green           1         1      0   0    0    0        0             0                  -                100.0%</span><br></pre></td></tr></table></figure></li><li><p>集群节点：GET /_cat/nodes?v</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl http://127.0.0.1:9200/_cat/nodes?v</span><br><span class="line">ip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name</span><br><span class="line">127.0.0.1           10          96   0    0.00    0.06     0.08 mdi       *      Jd3JKT1</span><br></pre></td></tr></table></figure></li><li><p>创建索引：PUT /customer?pretty</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl -X PUT  http://127.0.0.1:9200/customer?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot; : true,</span><br><span class="line">  &quot;shards_acknowledged&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>查看所有的索引：GET /_cat/indices?v</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl -X GET http://127.0.0.1:9200/_cat/indices?v</span><br><span class="line">health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">yellow open   customer cDDJVvowS-uZs0um21huWw   5   1          0            0       650b           650b</span><br></pre></td></tr></table></figure></li><li><p>传输document到index中：PUT /customer/external/1?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# curl -X PUT http://127.0.0.1:9200/customer/external/1?pretty -d &apos;&#123;&quot;name&quot;:&quot;John Doe&quot;&#125;&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;result&quot; : &quot;created&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：customer是index索引，external是type，1是id。POST方式是自增id，put方式必须要加上id。</p><p>这个操作，相当于是给这个索引新增一行数据</p></li><li><p>查看document：/customer/external/1?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# curl -X GET http://127.0.0.1:9200/customer/external/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;name&quot; : &quot;John Doe&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看id为1的document的具体内容</p></li><li><p>删除索引：DELETE /customer?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# curl -X DELETE  http://127.0.0.1:9200/customer?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot; : true</span><br><span class="line">&#125;</span><br><span class="line">[root@node001 ~]# curl -X GET http://127.0.0.1:9200/_cat/indices?v</span><br><span class="line">health status index uuid pri rep docs.count docs.deleted store.size pri.store.size</span><br></pre></td></tr></table></figure><p>注意：上面这些接口路径中的?pretty均可以省略，这个的作用只是为了显示美观，没有实际意义。</p></li><li><p>更新document：POST /customer/external/1/_update?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# curl -X POST  http://127.0.0.1:9200/customer/external/1?pretty -d &apos;&#123;&quot;doc&quot;:&quot;John Doe&quot;&#125;&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 2,</span><br><span class="line">  &quot;result&quot; : &quot;updated&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot; : false</span><br><span class="line">&#125;</span><br><span class="line">[root@node001 ~]#  curl -X GET http://127.0.0.1:9200/customer/external/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 2,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;doc&quot; : &quot;John Doe&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：这里所说的更新操作，实际上在ES内部部署更新替换，而是删除之后再重新创建</p></li><li><p>删除document：DELETE /customer/external/2?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]#  curl -X DELETE http://127.0.0.1:9200/customer/external/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 6,</span><br><span class="line">  &quot;result&quot; : &quot;deleted&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@node001 ~]#  curl -X GET http://127.0.0.1:9200/customer/external/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;found&quot; : false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>查看node上有哪些shard</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://172.16.1.129:9500/_cat/shards|  grep node004</span><br></pre></td></tr></table></figure></li><li><p>关闭打开索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">关闭：curl -XPOST localhost:9200/xxx_indices/_close</span><br><span class="line">打开：</span><br></pre></td></tr></table></figure></li><li><p>关闭集群的reroute-(有新节点新增之后，不要立马挪动shards)</p><p>这里是控制集群中的shard的移动，一般是在新增节点之后，如果不想马上就进行shards的挪动，那么可以暂停这个功能</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;persistent&quot;: &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">如果想取消，那么设置为null即可。</span><br></pre></td></tr></table></figure></li><li><p>集群统计信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _cluster/stats</span><br></pre></td></tr></table></figure><p>包括索引数量、shard的数量、主、副shard的比例等等、docs的数量、存储使用量、插件情况</p></li><li><p>cluster reroute</p><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/cluster-reroute.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.3/cluster-reroute.html</a></p><p>主要是涉及集群的一些内部路由，主要是shards分片的移动（move）、重新分片未分配的副本分片（allocate_replica）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST /_cluster/reroute</span><br><span class="line">&#123;</span><br><span class="line">    &quot;commands&quot; : [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;move&quot; : &#123;</span><br><span class="line">                &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 0,</span><br><span class="line">                &quot;from_node&quot; : &quot;node1&quot;, &quot;to_node&quot; : &quot;node2&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;allocate_replica&quot; : &#123;</span><br><span class="line">                &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 1,</span><br><span class="line">                &quot;node&quot; : &quot;node3&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>修改副本分片数量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT applog-prod-2016.12.18/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index&quot;:&#123;</span><br><span class="line">    &quot;number_of_replicas&quot;:0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>查看每个node上的task</p><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/tasks.html#_current_tasks_information" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.3/tasks.html#_current_tasks_information</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GET _tasks </span><br><span class="line">GET _tasks?nodes=nodeId1,nodeId2 </span><br><span class="line">GET _tasks?nodes=nodeId1,nodeId2&amp;actions=cluster:*</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>cluster allocation explain API</p><p>集群内部分配相关的解释api，可以解释未分配shard的原因等等，在诊断shard问题的时候非常有用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure></li><li><p>分片迁移</p><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/cluster-reroute.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/cluster-reroute.html</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST /_cluster/reroute</span><br><span class="line">&#123;</span><br><span class="line">    &quot;commands&quot; : [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;move&quot; : &#123;</span><br><span class="line">                &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 0,</span><br><span class="line">                &quot;from_node&quot; : &quot;node1&quot;, &quot;to_node&quot; : &quot;node2&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;allocate_replica&quot; : &#123;</span><br><span class="line">                &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 1,</span><br><span class="line">                &quot;node&quot; : &quot;node3&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>更新索引模板</p><p>例如更新索引名称的匹配规则：从<code>nginx*-logstash-*</code> 修改为<code>nginx-logstash-*</code></p><p>直接使用PUT的话将会是覆盖操作</p><p>操作如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure></li><li><p>更新monitor的索引保存天数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;&quot;persistent&quot;: &#123;&quot;xpack.monitoring.history.duration&quot;:&quot;1d&quot;&#125;&#125;</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>查看集群安装的插件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://172.24.148.199:9200/_cat/plugins</span><br></pre></td></tr></table></figure></li></ul><h3 id="Search-api"><a href="#Search-api" class="headerlink" title="Search api"></a>Search api</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/_the_search_api.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/_the_search_api.html</a></p><p>ES检索相关-【这部分相当重要】</p><p>这个api允许你执行一些查询请求，</p><h4 id="参数形式"><a href="#参数形式" class="headerlink" title="参数形式"></a>参数形式</h4><p>查找twitter索引下的tweet,user这2个type中user为kimchy的document</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/tweet,user/_search?q=user:kimchy</span><br><span class="line">实际执行为：</span><br><span class="line"></span><br><span class="line">[elk@node003 ~]$ curl http://192.168.103.133:9500/twitter/tweet,user/_search?q=user:kimchy</span><br><span class="line">&#123;&quot;took&quot;:31,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:3,&quot;successful&quot;:3,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:3,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;AWu2sYdrRw8iDPJNYgMX&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;,&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;AWu2sgI5Rw8iDPJNYgMY&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;,&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;]&#125;&#125;[elk@node003 ~]$</span><br></pre></td></tr></table></figure><p>查找所有索引中type为tweet的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_all/tweet/_search?q=tag:wow</span><br></pre></td></tr></table></figure><p>查找所有索引所有type</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_search?q=tag:wow</span><br></pre></td></tr></table></figure><h4 id="请求体形式"><a href="#请求体形式" class="headerlink" title="请求体形式"></a>请求体形式</h4><p>除了上面的在url请求中携带参数去search，es还支持在get请求使用body的方式</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/tweet/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行后的输出和上面是一致的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[elk@node003 ~]$ curl -XGET http://192.168.103.133:9500/twitter/tweet/_search -d &apos;&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line">&#123;&quot;took&quot;:48,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:3,&quot;successful&quot;:3,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:3,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;AWu2sYdrRw8iDPJNYgMX&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;,&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;AWu2sgI5Rw8iDPJNYgMY&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;,&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;]&#125;&#125;[elk@node003 ~]$</span><br></pre></td></tr></table></figure><h4 id="count"><a href="#count" class="headerlink" title="count"></a>count</h4><p>只获取搜索结果的条数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elk@node003 ~]$ curl http://192.168.103.133:9500/twitter/tweet/_count?q=user:kimchy</span><br><span class="line">&#123;&quot;count&quot;:3,&quot;_shards&quot;:&#123;&quot;total&quot;:3,&quot;successful&quot;:3,&quot;failed&quot;:0&#125;&#125;[elk@node003 ~]$</span><br></pre></td></tr></table></figure><h3 id="Cluster-api-集群api"><a href="#Cluster-api-集群api" class="headerlink" title="Cluster api-集群api"></a>Cluster api-集群api</h3><h2 id="Analyis-分词"><a href="#Analyis-分词" class="headerlink" title="Analyis-分词"></a>Analyis-分词</h2><p>在安装完插件之后，如果不确定插件的名称，可以通过这个接口查看信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET /_nodes</span><br><span class="line"># 插件部分的内容</span><br><span class="line">      &quot;plugins&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;analysis-ik&quot;,</span><br><span class="line">          &quot;version&quot;: &quot;5.1.2&quot;,</span><br><span class="line">          &quot;description&quot;: &quot;IK Analyzer for Elasticsearch&quot;,</span><br><span class="line">          &quot;classname&quot;: &quot;org.elasticsearch.plugin.analysis.ik.AnalysisIkPlugin&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br></pre></td></tr></table></figure><h3 id="Ik分词器"><a href="#Ik分词器" class="headerlink" title="Ik分词器"></a>Ik分词器</h3><p>IK分词器，是一个针对中文的分词器。</p><p>IK分词器github项目地址：<a href="https://link.zhihu.com/?target=https%3A//github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">medcl/elasticsearch-analysis-ik</a></p><p>IK分词器有两种分词模式：ik_max_word和ik_smart模式。</p><ul><li><p>ik_max_word</p><p>会将文本做最细粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为“中华人民共和国、中华人民、中华、华人、人民共和国、人民、共和国、大会堂、大会、会堂等词语。</p></li><li><p>ik_smart</p><p>会做最粗粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为中华人民共和国、人民大会堂。</p></li></ul><p>测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /_analyze</span><br><span class="line">&#123;&quot;text&quot;:&quot;中华人民共和国人民大会堂&quot;,&quot;analyzer&quot;:&quot;ik_smart&quot; &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">POST /_analyze</span><br><span class="line">&#123;&quot;text&quot;:&quot;中华人民共和国人民大会堂&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot; &#125;</span><br></pre></td></tr></table></figure><p>两种分词器使用的最佳实践是：</p><ul><li>索引时用ik_max_word</li><li>在搜索时用ik_smart</li></ul><p>即：索引时最大化的将文章内容分词，搜索时更精确的搜索到想要的结果。</p><h2 id="插件管理"><a href="#插件管理" class="headerlink" title="插件管理"></a>插件管理</h2><p>如何看es中安装了哪些插件？</p><p>GET _cat/plugins</p><h3 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h3><h4 id="sql插件安装"><a href="#sql插件安装" class="headerlink" title="sql插件安装"></a>sql插件安装</h4><p>命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.5.4.0/elasticsearch-sql-6.5.4.0.zip</span><br></pre></td></tr></table></figure><h4 id="IK分词器插件安装"><a href="#IK分词器插件安装" class="headerlink" title="IK分词器插件安装"></a>IK分词器插件安装</h4><p>安装之后就是：analysis-ik</p><h2 id="Index-Modules-索引模块"><a href="#Index-Modules-索引模块" class="headerlink" title="Index Modules-索引模块"></a>Index Modules-索引模块</h2><h3 id="slow-log"><a href="#slow-log" class="headerlink" title="slow log"></a>slow log</h3><p>slow log分为两种</p><ul><li>search slow log</li><li>index slow log</li></ul><p><strong>search slow log</strong></p><p>es支持记录分片级别的查询（包括query和fetch两个阶段）慢查询日志。</p><p>慢查询的阈值设置</p><p>在search中分为query和fetch两个部分</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">index.search.slowlog.threshold.query.warn: 10s</span><br><span class="line">index.search.slowlog.threshold.query.info: 5s</span><br><span class="line">index.search.slowlog.threshold.query.debug: 2s</span><br><span class="line">index.search.slowlog.threshold.query.trace: 500ms</span><br><span class="line"></span><br><span class="line">index.search.slowlog.threshold.fetch.warn: 1s</span><br><span class="line">index.search.slowlog.threshold.fetch.info: 800ms</span><br><span class="line">index.search.slowlog.threshold.fetch.debug: 500ms</span><br><span class="line">index.search.slowlog.threshold.fetch.trace: 200ms</span><br></pre></td></tr></table></figure><p>上面的这些配置可以在配置文件中指定，也可以通过接口去动态的设置</p><p>在默认情况下，上面这些参数没有一个是enabled的（默认值是 <code>-1</code>），提供的日志级别(<code>warn</code>, <code>info</code>, <code>debug</code>, <code>trace</code>)允许我们灵活的控制哪些级别是我们要打印输出的</p><p>上面这些配置并不是所有的都必须要设置。</p><p>上面是定义慢查询的阈值，除了这里，我们还需要再日志文件中进行配置</p><p>注意：日志中记录的shard级别的日志，也就是分片级别，这就意味着，这个es实例的日志可能不是一个完整的查询，而只是查询的一部分。使用这种方式的好处是可以毕竟精细的看到是哪一个节点的问题。</p><p>默认的日志配置（log4j2.properties）如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">appender.index_search_slowlog_rolling.type = RollingFile</span><br><span class="line">appender.index_search_slowlog_rolling.name = index_search_slowlog_rolling</span><br><span class="line">appender.index_search_slowlog_rolling.fileName = $&#123;sys:es.logs&#125;_index_search_slowlog.log</span><br><span class="line">appender.index_search_slowlog_rolling.layout.type = PatternLayout</span><br><span class="line">appender.index_search_slowlog_rolling.layout.pattern = [%d&#123;ISO8601&#125;][%-5p][%-25c] %marker%.-10000m%n</span><br><span class="line">appender.index_search_slowlog_rolling.filePattern = $&#123;sys:es.logs&#125;_index_search_slowlog-%d&#123;yyyy-MM-dd&#125;.log</span><br><span class="line">appender.index_search_slowlog_rolling.policies.type = Policies</span><br><span class="line">appender.index_search_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy</span><br><span class="line">appender.index_search_slowlog_rolling.policies.time.interval = 1</span><br><span class="line">appender.index_search_slowlog_rolling.policies.time.modulate = true</span><br><span class="line"></span><br><span class="line">logger.index_search_slowlog_rolling.name = index.search.slowlog</span><br><span class="line">logger.index_search_slowlog_rolling.level = trace</span><br><span class="line">logger.index_search_slowlog_rolling.appenderRef.index_search_slowlog_rolling.ref = index_search_slowlog_rolling</span><br><span class="line">logger.index_search_slowlog_rolling.additivity = false</span><br></pre></td></tr></table></figure><p>这里的配置根据版本的不同可能会不同</p><p><strong>index low log</strong></p><p>Indexing slow log的相关内容和上面的类似，文件名称也是以_index_indexing_slowlog.log结尾</p><p>阈值的配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">index.indexing.slowlog.threshold.index.warn: 10s</span><br><span class="line">index.indexing.slowlog.threshold.index.info: 5s</span><br><span class="line">index.indexing.slowlog.threshold.index.debug: 2s</span><br><span class="line">index.indexing.slowlog.threshold.index.trace: 500ms</span><br><span class="line">index.indexing.slowlog.level: info</span><br><span class="line">index.indexing.slowlog.source: 1000</span><br></pre></td></tr></table></figure><p>这些配置也是一样，可以在配置文件中设置，也可以通过接口进行设置。</p><p>注意：</p><ul><li>在默认情况下，es将只会把 _source 中的前1000个字符输出到日志文件中。如果有额外的需求，我们可以通过接口去进行设置。如果设置为false或者0，那么es将会忽略整个<code>source</code>。如果设置为true，那么将会无视size的限制。</li><li>最原始状态的<code>_source</code>将会被重新格式化，以便能够输出为单行的格式。如果document的格式非常重要，不能被重新格式化，那么我们可以将index.indexing.slowlog.reformat设置为false。</li></ul><p>同样的，我们也需要在日志文件中进行设置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">appender.index_indexing_slowlog_rolling.type = RollingFile</span><br><span class="line">appender.index_indexing_slowlog_rolling.name = index_indexing_slowlog_rolling</span><br><span class="line">appender.index_indexing_slowlog_rolling.fileName = $&#123;sys:es.logs&#125;_index_indexing_slowlog.log</span><br><span class="line">appender.index_indexing_slowlog_rolling.layout.type = PatternLayout</span><br><span class="line">appender.index_indexing_slowlog_rolling.layout.pattern = [%d&#123;ISO8601&#125;][%-5p][%-25c] %marker%.10000m%n</span><br><span class="line">appender.index_indexing_slowlog_rolling.filePattern = $&#123;sys:es.logs&#125;_index_indexing_slowlog-%d&#123;yyyy-MM-dd&#125;.log</span><br><span class="line">appender.index_indexing_slowlog_rolling.policies.type = Policies</span><br><span class="line">appender.index_indexing_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy</span><br><span class="line">appender.index_indexing_slowlog_rolling.policies.time.interval = 1</span><br><span class="line">appender.index_indexing_slowlog_rolling.policies.time.modulate = true</span><br><span class="line"></span><br><span class="line">logger.index_indexing_slowlog.name = index.indexing.slowlog.index</span><br><span class="line">logger.index_indexing_slowlog.level = trace</span><br><span class="line">logger.index_indexing_slowlog.appenderRef.index_indexing_slowlog_rolling.ref = index_indexing_slowlog_rolling</span><br><span class="line">logger.index_indexing_slowlog.additivity = false</span><br></pre></td></tr></table></figure><p>这里的配置根据版本的不同可能会不同</p><h3 id="slow-log实际案例"><a href="#slow-log实际案例" class="headerlink" title="slow log实际案例"></a>slow log实际案例</h3><p>我们可以通过api去动态的调整</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index.search.slowlog.threshold.query.warn&quot; : &quot;10s&quot;, </span><br><span class="line">    &quot;index.search.slowlog.threshold.fetch.debug&quot;: &quot;500ms&quot;, </span><br><span class="line">    &quot;index.indexing.slowlog.threshold.index.info&quot;: &quot;5s&quot; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里设置的是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">查询慢于 10 秒输出一个 WARN 日志。</span><br><span class="line">获取慢于 500 毫秒输出一个 DEBUG 日志。</span><br><span class="line">索引慢于 5 秒输出一个 INFO 日志。</span><br></pre></td></tr></table></figure><p>实际案例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT testindex/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index.search.slowlog.threshold.query.info&quot; : &quot;200ms&quot;, </span><br><span class="line">    &quot;index.search.slowlog.threshold.query.warn&quot; : &quot;500ms&quot;,</span><br><span class="line">    &quot;index.search.slowlog.threshold.fetch.info&quot;: &quot;200ms&quot;, </span><br><span class="line">    &quot;index.search.slowlog.threshold.fetch.warn&quot;: &quot;500ms&quot;, </span><br><span class="line">    &quot;index.indexing.slowlog.threshold.index.info&quot;: &quot;800ms&quot;,</span><br><span class="line">    &quot;index.indexing.slowlog.threshold.index.warn&quot;: &quot;1s&quot; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="查询DSL"><a href="#查询DSL" class="headerlink" title="查询DSL"></a>查询DSL</h2><h3 id="查询语句以及过滤语句"><a href="#查询语句以及过滤语句" class="headerlink" title="查询语句以及过滤语句"></a>查询语句以及过滤语句</h3><p>查询语句的处理行为取决于这个语句是在查询上下文中还是在过滤上下文中</p><p>两个的匹配级别不一样</p><ul><li><strong>Query context</strong>：关注于document和查询语句的匹配程度，也就是说目的是匹配出document</li><li><strong>Filter context</strong>：关注于document中的一些字段的过滤，例如过滤出document之后，过滤status字段为<em>published</em>的、<em>timestamp</em>字段的范围在2015到2016之间的</li></ul><p>案例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; </span><br><span class="line">    &quot;bool&quot;: &#123; </span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;title&quot;:   &quot;Search&quot;        &#125;&#125;, </span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;Elasticsearch&quot; &#125;&#125;  </span><br><span class="line">      ],</span><br><span class="line">      &quot;filter&quot;: [ </span><br><span class="line">        &#123; &quot;term&quot;:  &#123; &quot;status&quot;: &quot;published&quot; &#125;&#125;, </span><br><span class="line">        &#123; &quot;range&quot;: &#123; &quot;publish_date&quot;: &#123; &quot;gte&quot;: &quot;2015-01-01&quot; &#125;&#125;&#125; </span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="full-text-query-全文查询"><a href="#full-text-query-全文查询" class="headerlink" title="full-text query-全文查询"></a>full-text query-全文查询</h3><h3 id="Term-Query-术语查询"><a href="#Term-Query-术语查询" class="headerlink" title="Term Query-术语查询"></a>Term Query-术语查询</h3><p>term 查询可以包含指定术语的document</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST _search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot; : &#123; &quot;user&quot; : &quot;Kimchy&quot; &#125; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在查询的时候可以给查询添加添加优先级，也就是紧急程度：boost字段</p><p>例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">GET _search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;should&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;term&quot;: &#123;</span><br><span class="line">            &quot;status&quot;: &#123;</span><br><span class="line">              &quot;value&quot;: &quot;urgent&quot;,</span><br><span class="line">              &quot;boost&quot;: 2.0 </span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;term&quot;: &#123;</span><br><span class="line">            &quot;status&quot;: &quot;normal&quot; </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>默认语句的boost值为1.0</p><p>注意: </p><blockquote><p>在es中，在进行查询的时候，会把text类型的字段进行分割，例如：</p><p>“Quick Brown Fox!” 会被切割成术语：[<code>quick</code>, <code>brown</code>, <code>fox</code>]</p><p>因此，在进行term查询的时候，使用完整的字符串是查不到东西的</p></blockquote><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># 生成数据</span><br><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;my_type&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;full_text&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;text&quot; </span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;exact_value&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;keyword&quot; </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_index/my_type/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;full_text&quot;:   &quot;Quick Foxes!&quot;, </span><br><span class="line">  &quot;exact_value&quot;: &quot;Quick Foxes!&quot;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">查询数据</span><br><span class="line"></span><br><span class="line"># 查询成功</span><br><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;exact_value&quot;: &quot;Quick Foxes!&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询失败</span><br><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;full_text&quot;: &quot;Quick Foxes!&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询成功</span><br><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;full_text&quot;: &quot;foxes&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询成功</span><br><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;full_text&quot;: &quot;Quick Foxes!&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：match查询方式的处理逻辑和term的方式是不一样的,match是属于全文查询级别。</p><h2 id="批处理-Batch-Processing"><a href="#批处理-Batch-Processing" class="headerlink" title="批处理-Batch Processing"></a>批处理-Batch Processing</h2><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/_batch_processing.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/_batch_processing.html</a></p><p>ES的批处理主要使用bulk api来实现。</p><h2 id="Modules-ES组件"><a href="#Modules-ES组件" class="headerlink" title="Modules-ES组件"></a>Modules-ES组件</h2><h3 id="node"><a href="#node" class="headerlink" title="node"></a>node</h3><p>集群中的每一个节点都能感知到其他节点，并且，在收到请求之后，能够转发请求到对应的node节点上。</p><p><strong>master node-主节点</strong></p><p>主节点主要用于集群的控制以及元数据的处理，例如索引的新增、删除、分片的分配信息等等</p><ul><li>创建或删除索引</li><li>跟踪哪些节点是集群的一部分</li><li>决定要分配给哪些节点哪些分片</li></ul><p>配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node.master=true</span><br><span class="line">node.data=false</span><br><span class="line">node.ingest=false</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>虽然有多个节点开启了这个配置，但是一个集群只有一个主节点，其他的都是master候选节点</li></ul><p><strong>data node-数据节点</strong></p><p>数据节点保存数据(索引)分片，它负责数据相关操作，涉及：</p><ul><li><p>CRUD，以及搜索和聚合</p></li><li><p>因此，数据节点的CPU、内存、IO以及存储资源都消耗</p></li><li>如果数据节点的资源负载过高，则需要添加数据节点</li></ul><p>配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node.master=false</span><br><span class="line">node.data=true</span><br><span class="line">node.ingest=false</span><br></pre></td></tr></table></figure><p><strong>client node-路由节点</strong></p><p>可以看做是一个负载均衡器，负责：</p><ul><li>处理路由请求</li><li>处理搜索聚合节点</li><li>分发批量索引请求</li></ul><p>设置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node.master=false</span><br><span class="line">node.data=false</span><br><span class="line">node.ingest=false</span><br></pre></td></tr></table></figure><p>如果es集群不是规模很大的话，我们一般不设置client节点，使用master提供类似的功能即可。</p><h3 id="线程池-Thread-Pool"><a href="#线程池-Thread-Pool" class="headerlink" title="线程池-Thread Pool"></a>线程池-Thread Pool</h3><p>es中，定义了许多种类的线程池，为的是更好的控制线程的内存消耗</p><p>注意：</p><ul><li><p>所有的线程池都会队列的方式，这将允许在线程池满了之后，之后的请求将会排队，而不是直接被丢弃。</p></li><li><p>线程池类型分类固定的数值的（fixed），可以自行动态调整的(也就是说有上下限)（scaling）</p></li><li>进程数量（available_processors）一般会自动识别，上限为32个，也就是在超过32核的机器上，最多使用32个进程。有这个限制的原因是防止产生太多的线程，如果你修改系统的ulimit上限，那么可以手动调整这个上限。可以使用node的api去check具体的进程数量</li></ul><p>固定数值的配置案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread_pool:</span><br><span class="line">    index:</span><br><span class="line">        size: 30</span><br><span class="line">        queue_size: 1000</span><br></pre></td></tr></table></figure><p>注意：当queue_size设置为-1的时候，就意味着关闭队列功能，当线程池满了之后，后面来的请求都会被丢弃</p><p>弹性数值的配置案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">thread_pool:</span><br><span class="line">    warmer:</span><br><span class="line">        core: 1</span><br><span class="line">        max: 8</span><br><span class="line">        keep_alive: 2m</span><br></pre></td></tr></table></figure><p>工作线程数量的范围是：core-max。keep_alive的作用是：当多长时间线程池没有任务后，不保持可用的工作线程</p><p>进程数量设置，如果需要手动指定，可以使用下列的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">processors: 2</span><br></pre></td></tr></table></figure><p>目前有以下这些种类的线程池</p><ul><li><p>generic</p><p>可动态调整类型</p><p>通用操作，例如：用于后台的node发现</p></li><li><p>index</p><p>固定类型</p><p>用于索引的新增删除操作，size的数量是进程数量(available processors)，最大的数量是<code>1 + # of available processors</code>.队列长度queue_size默认为200</p></li><li><p>search </p><p>固定类型。</p><p>用于统计、检索等操作，默认配置值为：int((# of available_processors * 3) / 2) + 1，队列长度默认为1000。</p></li><li><p>下面还有很多略，看文档</p></li></ul><h3 id="zen-discovery-集群发现过程"><a href="#zen-discovery-集群发现过程" class="headerlink" title="zen discovery-集群发现过程"></a>zen discovery-集群发现过程</h3><p>暂时略</p><h2 id="ES的Merge功能"><a href="#ES的Merge功能" class="headerlink" title="ES的Merge功能"></a>ES的Merge功能</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/index-modules-merge.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.5/index-modules-merge.html</a></p><h3 id="基本概念："><a href="#基本概念：" class="headerlink" title="基本概念："></a>基本概念：</h3><p>ES中的shard分片，其实是lucene中的index索引。在lucene中，每一个index都会被分解成segments段，segments是index内部的基本存储单元</p><p>一些比较小的segment会被周期性的merge（合并）成为一个比较大的segment，为的是保持index的大小在一个稳定的范围，在合并之后将会删除这些小segment</p><p>segment是lucene索引的一种存储结构，每个segment都是一部分数据的完整索引，它是lucene每次flush或merge时候形成。每次flush就是将内存中的索引写出一个独立segment的过程。所以随着数据的不断增加，会形成越来越多的segment。因为segment是不可变的，删除操作不会改变segment内部数据，只是会在另外的地方记录某些数据删除，这样可能会导致segment中存在大量无用数据。搜索时，每个segment都需要一个reader来读取里面的数据，大量的segment会严重影响搜索效率。而merge过程，会将小的segment写到一起形成一个大的segment，减少其数量。同时重写过程会抛弃那些已经删除的数据。因此segment的merge是有利于查询效率的。</p><p>总结：大量的分段留在Lucene索引里面，意味着较慢的搜索和占用更多的内存。分段合并设计用来减少分段数量，但是合并动作是非常昂贵的，尤其是在低IO环境中，可能会受到存储性能上的限制。</p><h3 id="merge-scheduling"><a href="#merge-scheduling" class="headerlink" title="merge scheduling"></a>merge scheduling</h3><p>merge scheduler（并行调度方式）控制了我们在什么时候需要去执行merge操作。</p><p>merge使用单独的线程去实现，当到达了设定的最大线程数，余下到来的merge任务将会排队等候。</p><p>merge scheduler可以按照下面的这种方式进行动态的设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index.merge.scheduler.max_thread_count</span><br></pre></td></tr></table></figure><p>elasticsearch的merge其实就是lucene的merge机制。merge过程是lucene有一个后台线程，它会根据merge策略来决定是否进行merge，一旦merge的条件满足，就会启动后台merge。merge策略分为两种，这也是大多数大数据框架所采用的，segment的大小和segment中doc的数量。以这两个标准为基础实现了三种merge策略：TieredMergePolicy、LogDocMergePolicy 及LogByteSizeMergePolicy。elasticsearch这一部分就是对这三种合并策略的封装，并提供了对于的配置。</p><h3 id="forcemerge"><a href="#forcemerge" class="headerlink" title="forcemerge"></a>forcemerge</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/indices-forcemerge.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.5/indices-forcemerge.html</a></p><p>调用接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST /twitter/_forcemerge</span><br></pre></td></tr></table></figure><h3 id="merge优化"><a href="#merge优化" class="headerlink" title="merge优化"></a>merge优化</h3><p>merge的优化可以是整个集群的调整，也可以是某些索引的调整，一般建议是索引级别。</p><p>merge操作是一个很消耗性能的过程，特别是对于磁盘的IO</p><p>因为如果有某个节点的io出现问题时，通过热线程定位，发现是merge导致的时，可以针对当前比较大的索引，修改一下merge相关的配置。</p><h2 id="ES数据查询"><a href="#ES数据查询" class="headerlink" title="ES数据查询"></a>ES数据查询</h2><h3 id="routing参数"><a href="#routing参数" class="headerlink" title="routing参数"></a>routing参数</h3><p>在将document写入到es中的时候，默认的路由算法规则是根据document的id。</p><p>但是我们可以指定某个字段为路由值，确保这些doc分布在同一个shard上。</p><p>使用自定义路由规则的作用：</p><p>我们知道，正常的一次查询(search)，请求会被发给所有<code>shard</code>(不考虑副本)，然后等所有<code>shard</code>返回，再将结果聚合，返回给调用方。如果我们事先已经知道数据可能分布在哪些shard上，那么就可以减少不必要的请求。</p><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search.html</a></p><p>示例：</p><p>插入数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /twitter/tweet?routing=kimchy</span><br><span class="line">&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;postDate&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>检索数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">POST /twitter/tweet/_search?routing=kimchy</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;bool&quot; : &#123;</span><br><span class="line">            &quot;must&quot; : &#123;</span><br><span class="line">                &quot;query_string&quot; : &#123;</span><br><span class="line">                    &quot;query&quot; : &quot;some query string here&quot;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;filter&quot; : &#123;</span><br><span class="line">                &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="search"><a href="#search" class="headerlink" title="search"></a>search</h3><p>The query can either be provided using a simple <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-uri-request.html" target="_blank" rel="noopener">query string as a parameter</a>, or using a<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-request-body.html" target="_blank" rel="noopener">request body</a>.</p><p>使用search api有2种方式，一种是把查询字符串作为URI参数传入，一种是在请求体中嵌入查询语句</p><h4 id="多索引及多type操作"><a href="#多索引及多type操作" class="headerlink" title="多索引及多type操作"></a>多索引及多type操作</h4><p>search api支持操作多个索引以及多个type</p><p>例如：</p><ul><li><p>在所有的type中检索数据</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/_search?q=user:kimchy</span><br></pre></td></tr></table></figure></li><li><p>index确定，type多个</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/tweet,user/_search?q=user:kimchy</span><br></pre></td></tr></table></figure></li><li><p>type确定，索引多个(这里的type是tweet)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GET /kimchy,elasticsearch/tweet/_search?q=tag:wow</span><br><span class="line"></span><br><span class="line">或者所有的index</span><br><span class="line">GET /_all/tweet/_search?q=tag:wow</span><br></pre></td></tr></table></figure></li><li><p>在所有的index和type下搜索</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_search?q=tag:wow</span><br></pre></td></tr></table></figure></li></ul><p>注意：默认情况下，es拒绝超过涉及1000个shard的search请求，因为这么大的请求，会非常消耗coordinating node的cpu、内存等资源</p><p>当然，这个1000的值也是可以调整的，在cluster setting中，使用action.search.shard_count.limit参数。</p><h4 id="URI-search"><a href="#URI-search" class="headerlink" title="URI search"></a>URI search</h4><p>格式例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/tweet/_search?q=user:kimchy</span><br></pre></td></tr></table></figure><p>参数说明：</p><p>The parameters allowed in the URI are:</p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>q</code></td><td>The query string (maps to the <code>query_string</code> query, see <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-query-string-query.html" target="_blank" rel="noopener"><em>Query String Query</em></a>for more details).</td></tr><tr><td><code>df</code></td><td>The default field to use when no field prefix is defined within the query.</td></tr><tr><td><code>analyzer</code></td><td>The analyzer name to be used when analyzing the query string.</td></tr><tr><td><code>analyze_wildcard</code></td><td>Should wildcard and prefix queries be analyzed or not. Defaults to <code>false</code>.</td></tr><tr><td><code>default_operator</code></td><td>The default operator to be used, can be <code>AND</code> or <code>OR</code>. Defaults to <code>OR</code>.</td></tr><tr><td><code>lenient</code></td><td>If set to true will cause format based failures (like providing text to a numeric field) to be ignored. Defaults to false.</td></tr><tr><td><code>explain</code></td><td>For each hit, contain an explanation of how scoring of the hits was computed.</td></tr><tr><td><code>_source</code></td><td>Set to <code>false</code> to disable retrieval of the <code>_source</code> field. You can also retrieve part of the document by using <code>_source_include</code> &amp; <code>_source_exclude</code> (see the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-request-source-filtering.html" target="_blank" rel="noopener">request body</a> documentation for more details)</td></tr><tr><td><code>stored_fields</code></td><td>The selective stored fields of the document to return for each hit, comma delimited. Not specifying any value will cause no fields to return.</td></tr><tr><td><code>sort</code></td><td>Sorting to perform. Can either be in the form of <code>fieldName</code>, or<code>fieldName:asc</code>/<code>fieldName:desc</code>. The fieldName can either be an actual field within the document, or the special <code>_score</code> name to indicate sorting based on scores. There can be several <code>sort</code> parameters (order is important).</td></tr><tr><td><code>track_scores</code></td><td>When sorting, set to <code>true</code> in order to still track scores and return them as part of each hit.</td></tr><tr><td><code>timeout</code></td><td>A search timeout, bounding the search request to be executed within the specified time value and bail with the hits accumulated up to that point when expired. Defaults to no timeout.</td></tr><tr><td><code>terminate_after</code></td><td>The maximum number of documents to collect for each shard, upon reaching which the query execution will terminate early. If set, the response will have a boolean field <code>terminated_early</code> to indicate whether the query execution has actually terminated_early. Defaults to no terminate_after.</td></tr><tr><td><code>from</code></td><td>The starting from index of the hits to return. Defaults to <code>0</code>.</td></tr><tr><td><code>size</code></td><td>The number of hits to return. Defaults to <code>10</code>.</td></tr><tr><td><code>search_type</code></td><td>The type of the search operation to perform. Can be<code>dfs_query_then_fetch</code> or <code>query_then_fetch</code>. Defaults to <code>query_then_fetch</code>. See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-request-search-type.html" target="_blank" rel="noopener"><em>Search Type</em></a> for more details on the different types of search that can be performed.</td></tr></tbody></table><h4 id="Request-body-search"><a href="#Request-body-search" class="headerlink" title="Request body search"></a>Request body search</h4><p>同样的，我们也可以使用在请求体中嵌入<strong>查询语句</strong>的方式来查询数据。</p><p>格式例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/tweet/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>支持下面这些参数</p><table><thead><tr><th><code>timeout</code></th><th>A search timeout, bounding the search request to be executed within the specified time value and bail with the hits accumulated up to that point when expired. Defaults to no timeout. See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/common-options.html#time-units" target="_blank" rel="noopener">Time units</a>.</th></tr></thead><tbody><tr><td><code>from</code></td><td>To retrieve hits from a certain offset. Defaults to <code>0</code>.</td></tr><tr><td><code>size</code></td><td>The number of hits to return. Defaults to <code>10</code>. If you do not care about getting some hits back but only about the number of matches and/or aggregations, setting the value to <code>0</code> will help performance.</td></tr><tr><td><code>search_type</code></td><td>The type of the search operation to perform. Can be <code>dfs_query_then_fetch</code>or <code>query_then_fetch</code>. Defaults to <code>query_then_fetch</code>. See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-request-search-type.html" target="_blank" rel="noopener"><em>Search Type</em></a> for more.</td></tr><tr><td><code>request_cache</code></td><td>Set to <code>true</code> or <code>false</code> to enable or disable the caching of search results for requests where <code>size</code> is 0, ie aggregations and suggestions (no top hits returned). See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/shard-request-cache.html" target="_blank" rel="noopener">Shard request cache</a>.</td></tr><tr><td><code>terminate_after</code></td><td>The maximum number of documents to collect for each shard, upon reaching which the query execution will terminate early. If set, the response will have a boolean field <code>terminated_early</code> to indicate whether the query execution has actually terminated_early. Defaults to no terminate_after.</td></tr></tbody></table><p>注意：</p><ul><li><p>Both HTTP GET and HTTP POST can be used to execute search with body. Since not all clients support GET with body, POST is allowed as well.</p><p>也就是说，es接受HTTP的GET请求和POST请求携带这些参数。但是有些客户端不支持在使用GET时携带参数，那么可以使用POST</p></li><li><p>当我们仅仅需要知道是否有doc匹配，而不用关注具体的数据和数量时，为了加快检索速度，我们可以使用这些参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_search?q=message:elasticsearch&amp;size=0&amp;terminate_after=1</span><br></pre></td></tr></table></figure></li></ul><h5 id="From-size"><a href="#From-size" class="headerlink" title="From/size"></a>From/size</h5><p>我们可以结合使用from和size参数，来控制输出结果分页显示。</p><p>from控制开始显示的偏移量，size控制一次输出/读取的记录条数</p><p>from的默认值为0，size的默认值为10</p><p>from和size参数可以设置到URI中，也可以设置在request body中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;from&quot; : 0, &quot;size&quot; : 10,</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：</p><p><code>from</code> + <code>size</code> can not be more than the <code>index.max_result_window</code> index setting which defaults to 10,000. See the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-request-scroll.html" target="_blank" rel="noopener">Scroll</a> or <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-request-search-after.html" target="_blank" rel="noopener">Search After</a> API for more efficient ways to do deep scrolling.</p><h5 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h5><p>sort允许我们从doc中获取我们指定的一些字段数据，并且还可以根据这些字段进行排序输出</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GET /nginx_count/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;sort&quot; : [</span><br><span class="line">        &#123; &quot;timestamp&quot; : &#123;&quot;order&quot; : &quot;asc&quot;&#125;&#125;,</span><br><span class="line">        &quot;city&quot;,</span><br><span class="line">        &#123; &quot;isp&quot; : &quot;desc&quot; &#125;,</span><br><span class="line">        &#123; &quot;province&quot; : &quot;desc&quot; &#125;,</span><br><span class="line">        &quot;_score&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;count&quot; : 23  &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行后的输出是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;took&quot;: 15,</span><br><span class="line">  &quot;timed_out&quot;: false,</span><br><span class="line">  &quot;_shards&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 1,</span><br><span class="line">    &quot;successful&quot;: 1,</span><br><span class="line">    &quot;failed&quot;: 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;hits&quot;: &#123;</span><br><span class="line">    &quot;total&quot;: 268,</span><br><span class="line">    &quot;max_score&quot;: null,</span><br><span class="line">    &quot;hits&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">        &quot;_index&quot;: &quot;nginx_count&quot;,</span><br><span class="line">        &quot;_type&quot;: &quot;doc&quot;,</span><br><span class="line">        &quot;_id&quot;: &quot;299&quot;,</span><br><span class="line">        &quot;_score&quot;: 1,</span><br><span class="line">        &quot;_source&quot;: &#123;</span><br><span class="line">          &quot;city&quot;: &quot;赣州市&quot;,</span><br><span class="line">          &quot;count&quot;: 23,</span><br><span class="line">          &quot;isp&quot;: &quot;移动&quot;,</span><br><span class="line">          &quot;province&quot;: &quot;江西省&quot;,</span><br><span class="line">          &quot;timestamp&quot;: 1567146209783,</span><br><span class="line">          &quot;domain&quot;: &quot;ops.nidianwo.com&quot;,</span><br><span class="line">          &quot;aliyun&quot;: 700,</span><br><span class="line">          &quot;shanghai&quot;: 900,</span><br><span class="line">          &quot;binjiang&quot;: 100</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;sort&quot;: [</span><br><span class="line">          1567146209783,</span><br><span class="line">          &quot;赣州市&quot;,</span><br><span class="line">          &quot;移动&quot;,</span><br><span class="line">          &quot;江西省&quot;,</span><br><span class="line">          1</span><br><span class="line">        ]</span><br><span class="line">      &#125;,</span><br><span class="line">      ......下面省略</span><br></pre></td></tr></table></figure><p>说明：</p><blockquote><p>在这里，获取timestamp、city、isp、province这4个信息，并且对匹配到的doc，再根据timestamp进行正向排序（也就是从小到大）</p></blockquote><h5 id="source-filtering"><a href="#source-filtering" class="headerlink" title="_source filtering"></a>_source filtering</h5><p>我们还可以对要输出的内容进行过滤</p><p>例如：</p><p>不输出所有的doc内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;_source&quot;: false,</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>或者只输出匹配的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;_source&quot;: &quot;obj.*&quot;,</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">或者</span><br><span class="line"></span><br><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;_source&quot;: [ &quot;obj1.*&quot;, &quot;obj2.*&quot; ],</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还可以编写过滤条件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;_source&quot;: &#123;</span><br><span class="line">        &quot;includes&quot;: [ &quot;obj1.*&quot;, &quot;obj2.*&quot; ],</span><br><span class="line">        &quot;excludes&quot;: [ &quot;*.description&quot; ]</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="search-template"><a href="#search-template" class="headerlink" title="search template"></a>search template</h4><p>链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-template.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/search-template.html</a></p><h3 id="DSL-查询语句"><a href="#DSL-查询语句" class="headerlink" title="DSL-查询语句"></a>DSL-查询语句</h3><p>ES提供了一个完整的基于json的查询DSL。</p><p>DSL主要分为两类：</p><ul><li>子句查询。查询条件是某个具体字段的具体的值。有match、term、range等</li><li>复合查询子句</li></ul><h4 id="score"><a href="#score" class="headerlink" title="_score"></a>_score</h4><p> 使用ES时，对于查询出的文档无疑会有文档相似度之别。而理想的排序是和查询条件相关性越高排序越靠前，而这个排序的依据就是<code>_score</code>。本文就是详解<code>_score</code>有关的信息，希望能对排序评分的理解有所帮助。</p><h4 id="query-and-filter-context"><a href="#query-and-filter-context" class="headerlink" title="query and filter context"></a>query and filter context</h4><p>DSL在两种不用的使用场景下，又具有不同的特性</p><p><strong>query context</strong></p><p>在这种模式下，es思考的问题是：“doc和这个查询子句的匹配程度如何？“</p><p>注意：是匹配程度</p><p>这个功能，通常用来获取数据</p><p><strong>filter context</strong></p><p>在这种模式下，es思考的问题是：”这个doc是否匹配这个查询子句”</p><p>注意：这个的答案是非常简单的：yes or no。不涉及其他的计算任务</p><p>这个功能，通常用来过滤数据</p><p>案例分析：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; </span><br><span class="line">    &quot;bool&quot;: &#123; </span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;title&quot;:   &quot;Search&quot;        &#125;&#125;, </span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;Elasticsearch&quot; &#125;&#125;  </span><br><span class="line">      ],</span><br><span class="line">      &quot;filter&quot;: [ </span><br><span class="line">        &#123; &quot;term&quot;:  &#123; &quot;status&quot;: &quot;published&quot; &#125;&#125;, </span><br><span class="line">        &#123; &quot;range&quot;: &#123; &quot;publish_date&quot;: &#123; &quot;gte&quot;: &quot;2015-01-01&quot; &#125;&#125;&#125; </span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>说明：</p><ul><li>The <code>query</code> parameter indicates query context.</li><li>The <code>bool</code> and two <code>match</code> clauses are used in query context, which means that they are </li><li>used to score how well each document matches.</li><li>The <code>filter</code> parameter indicates filter context.</li><li>The <code>term</code> and <code>range</code> clauses are used in filter context. They will filter out documents </li><li>which do not match, but they will not affect the score for matching documents.</li></ul><h4 id="match-all-query"><a href="#match-all-query" class="headerlink" title="match all query"></a>match all query</h4><p>匹配所有的doc</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match_all&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这个基础上，我们可以添加_score参数（默认是1.0）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match_all&quot;: &#123; &quot;boost&quot; : 1.2 &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不匹配所有的doc</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match_none&quot;: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="full-text-queries-text数据类型的全文内容检索"><a href="#full-text-queries-text数据类型的全文内容检索" class="headerlink" title="full text queries-text数据类型的全文内容检索"></a>full text queries-text数据类型的全文内容检索</h4><p>用于字段类型是text的信息，like the body of an email.</p><p>针对这种内容，我们还需要指定字段的分析器analyzer。</p><h5 id="match-query"><a href="#match-query" class="headerlink" title="match query"></a>match query</h5><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-match-query.html#query-dsl-match-query-boolean" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-match-query.html#query-dsl-match-query-boolean</a></p><p><code>match</code> queries accept text/numerics/dates, analyzes them, and constructs a query. </p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;message&quot; : &quot;this is a test&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>说明：</p><p>The <code>match</code> query is of type <code>boolean</code>. It means that the text provided is analyzed and the analysis process constructs a boolean query from the provided text. The <code>operator</code> flag can be set to <code>or</code> or <code>and</code> to control the boolean clauses (defaults to <code>or</code>). The minimum number of optional <code>should</code> clauses to match can be set using the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-minimum-should-match.html" target="_blank" rel="noopener"><code>minimum_should_match</code></a> parameter.</p><p>The <code>analyzer</code> can be set to control which analyzer will perform the analysis process on the text. It defaults to the field explicit mapping definition, or the default search analyzer.</p><p>The <code>lenient</code> parameter can be set to <code>true</code> to ignore exceptions caused by data-type mismatches, such as trying to query a numeric field with a text query string. Defaults to <code>false</code>.</p><p>深入案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;match&quot; : &#123;</span><br><span class="line">            &quot;message&quot; : &#123;</span><br><span class="line">                &quot;query&quot; : &quot;to be or not to be&quot;,</span><br><span class="line">                &quot;operator&quot; : &quot;and&quot;,</span><br><span class="line">                &quot;zero_terms_query&quot;: &quot;all&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="multi-match-query"><a href="#multi-match-query" class="headerlink" title="multi match query"></a>multi match query</h5><p>The <code>multi_match</code> query builds on the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-match-query.html" target="_blank" rel="noopener"><code>match</code> query</a> to allow multi-field queries:</p><p>这种方式支持在多个字段中进行查询。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot; : &#123;</span><br><span class="line">      &quot;query&quot;:    &quot;this is a test&quot;, </span><br><span class="line">      &quot;fields&quot;: [ &quot;subject&quot;, &quot;message&quot; ] </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Fields can be specified with wildcards, eg:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;multi_match&quot; : &#123;</span><br><span class="line">      &quot;query&quot;:    &quot;Will Smith&quot;,</span><br><span class="line">      &quot;fields&quot;: [ &quot;title&quot;, &quot;*_name&quot; ] </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="term-level-queries-术语级别查询"><a href="#term-level-queries-术语级别查询" class="headerlink" title="term level queries-术语级别查询"></a>term level queries-术语级别查询</h4><p>不同于上面的全文内容检测，这个是查询非常具体的值。</p><p>因此，这种查询，通常适用于结构化的数据，例如numbers, dates, and enums，而不是没有结构的text文本类型。</p><h5 id="term-query"><a href="#term-query" class="headerlink" title="term query"></a>term query</h5><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST _search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot; : &#123; &quot;user&quot; : &quot;Kimchy&quot; &#125; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也可以再语句中加入boost参数，指定_score</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">GET _search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;should&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;term&quot;: &#123;</span><br><span class="line">            &quot;status&quot;: &#123;</span><br><span class="line">              &quot;value&quot;: &quot;urgent&quot;,</span><br><span class="line">              &quot;boost&quot;: 2.0 </span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;term&quot;: &#123;</span><br><span class="line">            &quot;status&quot;: &quot;normal&quot; </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="terms-query"><a href="#terms-query" class="headerlink" title="terms query"></a>terms query</h5><p>可以定义多个术语：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;constant_score&quot; : &#123;</span><br><span class="line">            &quot;filter&quot; : &#123;</span><br><span class="line">                &quot;terms&quot; : &#123; &quot;user&quot; : [&quot;kimchy&quot;, &quot;elasticsearch&quot;]&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="range-query"><a href="#range-query" class="headerlink" title="range query"></a>range query</h5><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET _search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;range&quot; : &#123;</span><br><span class="line">            &quot;age&quot; : &#123;</span><br><span class="line">                &quot;gte&quot; : 10,</span><br><span class="line">                &quot;lte&quot; : 20,</span><br><span class="line">                &quot;boost&quot; : 2.0</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The <code>range</code> query accepts the following parameters:</p><table><thead><tr><th><code>gte</code></th><th>Greater-than or equal to</th></tr></thead><tbody><tr><td><code>gt</code></td><td>Greater-than</td></tr><tr><td><code>lte</code></td><td>Less-than or equal to</td></tr><tr><td><code>lt</code></td><td>Less-than</td></tr><tr><td><code>boost</code></td><td>Sets the boost value of the query, defaults to <code>1.0</code></td></tr></tbody></table><p>date类型相关的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET _search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;range&quot; : &#123;</span><br><span class="line">            &quot;born&quot; : &#123;</span><br><span class="line">                &quot;gte&quot;: &quot;01/01/2012&quot;,</span><br><span class="line">                &quot;lte&quot;: &quot;2013&quot;,</span><br><span class="line">                &quot;format&quot;: &quot;dd/MM/yyyy||yyyy&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="exists-query"><a href="#exists-query" class="headerlink" title="exists query"></a>exists query</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;exists&quot; : &#123; &quot;field&quot; : &quot;user&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除此之外，还有非常多的类型，包括</p><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-prefix-query.html" target="_blank" rel="noopener">Prefix Query</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-wildcard-query.html" target="_blank" rel="noopener">Wildcard Query</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-regexp-query.html" target="_blank" rel="noopener">Regexp Query</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-fuzzy-query.html" target="_blank" rel="noopener">Fuzzy Query</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-type-query.html" target="_blank" rel="noopener">Type Query</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-ids-query.html" target="_blank" rel="noopener">Ids Query</a></li></ul><h3 id="复合查询"><a href="#复合查询" class="headerlink" title="复合查询"></a>复合查询</h3><h4 id="bool-query"><a href="#bool-query" class="headerlink" title="bool query"></a>bool query</h4><p>主要是一些情况的判断，选项有：</p><table><thead><tr><th>Occur</th><th>Description</th></tr></thead><tbody><tr><td><code>must</code></td><td>The clause (query) must appear in matching documents and will contribute to the score.</td></tr><tr><td><code>filter</code></td><td>The clause (query) must appear in matching documents. However unlike <code>must</code> the score of the query will be ignored. Filter clauses are executed in <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-filter-context.html" target="_blank" rel="noopener">filter context</a>, meaning that scoring is ignored and clauses are considered for caching.</td></tr><tr><td><code>should</code></td><td>The clause (query) should appear in the matching document. In a boolean query with no <code>must</code> or <code>filter</code> clauses, one or more <code>should</code> clauses must match a document. The minimum number of should clauses to match can be set using the<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-dsl-minimum-should-match.html" target="_blank" rel="noopener"><code>minimum_should_match</code></a> parameter.</td></tr><tr><td><code>must_not</code></td><td>The clause (query) must not appear in the matching documents. Clauses are executed in <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/query-filter-context.html" target="_blank" rel="noopener">filter context</a> meaning that scoring is ignored and clauses are considered for caching. Because scoring is ignored, a score of <code>0</code> for all documents is returned.</td></tr></tbody></table><p>下面是一个案例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">POST _search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot; : &#123;</span><br><span class="line">      &quot;must&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;filter&quot;: &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;tag&quot; : &quot;tech&quot; &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;must_not&quot; : &#123;</span><br><span class="line">        &quot;range&quot; : &#123;</span><br><span class="line">          &quot;age&quot; : &#123; &quot;gte&quot; : 10, &quot;lte&quot; : 20 &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;should&quot; : [</span><br><span class="line">        &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;wow&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;term&quot; : &#123; &quot;tag&quot; : &quot;elasticsearch&quot; &#125; &#125;</span><br><span class="line">      ],</span><br><span class="line">      &quot;minimum_should_match&quot; : 1,</span><br><span class="line">      &quot;boost&quot; : 1.0</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="kibana查询数据"><a href="#kibana查询数据" class="headerlink" title="kibana查询数据"></a>kibana查询数据</h3><p>上面说的都是直接从es中检索数据，但是对于大多数用户来说，更多的还是通过kibana去做</p><h2 id="ES监控"><a href="#ES监控" class="headerlink" title="ES监控"></a>ES监控</h2><p>zabbix上的配置：</p><p>key：</p><p>集群相关接口：GET /_cat/health?v、/_cat/allocation?v、GET /_cat/master?v</p><ul><li>集群颜色状态（非绿色报警）：es_status[9002,cluster,status]</li><li>集群分片健康度（非100%报警）：es_status[9002,cluster,active_shards_percent]</li><li>集群节点总数（有变化报警）：es_status[9002,cluster,total_node]</li><li>集群data节点总数（有变化报警）：es_status[9002,cluster,total_datanode]</li><li>集群未分配的分片数量（大于0报警）：es_status[9002,cluster,unassigned_shards]</li><li>集群的磁盘存储空间（打到80%报警）：es_status[9002,cluster,disk_used_percent]</li><li>集群master节点（有变化报警）：es_status[9002,cluster,masternode]</li><li>集群的写入速度</li><li>集群的读写速度</li><li>线程池的监控，总数以及每个线程池的监控</li><li>gc的情况</li></ul><p>节点相关：</p><p>相关api：</p><ul><li>es_status[9002,node,xx]</li><li>JVM内存占用超过90</li><li>负载</li><li>cpu使用率</li><li>日志中有报错就报警</li></ul><p>索引相关：</p><ul><li><p>索引总数：</p></li><li><p>es_status[9002,index,]</p></li></ul><p>主机相关监控，流量，cpu什么的，怎么能按照一个集群的维度-添加到grafana中</p><p>可以添加一下监控，针对每一个es集群：</p><ol><li><p>集群的磁盘使用情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_cat/allocation?v</span><br></pre></td></tr></table></figure></li><li><p>集群的健康性检查，例如红色和黄色、分片的状态等等</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_cat/health?v</span><br></pre></td></tr></table></figure><p>集群的不健康可能是多种原因导致的，这里不区分具体的原因，如果有问题，则报警，收到报警之后再去查看具体是什么原因。</p><p>具体的指标有：</p><ul><li></li></ul></li></ol><ol><li><p>监控数据节点的负载情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure></li><li><p>node的可用性监控</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure></li><li><p>node的性能监控</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure></li></ol><ol><li><p>集群负载情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure></li><li><p>集群的索引监控</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dd</span><br></pre></td></tr></table></figure><p>监控指标主要是索引的请求速率、请求处理延迟、索引大小等、索引异常等</p></li><li><p>ES的jmx监控(因为是java进程)</p></li></ol><h2 id="ES调优"><a href="#ES调优" class="headerlink" title="ES调优"></a>ES调优</h2><p>refresh时间间隔：refresh_interval</p><p>replica数目设置：在bulk大量数据到ES集群的可以把副本数设置为0，在数据导入完成之后再设置为1或者你集群的适合的数目。</p><h2 id="ES常见问题"><a href="#ES常见问题" class="headerlink" title="ES常见问题"></a>ES常见问题</h2><h3 id="慢查慢写日志设置及收集"><a href="#慢查慢写日志设置及收集" class="headerlink" title="慢查慢写日志设置及收集"></a>慢查慢写日志设置及收集</h3><p><strong>设置</strong></p><h3 id="热线程"><a href="#热线程" class="headerlink" title="热线程"></a>热线程</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/cluster-nodes-hot-threads.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.5/cluster-nodes-hot-threads.html</a></p><p>当有一些节点的cpu、负载、io等有异常时，我们可以通过热线程来定位到具体的产生原因。</p><p>使用格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[elk@es13.dwb.dgt ~]$ curl http://10.10.10.83:9200/_nodes/es13-data/hot_threads</span><br><span class="line"></span><br><span class="line">或者添加上时间，指定抓取多久时间内占用资源的热线程</span><br><span class="line">GET /_nodes/hot_threads&amp;interval=30s</span><br></pre></td></tr></table></figure><p>执行后的输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">[elk@es13.dwb.dgt ~]$ curl http://10.10.10.83:9200/_nodes/es13-data/hot_threads</span><br><span class="line">::: &#123;es13-data&#125;&#123;76c2DSkdRRqTyHUCoK1pyQ&#125;&#123;egVogFoJRzuFvJxUX1VnWQ&#125;&#123;10.10.10.83&#125;&#123;10.10.10.83:9300&#125;&#123;ml.machine_memory=270056525824, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true&#125;</span><br><span class="line">   Hot threads at 2019-07-23T07:21:24.850, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:</span><br><span class="line"></span><br><span class="line">   54.7% (273.5ms out of 500ms) cpu usage by thread &apos;elasticsearch[es13-data][[app-publishing-logstash-2019.07.23][1]: Lucene Merge Thread #983]&apos;</span><br><span class="line">     2/10 snapshots sharing following 24 elements</span><br><span class="line">       sun.misc.Unsafe.park(Native Method)</span><br><span class="line">       java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)</span><br><span class="line">       java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)</span><br><span class="line">       org.apache.lucene.index.MergePolicy$OneMergeProgress.pauseNanos(MergePolicy.java:156)</span><br><span class="line">       org.apache.lucene.index.MergeRateLimiter.maybePause(MergeRateLimiter.java:148)</span><br><span class="line">       org.apache.lucene.index.MergeRateLimiter.pause(MergeRateLimiter.java:93)</span><br><span class="line">       org.apache.lucene.store.RateLimitedIndexOutput.checkRate(RateLimitedIndexOutput.java:78)</span><br><span class="line">       org.apache.lucene.store.RateLimitedIndexOutput.writeBytes(RateLimitedIndexOutput.java:72)</span><br><span class="line">       org.apache.lucene.store.DataOutput.writeBytes(DataOutput.java:52)</span><br><span class="line">       org.apache.lucene.store.RAMOutputStream.writeTo(RAMOutputStream.java:90)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlock(BlockTreeTermsWriter.java:820)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlocks(BlockTreeTermsWriter.java:624)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.pushTerm(BlockTreeTermsWriter.java:905)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.write(BlockTreeTermsWriter.java:869)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:343)</span><br><span class="line">       org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)</span><br><span class="line">       org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:164)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:231)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:116)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4446)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)</span><br><span class="line">       org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)</span><br><span class="line">     5/10 snapshots sharing following 11 elements</span><br><span class="line">       org.apache.lucene.index.FilterLeafReader$FilterTermsEnum.next(FilterLeafReader.java:189)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:335)</span><br><span class="line">       org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)</span><br><span class="line">       org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:164)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:231)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:116)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4446)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)</span><br><span class="line">       org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)</span><br><span class="line">     2/10 snapshots sharing following 13 elements</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlocks(BlockTreeTermsWriter.java:633)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.pushTerm(BlockTreeTermsWriter.java:905)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.write(BlockTreeTermsWriter.java:869)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:343)</span><br><span class="line">       org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)</span><br><span class="line">       org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:164)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:231)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:116)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4446)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)</span><br><span class="line">       org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)</span><br><span class="line">     unique snapshot</span><br><span class="line">       sun.nio.ch.FileDispatcherImpl.write0(Native Method)</span><br><span class="line">       sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)</span><br><span class="line">       sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)</span><br><span class="line">       sun.nio.ch.IOUtil.write(IOUtil.java:65)</span><br><span class="line">       sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)</span><br><span class="line">       java.nio.channels.Channels.writeFullyImpl(Channels.java:78)</span><br><span class="line">       java.nio.channels.Channels.writeFully(Channels.java:101)</span><br><span class="line">       java.nio.channels.Channels.access$000(Channels.java:61)</span><br><span class="line">       java.nio.channels.Channels$1.write(Channels.java:174)</span><br><span class="line">       org.apache.lucene.store.FSDirectory$FSIndexOutput$1.write(FSDirectory.java:417)</span><br><span class="line">       java.util.zip.CheckedOutputStream.write(CheckedOutputStream.java:73)</span><br><span class="line">       java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)</span><br><span class="line">       java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)</span><br><span class="line">       org.apache.lucene.store.OutputStreamIndexOutput.writeBytes(OutputStreamIndexOutput.java:53)</span><br><span class="line">       org.elasticsearch.common.lucene.store.FilterIndexOutput.writeBytes(FilterIndexOutput.java:59)</span><br><span class="line">       org.apache.lucene.store.RateLimitedIndexOutput.writeBytes(RateLimitedIndexOutput.java:73)</span><br><span class="line">       org.apache.lucene.store.DataOutput.writeBytes(DataOutput.java:52)</span><br><span class="line">       org.apache.lucene.store.RAMOutputStream.writeTo(RAMOutputStream.java:90)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlock(BlockTreeTermsWriter.java:820)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlocks(BlockTreeTermsWriter.java:624)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.pushTerm(BlockTreeTermsWriter.java:905)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.write(BlockTreeTermsWriter.java:869)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:343)</span><br><span class="line">       org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)</span><br><span class="line">       org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:164)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:231)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:116)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4446)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)</span><br><span class="line">       org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)</span><br><span class="line"></span><br><span class="line">    5.2% (26ms out of 500ms) cpu usage by thread &apos;elasticsearch[es13-data][[transport_server_worker.default]][T#16]&apos;</span><br><span class="line">     4/10 snapshots sharing following 2 elements</span><br><span class="line">       io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)</span><br><span class="line">       java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure><p>输出分析：</p><h3 id="节点多磁盘时分配不均匀"><a href="#节点多磁盘时分配不均匀" class="headerlink" title="节点多磁盘时分配不均匀"></a>节点多磁盘时分配不均匀</h3><p>问题：一个数据量比较大的索引分片分配到某一台机器上的时候，整体的资源是够的，但是某一块盘的使用率是比较高的</p><p>如下图所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[ops@es061.ecs.east1-g ~]$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/vda1        40G  5.9G   32G  16% /</span><br><span class="line">tmpfs            16G   12K   16G   1% /dev/shm</span><br><span class="line">/dev/vdb1       197G   59G  129G  32% /data1</span><br><span class="line">/dev/vdc1       197G  135G   53G  73% /data2</span><br></pre></td></tr></table></figure><p>可以看到，两块盘的使用率将近相差了40%。</p><p>我们知道，es分配数据，主要是根据索引的分片级别到es的节点上，如果这个分配不均匀，我们可以通过挪动shard进行均衡。</p><p>但是，如果是节点下面的多快磁盘，这个的分配策略又是什么呢？</p><p><strong>多硬盘时的分配策略</strong></p><blockquote><p>磁盘的IO不均匀是因为可能挂在了裸盘，并且配置了多个data.path的原因。  </p><p>一个shard只能分布在其中一块磁盘上，如果某个索引比较热，写入量大，对应的shard所在磁盘就比其他繁忙很多。</p><p>多块磁盘推荐做raid，每个磁盘的IO基本上是均匀分布的。</p></blockquote><p>官方原文：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">The path.data settings can be set to multiple paths, in which case all paths will be used to store data (although the files belonging to a single shard will all be stored on the same data path):</span><br><span class="line">path:</span><br><span class="line">  data:</span><br><span class="line">    - /mnt/elasticsearch_1</span><br><span class="line">    - /mnt/elasticsearch_2</span><br><span class="line">    - /mnt/elasticsearch_3</span><br></pre></td></tr></table></figure><p>也就是说，我们可以设置多个存储路径来存储数据，es会自动去协调分配，但是一个shard的文件只会被存储到一个path中。</p><p><strong>综上</strong></p><p>导致这个问题出现的根本原因是：</p><ul><li>这个node上分配了一个大索引的一个shard。</li><li>node级别只会分配这个shard存储到其中一个路径下，这里是/data2下</li><li>分配路径的策略是：优先找磁盘剩余空间大的盘</li></ul><h3 id="队列溢出"><a href="#队列溢出" class="headerlink" title="队列溢出"></a>队列溢出</h3><p>使用这个命令查看队列的情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_cat/thread_pool?v</span><br></pre></td></tr></table></figure><p>当看到rejected列中有数据的时候，就表示队列被打满了。</p><p>出现问题的原因可能有很多，例如：</p><ul><li>往es写数据的程序写入的数据量太大</li><li>es集群需要扩容等等</li></ul><h2 id="ES扩容及缩容"><a href="#ES扩容及缩容" class="headerlink" title="ES扩容及缩容"></a>ES扩容及缩容</h2><h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><p>扩容比较简单，在配置文件中指定现有es节点的地址，启动之后就会自动添加进当前的集群，注意cluster name需要一致。</p><p>在新节点添加进来之后，shard会自动挪动，如果集群压力较大，数据量较多，在挪动的时候可能会影响集群的读写，那么，这个时候我可以自定义的选择合适的时间去操作，配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;persistent&quot;: &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>避免集群shard移动，待到合适的时间，设置：</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings &#123; "persistent": &#123; "cluster.routing.allocation.enable": null &#125; &#125;</span><br></pre></td></tr></table></figure><p>恢复shard移动</p><p>具体可以参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.2/rolling-upgrades.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.2/rolling-upgrades.html</a></p><p>注意：</p><ul><li>设置为none之后，如果创建了新的索引，那么该索引的分片将不会被分配，会被置为：UNASSIGNED。也就意味着无法往这个新索引中写入数据</li><li>在设置之前的索引，数据写入不受影响。</li></ul><h3 id="缩容"><a href="#缩容" class="headerlink" title="缩容"></a>缩容</h3><p>使用exclude：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;transient&quot; : &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.exclude._ip&quot; : &quot;10.0.0.1&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把要下线的机器exclude，然后数据会自动迁移到其他节点并且自动rebalance，集群不需要重启。</p><p>迁移完后可以重新划分节点角色。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#通过IP，排除集群中的某个节点：节点IP：10.100.0.11</span><br><span class="line">curl -XPUT http://&lt;domain&gt;:&lt;port&gt;/_cluster/settings?pretty -d &apos;&#123;&quot;transient&quot;:&#123;&quot;cluster.routing.allocation.exclude._ip&quot;:&quot;10.100.0.11&quot;&#125;&#125;&apos;</span><br><span class="line"></span><br><span class="line">#通过IP，排除集群中的多个节点：节点IP：10.10.0.11,10.100.0.12</span><br><span class="line">curl -XPUT http://&lt;domain&gt;:&lt;port&gt;/_cluster/settings?pretty -d &apos;&#123;&quot;transient&quot;:&#123;&quot;cluster.routing.allocation.exclude._ip&quot;:&quot;10.100.0.11,10.100.0.12&quot;&#125;&#125;&apos;</span><br><span class="line"></span><br><span class="line">#取消节点排除的限制</span><br><span class="line">curl -XPUT http://&lt;domain&gt;:&lt;port&gt;/_cluster/settings?pretty -d &apos;&#123;&quot;transient&quot;:&#123;&quot;cluster.routing.allocation.exclude._ip&quot;: null&#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>注意：当迁移过程中，其他节点的负载较高时，可以先取消，就是上面的设置为null</p><p>所以，整个的下线操作是：</p><ol><li>exclude掉要下线的节点</li><li>确认shard，待该节点上没有shard之后，停止该节点</li><li>将exclude设置为null</li></ol><p>问题：如何查看和控制shard的移动速度，防止数据量过大时出现问题。</p><h3 id="相关参数"><a href="#相关参数" class="headerlink" title="相关参数"></a>相关参数</h3><p>除了上面提到的哪些，还有一些集群级别的参数可以动态定义</p><p>迁移相关：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster.routing.allocation.cluster_concurrent_rebalance</span><br></pre></td></tr></table></figure><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/shards-allocation.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/shards-allocation.html</a></p><p>主要是modules中的集群部分内容</p><p>索引相关：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">indices.recovery.max_bytes_per_sec</span><br></pre></td></tr></table></figure><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/recovery.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/recovery.html</a></p><h2 id="ES故障处理"><a href="#ES故障处理" class="headerlink" title="ES故障处理"></a>ES故障处理</h2><h2 id="集群节点宕机导致shard-unassigned"><a href="#集群节点宕机导致shard-unassigned" class="headerlink" title="集群节点宕机导致shard unassigned"></a>集群节点宕机导致shard unassigned</h2><p>使用这个去获取未分配的分片详情</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XGET http://192.168.1.188:9200/_cat/shards|grep UNASSIGNED</span><br></pre></td></tr></table></figure><p>未分配的是副本分片，那么修改副本数量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT applog-prod-2016.12.18/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index&quot;:&#123;</span><br><span class="line">    &quot;number_of_replicas&quot;:0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果是主分片丢失了，那么没有办法了，要承受数据丢失，我们使用reindex，来尽可能的保证数据的完整</p><p>整体的流程如下：</p><ul><li>创建一个新的索引，mapping与要reindex的源index保持一致</li><li>执行reindex</li><li>删除原有的index</li><li>创建新的index，名称使用删除的名称</li><li>再次执行reindex，将数据恢复进去</li><li>删除掉临时的index即可</li></ul><p>接口如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">POST _reindex</span><br><span class="line">&#123;</span><br><span class="line">  &quot;source&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;twitter&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;dest&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &quot;new_twitter&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>不想再次创建索引的话也可以使用alias</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;twitter&quot;, &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种形式的话，那么临时的索引就能删除掉</p><h1 id="kibana部署"><a href="#kibana部署" class="headerlink" title="kibana部署"></a>kibana部署</h1><h2 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/kibana/6.5/install.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/6.5/install.html</a></p><h2 id="ES数据如何展示在kibana上"><a href="#ES数据如何展示在kibana上" class="headerlink" title="ES数据如何展示在kibana上"></a>ES数据如何展示在kibana上</h2><p>如何将es的索引数据展示在kibana上？</p><p>manager–&gt;index patterns</p><p>输入index的匹配规则，注意索引需要有一个时间字段，以作为排序</p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/kibana/5.3/production.html#load-balancing" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/5.3/production.html#load-balancing</a></p><p>使用es中的转发节点去实现，es的这个转发节点其实就是负载均衡的作用，它会去协调各个节点。</p><h2 id="ES的监控指标如何展示在kibana上"><a href="#ES的监控指标如何展示在kibana上" class="headerlink" title="ES的监控指标如何展示在kibana上"></a>ES的监控指标如何展示在kibana上</h2><h2 id="kibana监控"><a href="#kibana监控" class="headerlink" title="kibana监控"></a>kibana监控</h2><h2 id="kibana搜索"><a href="#kibana搜索" class="headerlink" title="kibana搜索"></a>kibana搜索</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/kibana/6.5/kuery-query.html#_new_simplified_syntax" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/6.5/kuery-query.html#_new_simplified_syntax</a></p><h3 id="lucence-query-syntax"><a href="#lucence-query-syntax" class="headerlink" title="lucence query syntax"></a>lucence query syntax</h3><p>kibana上的查询方式是基于lucence的，</p><p>官方的内容：</p><p>Kibana’s query language has historically been based on the Lucene query syntax. The following are some tips that can help get you started.</p><ul><li>To perform a free text search, simply enter a text string. For example, if you’re searching web server logs, you could enter <code>safari</code> to search all fields for the term <code>safari</code>.</li><li>To search for a value in a specific field, prefix the value with the name of the field. For example, you could enter <code>status:200</code> to find all of the entries that contain the value <code>200</code> in the <code>status</code> field.</li><li>To search for a range of values, you can use the bracketed range syntax, <code>[START_VALUE TO END_VALUE]</code>. For example, to find entries that have 4xx status codes, you could enter <code>status:[400 TO 499]</code>.</li><li>To specify more complex search criteria, you can use the Boolean operators <code>AND</code>, <code>OR</code>, and <code>NOT</code>. For example, to find entries that have 4xx status codes and have an extension of <code>php</code> or <code>html</code>, you could enter <code>status:[400 TO 499] AND (extension:php OR extension:html)</code>.</li></ul><p>For more detailed information about the Lucene query syntax, see the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/query-dsl-query-string-query.html#query-string-syntax" target="_blank" rel="noopener">Query String Query</a> docs.</p><h2 id="kibana-apm展示"><a href="#kibana-apm展示" class="headerlink" title="kibana apm展示"></a>kibana apm展示</h2><h2 id="xpack-monitor监控"><a href="#xpack-monitor监控" class="headerlink" title="xpack-monitor监控"></a>xpack-monitor监控</h2><p>默认情况下，在kibana界面是不展示各es节点的负载、资源使用率、索引信息等指标的，我们可以添加上这个功能，这在排查问题时还是挺有效果的。</p><p>除了能监控es，xpack体系还能监控filebeat、logstash等组件</p><p>注意：在6.3版本之后，xpack已经默认内嵌到elk组件当中了。</p><p>参考链接：<a href="https://www.elastic.co/cn/support/matrix#matrix_compatibility" target="_blank" rel="noopener">https://www.elastic.co/cn/support/matrix#matrix_compatibility</a></p><h3 id="在线方式安装"><a href="#在线方式安装" class="headerlink" title="在线方式安装"></a>在线方式安装</h3><p>es端配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch-plugin install x-pack</span><br></pre></td></tr></table></figure><p>如果es设置了关闭自动创建index，那么还需要添加下面这行配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history*</span><br></pre></td></tr></table></figure><p>kibana端配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kibana-plugin install x-pack</span><br></pre></td></tr></table></figure><h3 id="离线方式安装"><a href="#离线方式安装" class="headerlink" title="离线方式安装"></a>离线方式安装</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/x-pack/5.1/installing-xpack.html#xpack-installing-offline" target="_blank" rel="noopener">https://www.elastic.co/guide/en/x-pack/5.1/installing-xpack.html#xpack-installing-offline</a></p><p>如果服务器不能直连公网等，那么可以把相关的包文件下载下来上次到服务器上。</p><p>首先下载文件，并传输到服务器上。</p><p>然后执行以下命令</p><p><strong>es：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch-plugin install file:///path/to/file/x-pack-5.1.2.zip</span><br></pre></td></tr></table></figure><p><strong>kibana：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kibana-plugin install file:///path/to/file/x-pack-5.1.2.zip</span><br></pre></td></tr></table></figure><h3 id="xpack相关配置参数"><a href="#xpack相关配置参数" class="headerlink" title="xpack相关配置参数"></a>xpack相关配置参数</h3><p>有以下相关参数：</p><table><thead><tr><th>Setting</th><th>Description</th></tr></thead><tbody><tr><td><code>xpack.security.enabled</code></td><td>Set to <code>false</code> to disable X-Pack security. Configure in both <code>elasticsearch.yml</code> and <code>kibana.yml</code>.</td></tr><tr><td><code>xpack.monitoring.enabled</code></td><td>Set to <code>false</code> to disable X-Pack monitoring. Configure in both <code>elasticsearch.yml</code> and <code>kibana.yml</code>.</td></tr><tr><td><code>xpack.graph.enabled</code></td><td>Set to <code>false</code> to disable X-Pack graph. Configure in both <code>elasticsearch.yml</code> and <code>kibana.yml</code>.</td></tr><tr><td><code>xpack.watcher.enabled</code></td><td>Set to <code>false</code> to disable Watcher. Configure in <code>elasticsearch.yml</code>only.</td></tr><tr><td><code>xpack.reporting.enabled</code></td><td>Set to <code>false</code> to disable X-Pack reporting. Configure in <code>kibana.yml</code> only.</td></tr></tbody></table><p>默认情况下，所有的参数功能都是打开的，可以根据实际情况去选择开启</p><p>我们一般的实际配置是：</p><p><strong>es节点</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[elk@es032.ecs.east1-e config]$ grep xpack elasticsearch.yml</span><br><span class="line">xpack.security.audit.enabled: false</span><br><span class="line">xpack.monitoring.enabled: true</span><br><span class="line">xpack.security.enabled: false</span><br><span class="line">xpack.graph.enabled: false</span><br><span class="line">xpack.watcher.enabled: false</span><br></pre></td></tr></table></figure><p><strong>kibana</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[elk@redis2.dwb.dgt config]$ grep xpack kibana.yml</span><br><span class="line">xpack.monitoring.elasticsearch.url: &quot;http://172.24.48.34:9200&quot;</span><br><span class="line">xpack.monitoring.enabled: true</span><br><span class="line">xpack.security.enabled: false</span><br><span class="line">xpack.graph.enabled: false</span><br><span class="line">xpack.reporting.enabled: false</span><br></pre></td></tr></table></figure><h3 id="license更新"><a href="#license更新" class="headerlink" title="license更新"></a>license更新</h3><p>1、去下面这个链接提交 基础 license 申请</p><p><a href="https://license.elastic.co/registration/" target="_blank" rel="noopener">https://license.elastic.co/registration/</a></p><p>2、ELK 会给你填写的邮箱中发一封邮件。</p><p>去中间这个链接地址下载 license 文件</p><p>3、如果你和我一样使用的 ELK 6.3 版本，那么你需要使用以下以命令更新 License。注：License 更新命令经常变化，如果出现报错请注意报错信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># @license.json是你刚才下载的 license 文件上传到服务器上。</span><br><span class="line">curl -XPOST &apos;http://192.168.1.1:9200/_xpack/license/start_basic?acknowledge=true&apos; -H &quot;Content-Type:application/json&quot; -d @license.json</span><br></pre></td></tr></table></figure><p>5版本的命令是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -XPUT -u elastic &apos;http://172.16.1.128:9500/_xpack/license?acknowledge=true&apos; -H &quot;Content-Type: application/json&quot; -d @xiaohua-wang-9f31d302-4f35-46ad-b67d-2278833f3d58-v5.json</span><br></pre></td></tr></table></figure><p>默认密码是changeme</p><p>注意需要上传这个json文件到服务器上</p><p>参考链接：<a href="https://www.elastic.co/guide/en/x-pack/5.6/installing-license.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/x-pack/5.6/installing-license.html</a></p><h1 id="补充-yaml语法"><a href="#补充-yaml语法" class="headerlink" title="补充-yaml语法"></a>补充-yaml语法</h1><p>YAML语言的设计参考了JSON，XML和SDL等语言。也是一种数据交互的格式语言，YAML 强调以<strong>数据为中心</strong>,简洁易读,编写简单。</p><p>YAML主要的作用是作为程序的配置文件。</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>yaml语言有以下特点：</p><ul><li>大小写敏感</li><li>通过缩进表示层级关系</li><li><strong>禁止使用tab缩进，只能使用空格键</strong> （个人感觉这条最重要）</li><li>缩进的空格数目不重要，只要相同层级左对齐即可</li><li>使用#表示注释</li></ul><h2 id="支持的数据结构"><a href="#支持的数据结构" class="headerlink" title="支持的数据结构"></a>支持的数据结构</h2><p>支持以下数据结构：</p><ul><li>对象：键值对的<strong>集合</strong>，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary）</li><li>数组：一组按次序排列的值，又称为序列（sequence） / 列表（list）</li><li>纯量（scalars）：单个的、不可再分的值</li></ul><h2 id="数据结构的书写形式"><a href="#数据结构的书写形式" class="headerlink" title="数据结构的书写形式"></a>数据结构的书写形式</h2><h3 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h3><p>Map（属性和值）（键值对）的形式： key:(空格)v ：表示一堆键值对，空格不可省略。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">car:</span><br><span class="line">    color: red</span><br><span class="line">    brand: BMW</span><br></pre></td></tr></table></figure><p>一行写法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">car:&#123;color: red，brand: BMW&#125;</span><br></pre></td></tr></table></figure><p>相当于JSON格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;color&quot;:&quot;red&quot;,&quot;brand&quot;:&quot;BMW&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>一组连词线开头的行，构成一个数组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">brand:</span><br><span class="line">   - audi</span><br><span class="line">   - bmw</span><br><span class="line">   - ferrari</span><br></pre></td></tr></table></figure><p>一行写法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brand: [audi,bmw,ferrari]</span><br></pre></td></tr></table></figure><p>相当于JSON</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&quot;auri&quot;,&quot;bmw&quot;,&quot;ferrari&quot;]</span><br></pre></td></tr></table></figure><h3 id="纯量"><a href="#纯量" class="headerlink" title="纯量"></a>纯量</h3><p>纯量是最基本的、不可再分的值。以下数据类型都属于 JavaScript 的纯量。</p><ul><li>字符串</li><li>布尔值</li><li>整数</li><li>浮点数</li><li>Null</li><li>时间</li><li>日期</li></ul><h1 id="补充-kafka安装部署"><a href="#补充-kafka安装部署" class="headerlink" title="补充-kafka安装部署"></a>补充-kafka安装部署</h1><h2 id="kafka-3"><a href="#kafka-3" class="headerlink" title="kafka"></a>kafka</h2><p>参考文档：</p><ul><li><a href="https://kafka.apache.org/11/documentation.html#quickstart" target="_blank" rel="noopener">https://kafka.apache.org/11/documentation.html#quickstart</a></li></ul><h3 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h3><p>启动zk</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</span><br><span class="line">可以是：</span><br><span class="line">nohup bin/zookeeper-server-start.sh config/zookeeper.properties &gt; zk.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>启动kafka</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh config/server.properties</span><br><span class="line">可以是</span><br><span class="line">nohup  bin/kafka-server-start.sh config/server.properties &gt; kafka.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><h2 id="kafka-manager"><a href="#kafka-manager" class="headerlink" title="kafka-manager"></a>kafka-manager</h2><p>参考链接：</p><ul><li><a href="https://github.com/yahoo/kafka-manager/tree/1.3.3.16" target="_blank" rel="noopener">https://github.com/yahoo/kafka-manager/tree/1.3.3.16</a></li><li><a href="https://www.cnblogs.com/frankdeng/p/9584870.html" target="_blank" rel="noopener">https://www.cnblogs.com/frankdeng/p/9584870.html</a></li></ul><p>注意：.sbt/repositories文件中，每行后面不能有空格，每行都是以换行结尾的。如果存在空格，那么使用delete键删除。</p><h3 id="启动-2"><a href="#启动-2" class="headerlink" title="启动"></a>启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[admin@node21 kafka-manager-1.3.3.18]$ nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=8080 &amp;</span><br></pre></td></tr></table></figure><h1 id="补充-logrotate"><a href="#补充-logrotate" class="headerlink" title="补充-logrotate"></a>补充-logrotate</h1><p>参考链接：</p><ul><li><a href="https://linux.cn/article-4126-1.html" target="_blank" rel="noopener">https://linux.cn/article-4126-1.html</a></li><li><a href="https://linux.cn/article-8227-1.html" target="_blank" rel="noopener">https://linux.cn/article-8227-1.html</a></li></ul><p>注意：</p><p>在一个配置文件中，如果指定了多个日志文件，那么当第一个文件不需要进行轮转的时候，下面的文件就算需要进行轮转，也都会跳过，也就是说：当有多个日志文件时，下一个文件的操作，完全依赖上一个文件是否已经存在，当已经存在的时候，下面就不会再进行操作。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 logrotate.d]# cat /etc/logrotate.d/syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">&#123;</span><br><span class="line">    sharedscripts</span><br><span class="line">    create 0664 root root</span><br><span class="line">    postrotate</span><br><span class="line">/bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logrotate /etc/logrotate.conf  -f</span><br></pre></td></tr></table></figure><p>强制生成新文件的时候，当cron的轮询文件已经存在，但是maillog不存在的时候，这个时候，将会不操作，也就是，不会对maillog进行日志轮转。</p><h1 id="补充-JVM知识"><a href="#补充-JVM知识" class="headerlink" title="补充-JVM知识"></a>补充-JVM知识</h1><h1 id="补充-lucene知识"><a href="#补充-lucene知识" class="headerlink" title="补充-lucene知识"></a>补充-lucene知识</h1>]]></content>
    
    <summary type="html">
    
      ELK部署
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="ELK" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/"/>
    
      <category term="ELK部署" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/ELK%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="ELK" scheme="http://yoursite.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>大数据科普</title>
    <link href="http://yoursite.com/2019/06/18/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E6%99%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E6%99%AE/"/>
    <id>http://yoursite.com/2019/06/18/IT科学技术知识体系结构-Linux运维方向/大数据/大数据科普/大数据科普/</id>
    <published>2019-06-18T05:57:57.000Z</published>
    <updated>2019-06-18T05:57:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考文献：</p><ul><li><a href="https://wiki.mbalib.com/wiki/%E5%A4%A7%E6%95%B0%E6%8D%AE" target="_blank" rel="noopener">https://wiki.mbalib.com/wiki/%E5%A4%A7%E6%95%B0%E6%8D%AE</a></li></ul><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h2><p>大数据定义：<strong>大数据</strong>是指<strong>无法</strong>在一定时间内用<strong>常规软件工具</strong>对其内容进行抓取、管理(存储等)和处理(分析等)的<strong>数据集合</strong>。</p><p>大数据意义：有人把数据比喻为蕴藏能量的煤矿。煤炭按照性质有焦煤、无烟煤、肥煤、贫煤等分类，而露天煤矿、深山煤矿的挖掘成本又不一样。与此类似，大数据并不在“大”，而在于“有用”。价值含量、挖掘成本比数量更为重要。对于很多行业而言，如何利用这些大规模数据是赢得竞争的关键</p><p>大数据特征：一般来说，大数据具有以下几个特征</p><ul><li><strong>数据体量巨大。</strong></li><li><strong>数据类型复杂多样。</strong>现在的数据类型不仅是文本形式，更多的是图片、视频、音频、地理位置信息等多类型的数据，个性化数据占绝对多数。</li><li><strong>价值密度低。</strong>以视频为例，一小时的视频，在不间断的监控过程中，可能有用的数据仅仅只有一两秒。</li></ul><h2 id="大数据技术"><a href="#大数据技术" class="headerlink" title="大数据技术"></a>大数据技术</h2><p>大数据技术是指从各种各样类型的数据中，快速获得有价值信息的能力。</p><h2 id="常见问题及误区"><a href="#常见问题及误区" class="headerlink" title="常见问题及误区"></a>常见问题及误区</h2><h3 id="数据不等于信息"><a href="#数据不等于信息" class="headerlink" title="数据不等于信息"></a>数据不等于信息</h3><p>经常有人把数据和信息当作同义词来用。其实不然，数据指的是一个原始的数据点（无论是通过数字，文字，图片还是视频等等），信息则直接与内容挂钩，需要有资讯性（informative）。数据越多，不一定就能代表信息越多，更不能代表信息就会成比例增多。有两个简单的例子：</p><p>备份。很多人如今已经会定期的对自己的硬盘进行备份。这个没什么好多解释的，每次备份都会创造出一组新的数据，但信息并没有增多。</p><p>多个社交网站上的信息。我们当中的很多人在多个社交网站上活跃，随着我们上的社交网站越多，我们获得的数据就会成比例的增多，我们获得的信息虽然也会增多，但却不会成比例的增多。不单单因为我们会互相转发好友的微博（或者其他社交网站上的内容），更因为很多内容会十分类似，有些微博虽然具体文字不同，但表达的内容十分相似。</p>]]></content>
    
    <summary type="html">
    
      大数据科普知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据科普" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E6%99%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>tcpdump</title>
    <link href="http://yoursite.com/2019/06/04/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%91%BD%E4%BB%A4/tcpdump/"/>
    <id>http://yoursite.com/2019/06/04/IT科学技术知识体系结构-Linux运维方向/Linux命令/tcpdump/</id>
    <published>2019-06-04T09:09:11.000Z</published>
    <updated>2019-06-04T09:09:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h1 id="命令语法"><a href="#命令语法" class="headerlink" title="命令语法"></a>命令语法</h1><p>tcpdump命令的使用格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump [-adeflnNOpqStvx][-c&lt;数据包数目&gt;][-dd][-ddd][-F&lt;表达文件&gt;][-i&lt;网络界面&gt;][-r&lt;数据包文件&gt;][-s&lt;数据包大小&gt;][-tt][-T&lt;数据包类型&gt;][-vv][-w&lt;数据包文件&gt;][输出数据栏位]</span><br></pre></td></tr></table></figure><p><strong>参数说明</strong>：</p><ul><li>-a 尝试将网络和广播地址转换成名称。</li><li>-c&lt;数据包数目&gt; 收到指定的数据包数目后，就停止进行倾倒操作。</li><li>-d 把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出。</li><li>-dd 把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出。</li><li>-ddd 把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出。</li><li>-e 在每列倾倒资料上显示连接层级的文件头。</li><li>-f 用数字显示网际网络地址。</li><li>-F&lt;表达文件&gt; 指定内含表达方式的文件。</li><li>-i&lt;网络界面&gt; 使用指定的网络截面送出数据包。</li><li>-l 使用标准输出列的缓冲区。</li><li>-n 不把主机的网络地址转换成名字。</li><li>-N 不列出域名。</li><li>-O 不将数据包编码最佳化。</li><li>-p 不让网络界面进入混杂模式。</li><li>-q 快速输出，仅列出少数的传输协议信息。</li><li>-r&lt;数据包文件&gt; 从指定的文件读取数据包数据。</li><li>-s&lt;数据包大小&gt; 设置每个数据包的大小。</li><li>-S 用绝对而非相对数值列出TCP关联数。</li><li>-t 在每列倾倒资料上不显示时间戳记。</li><li>-tt 在每列倾倒资料上显示未经格式化的时间戳记。</li><li>-T&lt;数据包类型&gt; 强制将表达方式所指定的数据包转译成设置的数据包类型。</li><li>-v 详细显示指令执行过程。</li><li>-vv 更详细显示指令执行过程。</li><li>-x 用十六进制字码列出数据包资料。</li><li>-w&lt;数据包文件&gt; 把数据包数据写入指定的文件。</li></ul><h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><p>有以下案例</p><ul><li><p>案例1：指定对端ip地址的流量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -nnn -s0 host 172.24.0.20 -w /root/dhub-api.pcap</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      tcpdump命令
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux命令" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="tcpdump" scheme="http://yoursite.com/tags/tcpdump/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper从入门到实践</title>
    <link href="http://yoursite.com/2019/04/08/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/zookeeper/zookeeper%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5/"/>
    <id>http://yoursite.com/2019/04/08/IT科学技术知识体系结构-Linux运维方向/运维架构/分布式/zookeeper/zookeeper从入门到实践/</id>
    <published>2019-04-08T08:43:59.000Z</published>
    <updated>2019-04-08T08:43:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="zookeeper基础知识"><a href="#zookeeper基础知识" class="headerlink" title="zookeeper基础知识"></a>zookeeper基础知识</h1><p>学习链接：<a href="http://zookeeper.apache.org/" target="_blank" rel="noopener">http://zookeeper.apache.org/</a></p><h2 id="zk概述"><a href="#zk概述" class="headerlink" title="zk概述"></a>zk概述</h2><p>zookeeper是一个分布式的、开源的分布式应用程序协调服务。它公开了一组简单的原语，分布式应用程序可以在此基础上实现更高级别的同步、配置维护、组和命名服务。它的设计易于编程，并使用了一个熟悉的目录树结构的文件系统。它在java中运行，并且有java和c的绑定。</p><p>众所周知，协调服务很难做好。它们特别容易出错，例如竞争条件和死锁。zookeeper背后的动机是从零开始减轻分布式应用程序实现协调服务的责任。</p><h3 id="zk设计目标-理念"><a href="#zk设计目标-理念" class="headerlink" title="zk设计目标-理念"></a>zk设计目标-理念</h3><p><strong>ZooKeeper is simple.</strong></p><blockquote><p>ZooKeeper allows distributed processes to coordinate with each other through a shared hierarchal namespace which is organized similarly to a standard file system. The name space consists of data registers - called znodes, in ZooKeeper parlance - and these are similar to files and directories. Unlike a typical file system, which is designed for storage, ZooKeeper data is kept in-memory, which means ZooKeeper can acheive high throughput and low latency numbers.</p><p>zk允许分布式程序之间通过一个共享的命名空间进行协调-这个命名空间被组织成类似linux文件系统的方式。</p><p>这个空间由多个数据寄存器（data registry）组成，这个在zk中叫做znode，他们类似文件和目录。</p><p>但与典型的文件系统不同，zk的数据保存在内存中，这意味着zk可以获得高吞吐量和低延迟。</p></blockquote><p><strong>ZooKeeper is replicated.</strong></p><blockquote><p>Like the distributed processes it coordinates, ZooKeeper itself is intended to be replicated over a sets of hosts called an ensemble.</p><p>The servers that make up the ZooKeeper service must all know about each other. They maintain an in-memory image of state, along with a transaction logs and snapshots in a persistent store. As long as a majority of the servers are available, the ZooKeeper service will be available.</p><p>Clients connect to a single ZooKeeper server. The client maintains a TCP connection through which it sends requests, gets responses, gets watch events, and sends heart beats. If the TCP connection to the server breaks, the client will connect to a different server.</p></blockquote><p><img src="https://zookeeper.apache.org/doc/r3.4.6/images/zkservice.jpg" alt="img"></p><blockquote><p>就像分布式程序一样，zk本身也趋向于在一组主机上进行复制，这一组主机就叫做ensemble-剧团</p><p>组成zk服务（zk service）的服务器们必须相互之间能够感知，它们在内存中维护状态的映像，同时持久化事务日志以及内容快照。</p><p>客户端连接到单个ZooKeeper服务器。客户端维护一个TCP连接，通过它发送请求、获取响应、获取监视事件和发送心跳。如果到服务器的TCP连接中断，客户端将连接到另一个服务器。</p></blockquote><p><strong>ZooKeeper is ordered.</strong> </p><blockquote><p>ZooKeeper stamps each update with a number that reflects the order of all ZooKeeper transactions. Subsequent operations can use the order to implement higher-level abstractions, such as synchronization primitives.</p><p>zk使用数字标记每一个事务更新。所以，后续的更新可以使用这个数字来实现更高级别的抽象操作，例如同步原语等</p></blockquote><p><strong>ZooKeeper is fast.</strong></p><blockquote><p>It is especially fast in “read-dominant” workloads. ZooKeeper applications run on thousands of machines, and it performs best where reads are more common than writes, at ratios of around 10:1.</p><p>zk在读多写少的工作模式中非常快。</p><p>zk应用程序运行在数千台机器上，当读写比例为10：1时，它的性能最好。</p></blockquote><h3 id="数据模型及分层命名空间"><a href="#数据模型及分层命名空间" class="headerlink" title="数据模型及分层命名空间"></a>数据模型及分层命名空间</h3><p>原文如下：</p><blockquote><p>The name space provided by ZooKeeper is much like that of a standard file system. A name is a sequence of path elements separated by a slash (/). Every node in ZooKeeper’s name space is identified by a path.</p><p>zk的命名空间非常类似标准的文件系统，以/为开始，在命名空间中的每一个节点都以路径为标识。</p></blockquote><p>模型如下：</p><p>ZooKeeper’s Hierarchical Namespace</p><p><img src="https://zookeeper.apache.org/doc/r3.4.6/images/zknamespace.jpg" alt="img"></p><h2 id="重要概念"><a href="#重要概念" class="headerlink" title="重要概念"></a>重要概念</h2><p>基础概念</p><ul><li><strong>ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟</strong>（但是内存限制了能够存储的容量不太大，此限制也是保持znode中存储的数据量较小的进一步原因）。</li><li><p><strong>ZooKeeper有临时节点的概念。 当创建临时节点的客户端会话一直保持活动，瞬时节点就一直存在。而当会话终结时，瞬时节点被删除。持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。</strong></p></li><li><p>ZooKeeper 底层其实只提供了两个功能：①管理（存储、读取）用户程序提交的数据；②为用户程序提交数据节点监听服务。</p></li></ul><h3 id="session"><a href="#session" class="headerlink" title="session"></a>session</h3><p>Session 指的是 ZooKeeper 服务器与客户端会话。<strong>在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接</strong>。客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端会话的生命周期也开始了。<strong>通过这个连接，客户端能够通过心跳检测与服务器保持有效的会话，也能够向Zookeeper服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的Watch事件通知。</strong> </p><p>Session的<code>sessionTimeout</code>值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，<strong>只要在sessionTimeout规定的时间内能够重新连接上集群中任意一台服务器，那么之前创建的会话仍然有效。</strong></p><p><strong>在为客户端创建会话之前，服务端首先会为每个客户端都分配一个sessionID。由于 sessionID 是 Zookeeper 会话的一个重要标识，许多与会话相关的运行机制都是基于这个 sessionID 的，因此，无论是哪台服务器为客户端分配的 sessionID，都务必保证全局唯一。</strong></p><p>小总结：</p><ul><li>客户端配置中有一个sessiontimeout参数，用于控制和服务器之间的连接的超时时间，当超过这个时间检测这个tcp连接还是失败的话，那么就会断开这个会话</li></ul><h3 id="znode"><a href="#znode" class="headerlink" title="znode"></a>znode</h3><p><strong>在谈到分布式的时候，我们通常说的“节点”是指组成集群的每一台机器。然而，在Zookeeper中，“节点”分为两类，第一类同样是指构成集群的机器，我们称之为机器节点；第二类则是指数据模型中的数据单元，我们称之为数据节点一一ZNode。</strong></p><p>Zookeeper将所有数据存储在内存中，数据模型是一棵树（Znode Tree)，由斜杠（/）的进行分割的路径，就是一个Znode，例如/foo/path1。每个上都会保存自己的数据内容，同时还会保存一系列属性信息。</p><p><strong>在Zookeeper中，node可以分为持久节点和临时节点两类。所谓持久节点是指一旦这个ZNode被创建了，除非主动进行ZNode的移除操作，否则这个ZNode将一直保存在Zookeeper上。而临时节点就不一样了，它的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。</strong>另外，ZooKeeper还允许用户为每个节点添加一个特殊的属性：<strong>SEQUENTIAL</strong>.一旦节点被标记上这个属性，那么在这个节点被创建的时候，Zookeeper会自动在其节点名后面追加上一个整型数字，这个整型数字是一个由父节点维护的自增数字。</p><h3 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h3><p>在前面我们已经提到，Zookeeper 的每个 ZNode 上都会存储数据，对应于每个ZNode，Zookeeper 都会为其维护一个叫作 <strong>Stat</strong> 的数据结构，Stat中记录了这个 ZNode 的三个数据版本，分别是version（当前ZNode的版本）、cversion（当前ZNode子节点的版本）和 cversion（当前ZNode的ACL版本）。</p><h3 id="watcher-监听"><a href="#watcher-监听" class="headerlink" title="watcher-监听"></a>watcher-监听</h3><p>原文：</p><blockquote><p>ZooKeeper supports the concept of <em>watches</em>. Clients can set a watch on a znodes. A watch will be triggered and removed when the znode changes. When a watch is triggered the client receives a packet saying that the znode has changed. And if the connection between the client and one of the Zoo Keeper servers is broken, the client will receive a local notification. These can be used to <em>[tbd]</em>.</p></blockquote><p><strong>Watcher（事件监听器），是Zookeeper中的一个很重要的特性。Zookeeper允许用户在指定节点上注册一些Watcher，并且在一些特定事件触发的时候，ZooKeeper服务端会将事件通知到感兴趣的客户端上去，该机制是Zookeeper实现分布式协调服务的重要特性。</strong></p><p>### </p><h3 id="ACl"><a href="#ACl" class="headerlink" title="ACl"></a>ACl</h3><p>Zookeeper采用ACL（AccessControlLists）策略来进行权限控制，类似于 UNIX 文件系统的权限控制。Zookeeper 定义了如下5种权限。</p><ul><li>create：创建子节点权限</li><li>read：获取节点数据和子节点列表的权限</li><li>write：更新节点数据的权限</li><li>delete：删除子节点权限</li><li>admin：设置节点acl权限</li></ul><p>其中尤其需要注意的是，CREATE和DELETE这两种权限都是针对子节点的权限控制。</p><p>zk的每一个znode都可以配置acl，控制谁可以访问</p><h3 id="leader和follower"><a href="#leader和follower" class="headerlink" title="leader和follower"></a>leader和follower</h3><p>所有的写请求都会被转发到leader节点上。follower节点同步主节点的数据。</p><p>zk内部保证了数据的原子性，也就是一个写入操作，在整个集群内部保证数据一致之后才认为成功</p><h3 id="节点数量"><a href="#节点数量" class="headerlink" title="节点数量"></a>节点数量</h3><p>参考链接：<a href="https://zookeeper.apache.org/doc/current/zookeeperAdmin.html" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/current/zookeeperAdmin.html</a></p><p>的<strong>Cross Machine Requirements</strong>部分</p><p>当你想允许F台主机/实例进程异常终止时，集群总数就需要是2*F+1</p><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><p>zk提供了下面这些操作接口</p><ul><li><em>create</em> : creates a node at a location in the tree</li><li><em>delete</em> : deletes a node</li><li><em>exists</em> : tests if a node exists at a location</li><li><em>get data</em> : reads the data from a node</li><li><em>set data</em> : writes data to a node</li><li><em>get children</em> : retrieves a list of children of a node</li><li><em>sync</em> : waits for data to be propagated</li></ul><p>For a more in-depth discussion on these, and how they can be used to implement higher level operations, please refer to <em>[tbd]</em></p><h2 id="zk实现"><a href="#zk实现" class="headerlink" title="zk实现"></a>zk实现</h2><p>如下图所示：</p><p><img src="https://zookeeper.apache.org/doc/r3.4.6/images/zkcomponents.jpg" alt="img"></p><p>组件讲解</p><ul><li><p>复制数据库</p><p>The replicated database is an in-memory database containing the entire data tree. Updates are logged to disk for recoverability, and writes are serialized to disk before they are applied to the in-memory database.</p><p>复制数据库是一个在内存中的数据库，它包含整个数据目录树。更新操作被记录到磁盘中以便于恢复操作，写操作在被应用到内存之前会被序列化到磁盘上。</p></li><li><p>读写请求流程</p><p>Every ZooKeeper server services clients. Clients connect to exactly one server to submit irequests. Read requests are serviced from the local replica of each server database. Requests that change the state of the service, write requests, are processed by an agreement protocol.</p><p>As part of the agreement protocol all write requests from clients are forwarded to a single server, called the <em>leader</em>. The rest of the ZooKeeper servers, called <em>followers</em>, receive message proposals from the leader and agree upon message delivery. The messaging layer takes care of replacing leaders on failures and syncing followers with leaders.</p><p>客户端会精确的连接到一个zk server上，读请求会被提供服务-从本地的复制数据库中。如果是状态变更或者是写请求，将会被一致性协议处理</p><p>作为一致性协议的一部分，来自客户端的所有写请求，都会被转发到leader节点进行，其余的zk servers，叫做followers，这些节点接收leader的协商消息并进行集群内转发。这些协商信息层控制leader节点的故障替换，然后重新进行关系建立</p><p>ZooKeeper uses a custom atomic messaging protocol. Since the messaging layer is atomic, ZooKeeper can guarantee that the local replicas never diverge. When the leader receives a write request, it calculates what the state of the system is when the write is to be applied and transforms this into a transaction that captures this new state.</p></li></ul><h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><ol><li>目标服务器新建 zookeeper 用户</li><li>拷贝线上在用的zookeeper的文件夹（路径：/home/zookeeper/2181/zookeeper），到目标服务器</li><li>新建data文件夹（路径：/home/zookeeper/2181/data）</li><li>新建myid文件（路径：/home/zookeeper/2181/data/myid），第一个节点内容为1，之后类推</li></ol><h2 id="standalone模式"><a href="#standalone模式" class="headerlink" title="standalone模式"></a>standalone模式</h2><p>执行下面步骤，运行在单实例模式：</p><p>解压缩：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># tar -zxvf  zookeeper-3.4.6.tar.gz</span><br><span class="line"># cp -rp zookeeper-3.4.6 zookeeper</span><br><span class="line"># mkdir 2181</span><br><span class="line"># mv zookeeper 2181</span><br><span class="line"># cd 2181</span><br><span class="line"># mkdir data logs</span><br></pre></td></tr></table></figure><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@node001 zookeeper]$ cd /home/zookeeper/2181/zookeeper/conf/</span><br><span class="line">[zookeeper@node001 conf]$ cp zoo_sample.cfg  zoo.cfg</span><br><span class="line">[zookeeper@node001 conf]$ grep -v &apos;#&apos; zoo.cfg</span><br><span class="line">tickTime=2000</span><br><span class="line">initLimit=10</span><br><span class="line">syncLimit=5</span><br><span class="line">dataDir=/home/zookeeper/2181/data</span><br><span class="line">clientPort=2181</span><br></pre></td></tr></table></figure><p>设置java堆内存</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@node001 bin]$ vim zkServer.sh</span><br><span class="line">搜索nohup</span><br><span class="line">将原内容：</span><br><span class="line"></span><br><span class="line">    nohup &quot;$JAVA&quot; &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \</span><br><span class="line">    -cp &quot;$CLASSPATH&quot; $JVMFLAGS $ZOOMAIN &quot;$ZOOCFG&quot; &gt; &quot;$_ZOO_DAEMON_OUT&quot; 2&gt;&amp;1 &lt; /dev/null &amp;</span><br><span class="line"></span><br><span class="line">修改为：</span><br><span class="line"></span><br><span class="line">    nohup &quot;$JAVA&quot; &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \</span><br><span class="line">    -cp &quot;$CLASSPATH&quot; $JVMFLAGS -Xmx2500M -Xms2500M $ZOOMAIN &quot;$ZOOCFG&quot; &gt; &quot;$_ZOO_DAEMON_OUT&quot; 2&gt;&amp;1 &lt; /dev/null &amp;</span><br></pre></td></tr></table></figure><p>内存大小自定义设置，可以是3G或者是2500M这种</p><p>启动zk</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@node001 zookeeper]$ pwd</span><br><span class="line">/home/zookeeper/2181/zookeeper</span><br><span class="line">[zookeeper@node001 zookeeper]$ ./bin/zkServer.sh start</span><br></pre></td></tr></table></figure><h2 id="集群模式"><a href="#集群模式" class="headerlink" title="集群模式"></a>集群模式</h2><p>上面的配置要变成下面这种：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000</span><br><span class="line">dataDir=/var/lib/zookeeper/</span><br><span class="line">clientPort=2181</span><br><span class="line">initLimit=5</span><br><span class="line">syncLimit=2</span><br><span class="line">server.1=host1:2888:3888</span><br><span class="line">server.2=host2:2888:3888</span><br><span class="line">server.3=host3:2888:3888</span><br></pre></td></tr></table></figure><p>注意：server id的取值范围是1-255</p><p>创建myid文件</p><p>myid文件的所在路径是dataDir参数指定的目录</p><h1 id="zk配置文件详解"><a href="#zk配置文件详解" class="headerlink" title="zk配置文件详解"></a>zk配置文件详解</h1><p>参考链接：<a href="https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_configuration" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_configuration</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@common001-dev.novalocal conf]$ cat zoo.cfg</span><br><span class="line"></span><br><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line"># synchronization phase can take</span><br><span class="line">initLimit=10</span><br><span class="line"># The number of ticks that can pass between</span><br><span class="line"># sending a request and getting an acknowledgement</span><br><span class="line">syncLimit=5</span><br><span class="line"># the directory where the snapshot is stored.</span><br><span class="line"># do not use /tmp for storage, /tmp here is just</span><br><span class="line"># example sakes.</span><br><span class="line">dataDir=/home/zookeeper/2181/data</span><br><span class="line"># the port at which the clients will connect</span><br><span class="line">clientPort=2181</span><br><span class="line"># the maximum number of client connections.</span><br><span class="line"># increase this if you need to handle more clients</span><br><span class="line">maxClientCnxns=0</span><br><span class="line">#</span><br><span class="line"># Be sure to read the maintenance section of the</span><br><span class="line"># administrator guide before turning on autopurge.</span><br><span class="line">#</span><br><span class="line"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span><br><span class="line">#</span><br><span class="line"># The number of snapshots to retain in dataDir</span><br><span class="line">autopurge.snapRetainCount=3</span><br><span class="line"># Purge task interval in hours</span><br><span class="line"># Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">autopurge.purgeInterval=1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">server.1=192.168.11.29:2888:3888</span><br><span class="line">server.2=192.168.11.32:2888:3888</span><br><span class="line">server.3=192.168.11.20:2888:3888</span><br></pre></td></tr></table></figure><h3 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h3><ul><li><p>tickTime </p><p>Client-Server通信心跳时间，以毫秒为单位。</p><p>它用来控制心跳和session超时，默认情况下最小的会话超时时间为两倍的 tickTime。</p></li><li><p>dataDir是存放内存数据库快照的位置；</p></li><li><p>dataLogDir 是事务日志目录；</p></li><li><p>clientPort是client连接的端口。</p></li><li><p>initLimit：</p><p>集群中的follower服务器(F)与leader服务器(L)之间初始连接时能容忍的最多心跳数（tickTime的数量）。</p><p>如果超时这个时间，节点还没有连接上leader，那么就会放弃加入集群。</p><p>参数设定了允许所有跟随者与领导者进行连接并同步的时间，如果在设定的时间段内，半数以上的跟随者未能完成同步，领导者便会宣布放弃领导地位，进行另一次的领导选举。如果zk集群环境数量确实很大，同步数据的时间会变长，因此这种情况下可以适当调大该参数。默认为10</p></li></ul><ul><li><p>syncLimit：</p><p>集群中的follower服务器与leader服务器之间请求和应答之间能容忍的最多心跳数（tickTime的数量）。</p><p>此配置表示， <em>leader</em> 与 <em>follower</em> 之间发送消息，请求 和 应答 时间长度。如果 <em>follower</em> 在设置的时间内不能与<em>leader</em> 进行通信，那么此 <em>follower</em> 将被丢弃。</p><p>参数设定了允许一个跟随者与一个领导者进行同步的时间，如果在设定的时间段内，跟随者未完成同步，它将会被集群丢弃。所有关联到这个跟随者的客户端将连接到另外一个跟随着。</p></li><li><p>autopurge.snapRetainCount这个参数指定了需要保留的文件数目，默认保留3个；</p></li><li><p>autopurge.purgeInterval这个参数指定了清理频率，单位是小时，需要填写一个1或者更大的数据，默认0表示不开启自动清理功能。</p></li></ul><h3 id="server段"><a href="#server段" class="headerlink" title="server段"></a>server段</h3><p>server.X代表组成整个服务的机器，当服务启动时，会在数据目录下查找这个文件myid,这个文件中存有服务器的号码。</p><p>配置格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server.A=B：C：D</span><br></pre></td></tr></table></figure><ul><li>A 是一个数字，表示这个是第几号服务器；</li><li>B 是这个服务器的 ip 地址；</li><li>C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；</li><li>D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。</li></ul><p>除了修改 zoo.cfg 配置文件，集群模式下还要配置一个文件 myid，这个文件在 dataDir 目录下，这个文件里面就有一个数据就是 A 的值，Zookeeper 启动时会读取这个文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是那个 server。</p><h3 id="myid配置"><a href="#myid配置" class="headerlink" title="myid配置"></a>myid配置</h3><p>在dataDir所定义的目录下新建myid文件，本例中在/home/zookeeper/2181/data下新建myid文件，填入各主机之ID。如192.168.11.29主机的myid文件内容为1。</p><h3 id="maxClientCnxns"><a href="#maxClientCnxns" class="headerlink" title="maxClientCnxns"></a>maxClientCnxns</h3><p>maxClientCnxns默认值60，这个连接数不是针对某个ip的，请注意这个限制的使用范围</p><p>指的是单台客户端机器与单台zookeeper服务器之间的连接数限制，不是针对指定客户端IP，也不是zookeeper集群的连接数限制</p><h1 id="zookeeper日志管理"><a href="#zookeeper日志管理" class="headerlink" title="zookeeper日志管理"></a>zookeeper日志管理</h1><h2 id="日志分类"><a href="#日志分类" class="headerlink" title="日志分类"></a>日志分类</h2><p>zookeeper服务器会产生三类日志：</p><ul><li>事务日志</li><li>快照日志</li><li>log4j日志。</li></ul><p>在zookeeper默认配置文件zoo.cfg（可以修改文件名）中有一个配置项dataDir，该配置项用于配置zookeeper<strong>快照日志和事务日志</strong>的存储地址。</p><p>在官方提供的默认参考配置文件zoo_sample.cfg中，只有dataDir配置项。</p><p>其实在实际应用中，还可以为事务日志专门配置存储地址，配置项名称为<strong>dataLogDir</strong>，在zoo_sample.cfg中并未体现出来。在没有dataLogDir配置项的时候，zookeeper默认将事务日志文件和快照日志文件都存储在dataDir对应的目录下。</p><p>建议将事务日志（dataLogDir）与快照日志（dataLog）单独配置，因为当zookeeper集群进行频繁的数据读写操作是，会产生大量的事务日志信息，将两类日志分开存储会提高系统性能，而且，可以允许将两类日志存在在不同的存储介质上，减少磁盘压力。</p><h2 id="log4j-运行日志"><a href="#log4j-运行日志" class="headerlink" title="log4j-运行日志"></a>log4j-运行日志</h2><p>log4j用于记录zookeeper集群服务器运行日志，该日志的配置地址在conf/目录下的log4j.properties文件中，该文件中有一个配置项为“zookeeper.log.dir=.”，表示log4j日志文件在与执行程序（<a href="http://zkserver.sh/" target="_blank" rel="noopener">zkServer.sh</a>）在同一目录下。<a href="http://xn--zkserver-fm2pi0w5y6i.sh/" target="_blank" rel="noopener">当执行zkServer.sh</a> 时，在该文件夹下会产生zookeeper.out日志文件。下面主要介绍事务日志与快照日志。</p><h2 id="事务日志"><a href="#事务日志" class="headerlink" title="事务日志"></a>事务日志</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>事务日志指zookeeper系统在正常运行过程中，针对所有的更新操作，在返回客户端“更新成功”的响应前，zookeeper会保证已经将本次更新操作的事务日志已经写到磁盘上，只有这样，整个更新操作才会生效。</p><p>根据上文所述，可以通过zoo.cfg文件中的dataLogDir配置项找到事物日志存储地点：<br>dataDir=/home/kafka/data/zookeeper<br>在datalog/目录下存在一个文件夹version-2，该文件夹中保存着事物日志文件:<br>log.504e25800<br>日志文件的命名规则为log.<strong>，文件大小为64MB，</strong>表示写入该日志的第一个事务的ID，十六进制表示。</p><h3 id="事务日志可视化"><a href="#事务日志可视化" class="headerlink" title="事务日志可视化"></a>事务日志可视化</h3><p>zookeeper的事务日志为二进制文件，不能通过vim等工具直接访问。其实可以通过zookeeper自带的jar包读取事务日志文件。<br>首先将libs中的slf4j-api-1.6.1.jar文件和zookeeper根目录下的zookeeper-3.4.8.jar文件复制到临时文件夹tmplibs中，然后执行如下命令,将日志内容输出至a.txt文件中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># java -classpath .:slf4j-api-1.6.1.jar:zookeeper-3.4.8.jar org.apache.zookeeper.server.LogFormatter /home/zookeeper/2181/data/version-2/log.2f019aaf7f &gt; a.txt</span><br></pre></td></tr></table></figure><h3 id="日志分析"><a href="#日志分析" class="headerlink" title="日志分析"></a><strong>日志分析</strong></h3><p>第一行：ZooKeeper Transactional Log File with dbid 0 txnlog format version 2</p><p>上面的代码分析中有说到每个日志文件都有一个这就是那里所说的日志头，这里magic没有输出，只输出了dbid还有version；</p><p>第二行：15-8-12 下午03时59分53秒 session 0x14f20ea71c10000 cxid 0x0 zxid 0x1 createSession 4000这也就是具体的事务日志内容了，这里是说xxx时间有一个sessionid为0x14f20ea71c10000、cxid为0x0、zxid 为0x1、类型为createSession、超时时间为4000毫秒</p><p>第三行：15-8-12 下午03时59分54秒 session 0x14f20ea71c10000 cxid 0x1 zxid 0x2 create ‘/solinx0000000000,#736f6c696e78,v{s{31,s{‘world,’anyone}}},F,1sessionID 为0x14f20ea71c10000，cxid：0x01、zxid：0x02、创建了一个节点路径为：/solinx0000000000、节点内容 为：#736f6c696e78(经过ASCII，实际内容为solinx)、acl为world:anyone任何人都可以管理该节点、节点不是 ephemeral节点的、父节点子版本：1</p><p>第四行：15-8-12 下午04时15分56秒 session 0x14f20ea71c10000 cxid 0x0 zxid 0x3 closeSession null这里是说xxx时间有一个sessionid为0x14f20ea71c10000、cxid为0x0、zxid为0x3、类型为 closeSession</p><h2 id="快照日志"><a href="#快照日志" class="headerlink" title="快照日志"></a>快照日志</h2><p>zookeeper的数据在内存中是以树形结构进行存储的，而快照就是每隔一段时间就会把整个DataTree的数据序列化后存储在磁盘中，这就是zookeeper的快照文件。</p><p>zookeeper快照日志的存储路径同样可以在zoo.cfg中查看，如上文截图所示。访问dataDir路径可以看到version-2文件夹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/home/zookeeper/2181/data</span><br></pre></td></tr></table></figure><p>zookeeper快照文件的命名规则为snapshot.<strong>，其中</strong>表示zookeeper触发快照的那个瞬间，提交的最后一个事务的ID。</p><p>与上面说的事务日志文件一样，Zookeeper也为快照文件提供了可视化的工具：org.apache.zookeeper.server包中的SnapshotFormatter类，接下来就使用该工具输出该事务日志文件，并解释该数据；</p><h3 id="SnapshotFormatter工具使用"><a href="#SnapshotFormatter工具使用" class="headerlink" title="SnapshotFormatter工具使用"></a>SnapshotFormatter工具使用</h3><p>命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># java -classpath .:slf4j-api-1.6.1.jar:zookeeper-3.4.8.jar org.apache.zookeeper.server.SnapshotFormatter /home/zookeeper/2181/data/version-2/snapshot.2f019b7bc0 |less</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">ZNode Details (count=105078):</span><br><span class="line">----</span><br><span class="line">/</span><br><span class="line">  cZxid = 0x00000000000000</span><br><span class="line">  ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">  mZxid = 0x00000000000000</span><br><span class="line">  mtime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">  pZxid = 0x00002c05e92d48</span><br><span class="line">  cversion = 71</span><br><span class="line">  dataVersion = 0</span><br><span class="line">  aclVersion = 0</span><br><span class="line">  ephemeralOwner = 0x00000000000000</span><br><span class="line">  dataLength = 0</span><br><span class="line">----</span><br><span class="line">/com</span><br><span class="line">  cZxid = 0x0000010003a93a</span><br><span class="line">  ctime = Mon Mar 06 00:26:24 CST 2017</span><br><span class="line">  mZxid = 0x0000010003a93a</span><br><span class="line">  mtime = Mon Mar 06 00:26:24 CST 2017</span><br><span class="line">  pZxid = 0x0000010003a93b</span><br><span class="line">  cversion = 1</span><br><span class="line">  dataVersion = 0</span><br><span class="line">  aclVersion = 0</span><br><span class="line">  ephemeralOwner = 0x00000000000000</span><br><span class="line">  dataLength = 0</span><br><span class="line">  </span><br><span class="line">......</span><br></pre></td></tr></table></figure><h3 id="快照分析"><a href="#快照分析" class="headerlink" title="快照分析"></a>快照分析</h3><p>快照文件就很容易看得懂了，这就是Zookeeper整个节点数据的输出；<br>第一行：ZNode Details (count=105078):ZNode节点数总共有105078个<br>/<br>cZxid = 0x00000000000000<br>ctime = Thu Jan 01 08:00:00 CST 1970<br>mZxid = 0x00000000000000<br>mtime = Thu Jan 01 08:00:00 CST 1970<br>pZxid = 0x00002c05e92d48<br>cversion = 71<br>dataVersion = 0<br>aclVersion = 0<br>ephemeralOwner = 0x00000000000000<br>dataLength = 0</p><p>这么一段数据是说：</p><p>根节点/：<br>cZxid：创建节点时的ZXID<br>ctime：创建节点的时间<br>mZxid：节点最新一次更新发生时的zxid<br>mtime：最近一次节点更新的时间<br>pZxid：父节点的zxid<br>cversion：子节点更新次数<br>dataVersion：节点数据更新次数<br>aclVersion：节点acl更新次数<br>ephemeralOwner：如果节点为ephemeral节点则该值为sessionid，否则为0<br>dataLength：该节点数据的长度<br>快照文件的末尾：<br>Session Details (sid, timeout, ephemeralCount): 0x14f211584840000, 4000, 0 0x14f211399480001, 4000, 0</p><p>这里是说当前抓取快照文件的时间Zookeeper中Session的详情，有两个session超时时间都是4000毫秒ephemeral节点为0；</p><h3 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h3><p>在zookeeper 3.4.0以后，zookeeper提供了自动清理snapshot和事务日志功能</p><p>通过配置zoo.cfg下的autopurge.snapRetainCount和autopurge.purgeInterval这两个参数实现日志文件的定时清理。</p><ul><li>autopurge.snapRetainCount这个参数指定了需要保留的文件数目，默认保留3个；</li><li>autopurge.purgeInterval这个参数指定了清理频率，单位是小时，需要填写一个1或者更大的数据，默认0表示不开启自动清理功能。</li></ul><h2 id="日志管理配置修改"><a href="#日志管理配置修改" class="headerlink" title="日志管理配置修改"></a>日志管理配置修改</h2><p><strong>注意，如果Zookeeper集群只有3个实例，那么日志修改务必先修改follower 节点的配置，再修改leader 节点的配置，否则可能会导致问题。</strong></p><h3 id="配置集群运行日志并设置切割"><a href="#配置集群运行日志并设置切割" class="headerlink" title="配置集群运行日志并设置切割"></a>配置集群运行日志并设置切割</h3><p>操作文件：log4j.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zookeeper.root.logger=INFO, ROLLINGFILE</span><br><span class="line"></span><br><span class="line">log4j.appender.ROLLINGFILE.MaxFileSize=100MB # 每个日志文件的最大size为100M</span><br><span class="line">log4j.appender.ROLLINGFILE.MaxBackupIndex=50 # 保留5个G的日志</span><br></pre></td></tr></table></figure><p>操作文件：bin/zkEnv.sh文件</p><p>将</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ]</span><br><span class="line">then</span><br><span class="line">    ZOO_LOG_DIR=&quot;.&quot;</span><br><span class="line">fi</span><br><span class="line">if [ &quot;x$&#123;ZOO_LOG4J_PROP&#125;&quot; = &quot;x&quot; ]</span><br><span class="line">then</span><br><span class="line">    ZOO_LOG4J_PROP=&quot;INFO,CONSOLE&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>修改成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ]</span><br><span class="line">then</span><br><span class="line">    ZOO_LOG_DIR=&quot;/home/zookeeper/2181/logs&quot;</span><br><span class="line">fi</span><br><span class="line">if [ &quot;x$&#123;ZOO_LOG4J_PROP&#125;&quot; = &quot;x&quot; ]</span><br><span class="line">then</span><br><span class="line">    ZOO_LOG4J_PROP=&quot;INFO,ROLLINGFILE&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>注意：log4j.properties中的zookeeper.root.logger的值需要和zkEnv.sh文件的配置ZOO_LOG4J_PROP保持一致。</p><p>去除<strong>zookeeper.out 文件</strong></p><p>操作文件：bin/zkServer.sh</p><p>注释如下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># _ZOO_DAEMON_OUT=&quot;$ZOO_LOG_DIR/zookeeper.out&quot;</span><br></pre></td></tr></table></figure><p>将如下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup &quot;$JAVA&quot; &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \</span><br><span class="line">    -cp &quot;$CLASSPATH&quot; $JVMFLAGS $ZOOMAIN &quot;$ZOOCFG&quot; &gt; &quot;$_ZOO_DAEMON_OUT&quot; 2&gt;&amp;1 &lt; /dev/null &amp;</span><br></pre></td></tr></table></figure><p>修改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup &quot;$JAVA&quot; &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \</span><br><span class="line">    -cp &quot;$CLASSPATH&quot; $JVMFLAGS $ZOOMAIN &quot;$ZOOCFG&quot; &gt;&amp;1 &lt; /dev/null &amp;</span><br></pre></td></tr></table></figure><p>然后重启zk即可</p><h3 id="事务日志-1"><a href="#事务日志-1" class="headerlink" title="事务日志"></a>事务日志</h3><p>操作文件：zoo.cfg</p><p>在zoo.cfg文件的中添加如下这行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataLogDir=/home/zookeeper/2181/data/event</span><br></pre></td></tr></table></figure><p>这部分是可选操作，默认不配置的话就会使用快照日志的配置。一般不进行额外配置</p><h3 id="快照日志-1"><a href="#快照日志-1" class="headerlink" title="快照日志"></a>快照日志</h3><p>操作文件：zoo.cfg</p><p>快照日志不需要额外的处理，默认的配置就是针对快照日志，也就是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/home/zookeeper/2181/data</span><br><span class="line">autopurge.snapRetainCount=10# 需要保留的文件数目，默认设置为3个；</span><br><span class="line">autopurge.purgeInterval=24# 清理频率，默认单位是小时</span><br></pre></td></tr></table></figure><h1 id="zk运维"><a href="#zk运维" class="headerlink" title="zk运维"></a>zk运维</h1><p>测试版本使用3.4.6</p><h2 id="zkcli使用"><a href="#zkcli使用" class="headerlink" title="zkcli使用"></a>zkcli使用</h2><p>使用方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># ./bin/zkCli.sh  -server 127.0.0.1:2181</span><br></pre></td></tr></table></figure><p>支持的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[zk: 127.0.0.1:2181(CONNECTED) 5] help</span><br><span class="line">ZooKeeper -server host:port cmd args</span><br><span class="line">stat path [watch]</span><br><span class="line">set path data [version]</span><br><span class="line">ls path [watch]</span><br><span class="line">delquota [-n|-b] path</span><br><span class="line">ls2 path [watch]</span><br><span class="line">setAcl path acl</span><br><span class="line">setquota -n|-b val path</span><br><span class="line">history</span><br><span class="line">redo cmdno</span><br><span class="line">printwatches on|off</span><br><span class="line">delete path [version]</span><br><span class="line">sync path</span><br><span class="line">listquota path</span><br><span class="line">rmr path</span><br><span class="line">get path [watch]</span><br><span class="line">create [-s] [-e] path data acl</span><br><span class="line">addauth scheme auth</span><br><span class="line">quit</span><br><span class="line">getAcl path</span><br><span class="line">close</span><br><span class="line">connect host:port</span><br></pre></td></tr></table></figure><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><h2 id="快照数据文件清理"><a href="#快照数据文件清理" class="headerlink" title="快照数据文件清理"></a>快照数据文件清理</h2><h2 id="数据备份及恢复"><a href="#数据备份及恢复" class="headerlink" title="数据备份及恢复"></a>数据备份及恢复</h2><h2 id="集群节点停机及恢复"><a href="#集群节点停机及恢复" class="headerlink" title="集群节点停机及恢复"></a>集群节点停机及恢复</h2><h2 id="内存设置"><a href="#内存设置" class="headerlink" title="内存设置"></a>内存设置</h2><h2 id="zk集群节点奇数标准"><a href="#zk集群节点奇数标准" class="headerlink" title="zk集群节点奇数标准"></a>zk集群节点奇数标准</h2><p>官方原文：</p><blockquote><p>For the ZooKeeper service to be active, there must be a majority of non-failing machines that can communicate with each other. To create a deployment that can tolerate the failure of F machines, you should count on deploying 2xF+1 machines. Thus, a deployment that consists of three machines can handle one failure, and a deployment of five machines can handle two failures. Note that a deployment of six machines can only handle two failures since three machines is not a majority. For this reason, ZooKeeper deployments are usually made up of an odd number of machines.</p></blockquote><p>也就是说：</p><blockquote><p>为了保证整体zk服务的可用。必须保证zk集群中的大多数节点是可用的，可以互相通信的。</p><p>如果需要创建一个能够容忍F节点故障的集群，那么集群总数需要是2*F+1。</p><p>因此，3节点的集群，能够容忍1个节点故障，5节点的集群能够容忍2个节点</p><p>如果是6个节点的集群，那么也只能容忍2个节点故障，因为如果是3个节点的话，不满足大于大多数的要求。因为这个原因，所以我们的zk集群设计都是按照奇数来进行。</p></blockquote><h2 id="zk监控"><a href="#zk监控" class="headerlink" title="zk监控"></a>zk监控</h2><p>官方链接：<a href="https://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_monitoring" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_monitoring</a></p><p>The ZooKeeper service can be monitored in one of two primary ways; 1) the command port through the use of <a href="https://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_zkCommands" target="_blank" rel="noopener">4 letter words</a> and 2) <a href="https://zookeeper.apache.org/doc/r3.4.6/zookeeperJMX.html" target="_blank" rel="noopener">JMX</a>. See the appropriate section for your environment/requirements.</p><p>zk集群服务的监控，可以通过两种方式来实现。</p><p>1种是4个字母的命令，第2种是JMX方式。具体选择哪一种需要看具体的环境和需求来定</p><h2 id="zk性能优化"><a href="#zk性能优化" class="headerlink" title="zk性能优化"></a>zk性能优化</h2><p>有以下这些操作可以执行</p><ul><li><p>To get low latencies on updates it is important to have a dedicated transaction log directory. By default transaction logs are put in the same directory as the data snapshots and <em>myid</em> file. The dataLogDir parameters indicates a different directory to use for the transaction logs.</p><p>为了降低更新请求的处理延迟，有一个非常重要的配置-将事务日志存储到一个指定的目录。</p><p>默认情况下，事务日志会和数据快照以及myid文件存放在一个目录中。</p><p>使用dataLogDir参数来执行事务日志的存储目录。</p></li><li><p>不要使zk使用到swap</p></li></ul><h2 id="4字命令"><a href="#4字命令" class="headerlink" title="4字命令"></a>4字命令</h2><p>参考链接：<a href="https://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_zkCommands" target="_blank" rel="noopener">https://zookeeper.apache.org/doc/r3.4.6/zookeeperAdmin.html#sc_zkCommands</a></p><p>zk提供了命令行方式去获取zk集群的状态，这个可以拿来做监控等。</p><p>使用语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@common001-dev.novalocal ~]# echo mntr | nc 127.0.0.1 2181</span><br><span class="line">zk_version3.4.8--1, built on 02/06/2016 03:18 GMT</span><br><span class="line">zk_avg_latency0</span><br><span class="line">zk_max_latency2812</span><br><span class="line">zk_min_latency0</span><br><span class="line">zk_packets_received42630860</span><br><span class="line">zk_packets_sent42878757</span><br><span class="line">zk_num_alive_connections509</span><br><span class="line">zk_outstanding_requests0</span><br><span class="line">zk_server_statefollower</span><br><span class="line">zk_znode_count108438</span><br><span class="line">zk_watch_count84655</span><br><span class="line">zk_ephemerals_count9526</span><br><span class="line">zk_approximate_data_size17629011</span><br><span class="line">zk_open_file_descriptor_count538</span><br><span class="line">zk_max_file_descriptor_count65535</span><br></pre></td></tr></table></figure><p>下面是支持的命令</p><ul><li><p>conf</p><p><strong>New in 3.3.0:</strong> Print details about serving configuration.</p><p>输出配置信息</p></li><li><p>cons</p><p><strong>New in 3.3.0:</strong> List full connection/session details for all clients connected to this server. Includes information on numbers of packets received/sent, session id, operation latencies, last operation performed, etc…</p><p>列出详细的客户端连接信息，包括ip、session id等信息。</p></li><li><p>crst</p><p><strong>New in 3.3.0:</strong> Reset connection/session statistics for all connections.</p><p>重置所有的连接统计信息，一般用不到。</p></li><li><p>dump</p><p>Lists the outstanding sessions and ephemeral nodes. This only works on the leader.</p><p>输出当前集群的所有会话信息，主要是会话id的形式，还有创建的临时节点信息。【排查问题时涉及】</p></li><li><p>envi</p><p>Print details about serving environment</p><p>输出环境变量信息</p></li><li><p>ruok</p><p>Tests if server is running in a non-error state. The server will respond with imok if it is running. Otherwise it will not respond at all.</p><p>A response of “imok” does not necessarily indicate that the server has joined the quorum, just that the server process is active and bound to the specified client port. Use “stat” for details on state wrt quorum and client connection information.</p><p>检测zk节点的存活状态【监控时需要添加】</p></li><li><p>srst</p><p>Reset server statistics.</p><p>重置统计信息</p></li><li><p>srvr</p><p><strong>New in 3.3.0:</strong> Lists full details for the server.</p><p>输出zk服务的一些信息，例如zk版本、角色、znode总数、延迟、队列数量、连接数、接收包的总数等</p></li><li><p>stat</p><p>Lists brief details for the server and connected clients.</p><p>除了上面的信息之外，还是会显示客户端连接信息（只显示ip:port，接发包）</p></li><li><p>wchs</p><p><strong>New in 3.3.0:</strong> Lists brief information on watches for the server.</p><p>获取watch的zonde总数</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">540 connections watching 5362 paths</span><br><span class="line">Total watches:17544</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>wchc</p><p><strong>New in 3.3.0:</strong> Lists detailed information on watches for the server, by session. This outputs a list of sessions(connections) with associated watches (paths). Note, depending on the number of watches this operation may be expensive (ie impact server performance), use it carefully.</p><p>输出watch的详细信息，分类字段是session ID。获取它watch的path</p><p>因为数据量可能比较大，所以在执行的时候，可能会影响性能</p></li><li><p>wchp</p><p><strong>New in 3.3.0:</strong> Lists detailed information on watches for the server, by path. This outputs a list of paths (znodes) with associated sessions. Note, depending on the number of watches this operation may be expensive (ie impact server performance), use it carefully.</p><p>和上面类似，输出watch的详细信息，只不过分类字段是path，获取某个path，有哪些session在watch它。</p><p>因为数据量可能比较大，所以在执行的时候，也可能会影响性能</p><p>mntr</p></li><li><p><strong>New in 3.4.0:</strong> Outputs a list of variables that could be used for monitoring the health of the cluster.</p><p>输出集群的汇总统计信息</p></li></ul><h2 id="事务日志可视化-1"><a href="#事务日志可视化-1" class="headerlink" title="事务日志可视化"></a>事务日志可视化</h2><p>案例：</p><p>将libs中的slf4j-api-1.7.5.jar文件和zookeeper根目录下的zookeeper.jar文件复制到临时文件夹tmplibs中，<br>然后执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># cd tmplibs</span><br><span class="line"># java -classpath .:slf4j-api-1.7.5.jar:zookeeper.jar org.apache.zookeeper.server.LogFormatter /data/hadoop/var/lib/zookeeper/version-2/log.7600180b03</span><br></pre></td></tr></table></figure><h2 id="jvm调优"><a href="#jvm调优" class="headerlink" title="jvm调优"></a>jvm调优</h2><p> 在zk的jvm相关默认参数满足需求的时候，就可以设置一下：</p><p>修改zk目录下的bin子目录下的zkServer.sh文件，搜索nohup关键词，定位到需要修改的行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">nohup &quot;$JAVA&quot; &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \</span><br><span class="line">-cp &quot;$CLASSPATH&quot; $JVMFLAGS -verbose:gc -Xloggc:/home/zookeeper/2181/logs/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps \</span><br><span class="line">-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/zookeeper/2181/logs/java.hprof -XX:+PrintAdaptiveSizePolicy \</span><br><span class="line">-server -Xms3G -Xmx3G  $ZOOMAIN &quot;$ZOOCFG&quot; &gt; &quot;$_ZOO_DAEMON_OUT&quot; 2&gt;&amp;1 &lt; /dev/null &amp;</span><br></pre></td></tr></table></figure><p>如代码框中的内容显示，我们添加打印gc日志、打印gc的AdaptiveSizePolicy自动优化调整日志，jvm大小等配置。</p><h2 id="zk的事务日志和快照以及数据恢复"><a href="#zk的事务日志和快照以及数据恢复" class="headerlink" title="zk的事务日志和快照以及数据恢复"></a>zk的事务日志和快照以及数据恢复</h2><p>数据恢复过程数据初始化工作其实就是从磁盘中加载数据的过程，主要包括了从快照文件中加载快照数据的根据事务日志进行数据订正两个过程。<br>1.初始化FileTxnSnapLog<br>FileTxnSnapLog是ZooKeeper事务日志和快照数据访问层，用于衔接上层业务与底层数据存储。底层数据包括了事务日志和快照两部分，因此FileTxnSnapLog内部氛围FileTxnLog和FileSnap的初始化，分别代表事务日志管理器和快照数据管理器的初始化。<br>2.初始化ZKDatabase<br>接下来就开始构建内存数据库ZKDatabase了。在初始化过程中，首先会构建一个初始化的DataTree，同时将步骤1中初始化的FileTxnSnapLog交给ZKDatabase，以便于内存数据库能够对事务日志和快照数据进行访问。<br>DataTree是ZooKeeper内存模型的核心模型，简而言之就是一棵树，保存了ZooKeeper上的所有节点信息，在每个ZooKeeper服务器内部都是单例。在ZKDatabase初始化的时候，DataTree也会进行相应的初始化工作——创建一些ZooKeeper的默认节点，包括/、/zookeeper、/zookeeper/quota三个节点的创建。<br>除了ZooKeeper的数据节点，在ZKDatabase的初始化阶段还会创建一个用于保存所有客户端会话超时时间的记录器：sessionsWithTimeouts——会话超时时间记录器。<br>3.创建PlayBackListener监听器<br>PlayBackListener监听器主要用来接收事务应用过程中的回调。在后面读者会看到，在ZooKeeper数据恢复后期，会有一个事务订正过程，在这个过程中会回调PlayBackListener监听器来进行对应的数据订正。<br>4.处理快照文件<br>完成内存数据库的初始化之后，ZooKeeper就开始从磁盘中恢复数据了。在上文中我们已经提到，每一个快照数据文件中都保存了ZooKeeper服务器近似全量的数据，因此首先从这些快照文件开始加载。<br>5.获取最新的100个快照文件<br>ZooKeeper服务器运行一段时间之后，磁盘上会保留许多快照文件。另外由于每次数据快照过程中，ZooKeeper都会将全量数据Dump到磁盘快照文件中，因此往往更新时间最晚的那个文件包含了最新的全量数据。那么是否我们只需要这个罪行的快照文件就可以了呢？在ZooKeeper的实现中，会获取最新的之多100个快照文件。<br>6.解析快照文件<br>获取到这之多100个文件之后，ZooKeeper会“逐个”进行解析每个快照文件都是内存数据序列化到磁盘的二进制文件，因此在这里需要对其进行反序列化，生成DataTree对象和sessionsWithTimeouts集合。同时在这个过程中，还会进行文件的checkSum校验以确认快照文件的正确性。<br>在“逐个”解析的过程中，如果正确性校验通过的话，呢么通常只会解析最新的那个快照文件。换句话说，只有当最新的快照文件不可用的时候，才会逐个进行解析，知道将这100个文件全部解析完成。如果将步骤4中获取的所有快照文件都解析完成后还是无法完成恢复一个完整的DataTree和sessionWithTimeouts，则认为无法从磁盘中加载数据，服务器启动失败。<br>7.获取罪行的ZXID<br>完成6之后，就已经基于开招文件构建了一个完整的DataTree实例和sessionsWithTimeouts集合了。此时根据这个快照文件的文件名就可以解析出一个最新的ZXID：zxid_for_snap，它代表了ZooKeeper开始进行数据快照的时刻。<br>8.处理事务日志<br>在经过前面7处理后，此时ZooKeeper服务器内存中已经有了一份近似全量的数据了，开始就要通过事务日志来更新增量数据了。<br>9.获取所有zxid_for_snap之后提交的事务<br>到这里，我们已经获取到了快照数据的最新ZXID。ZooKeeper中数据的快照机制决定了快照文件中并非包含了所有的事务操作。蛋是未被包含在快照中的那部分事务操作是可以我替你故宫 数据订正来实现的。因此这里我们只需要从事务日志中获取所有ZXID比步骤7中得到的zxid_for_snap大的事务操作。<br>10.事务应用<br>获取到所有ZXID大于zxid_for_snap的事务后，将其逐个应用到之前基于快照数据文件恢复出来的DataTree和sessionsWithTimeouts中去。在事务应用的过程中，还有一个细节需要我们注意，每当有一个事务被应用到内存数据库中，ZooKeeper同时会回调PlayBackListener监听器，将这一事务操作记录转换成Proposal，保存到ZKDatabase.committedLog中，以便Follower进行快速同步。<br>11.获取最新ZXID<br>待所有事务都被完整地应用到内存数据库中，基本上就完成了数据的初始化过程，此时再次获取一个ZXID，用来标识上次服务器正常运行时提交的最大事务ID。<br>12.校验epoch<br>epoch是ZooKeeper中一个非常特别的变量，其字面意思是“时代”，在ZooKeeper中，epoch标识了当前Leader周期。每次选举产生一个新的Leader服务器之后，就会生成一个新的cpoch。在运行期间集群中机器互相通信的过程中，都会带上这个epoch一确保彼此在同一个Leader周期内。<br>在完成数据加载后，ZooKeeper会从步骤11中确定的ZXID中解析出事务处理的Leader周期：epochOfZxid。同时会从磁盘的currentEpoch和acceptedEpoch文件中对去出上次记录的最新的epoch值，进行校验。<br>以上就是ZooKeeper服务器启动时期的数据初始化的全过程。</p><p>实际进行数据恢复的时候，操作如下：</p><ol><li>找到要恢复的快照和事务文件</li><li>传输到目标端</li><li>要恢复数据的目标端，停止zk进程，删除数据目录下的文件，复制刚才的两个文件到数据目录下。</li><li>启动zk服务</li></ol><p>注意：如果是3台及以上的zk集群的话，则需要全部停止进程，删除数据，恢复其中的一台，然后等数据恢复完成后，再启动其余的两台服务让zk自己同步数据过去</p><h2 id="zk缩容扩容"><a href="#zk缩容扩容" class="headerlink" title="zk缩容扩容"></a>zk缩容扩容</h2><h2 id="zk-avg-latency指标分析"><a href="#zk-avg-latency指标分析" class="headerlink" title="zk_avg_latency指标分析"></a>zk_avg_latency指标分析</h2><p>参考链接：<a href="https://mp.weixin.qq.com/s/j8p-953azVVHwpnebuJvbQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/j8p-953azVVHwpnebuJvbQ</a></p><p>Zookeeper服务器累计所有请求的延迟时间（totalLatency），累计总共请求次数（count），通过totalLatency/count获取avgLatency指标。至于avgLatency指标持续维持为0ms，由于totalLatency &lt;count导致。也就是多次请求Latency的延迟为0ms。</p><h1 id="zk案例-dubbo讲解"><a href="#zk案例-dubbo讲解" class="headerlink" title="zk案例-dubbo讲解"></a>zk案例-dubbo讲解</h1>]]></content>
    
    <summary type="html">
    
      zookeeper
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维架构" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="zookeeper" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/zookeeper/"/>
    
    
      <category term="zookeeper" scheme="http://yoursite.com/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>PostgreSQL安装部署及使用</title>
    <link href="http://yoursite.com/2019/03/27/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PostgreSQL%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2019/03/27/IT科学技术知识体系结构-Linux运维方向/数据库/PostgreSQL/PostgreSQL安装部署及使用/</id>
    <published>2019-03-27T14:52:37.000Z</published>
    <updated>2019-03-27T14:52:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><p>下载页面：<a href="https://www.postgresql.org/download/" target="_blank" rel="noopener">https://www.postgresql.org/download/</a></p><p>本文以安装version 11为例</p><h2 id="centos6"><a href="#centos6" class="headerlink" title="centos6"></a>centos6</h2><p>安装repo源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install https://download.postgresql.org/pub/repos/yum/11/redhat/rhel-6-x86_64/pgdg-centos11-11-2.noarch.rpm</span><br></pre></td></tr></table></figure><p>安装client</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install postgresql11</span><br></pre></td></tr></table></figure><p>安装server</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install postgresql11-server</span><br></pre></td></tr></table></figure><p>初始化数据库以及启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service postgresql-11 initdb</span><br><span class="line">chkconfig postgresql-11 on</span><br><span class="line">service postgresql-11 start</span><br></pre></td></tr></table></figure><h2 id="centos7"><a href="#centos7" class="headerlink" title="centos7"></a>centos7</h2><p>安装repo源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install https://download.postgresql.org/pub/repos/yum/11/redhat/rhel-7-x86_64/pgdg-centos11-11-2.noarch.rpm</span><br></pre></td></tr></table></figure><p>安装client</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install postgresql11</span><br></pre></td></tr></table></figure><p>安装server</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install postgresql11-server</span><br></pre></td></tr></table></figure><p>初始化数据库以及启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/pgsql-11/bin/postgresql-11-setup initdb</span><br><span class="line">systemctl enable postgresql-11</span><br><span class="line">systemctl start postgresql-11</span><br></pre></td></tr></table></figure><p>在启动之后，默认监控的端口是127.0.0.1:5432</p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>在初次安装后，默认生成一个名为<code>postgres</code>的数据库和一个名为<code>postgres</code>的数据库用户。这里需要注意的是，同时还生成了一个名为<code>postgres</code>的Linux系统用户。<br>有两种方式为PostgreSQL添加用户和添加数据库</p><h2 id="设置登录密码"><a href="#设置登录密码" class="headerlink" title="设置登录密码"></a>设置登录密码</h2><p>在启动之后，默认是没有密码的，因此我们首先要创建密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node010-dev data]# su - postgres</span><br><span class="line">-bash-4.2$ psql</span><br><span class="line">psql (11.2)</span><br><span class="line">输入 &quot;help&quot; 来获取帮助信息.</span><br><span class="line">postgres=# \password postgres</span><br></pre></td></tr></table></figure><p>注意，这里虽然设置了，但是不允许直接登录，需要进行一下设置</p><h3 id="配置监听ip"><a href="#配置监听ip" class="headerlink" title="配置监听ip"></a>配置监听ip</h3><p>编辑<code>/var/lib/pgsql/11/data/postgresql.conf</code> 文件</p><p>将<code>#listen_addresses = &#39;localhost&#39;</code>修改为<code>listen_addresses=&#39;*&#39;</code> （当然，此处‘*’也可以改为任何你想开放的服务器IP）</p><h3 id="配置允许登录"><a href="#配置允许登录" class="headerlink" title="配置允许登录"></a>配置允许登录</h3><p>默认情况下PostgreSQL不支持密码登录，在登录的时候会有如下报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node010-dev data]# psql -U postgres</span><br><span class="line">psql: 致命错误:  对用户&quot;postgres&quot;的对等认证失败</span><br></pre></td></tr></table></figure><p>如需支持需要修改配置文件</p><p>编辑该文件，将未注释的peer都替换成为md5</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># vim /var/lib/pgsql/11/data/pg_hba.conf</span><br></pre></td></tr></table></figure><p>重启服务之后即可正常登录数据库</p><h3 id="配置允许远程登录"><a href="#配置允许远程登录" class="headerlink" title="配置允许远程登录"></a>配置允许远程登录</h3><p>在进行了上面的配置之后，是可以进行本地端的登录的，但是在远端使用连接命令，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># psql -U devuser -d registry -h 192.168.1.196 -p 5432</span><br></pre></td></tr></table></figure><p>会产生报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">psql: 致命错误:  没有用于主机 &quot;192.168.1.219&quot;, 用户 &quot;devuser&quot;, 数据库 &quot;registry&quot;, SSL 关闭 的 pg_hba.conf 记录</span><br></pre></td></tr></table></figure><p>解决：在server端的pg_hba.conf文件末尾添加以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># TYPE DATABASE USER CIDR-ADDRESS METHOD</span><br><span class="line">host    all             all              0.0.0.0/0              md5</span><br><span class="line"></span><br><span class="line">全网段换成指定的网段也可以</span><br></pre></td></tr></table></figure><p>然后重启服务即可。</p><h1 id="数据库使用"><a href="#数据库使用" class="headerlink" title="数据库使用"></a>数据库使用</h1><p>数据库使用首先需要psql -U postgres进入数据后再执行</p><h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><p>创建用户并设置密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE USER dbuser WITH PASSWORD &apos;password&apos;;</span><br><span class="line">例如：</span><br><span class="line">postgres=# create user devuser with password &apos;Devuser123&apos;;</span><br><span class="line">postgres=# create user prouser with password &apos;Prouser123&apos;;</span><br></pre></td></tr></table></figure><p>注意：如果只设置了数据库用户，那么在系统的shell登录的时候需要使用-U指定登录用户，如果还在系统中useradd了同名用户，那么可以切换到这个同名用户然后执行psql即可。</p><h2 id="创建数据库及授权"><a href="#创建数据库及授权" class="headerlink" title="创建数据库及授权"></a>创建数据库及授权</h2><p>创建数据库并指定用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE exampledb OWNER dbuser;</span><br><span class="line">例如：</span><br><span class="line">postgres=# create database  registry owner devuser;</span><br><span class="line">postgres=# create database  registry owner prouser;</span><br></pre></td></tr></table></figure><p>进行用户授权，将指定数据库的所有权限都赋予dbuser，否则dbuser只能登录控制台，没有任何数据库操作权限。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GRANT ALL PRIVILEGES ON DATABASE exampledb to dbuser;</span><br><span class="line">例如：</span><br><span class="line">postgres=# grant all privileges on database registry to devuser;</span><br><span class="line">postgres=# grant all privileges on database registry to prouser;</span><br></pre></td></tr></table></figure><h2 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DROP DATABASE chado</span><br><span class="line">删除名为 chado 的数据库</span><br></pre></td></tr></table></figure><h2 id="登录数据库"><a href="#登录数据库" class="headerlink" title="登录数据库"></a>登录数据库</h2><p>添加了新用户和新数据库后，以新用户的身份登陆数据库。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">psql -U dbuser -d exampledb -h 127.0.0.1 -p 5432</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>psql命令存在简写形式，如果当前的Linux系统用户存在于postgreSQL中，则可以省略用户名，不需要使用-U参数，只需要其他参数。</li><li>PostgreSQL内部还存在与当前系统用户同名的数据库，则连数据库名都可以省略。</li></ul><h2 id="数据导入导出"><a href="#数据导入导出" class="headerlink" title="数据导入导出"></a>数据导入导出</h2><h3 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h3><p>完整的语法格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pg_dump --host hostname --port port --username username -t tablename -d dbname &gt;/home/jihite/table.sql</span><br></pre></td></tr></table></figure><p>一般情况下，我们的命令会是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pg_dump  -U devuser  registry &gt; registry.sql </span><br><span class="line"></span><br><span class="line">pg_dump  -U prouser  registry &gt; registry.sql</span><br></pre></td></tr></table></figure><h3 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h3><p>完整的语法格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">psql -h host_ip -p 5432 -d dbname -U postgres -W postgres -f 2.sql</span><br></pre></td></tr></table></figure><p>一般情况下，我们的命令会是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">psql exampledb &lt; exampledb.sql</span><br><span class="line"></span><br><span class="line">psql  -d  registry  -f  registry.sql  devuser</span><br><span class="line">psql  -d  registry  -f  registry.sql  prouser</span><br></pre></td></tr></table></figure><p>create user prouser with password ‘Prouser123’;</p><h1 id="postgreSQL命令"><a href="#postgreSQL命令" class="headerlink" title="postgreSQL命令"></a>postgreSQL命令</h1><p>pg常用命令：</p><ul><li>\h：查看SQL命令的详细解释，例如 \h select</li><li>?：查看psql命令列表</li><li>\l：列出所有数据库</li><li>\c [database_name]：连接其他数据库</li><li>\d 或者\dt：列出数据库的所有表</li><li>\du：列出所有数据库用户</li><li>\conninfo：列出连接</li><li><p>查看表的所有数据：select * from table_name;</p></li><li><p>查看数据库数据量（占用存储空间）情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select pg_size_pretty(pg_database_size(&apos;registry&apos;));</span><br></pre></td></tr></table></figure></li><li><p>查看表的数据量大小(注意，首先需要\c切换数据库下再执行)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select pg_size_pretty(pg_relation_size(&apos;test&apos;));</span><br><span class="line">or</span><br><span class="line">select pg_size_pretty(pg_table_size(&apos;test&apos;));</span><br></pre></td></tr></table></figure></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">registry=# \dt</span><br><span class="line">                    List of relations</span><br><span class="line"> Schema |             Name              | Type  |  Owner</span><br><span class="line">--------+-------------------------------+-------+---------</span><br><span class="line"> public | access                        | table | prouser</span><br><span class="line"> public | access_log                    | table | prouser</span><br><span class="line"> public | admin_job                     | table | prouser</span><br><span class="line"> public | alembic_version               | table | prouser</span><br><span class="line"> public | clair_vuln_timestamp          | table | prouser</span><br><span class="line"> public | harbor_label                  | table | prouser</span><br><span class="line"> public | harbor_resource_label         | table | prouser</span><br><span class="line"> public | harbor_user                   | table | prouser</span><br><span class="line"> public | img_scan_job                  | table | prouser</span><br><span class="line"> public | img_scan_overview             | table | prouser</span><br><span class="line"> public | job_log                       | table | prouser</span><br><span class="line"> public | project                       | table | prouser</span><br><span class="line"> public | project_member                | table | prouser</span><br><span class="line"> public | project_metadata              | table | prouser</span><br><span class="line"> public | properties                    | table | prouser</span><br><span class="line"> public | replication_immediate_trigger | table | prouser</span><br><span class="line"> public | replication_job               | table | prouser</span><br><span class="line"> public | replication_policy            | table | prouser</span><br><span class="line"> public | replication_target            | table | prouser</span><br><span class="line"> public | repository                    | table | prouser</span><br><span class="line"> public | role                          | table | prouser</span><br><span class="line"> public | schema_migrations             | table | prouser</span><br><span class="line"> public | user_group                    | table | prouser</span><br><span class="line">(23 rows)</span><br></pre></td></tr></table></figure><h1 id="pg免密操作"><a href="#pg免密操作" class="headerlink" title="pg免密操作"></a>pg免密操作</h1><p>参考链接：<a href="http://www.oradbca.com/529.html?imrgvm=a1ndo2" target="_blank" rel="noopener">http://www.oradbca.com/529.html?imrgvm=a1ndo2</a></p><p>在远程备份或者登录时总要手工输入密码，导致效率很低。</p><p>postgresql可以通过密码文件来实现”无钥验证“。</p><p>在用户的根目录下，需要创建一个.pgpass文件，并将权限设置为0600，就可以实现了。</p><p>文件的格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostname:port:database:username:password</span><br></pre></td></tr></table></figure><p><strong>演示：</strong></p><p><strong>1.psql登入</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[postgres@oradbca ~]$ cd</span><br><span class="line">[postgres@oradbca ~]$ touch .pgpass</span><br><span class="line">[postgres@oradbca ~]$ vi .pgpass </span><br><span class="line">192.168.1.11:5432:postgres:postgres:postgres</span><br><span class="line">[postgres@oradbca ~]$ chmod 600 .pgpass </span><br><span class="line">[postgres@oradbca ~]$ psql -h 192.168.1.11 -p 5432 -d postgres -U postgres</span><br><span class="line">psql (9.3.4)</span><br><span class="line">Type &quot;help&quot; for help.</span><br><span class="line"></span><br><span class="line">postgres=#</span><br></pre></td></tr></table></figure><p><strong>2.pg_dump备份</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pg_dump -d postgres -h 192.168.1.11 -p 5532 -U postgres &gt;back.dmp</span><br></pre></td></tr></table></figure><p><strong>3.pg_basebackup同步</strong></p><p>在使用pg_basebackup时需要在.pgpass中增加一行 <strong>replication</strong>类型的</p><p>192.168.1.11:5432:replication:repuser:repuser</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[postgres@oradbca ~]$ pg_basebackup -D /u01/pgdata -Fp -Xs -v -P -h 192.168.1.11 -p 5432 -U repuser</span><br><span class="line">transaction log start point: 0/1A000028 on timeline 1</span><br><span class="line">pg_basebackup: starting background WAL receiver</span><br><span class="line">37929/37929 kB (100%), 2/2 tablespaces                                         </span><br><span class="line">transaction log end point: 0/1A0000F0</span><br><span class="line">pg_basebackup: waiting for background process to finish streaming ...</span><br><span class="line">pg_basebackup: base backup completed</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      PostgreSQL安装部署及使用
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="数据库" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="PostgreSQL" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/"/>
    
    
      <category term="PostgreSQL" scheme="http://yoursite.com/tags/PostgreSQL/"/>
    
  </entry>
  
  <entry>
    <title>NFS网络存储</title>
    <link href="http://yoursite.com/2019/03/25/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/NFS/NFS%E7%BD%91%E7%BB%9C%E5%AD%98%E5%82%A8/"/>
    <id>http://yoursite.com/2019/03/25/IT科学技术知识体系结构-Linux运维方向/网络知识及网络服务/网络服务/NFS/NFS网络存储/</id>
    <published>2019-03-25T08:35:33.000Z</published>
    <updated>2019-03-25T08:35:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>NFS（Network File System）即<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/9719420" target="_blank" rel="noopener">网络文件系统</a>，是FreeBSD支持的文件系统中的一种，它允许网络中的计算机之间通过TCP/IP网络共享资源。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样。</p><p><code>NFS</code>与<code>Samba</code>服务类似，但一般<code>Samba</code>服务常用于办公局域网共享，而<code>NFS</code>常用于互联网中小型网站集群架构后端的数据共享。</p><p><code>NFS</code>客户端将<code>NFS</code>服务端设置好的共享目录挂载到本地某个挂载点，对于客户端来说，共享的资源就相当于在本地的目录下。</p><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p><code>NFS</code>在传输数据时使用的端口是随机选择的，依赖<code>RPC</code>服务来与外部通信，要想正常使用<code>NFS</code>,就必须保证<code>RPC</code>正常。</p><h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><p><code>RPC</code>（<em>Remote Procedure Call Protocol</em>）远程过程调用协议。它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。<br> 在<code>NFS</code>服务端和<code>NFS</code>客户端之间，<code>RPC</code>服务扮演一个中介角色，<code>NFS</code>客户端通过<code>RPC</code>服务得知<code>NFS</code>服务端使用的端口，从而双方可以进行数据通信。</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>当<code>NFS</code>服务端启动服务时会随机取用若干端口，并主动向<code>RPC</code>服务注册取用相关端口及功能信息，这样，<code>RPC</code>服务就知道<code>NFS</code>每个端口对应的的<code>NFS</code>功能了，然后<code>RPC</code>服务使用固定的111端口来监听<code>NFS</code>客户端提交的请求，并将正确的<code>NFS</code>端口信息回复给请求的<code>NFS</code>客户端。这样，<code>NFS</code>客户就可以与<code>NFS</code>服务端进行数据传输了。</p><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><h2 id="服务端部署"><a href="#服务端部署" class="headerlink" title="服务端部署"></a>服务端部署</h2><h3 id="安装nfs-与-rpc-相关软件包"><a href="#安装nfs-与-rpc-相关软件包" class="headerlink" title="安装nfs 与 rpc 相关软件包"></a>安装nfs 与 rpc 相关软件包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum -y install nfs-utils rpcbind</span><br></pre></td></tr></table></figure><p>注意：在centos7下其实只需要安装nfs-utils即可，因为rpcbind 属于它的依赖，yum会自动安装上。</p><p>根据官网说明 <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/ch-nfs" target="_blank" rel="noopener">Chapter 8. Network File System (NFS) - Red Hat Customer Portal</a>，CentOS 7.4 以后，支持 NFS v4.2 不需要 rpcbind 了，但是如果客户端只支持 NFC v3 则需要 rpcbind 这个服务。</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h4><p>NFS默认的配置文件是 ：/etc/exports </p><p><strong>配置格式为：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NFS共享目录绝对路径    NFS客户端1地址范围（参数）NFS客户端2地址范围（参数）.....</span><br><span class="line"></span><br><span class="line">注意：客户端IP范围配置中，* 代表所有，即没有限制。</span><br></pre></td></tr></table></figure><p><strong>常用参数：</strong></p><ul><li>rw             read-write   读写</li><li>ro             read-only    只读</li><li>sync           请求或写入数据时，数据同步写入到NFS server的硬盘后才返回。数据安全，但性能降低了</li><li>async          优先将数据保存到内存，硬盘有空档时再写入硬盘，效率更高，但可能造成数据丢失。</li><li>root_squash    当NFS 客户端使用root 用户访问时，映射为NFS 服务端的匿名用户。NFS为了安全考虑，默认会将root账户降权为普通匿名账户。所以，如果不进行配置的话，这个将会是默认值</li><li>no_root_squash 当NFS 客户端使用root 用户访问时，映射为NFS 服务端的root 用户</li><li>all_squash     不论NFS 客户端使用任何帐户，均映射为NFS 服务端的匿名用户</li></ul><h4 id="配置案例"><a href="#配置案例" class="headerlink" title="配置案例"></a>配置案例</h4><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># vim  /etc/exports</span><br><span class="line">/sharedir 192.168.0.0/16(rw,sync,root_squash)</span><br></pre></td></tr></table></figure><p>创建共享目录以及测试文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /sharedir</span><br><span class="line">touch /sharedir/Welcom.file</span><br><span class="line">echo &quot;Welcome to onlylink.top&quot; &gt;/sharedir/Welcom.file</span><br></pre></td></tr></table></figure><p>给共享目录添加权限：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown -R nfsnobody.nfsnobody /sharedir/</span><br></pre></td></tr></table></figure><p>把NFS共享目录赋予 NFS默认用户nfsnobody用户和用户组权限，如不设置，会导致NFS客户端无法在挂载好的共享目录中写入数据</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>启动 rpc服务并设置成开机自启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># /etc/init.d/rpcbind start</span><br><span class="line"># chkconfig rpcbind on</span><br></pre></td></tr></table></figure><p>启动 nfs服务并设置成开机自启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># /etc/init.d/nfs start</span><br><span class="line"># chkconfig nfs on</span><br></pre></td></tr></table></figure><p>在centos 7下的操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># systemctl enable rpcbind</span><br><span class="line"># systemctl enable nfs</span><br><span class="line"></span><br><span class="line"># systemctl start rpcbind</span><br><span class="line"># systemctl start nfs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">如果开启了防火墙，还需要进行设置</span><br><span class="line"># firewall-cmd --zone=public --permanent --add-service=rpc-bind</span><br><span class="line">success</span><br><span class="line"># firewall-cmd --zone=public --permanent --add-service=mountd</span><br><span class="line">success</span><br><span class="line"># firewall-cmd --zone=public --permanent --add-service=nfs</span><br><span class="line">success</span><br><span class="line"># firewall-cmd --reload</span><br><span class="line">success</span><br></pre></td></tr></table></figure><h2 id="客户端部署"><a href="#客户端部署" class="headerlink" title="客户端部署"></a>客户端部署</h2><h3 id="安装nfs-与-rpc-相关软件包-1"><a href="#安装nfs-与-rpc-相关软件包-1" class="headerlink" title="安装nfs 与 rpc 相关软件包"></a>安装nfs 与 rpc 相关软件包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum -y install nfs-utils rpcbind</span><br></pre></td></tr></table></figure><p>注意：在centos7下其实只需要安装nfs-utils即可，因为rpcbind 属于它的依赖，yum会自动安装上。</p><h3 id="配置启动"><a href="#配置启动" class="headerlink" title="配置启动"></a>配置启动</h3><p>设置 rpcbind 服务的开机启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#  systemctl enable rpcbind</span><br></pre></td></tr></table></figure><p>启动 NFS 服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#  systemctl start rpcbind</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>客户端不需要打开防火墙，因为客户端时发出请求方，网络能连接到服务端即可。 </li><li>客户端也不需要开启 NFS 服务，因为不共享目录。</li></ul><h2 id="客户端挂载服务端"><a href="#客户端挂载服务端" class="headerlink" title="客户端挂载服务端"></a>客户端挂载服务端</h2><p>客户端连接服务端其实就是正常的挂载操作，只不过对象从本地变成了远端</p><p>先查服务端的共享目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># showmount -e 192.168.0.101</span><br><span class="line">Export list for 192.168.0.101:</span><br><span class="line">/data 192.168.0.0/24</span><br></pre></td></tr></table></figure><p>在客户端创建目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># mkdir /data</span><br></pre></td></tr></table></figure><p>挂载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># mount -t nfs 192.168.0.101:/data /data</span><br></pre></td></tr></table></figure><p>当然，可以写到fstab中，设置为开机自启动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/fstab</span><br><span class="line">在文件末尾添加一下内容</span><br><span class="line"></span><br><span class="line">192.168.0.101:/data /data nfs defaults 0 0</span><br></pre></td></tr></table></figure><h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><ul><li><p>showmount -e 服务器的IP地址        #查看服务端的的共享配置</p></li><li><p>mount  -t nfs IP地址:/目录   /目录             # 挂载</p><p>例如：mount 192.168.4.5:/common  /common</p></li><li><p>exportfs</p><ul><li>-a：表示全部挂载或者全部卸载</li><li>-r：表示重新挂载</li><li>-u：表示卸载某一个目录</li><li>-v：表示显示共享目录</li></ul></li></ul><h1 id="其他配置案例"><a href="#其他配置案例" class="headerlink" title="其他配置案例"></a>其他配置案例</h1><h2 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h2><p>共享/common目录，192.168.0.0网络的主机均可以只读访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#vim  /etc/exports</span><br><span class="line"></span><br><span class="line">/common 192.168.0.0/24(ro)</span><br></pre></td></tr></table></figure><h2 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h2><p>192.168.0.1可以读写的方式访问/abc,<br>192.168.0.2可以只读的方式访问/abc</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/abc    192.168.0.1(rw) 192.168.0.2(ro)</span><br></pre></td></tr></table></figure><h2 id="案例3"><a href="#案例3" class="headerlink" title="案例3"></a>案例3</h2><p>任何人均可以只读的形式访问/dvd</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/dvd    *(ro)</span><br></pre></td></tr></table></figure><h2 id="案例4-root权限管理"><a href="#案例4-root权限管理" class="headerlink" title="案例4-root权限管理"></a>案例4-root权限管理</h2><p>客户端使用root登录系统，访问服务器的NFS，则会以root身份访问NFS共享，<br>如果客户端系统使用tom登录，访问服务器的NFS，则会以tom身份访问NFS共享。</p><p>实现客户端可读写的方式：</p><ol><li>修改目录本身的权限（exports已经设置好了rw）</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod  777  目录名称 </span><br><span class="line">或者其他值，但是需要读写</span><br></pre></td></tr></table></figure><ol><li>仅让root可以写，则需要修改exports,让NFS不对root进行降权</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#vim  /etc/exports</span><br><span class="line">/abc*(rw,no_root_squash)</span><br><span class="line"></span><br><span class="line">#service nfs  restart</span><br></pre></td></tr></table></figure><p>客户端使用root登录系统后，cd到NFS共享目录，则可以获得root权限</p><h2 id="案例5-触发挂载"><a href="#案例5-触发挂载" class="headerlink" title="案例5-触发挂载"></a>案例5-触发挂载</h2><p>在客户端实现触发挂载NFS服务器共享的/usr/src目录到本地/data/nfsdir</p><ol><li><p>安装软件包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># rpm -q autofs</span><br><span class="line"># yum -y install autofs</span><br></pre></td></tr></table></figure></li></ol><ol><li><p>修改主配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># grep mnt /etc/auto.master </span><br><span class="line">/data/etc/auto.data</span><br><span class="line"></span><br><span class="line"># cat /etc/auto.data</span><br><span class="line">nfsdir2-fstype=nfs,rw192.168.10.10:/usr/src</span><br></pre></td></tr></table></figure></li><li><p>启动服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># service autofs restart</span><br><span class="line"># chkconfig autofs on</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      NFS网络存储
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="网络知识及网络服务" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="网络服务" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="NFS" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/NFS/"/>
    
    
      <category term="NFS网络存储" scheme="http://yoursite.com/tags/NFS%E7%BD%91%E7%BB%9C%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>Centos6的iptables及Centos7的firewalld配置</title>
    <link href="http://yoursite.com/2019/03/15/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/%E9%98%B2%E7%81%AB%E5%A2%99/Centos7%E7%9A%84firewalld%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2019/03/15/IT科学技术知识体系结构-Linux运维方向/运维安全/防火墙/Centos7的firewalld配置/</id>
    <published>2019-03-15T03:11:00.000Z</published>
    <updated>2019-03-15T03:11:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Centos6的iptables配置"><a href="#Centos6的iptables配置" class="headerlink" title="Centos6的iptables配置"></a>Centos6的iptables配置</h1><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><h2 id="案例-SNAT配置"><a href="#案例-SNAT配置" class="headerlink" title="案例-SNAT配置"></a>案例-SNAT配置</h2><p>假如在NAT机器上，想要将192.168.1.0/24网段的数据包的源地址修改为公网的ip58.20.51.66，通过网卡eth1送出，可以：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth1 -j SNAT --to-source 58.20.51.66</span><br></pre></td></tr></table></figure><h1 id="Centos7的firewalld配置"><a href="#Centos7的firewalld配置" class="headerlink" title="Centos7的firewalld配置"></a>Centos7的firewalld配置</h1><p>参考文献：</p><ul><li><a href="https://linux.cn/article-8098-1.html" target="_blank" rel="noopener">CentOS 上的 FirewallD 简明指南</a></li></ul><h2 id="基础知识-1"><a href="#基础知识-1" class="headerlink" title="基础知识"></a>基础知识</h2><p><a href="http://www.firewalld.org/" target="_blank" rel="noopener">FirewallD</a> 是 iptables 的前端控制器，用于实现持久的网络流量规则。它提供命令行和图形界面，在大多数 Linux 发行版的仓库中都有。与直接控制 iptables 相比，使用 FirewallD 有两个主要区别：</p><ol><li>FirewallD 使用区域和服务而不是链式规则。</li><li>它动态管理规则集，允许更新规则而不破坏现有会话和连接。</li></ol><p>注意：FirewallD 是 iptables 的一个封装，可以让你更容易地管理 iptables 规则 - 它并<em>不是</em> iptables 的替代品。虽然 iptables 命令仍可用于 FirewallD，但建议使用 FirewallD 时仅使用 FirewallD 命令。</p><h2 id="启停查看相关命令"><a href="#启停查看相关命令" class="headerlink" title="启停查看相关命令"></a>启停查看相关命令</h2><p>1、 启动服务，并在系统引导时启动该服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start firewalld</span><br><span class="line">sudo systemctl enable firewalld</span><br></pre></td></tr></table></figure><p>要停止并禁用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop firewalld</span><br><span class="line">sudo systemctl disable firewalld</span><br></pre></td></tr></table></figure><p>2、 检查防火墙状态。输出应该是 <code>running</code> 或者 <code>not running</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --state</span><br></pre></td></tr></table></figure><p>3、 要查看 FirewallD 守护进程的状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status firewalld</span><br></pre></td></tr></table></figure><p>示例输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewalld.service - firewalld - dynamic firewall daemon   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled)   Active: active (running) since Wed 2015-09-02 18:03:22 UTC; 1min 12s ago Main PID: 11954 (firewalld)   CGroup: /system.slice/firewalld.service   └─11954 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid</span><br></pre></td></tr></table></figure><p>4、 重新加载 FirewallD 配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><h2 id="配置firewalld"><a href="#配置firewalld" class="headerlink" title="配置firewalld"></a>配置firewalld</h2><p>FirewallD 使用 XML 进行配置。除非是非常特殊的配置，你不必处理它们，而应该使用 <code>firewall-cmd</code>。</p><p>配置文件位于两个目录中：</p><ul><li><code>/usr/lib/FirewallD</code> 下保存默认配置，如默认区域和公用服务。 避免修改它们，因为每次 firewall 软件包更新时都会覆盖这些文件。</li><li><code>/etc/firewalld</code> 下保存系统配置文件。 这些文件将覆盖默认配置。</li></ul><h3 id="配置集"><a href="#配置集" class="headerlink" title="配置集"></a>配置集</h3><p>FirewallD 使用两个<em>配置集</em>：“运行时”和“持久”。 在系统重新启动或重新启动 FirewallD 时，不会保留运行时的配置更改，而对持久配置集的更改不会应用于正在运行的系统。</p><p><strong>小总结：</strong>2种配置方式，当前的实时生效和永久生效，实时是直接写入到内存中，永久是写入到配置文件当中</p><p>默认情况下，<code>firewall-cmd</code> 命令适用于运行时配置，但使用 <code>--permanent</code> 标志将保存到持久配置中。要添加和激活持久性规则，你可以使用两种方法之一。</p><p>1、 将规则同时添加到持久规则集和运行时规则集中。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-service=http --permanentsudo firewall-cmd --zone=public --add-service=http</span><br></pre></td></tr></table></figure><p>2、 将规则添加到持久规则集中并重新加载 FirewallD。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-service=http --permanentsudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><p><strong>特别注意</strong>：<code>reload</code> 命令会删除所有运行时配置并应用永久配置。因为 firewalld 动态管理规则集，所以它不会破坏现有的连接和会话。</p><h3 id="防火墙的区域"><a href="#防火墙的区域" class="headerlink" title="防火墙的区域"></a>防火墙的区域</h3><p>“区域”是针对给定位置或场景（例如家庭、公共、受信任等）可能具有的各种信任级别的预构建规则集。不同的区域允许不同的网络服务和入站流量类型，而拒绝其他任何流量。 首次启用 FirewallD 后，<code>public</code> 将是默认区域。</p><p>区域也可以用于不同的网络接口。例如，要分离内部网络和互联网的接口，你可以在 <code>internal</code> 区域上允许 DHCP，但在<code>external</code> 区域仅允许 HTTP 和 SSH。未明确设置为特定区域的任何接口将添加到默认区域。</p><p>要找到默认区域： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-default-zone</span><br></pre></td></tr></table></figure><p>要修改默认区域：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --set-default-zone=internal</span><br></pre></td></tr></table></figure><p>要查看你网络接口使用的区域：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-active-zones</span><br></pre></td></tr></table></figure><p>示例输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public  interfaces: eth0</span><br></pre></td></tr></table></figure><p>要得到特定区域的所有配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --list-all</span><br></pre></td></tr></table></figure><p>示例输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public (default, active)  interfaces: ens160  sources:  services: dhcpv6-client http ssh  ports: 12345/tcp  masquerade: no  forward-ports:  icmp-blocks:  rich rules:</span><br></pre></td></tr></table></figure><p>要得到所有区域的配置： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --list-all-zones</span><br></pre></td></tr></table></figure><p>示例输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">block  interfaces:  sources:  services:  ports:  masquerade: no  forward-ports:  icmp-blocks:  rich rules:  ...work  interfaces:  sources:  services: dhcpv6-client ipp-client ssh  ports:  masquerade: no  forward-ports:  icmp-blocks:  rich rules:</span><br></pre></td></tr></table></figure><h3 id="与服务一起使用"><a href="#与服务一起使用" class="headerlink" title="与服务一起使用"></a>与服务一起使用</h3><p>FirewallD 可以根据特定网络服务的预定义规则来允许相关流量。你可以创建自己的自定义系统规则，并将它们添加到任何区域。 默认支持的服务的配置文件位于 <code>/usr/lib /firewalld/services</code>，用户创建的服务文件在 <code>/etc/firewalld/services</code> 中。</p><p>要查看默认的可用服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-services</span><br></pre></td></tr></table></figure><p>比如，要启用或禁用 HTTP 服务： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-service=http --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --remove-service=http --permanent</span><br></pre></td></tr></table></figure><h3 id="与端口一起使用"><a href="#与端口一起使用" class="headerlink" title="与端口一起使用"></a>与端口一起使用</h3><p>比如：允许或者禁用 12345 端口的 TCP 流量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-port=12345/tcp --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --remove-port=12345/tcp --permanent</span><br></pre></td></tr></table></figure><h3 id="端口转发"><a href="#端口转发" class="headerlink" title="端口转发"></a>端口转发</h3><p>下面是在同一台服务器上将 80 端口的流量转发到 12345 端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=&quot;public&quot; --add-forward-port=port=80:proto=tcp:toport=12345</span><br></pre></td></tr></table></figure><p>要将端口转发到另外一台服务器上：</p><p>1、 在需要的区域中激活 masquerade。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-masquerade</span><br></pre></td></tr></table></figure><p>2、 添加转发规则。例子中是将本地的 80 端口的流量转发到 IP 地址为 ：123.456.78.9 的<em>远程服务器上的</em>  8080 端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=&quot;public&quot; --add-forward-port=port=80:proto=tcp:toport=8080:toaddr=123.456.78.9</span><br></pre></td></tr></table></figure><p>要删除规则，用 <code>--remove</code> 替换 <code>--add</code>。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --remove-masquerade</span><br></pre></td></tr></table></figure><h3 id="用-FirewallD-构建规则集"><a href="#用-FirewallD-构建规则集" class="headerlink" title="用 FirewallD 构建规则集"></a>用 FirewallD 构建规则集</h3><p>例如，以下是如何使用 FirewallD 为你的服务器配置基本规则（如果您正在运行 web 服务器）。</p><ol><li>将 <code>eth0</code> 的默认区域设置为 <code>dmz</code>。 在所提供的默认区域中，dmz（非军事区）是最适合于这个程序的，因为它只允许 SSH 和 ICMP。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --set-default-zone=dmzsudo firewall-cmd --zone=dmz --add-interface=eth0</span><br></pre></td></tr></table></figure><p>2、 把 HTTP 和 HTTPS 添加永久的服务规则到 dmz 区域中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=dmz --add-service=http --permanentsudo firewall-cmd --zone=dmz --add-service=https --permanent</span><br></pre></td></tr></table></figure><p> 3、 重新加载 FirewallD 让规则立即生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><p> 如果你运行 <code>firewall-cmd --zone=dmz --list-all</code>， 会有下面的输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dmz (default)  interfaces: eth0  sources:  services: http https ssh  ports:  masquerade: no  forward-ports:  icmp-blocks:  rich rules:</span><br></pre></td></tr></table></figure><p> 这告诉我们，<code>dmz</code> 区域是我们的默认区域，它被用于 <code>eth0</code> 接口中所有网络的源地址和端口。 允许传入 HTTP（端口 80）、HTTPS（端口 443）和 SSH（端口 22）的流量，并且由于没有 IP 版本控制的限制，这些适用于 IPv4 和 IPv6。 不允许IP 伪装以及端口转发。 我们没有 ICMP 块，所以 ICMP 流量是完全允许的。没有丰富Rich规则，允许所有出站流量。</p><h2 id="高级配置"><a href="#高级配置" class="headerlink" title="高级配置"></a>高级配置</h2><p>服务和端口适用于基本配置，但对于高级情景可能会限制较多。 Rich规则和Direct接口允许你为任何端口、协议、地址和操作向任何区域 添加完全自定义的防火墙规则。</p><h3 id="rich规则"><a href="#rich规则" class="headerlink" title="rich规则"></a>rich规则</h3><p>rich规则的语法有很多，但都完整地记录在 <a href="https://jpopelka.fedorapeople.org/firewalld/doc/firewalld.richlanguage.html" target="_blank" rel="noopener">firewalld.richlanguage(5)</a> 的手册页中（或在终端中 <code>man firewalld.richlanguage</code>）。 使用 <code>--add-rich-rule</code>、<code>--list-rich-rules</code> 、 <code>--remove-rich-rule</code> 和 firewall-cmd 命令来管理它们。</p><p>这里有一些常见的例子：</p><p>允许来自主机 192.168.0.14 的所有 IPv4 流量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=192.168.0.14 accept&apos;</span><br></pre></td></tr></table></figure><p>拒绝来自主机 192.168.1.10 到 22 端口的 IPv4 的 TCP 流量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=&quot;192.168.1.10&quot; port port=22 protocol=tcp reject&apos;</span><br></pre></td></tr></table></figure><p>允许来自主机 10.1.0.3 到 80 端口的 IPv4 的 TCP 流量，并将流量转发到 6532 端口上。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-rich-rule &apos;rule family=ipv4 source address=10.1.0.3 forward-port port=80 protocol=tcp to-port=6532&apos;</span><br></pre></td></tr></table></figure><p>将主机 172.31.4.2 上 80 端口的 IPv4 流量转发到 8080 端口（需要在区域上激活 masquerade）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-rich-rule &apos;rule family=ipv4 forward-port port=80 protocol=tcp to-port=8080 to-addr=172.31.4.2&apos;</span><br></pre></td></tr></table></figure><p>列出你目前的丰富规则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --list-rich-rules</span><br></pre></td></tr></table></figure><h2 id="实例案例"><a href="#实例案例" class="headerlink" title="实例案例"></a>实例案例</h2><p>IDC机房机器，有以下需求：</p><ul><li>ssh只允许内网网段访问，拒绝所有其他网段</li><li>开放指定的端口（8080、9000）给所有网段</li></ul><p>注意，因为使用的是public这个zone，所有在配置都配置完成之后，需要将默认的ssh服务remove掉</p><p>具体的命令如下：</p><ul><li>添加内网网段</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">即时生效</span><br><span class="line"></span><br><span class="line"># firewall-cmd   --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=172.24.0.0/16 accept&apos;</span><br><span class="line"></span><br><span class="line">#firewall-cmd   --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=10.11.0.0/16 accept&apos;</span><br><span class="line"></span><br><span class="line">#firewall-cmd   --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=10.11.10.0/24 accept&apos;</span><br><span class="line"></span><br><span class="line">永久生效</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=172.24.0.0/16 accept&apos;</span><br><span class="line"></span><br><span class="line">#firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=10.11.0.0/16 accept&apos;</span><br><span class="line"></span><br><span class="line">#firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=10.10.10.0/24 accept&apos;</span><br></pre></td></tr></table></figure><ul><li>开放指定端口</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">即时生效</span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=60.191.68.43 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=60.191.68.43 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=183.129.221.128/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=183.129.221.128/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=122.224.251.144/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=122.224.251.144/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">永久生效</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=60.191.68.43 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=60.191.68.43 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=183.129.221.128/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=183.129.221.128/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=122.224.251.144/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=122.224.251.144/29 port port=9000 protocol=tcp accept&apos;</span><br></pre></td></tr></table></figure><ul><li>删除ssh服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># firewall-cmd --zone=public --remove-service=ssh </span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --remove-service=ssh --permanent</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=443 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=443 protocol=tcp accept&apos;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Centos6的iptables及Centos7的firewalld配置
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维安全" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/"/>
    
      <category term="防火墙" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/%E9%98%B2%E7%81%AB%E5%A2%99/"/>
    
    
      <category term="firewalld" scheme="http://yoursite.com/tags/firewalld/"/>
    
  </entry>
  
  <entry>
    <title>centos升级openssh</title>
    <link href="http://yoursite.com/2019/02/19/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/centos%E5%8D%87%E7%BA%A7openssh/"/>
    <id>http://yoursite.com/2019/02/19/IT科学技术知识体系结构-Linux运维方向/Linux系统管理/centos升级openssh/</id>
    <published>2019-02-19T02:04:55.000Z</published>
    <updated>2019-02-19T02:04:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>主要对象分为2个版本，一个是centos6.8，一个是centos7.3和7.4.</p><h1 id="升级原因"><a href="#升级原因" class="headerlink" title="升级原因"></a>升级原因</h1><p>7.4以下openssh版本存在严重漏洞：</p><p>1.OpenSSH 远程权限提升漏洞(CVE-2016-10010)<br>2.OpenSSH J-PAKE授权问题漏洞(CVE-2010-4478)<br>3.Openssh MaxAuthTries限制绕过漏洞(CVE-2015-5600)<br>OpenSSL&gt;=1.0.1可以不用升级OpenSSL</p><h1 id="当前版本"><a href="#当前版本" class="headerlink" title="当前版本"></a>当前版本</h1><p><strong>6.8</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@app018-dev.novalocal ~]# cat /etc/redhat-release</span><br><span class="line">CentOS release 6.8 (Final)</span><br><span class="line">[root@app018-dev.novalocal ~]# rpm -qa | grep openssh</span><br><span class="line">openssh-clients-5.3p1-118.1.el6_8.x86_64</span><br><span class="line">openssh-5.3p1-118.1.el6_8.x86_64</span><br><span class="line">openssh-server-5.3p1-118.1.el6_8.x86_64</span><br></pre></td></tr></table></figure><p><strong>7</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">de</span><br></pre></td></tr></table></figure><p>可以看到，当前的版本是：</p><ul><li>centos6.8：5.3p1</li><li>centos7：7.4p1</li></ul><h1 id="目标版本"><a href="#目标版本" class="headerlink" title="目标版本"></a>目标版本</h1><p>要求的目标版本是7.5及以上</p><p>在当前时间节点（2019年02月19日10:09:56），最高版本为：<a href="https://www.openssh.com/txt/release-7.9" target="_blank" rel="noopener">OpenSSH 7.9</a>/<a href="https://www.openssh.com/txt/release-7.9" target="_blank" rel="noopener">7.9p1</a> (2018-10-19)</p><p>在这里，我们选择升级到最新版本</p><p>整个的升级操作是server和client都要升级</p><h1 id="实际操作"><a href="#实际操作" class="headerlink" title="实际操作"></a>实际操作</h1><h2 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum -y install gcc pam-devel zlib-devel openssl openssl-devel wget telnet-server* telnet</span><br></pre></td></tr></table></figure><h2 id="安装及配置telnet"><a href="#安装及配置telnet" class="headerlink" title="安装及配置telnet"></a>安装及配置telnet</h2><p><strong>安装</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum -y install telnet-server* telnet</span><br></pre></td></tr></table></figure><p><strong>配置</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># vi /etc/xinetd.d/telnet </span><br><span class="line">将其中disable字段的yes改为no以启用telnet服务 </span><br><span class="line"></span><br><span class="line"># mv /etc/securetty /etc/securetty.old    #允许root用户通过telnet登录 </span><br><span class="line"></span><br><span class="line"># service xinetd start                    #启动telnet服务 </span><br><span class="line"></span><br><span class="line"># chkconfig xinetd on                    #使telnet服务开机启动，避免升级过程中服务器意外重启后无法远程登录系统</span><br></pre></td></tr></table></figure><p>在centos7下的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># mv /etc/securetty /etc/securetty.old </span><br><span class="line"></span><br><span class="line"># systemctl start telnet.socket</span><br><span class="line"></span><br><span class="line"># systemctl enable telnet.socket</span><br></pre></td></tr></table></figure><p><strong>测试</strong></p><p>测试telnet能否正常登入系统</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@common001-dev.novalocal ~]# telnet 192.168.11.27</span><br></pre></td></tr></table></figure><h2 id="安装ssh"><a href="#安装ssh" class="headerlink" title="安装ssh"></a>安装ssh</h2><p><strong>下载软件包</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># wget https://cdn.openbsd.org/pub/OpenBSD/OpenSSH/portable/openssh-7.9p1.tar.gz</span><br></pre></td></tr></table></figure><p><strong>解压安装</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># tar zxvf openssh-7.4p1.tar.gz</span><br><span class="line"># cd openssh-7.4p1</span><br><span class="line"># ./configure</span><br><span class="line"># make</span><br><span class="line"># make install</span><br></pre></td></tr></table></figure><p>我们使用默认的安装，不加指定路径，在安装完毕之后sshd将会安装到/usr/local/sbin/下。而ssh、ssh-keygen等都会安装到/usr/local/bin目录下。</p><p>而操作系统的PATH路径是优先选择/usr/local/的，所以普通命令都可以使用到最新的，但是server端的sshd我们还需要做额外的配置</p><p><strong>修改sshd启动脚本</strong></p><p>将sshd启动脚本中的sshd命令路径修改为指定版本的路径：</p><p>centos6下就一个启动脚本文件的内容需要替换</p><ul><li>/etc/init.d/sshd</li></ul><p>#  vim /etc/init.d/sshd</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">将</span><br><span class="line">KEYGEN=/usr/bin/ssh-keygen</span><br><span class="line">SSHD=/usr/sbin/sshd</span><br><span class="line"></span><br><span class="line">修改成为：</span><br><span class="line">KEYGEN=/usr/local/bin/ssh-keygen</span><br><span class="line">SSHD=/usr/local/sbin/sshd</span><br></pre></td></tr></table></figure><p>centos7下有一下几个文件的内容需要替换</p><ul><li>/usr/lib/systemd/system/sshd-keygen.service</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">将</span><br><span class="line">ExecStart=/usr/sbin/sshd-keygen</span><br><span class="line"></span><br><span class="line">替换为：</span><br><span class="line">ExecStart=/usr/local/bin/sshd-keygen</span><br></pre></td></tr></table></figure><ul><li>/usr/lib/systemd/system/sshd.service</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">将</span><br><span class="line">ExecStart=/usr/sbin/sshd $OPTIONS</span><br><span class="line"></span><br><span class="line">替换为：</span><br><span class="line">ExecStart=/usr/local/sbin/sshd $OPTIONS</span><br></pre></td></tr></table></figure><ul><li>/usr/lib/systemd/system/sshd@.service</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">将</span><br><span class="line">ExecStart=-/usr/sbin/sshd -i $OPTIONS</span><br><span class="line"></span><br><span class="line">替换为：</span><br><span class="line">ExecStart=-/usr/local/sbin/sshd -i $OPTIONS</span><br></pre></td></tr></table></figure><h2 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h2><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><h2 id="防火墙问题"><a href="#防火墙问题" class="headerlink" title="防火墙问题"></a>防火墙问题</h2><p>有防火墙的要添加一条23端口的记录</p>]]></content>
    
    <summary type="html">
    
      centos升级openssh
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux系统管理" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"/>
    
    
      <category term="centos升级openssh" scheme="http://yoursite.com/tags/centos%E5%8D%87%E7%BA%A7openssh/"/>
    
  </entry>
  
  <entry>
    <title>redis集群</title>
    <link href="http://yoursite.com/2019/02/16/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E9%9B%86%E7%BE%A4/redis%E9%9B%86%E7%BE%A4/"/>
    <id>http://yoursite.com/2019/02/16/IT科学技术知识体系结构-Linux运维方向/数据库/Redis/Redis集群/redis集群/</id>
    <published>2019-02-16T03:20:59.000Z</published>
    <updated>2019-02-16T03:20:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="数据分布"><a href="#数据分布" class="headerlink" title="数据分布"></a>数据分布</h2><p>常见的数据分布方式有：哈希分区和顺序分区。Redis集群使用的是哈希分析，因此这里主要关注哈希分区。</p><p>Hash（哈希）也叫散列，指的是一类特征，也就是把任意长度的<a href="https://baike.baidu.com/item/%E8%BE%93%E5%85%A5/5481954" target="_blank" rel="noopener">输入</a>（又叫做预映射pre-image）通过散列算法变换成固定长度的<a href="https://baike.baidu.com/item/%E8%BE%93%E5%87%BA/11056752" target="_blank" rel="noopener">输出</a>，该输出就是散列值或者叫hash值。</p><p>因此只要是符合这个特征的方式（因为会存在很多不同的算法实现）都可以叫做哈希方式。</p><p>常见的哈希分区主要有以下几种（Redis集群使用的是第三种）：</p><ul><li><p>节点取余。使用特定的值，例如Redis的key名称或者指定id，然后根据节点数量计算出哈希值（hash(key)%N）。但是这种方式在节点数量变化时，映射关系会变化，会涉及到数据牵引。</p></li><li><p>一致性哈希。可以参考这篇文章：<a href="https://www.jianshu.com/p/e8fb89bb3a61" target="_blank" rel="noopener">https://www.jianshu.com/p/e8fb89bb3a61</a></p></li><li>虚拟槽分区（优化后的一致性哈希）。在一个哈希环之后，定义出16364个节点，然后将这些物理的节点动态的分配给集群节点，让每一个节点负责一定数量的slot。在数据写入的时候，hash（key）–&gt;[0,16383]，实际的计算公式为：slot=CRC16(key)&amp;16383。<ul><li>一个slot实际上一个物理的存储节点，由于这些slot是不会发生变化的（在默认的一致性哈希中数量会发生变化，由此会对数据产生影响），所有也就保证了集群数据的可靠性和平衡性。</li></ul></li></ul><p>Redis集群使用虚拟槽分区的特点：</p><ul><li>解耦数据和节点之间的关系，简化了扩容和缩容的难度。因此实际存储的slot数量是不变的，变化的只是分配关系。</li><li>每一个集群节点本身去维护节点和slot的映射关系，不需要客户端或者代理服务去维护这个映射关系。</li><li>支持集群节点、slot、key等之间的映射关系查询，通过获取这些信息，可以用于数据路由、在线伸缩等场景。</li></ul><p>Redis集群中的每一个节点会分配若干个slot。</p><p>作为分布式解决方案，需要为每一个集群节点定义一个固定的id，也就是上面说的哈希值，外层哈希计算之后然后进行分布式的存储。</p><h2 id="集群功能的限制"><a href="#集群功能的限制" class="headerlink" title="集群功能的限制"></a>集群功能的限制</h2><p>Redis集群相对于单实例模式，在功能上会有一些限制</p><ul><li>不支持链式复制。也就是从节点只能复制主节点，不能复制从节点。</li><li>key的批量操作，只支持在同一个slot中的key。</li><li>key的事务操作，只支持在同一个slot中，当多个key分布在不同槽时无法使用事务功能。</li><li>只支持db0</li></ul><h1 id="集群创建"><a href="#集群创建" class="headerlink" title="集群创建"></a>集群创建</h1><p>集群的创建过程也比较简单，只需要3个步骤：</p><ol><li>准备节点</li><li>节点握手，组成集群</li><li>为每个节点分配slot槽</li><li>创建主从关系</li></ol><h2 id="集群节点创建"><a href="#集群节点创建" class="headerlink" title="集群节点创建"></a>集群节点创建</h2><p>在配置文件中开启：cluster-enabled yes即可让节点运行在集群模式之下。</p><p>建议为所有的集群节点规划统一的配置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@common007-dev.novalocal conf]# cat redis-cluster-6379.conf # 以下只显示部分核心的配置</span><br><span class="line">daemonize yes</span><br><span class="line">dir &quot;/home/cachecloud/data&quot;</span><br><span class="line">port 6379</span><br><span class="line">protected-mode no</span><br><span class="line">bind 0.0.0.0</span><br><span class="line"></span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-node-timeout 15000</span><br><span class="line">cluster-config-file &quot;nodes-6379.conf&quot;</span><br></pre></td></tr></table></figure><h3 id="关于集群配置文件"><a href="#关于集群配置文件" class="headerlink" title="关于集群配置文件"></a>关于集群配置文件</h3><p>集群模式的Redis除了原有的配置文件之外，又加了一份集群配置文件。当集群内节点信息发生变化，例如添加节点、节点下线、故障转移等时，节点会自动保存这些信息到集群配置文件。</p><p>需要注意的是：</p><ul><li><p>Redis实例会自动维护集群配置文件，不要手动修改。防止节点重启时产生集群信息错乱。</p></li><li><p>集群配置文件会存储在指定的dir路径下。也就是说和aof、rdb等数据文件再同一个路径下。</p></li></ul><h2 id="集群节点握手"><a href="#集群节点握手" class="headerlink" title="集群节点握手"></a>集群节点握手</h2><p>节点握手是指一批运行在集群模式下的节点通过gossip协议彼此通信，感知对方的过程。</p><p>使用命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; cluster meet 127.0.0.1 6380</span><br></pre></td></tr></table></figure><p>注意：我们只需要在其中一个节点执行cluster meet命令即可，握手状态会通过消息在集群内进行传播，最终所有的节点都会发现其他节点并发起握手流程。最后我们执行cluster nodes命令去查看验证效果即可。</p><p>所有集群节点都握手建立连接之后，此时集群处于下线状态。</p><h2 id="为集群节点分配slot"><a href="#为集群节点分配slot" class="headerlink" title="为集群节点分配slot"></a>为集群节点分配slot</h2><p>Redis集群把所有数据都映射到16384个slot当中，每个key都会映射到一个固定的slot当中，只有当节点分配了slot，才能响应和这些slot关联的key命令。</p><p>因为在交互模式下，不能批量的输入slot的范围，因此使用这种非交互的方式进行添加slot </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[cachecloud@common007-dev.novalocal logs]$ redis-cli  -p 7000 CLUSTER ADDSLOTS &#123;0..16383&#125;</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h2 id="集群的从节点"><a href="#集群的从节点" class="headerlink" title="集群的从节点"></a>集群的从节点</h2><p>可以看到，和sentinel等方式不一样，节点的主从关系我们没有在配置文件当中使用slaveof进行指定，在当前状态下，每一个集群的节点都是master。</p><p>一般情况下我们会对半，一半为master，一半为slave，因此在上面分配slot时，如果节点总数为6，那么将16384个slot进行三等分，分配之后，还剩下3个节点时为空，这个时候，我们执行以下命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6380&gt; cluster replicate 集群node的id</span><br></pre></td></tr></table></figure><h2 id="redis-trib-rb方式创建"><a href="#redis-trib-rb方式创建" class="headerlink" title="redis-trib.rb方式创建"></a>redis-trib.rb方式创建</h2><p>使用这种方式首先需要解决ruby的相关问题，默认使用yum安装的版本太低，无法正确安装Redis</p><p>ruby的官方网站为：<a href="http://www.rvm.io/" target="_blank" rel="noopener">http://www.rvm.io/</a></p><p>整个的操作过程为：</p><p>第1步：解决ruby问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB</span><br><span class="line"></span><br><span class="line">下载rvm</span><br><span class="line"># curl -sSL https://get.rvm.io | bash -s stable</span><br><span class="line"></span><br><span class="line">查找配置文件</span><br><span class="line"># find / -name rvm.sh</span><br><span class="line"></span><br><span class="line">配置文件生效</span><br><span class="line"># source /etc/profile.d/rvm.sh </span><br><span class="line"></span><br><span class="line">下载rvm依赖</span><br><span class="line"># rvm requirements </span><br><span class="line"></span><br><span class="line">查看rvm库ruby版本</span><br><span class="line"># rvm list known</span><br><span class="line"></span><br><span class="line">安装ruby指定版本</span><br><span class="line"># rvm install ruby-2.4.1</span><br><span class="line"></span><br><span class="line">使用ruby版本默认</span><br><span class="line"># rvm use 2.4.1 default</span><br><span class="line"></span><br><span class="line">安装Redis</span><br><span class="line"># gem install redis</span><br></pre></td></tr></table></figure><p>可能还需要：yum install -y rubygems</p><p>第2步：启动集群节点</p><p>第3步：创建Redis集群</p><p>接下来我们创建Redis集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">使用 --replicas 1 创建 每个master带一个 slave 指令</span><br><span class="line"># ./redis-trib.rb create --replicas 1   192.168.11.84:7000 192.168.11.84:7001 192.168.11.84:7002 192.168.11.11:7000 192.168.11.11:7001 192.168.11.11:7002</span><br></pre></td></tr></table></figure><p>如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[cachecloud@common007-dev.novalocal src]$ ./redis-trib.rb create --replicas 1   192.168.11.84:7000 192.168.11.84:7001 192.168.11.84:7002 192.168.11.11:7000 192.168.11.11:7001 192.168.11.11:7002</span><br><span class="line">&gt;&gt;&gt; Creating cluster</span><br><span class="line">&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...</span><br><span class="line">Using 3 masters:</span><br><span class="line">192.168.11.84:7000</span><br><span class="line">192.168.11.11:7000</span><br><span class="line">192.168.11.84:7001</span><br><span class="line">Adding replica 192.168.11.11:7001 to 192.168.11.84:7000</span><br><span class="line">Adding replica 192.168.11.84:7002 to 192.168.11.11:7000</span><br><span class="line">Adding replica 192.168.11.11:7002 to 192.168.11.84:7001</span><br><span class="line">M: 2fcb0a92c0b055e9e0c0ec7a279a1c33e400b92c 192.168.11.84:7000</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">M: 94d79d6303e6de4745ec4f1dd61d51d61f73919e 192.168.11.84:7001</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">S: 1c6db7f5c2998db943cb26bf9716d13a367034b9 192.168.11.84:7002</span><br><span class="line">   replicates 1073c42cefa1e192ff219e554c843cbdc1eabd80</span><br><span class="line">M: 1073c42cefa1e192ff219e554c843cbdc1eabd80 192.168.11.11:7000</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">S: 8c911465ef9118912ab848f6a9e5790027b0d4fa 192.168.11.11:7001</span><br><span class="line">   replicates 2fcb0a92c0b055e9e0c0ec7a279a1c33e400b92c</span><br><span class="line">S: 39f885d55462cd7fc4e975317da9db19abcc1835 192.168.11.11:7002</span><br><span class="line">   replicates 94d79d6303e6de4745ec4f1dd61d51d61f73919e</span><br><span class="line">Can I set the above configuration? (type &apos;yes&apos; to accept): yes</span><br><span class="line">&gt;&gt;&gt; Nodes configuration updated</span><br><span class="line">&gt;&gt;&gt; Assign a different config epoch to each node</span><br><span class="line">&gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster</span><br><span class="line">Waiting for the cluster to join....</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 192.168.11.84:7000)</span><br><span class="line">M: 2fcb0a92c0b055e9e0c0ec7a279a1c33e400b92c 192.168.11.84:7000</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 8c911465ef9118912ab848f6a9e5790027b0d4fa 192.168.11.11:7001</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 2fcb0a92c0b055e9e0c0ec7a279a1c33e400b92c</span><br><span class="line">M: 94d79d6303e6de4745ec4f1dd61d51d61f73919e 192.168.11.84:7001</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 1073c42cefa1e192ff219e554c843cbdc1eabd80 192.168.11.11:7000</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 1c6db7f5c2998db943cb26bf9716d13a367034b9 192.168.11.84:7002</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 1073c42cefa1e192ff219e554c843cbdc1eabd80</span><br><span class="line">S: 39f885d55462cd7fc4e975317da9db19abcc1835 192.168.11.11:7002</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 94d79d6303e6de4745ec4f1dd61d51d61f73919e</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p>192.168.11.84:7000:2048<br>192.168.11.11:7001:2048<br>192.168.11.11:7000:2048<br>192.168.11.84:7002:2048<br>192.168.11.84:7001:2048<br>192.168.11.11:7002:2048</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./redis-trib.rb create --replicas 1  10.11.4.1:6526 10.11.4.2:6526 10.11.4.3:6526 10.11.4.4:6526 10.11.4.5:6526 10.11.4.6:6526</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> ./redis-trib.rb create --replicas 1  10.11.4.1:6527 10.11.4.2:6527 10.11.4.3:6527 10.11.4.4:6527 10.11.4.5:6527 10.11.4.6:6527</span><br><span class="line"> </span><br><span class="line">  ./redis-trib.rb create --replicas 1  10.11.4.1:6528 10.11.4.2:6528 10.11.4.3:6528 10.11.4.4:6528 10.11.4.5:6528 10.11.4.6:6528</span><br><span class="line">  </span><br><span class="line">   ./redis-trib.rb create --replicas 1  10.11.4.1:6529 10.11.4.2:6529 10.11.4.3:6529 10.11.4.4:6529 10.11.4.5:6529 10.11.4.6:6529</span><br></pre></td></tr></table></figure><p>10.11.4.1:6526:8192</p><p>10.11.4.4:6526:8192</p><p>10.11.4.2:6526:8192</p><p>10.11.4.5:6526:8192</p><p>10.11.4.3:6526:8192</p><p>10.11.4.6:6526:8192</p><p>10.11.4.1:6529:8192<br>10.11.4.4:6529:8192<br>10.11.4.2:6529:8192<br>10.11.4.5:6529:8192<br>10.11.4.3:6529:8192<br>10.11.4.6:6529:8192</p><h1 id="集群运维"><a href="#集群运维" class="headerlink" title="集群运维"></a>集群运维</h1><h2 id="集群伸缩"><a href="#集群伸缩" class="headerlink" title="集群伸缩"></a>集群伸缩</h2><p>Redis集群可以实现对节点的灵活上下线控制，其中的原理可以抽象为槽和对应数据在不同节点之间的灵活移动。</p><p>也就是：<font color="red"><strong>集群伸缩=slot槽和数据在节点之间的移动</strong></font></p><h2 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h2><p>整个集群的扩容操作可以分为以下步骤：</p><ol><li>启动新节点</li><li>加入现有集群</li><li>迁移slot和数据</li></ol><h3 id="新集群节点创建"><a href="#新集群节点创建" class="headerlink" title="新集群节点创建"></a>新集群节点创建</h3><p>和之前的配置一样，在配置文件中设置cluster-enabled为yes，然后启动即可。</p><h3 id="加入现有集群"><a href="#加入现有集群" class="headerlink" title="加入现有集群"></a>加入现有集群</h3><p>其实也就是一个meet操作</p><p>在随便一个集群节点当中执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; cluster meet ip port</span><br></pre></td></tr></table></figure><p>即可将该节点加入现有集群当中，注意，这里应该是加入了2个节点（另一个后续会作为从节点）</p><p>1. 152</p><p>multi-message-gw-service</p><p>rider-station-base-service</p><p>221</p><p>red-packet-unit-service</p><p>105</p><p>rider-elastic-probe</p><p>153</p><p>rich-unit-service</p><p>220 </p><p>order-rule-unit-service</p><p>candidate-select-service</p><p>dispatch-alg-config</p><p>dispatch-bywaydegree-provider</p><p>dispatch-config-dispatch-mode</p><p>dispatch-consistent-service</p><p>dispatch-fairy-provider</p><p>dispatch-pathplan-rider</p><p>dispatch-pathplan-service</p><p>dispatch-revise-params</p><p>dispatch-timer-task</p><p>grab-order-service</p><p>lbs-provider</p><p>lbs-rider-position-service</p><p>lbs-rider-space-service</p><p>order-diagnose-service</p><p>package-order-service</p><p>parameter-service</p><p>recommend-config-provider</p><p>rider-gateway-current-limit</p><p>rider-invert-select</p><p>system-dispatch</p><p>/usr/bin/nohup /usr/local/jdk/bin/java -Dproject.name=${name} -Dlogging.file.path=”/home/${start_user}/deploy/logs/${name}” -Dmonitor.file.path=”/home/${start_user}/deploy/logs/monitor” -Daction.file.path=”/home/${start_user}/deploy/logs/action/“ -Dbigdata.file.path=”/home/${start_user}/deploy/logs/bigdata/“ -Ddisconf.env=${disconf_env} -Ddisconf.enable.remote.conf=true -Ddisconf.conf_server_host=${disconf_url} &lt;#if zone??  &amp;&amp; zone != “”&gt; -Dspring.cloud.config.label=${region}.${zone} -Dspring.cloud.config.index=${region}.${zone} -Dzone=${zone} &lt;/#if&gt; &lt;#if region??  &amp;&amp; region != “”&gt; -Dregion=${region} &lt;/#if&gt; &lt;#if service_chain??&gt; -javaagent:/home/${start_user}/deploy/tools/service-chain-1.0-RELEASE.jar -Xbootclasspath/a:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -javaagent:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -Dservice-chain=${service_chain} &lt;/#if&gt; -Dlogging.console.level=off -server &lt;#if config_prefix == “production”&gt; -Xmx4g -Xms4g &lt;#else&gt; -Xms${xms}m -Xmx${xmx}m &lt;/#if&gt;  -XX:NewRatio=1 -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+CMSScavengeBeforeRemark -XX:+ParallelRefProcEnabled -XX:+CMSParallelInitialMarkEnabled -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+ExplicitGCInvokesConcurrent -XX:+AlwaysPreTouch -server -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=”/home/${start_user}/deploy/logs/${name}/“ -XX:-UseBiasedLocking -XX:AutoBoxCacheMax=20000 -XX:+UseCondCardMark -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -XX:+PrintJNIGCStalls -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -XX:+PrintPromotionFailure -XX:+PrintCommandLineFlags -XX:-OmitStackTraceInFastThrow -Xloggc:/dev/shm/${name}-gc.log -XX:ErrorFile=/home/${start_user}/deploy/logs/${name}/hs<em>err</em>%p.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=2 -XX:GCLogFileSize=20M -Djava.security.egd=file:/dev/./urandom -Dlog4j.shutdownHookEnabled=false -jar ${name}.jar –spring.profiles.active=${config_prefix} &gt; &lt;#if config_prefix == “production” || config_prefix == “dwd-pre”&gt; /dev/null &lt;#else&gt; /home/${start_user}/deploy/logs/${name}/${name}-start.log &lt;/#if&gt; 2&gt;&amp;1 &amp;</p><p>-server -Xmx4g -Xms4g -XX:NewRatio=1 -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+CMSScavengeBeforeRemark -XX:+ParallelRefProcEnabled -XX:+CMSParallelInitialMarkEnabled -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+ExplicitGCInvokesConcurrent -XX:+AlwaysPreTouch -server -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=”/home/appdeploy/deploy/logs/scan-order-service/“ -XX:-UseBiasedLocking -XX:AutoBoxCacheMax=20000 -XX:+UseCondCardMark -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -XX:+PrintJNIGCStalls -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -XX:+PrintPromotionFailure -XX:+PrintCommandLineFlags -XX:-OmitStackTraceInFastThrow -Xloggc:/dev/shm/scan-order-service-gc.log -XX:ErrorFile=/home/appdeploy/deploy/logs/scan-order-service/hs<em>err</em>%p.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=2 -XX:GCLogFileSize=20M -Djava.security.egd=file:/dev/./urandom -Dlog4j.shutdownHookEnabled=false -jar scan-order-service.jar –spring.profiles.active=production &gt; /dev/null 2&gt;&amp;1 &amp;</p><p>上海的多活环境，jvm内存1.5G。<br>没问题的话，下面这个模板就作为你们所有应用部署上海机房的默认启动脚本了，有问题跟我说下。</p><p>#!/bin/bash<br>mkdir -p /home/${start_user}/deploy/logs/${name}<br>cd /home/${start_user}/deploy/apps/${name}<br>/usr/bin/nohup /usr/local/jdk/bin/java -Dproject.name=${name} -verbose:gc -Xloggc:/home/${start_user}/deploy/logs/${name}/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/${start_user}/deploy/logs/${name}/java.hprof -XX:ErrorFile=/home/${start_user}/deploy/logs/${name}/java_error.log -Dlogging.file.path=”/home/${start_user}/deploy/logs/${name}” &lt;#if zone??  &amp;&amp; zone != “”&gt; -Dspring.cloud.config.label=${region}.${zone} -Dspring.application.index=${region}.${zone} -Dlogging.console.level=off -Dzone=${zone} &lt;/#if&gt; &lt;#if region??  &amp;&amp; region != “”&gt; -Dregion=${region} &lt;/#if&gt; &lt;#if service_chain??&gt; -javaagent:/home/${start_user}/deploy/tools/service-chain-1.0-RELEASE.jar -Xbootclasspath/a:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -javaagent:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -Dservice-chain=${service_chain} &lt;/#if&gt; -Dmonitor.file.path=/home/${start_user}/deploy/logs/monitor -Daction.file.path=/home/${start_user}/deploy/logs/action/ -Dbigdata.file.path=/home/${start_user}/deploy/logs/bigdata/ -Ddisconf.env=${disconf_env} -Ddisconf.enable.remote.conf=true -Ddisconf.conf_server_host=${disconf_url} -server -Xms${xms}m -Xmx${xmx}m -XX:MaxNewSize=${max_new_size}m  -XX:ThreadStackSize=${thread_stack_size} -jar ${name}.jar –spring.profiles.active=${config_prefix} &gt;/home/${start_user}/deploy/logs/${name}/${name}-start.log 2&gt;&amp;1 &amp;</p><p>#!/bin/bash<br>mkdir -p /home/${start_user}/deploy/logs/${name}<br>cd /home/${start_user}/deploy/apps/${name}<br>/usr/bin/nohup /usr/local/jdk/bin/java -Dproject.name=${name} -Dlogging.file.path=”/home/${start_user}/deploy/logs/${name}” &lt;#if zone??  &amp;&amp; zone != “”&gt; -Dspring.cloud.config.label=${region}.${zone} -Dspring.application.index=${region}.${zone} -Dspring.application.name=fortune-unit-service-primary -Dlogging.console.level=off -Dzone=${zone} &lt;/#if&gt; &lt;#if region??  &amp;&amp; region != “”&gt; -Dregion=${region} &lt;/#if&gt; &lt;#if service_chain??&gt; -javaagent:/home/${start_user}/deploy/tools/service-chain-1.0-RELEASE.jar -Xbootclasspath/a:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -javaagent:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -Dservice-chain=${service_chain} &lt;/#if&gt; -server -Xms3000m -Xmx3000m -XX:MaxNewSize=${max_new_size}m  -XX:ThreadStackSize=${thread_stack_size} -jar ${name}.jar –spring.profiles.active=${config_prefix} &gt; &lt;#if config_prefix == “production” || config_prefix == “dwd-pre” || config_prefix == “production-sh”&gt; /dev/null &lt;#else&gt; /home/${start_user}/deploy/logs/${name}/${name}-start.log &lt;/#if&gt; 2&gt;&amp;1 &amp;</p><p>grant all on zentaopro.* to ‘dev’@’192.168.%’ identified by ‘zentao123’;</p>]]></content>
    
    <summary type="html">
    
      Redis集群相关知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="数据库" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Redis" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"/>
    
      <category term="Redis集群" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E9%9B%86%E7%BE%A4/"/>
    
    
      <category term="redis集群" scheme="http://yoursite.com/tags/redis%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>语言学基础</title>
    <link href="http://yoursite.com/2019/01/26/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%8F%8A%E8%B7%AF%E7%BA%BF/%E8%AF%AD%E8%A8%80%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2019/01/26/个人知识体系/英语学习/英语学习方法及路线/语言学基础/</id>
    <published>2019-01-26T10:18:49.000Z</published>
    <updated>2019-01-26T10:18:49.000Z</updated>
    
    <summary type="html">
    
      语言学基础
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="英语学习" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="英语学习方法及路线" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%8F%8A%E8%B7%AF%E7%BA%BF/"/>
    
    
      <category term="语言学基础" scheme="http://yoursite.com/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>rsync用法</title>
    <link href="http://yoursite.com/2019/01/24/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/rsync/rsync/"/>
    <id>http://yoursite.com/2019/01/24/IT科学技术知识体系结构-Linux运维方向/网络知识及网络服务/网络服务/rsync/rsync/</id>
    <published>2019-01-24T15:13:25.000Z</published>
    <updated>2019-01-24T15:13:25.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>rsync作为一个数据<strong>同步</strong>的工具，可通过LAN/WAN快速同步多台主机间的文件。</p><p>主要解决的核心问题是：<strong>使两端的数据保持同步</strong></p><p>可以分为2个部分：</p><ul><li>全量传输（也可以理解为全量备份）</li><li>差异化传输（只传输有变化的部分内容）</li></ul><h2 id="语法及6种命令格式"><a href="#语法及6种命令格式" class="headerlink" title="语法及6种命令格式"></a>语法及6种命令格式</h2><p>抽象后的语法表达式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync [option] src dest</span><br></pre></td></tr></table></figure><p>在实际使用中，源和目的地的组合有一下几种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Usage: rsync [OPTION]... SRC [SRC]... DEST</span><br><span class="line">  or   rsync [OPTION]... SRC [SRC]... [USER@]HOST:DEST</span><br><span class="line">  or   rsync [OPTION]... SRC [SRC]... [USER@]HOST::DEST</span><br><span class="line">  or   rsync [OPTION]... SRC [SRC]... rsync://[USER@]HOST[:PORT]/DEST</span><br><span class="line">  or   rsync [OPTION]... [USER@]HOST:SRC [DEST]</span><br><span class="line">  or   rsync [OPTION]... [USER@]HOST::SRC [DEST]</span><br><span class="line">  or   rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]</span><br><span class="line">The &apos;:&apos; usages connect via remote shell, while &apos;::&apos; &amp; &apos;rsync://&apos; usages connect</span><br><span class="line">to an rsync daemon, and require SRC or DEST to start with a module name.</span><br></pre></td></tr></table></figure><p>:表示连接的是远端的shell。而::或者rsync://表示连接的是远端的rsync守护进程。</p><p>以上这几种命令格式对应的是不同的工作模式和场景，我们把它提取精简出来就是：</p><ul><li>本地文件之间的传输。src dest</li><li>将本地同步到远端。src user@host:dest</li><li>将本地文件同步到远端的默认配置rsync服务端。src user@host::dest</li><li>将本地文件同步到远端的指定配置的rsync服务端。src rsync://user@host:port/dest</li><li>将远端机器上的数据同步传输到本地。user@host:src local_dest</li><li>将远端rsync服务器(默认配置)上的数据同步传输到本地。user@host::src local_dest</li><li>将远端rsync服务器(指定配置)上的数据同步传输到本地。rsync://user@host:por/src local_dest</li></ul><p>一共7种方式。</p><h2 id="6种命令格式对"><a href="#6种命令格式对" class="headerlink" title="6种命令格式对"></a>6种命令格式对</h2><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="目的或者说要解决的问题"><a href="#目的或者说要解决的问题" class="headerlink" title="目的或者说要解决的问题"></a>目的或者说要解决的问题</h2><p>rsync作为一个数据<strong>同步</strong>的工具，可通过LAN/WAN快速同步多台主机间的文件。</p><p>主要解决的核心问题是：<strong>使两端的数据保持同步</strong></p><p>可以分为2个部分：</p><ul><li>全量传输（也可以理解为全量备份）</li><li>差异化传输（只传输有变化的部分内容）</li></ul><h2 id="核心观点和内容"><a href="#核心观点和内容" class="headerlink" title="核心观点和内容"></a>核心观点和内容</h2><h2 id="目的和核心内容是怎么连接的"><a href="#目的和核心内容是怎么连接的" class="headerlink" title="目的和核心内容是怎么连接的"></a>目的和核心内容是怎么连接的</h2><h2 id="整体的实现逻辑"><a href="#整体的实现逻辑" class="headerlink" title="整体的实现逻辑"></a>整体的实现逻辑</h2><h2 id="启发点和疑问点"><a href="#启发点和疑问点" class="headerlink" title="启发点和疑问点"></a>启发点和疑问点</h2><h2 id="抽象化"><a href="#抽象化" class="headerlink" title="抽象化"></a>抽象化</h2><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>Redis数据备份这个我已经把核心的sentinel这些实现好了，cpu、内存、流量、sentinel日志这些可能会出现的报警情况都已经思考确认优化过了。</p><p>刚才11点的时候做了一次测试，没有问题，待会我把时间点换成凌晨。</p><p>cluster部分的数据备份和恢复稍微有点不一样，我先把上海机房Redis都创建之后再来做下这个。</p>]]></content>
    
    <summary type="html">
    
      rsync用法
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="网络知识及网络服务" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="网络服务" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="rsync" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/rsync/"/>
    
    
      <category term="rsync" scheme="http://yoursite.com/tags/rsync/"/>
    
  </entry>
  
  <entry>
    <title>django-定时任务</title>
    <link href="http://yoursite.com/2019/01/13/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/django/django-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    <id>http://yoursite.com/2019/01/13/IT科学技术知识体系结构-Linux运维方向/编程开发/Python/django/django-定时任务/</id>
    <published>2019-01-13T06:19:01.000Z</published>
    <updated>2019-01-13T06:19:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>在编写django项目的时候，很多时候会有定时任务的需求。</p><h1 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h1><h2 id="步骤1：安装django-crontab库"><a href="#步骤1：安装django-crontab库" class="headerlink" title="步骤1：安装django-crontab库"></a>步骤1：安装django-crontab库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install django-crontab</span><br></pre></td></tr></table></figure><p>再在settings.py中添加app:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">INSTALLED_APPS = (</span><br><span class="line">       ...</span><br><span class="line">       &apos;django_crontab&apos;,</span><br><span class="line">   )</span><br></pre></td></tr></table></figure><h2 id="步骤2：创建定时任务"><a href="#步骤2：创建定时任务" class="headerlink" title="步骤2：创建定时任务"></a>步骤2：创建定时任务</h2><p>在app内新建py文件，文件名称随意。</p><p>例如我们在名为bind_ops的app下新建了一个bind_crontab.py文件。</p><p>文件内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from lib.logger  import logger</span><br><span class="line">import datetime</span><br><span class="line">time = datetime.datetime.now()</span><br><span class="line">time = str(time)</span><br><span class="line">def crontab_test():</span><br><span class="line">    print (111)</span><br><span class="line">    logger.info(&quot;bind crontab&quot; +time )</span><br></pre></td></tr></table></figure><p>因为要看定时任务的效果，所以采用了直接输出和记录到文件的形式</p><p>经过测试发现：当定时任务在执行时，如果你只是输出一些语句，那么你将看不到任何内容，所以请不要怀疑这个定时任务没有执行。</p><p>然后在 settings.py中增加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 最简单配置</span><br><span class="line">CRONJOBS = [</span><br><span class="line">    # 表示每天2：01执行</span><br><span class="line">    (&apos;01 2 * * *&apos;, &apos;bind_ops.bind_crontab.crontab_test&apos;)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">#</span><br></pre></td></tr></table></figure><p><strong>参数及字段说明：</strong></p><p>第一个参数（表示时间），前5个字段分别表示：</p><ul><li>分钟：0-59</li><li>小时：1-23</li><li>日期：1-31</li><li>月份：1-12</li><li>星期：0-6（0表示周日）</li></ul><p>一些特殊符号：</p><ul><li>*： 表示任何时刻</li><li>,：　表示分割</li><li>-：表示一个段，如在第二段里： 1-5，就表示1到5点</li><li>/n : 表示每个n的单位执行一次，如第二段里，*/1, 就表示每隔1个小时执行一次命令。也可以写成1-23/1.</li></ul><p>第二个参数（表示路径）：</p><p>格式：app名称.文件名.函数名</p><p>如果想生成日志，那就<strong>再加一个字符串类型的参数</strong>：’&gt;&gt; path/name.log’， path路径，name文件名。’&gt;&gt;’表示追加写入，’&gt;’表示覆盖写入。</p><p><strong>提示：</strong></p><ul><li>如果你有多个定时任务，以逗号隔开，都放入CORNJOBS的列表中即可。</li><li>路径必须写绝对路径，写相对路径是不识别的。</li></ul><h2 id="步骤3：启动任务"><a href="#步骤3：启动任务" class="headerlink" title="步骤3：启动任务"></a>步骤3：启动任务</h2><p>以上都完成后，需要执行以下命令将任务添加并生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py crontab add</span><br></pre></td></tr></table></figure><p>显示当前的定时任务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py crontab show</span><br></pre></td></tr></table></figure><p>删除所有定时任务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py crontab remove</span><br></pre></td></tr></table></figure><p>重启django服务执行（可能不需要，因为并没有用，也正常使用了。）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py corntab -e</span><br></pre></td></tr></table></figure><h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><h2 id="dname项目-bind定时获取主机名"><a href="#dname项目-bind定时获取主机名" class="headerlink" title="dname项目-bind定时获取主机名"></a>dname项目-bind定时获取主机名</h2><h3 id="需求说明"><a href="#需求说明" class="headerlink" title="需求说明"></a>需求说明</h3><p>需求：bind服务需要提供解析主机名的功能</p><p>拆分：</p><ul><li>从数据源中获取主机名的对应信息并写入zone数据文件-这里的数据源是cmdb</li><li>定期检测删除的主机</li><li>定期更新有ip变化的主机记录</li></ul><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3>]]></content>
    
    <summary type="html">
    
      django-定时任务
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="编程开发" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/"/>
    
      <category term="django" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/django/"/>
    
    
      <category term="django-定时任务" scheme="http://yoursite.com/tags/django-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>sed命令</title>
    <link href="http://yoursite.com/2019/01/07/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%91%BD%E4%BB%A4/sed%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2019/01/07/IT科学技术知识体系结构-Linux运维方向/Linux命令/sed命令/</id>
    <published>2019-01-07T01:42:29.000Z</published>
    <updated>2019-01-07T01:42:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>sed全称stream editor，流编辑器，用程序的方式来编辑文本，它是文本处理中常用的工具，能够完美的配合正则表达式使用。</p><p>sed处理文件的具体过程如下：</p><ol><li><p>首先sed把当前正在处理的行保存在一个临时缓存区中（也称为模式空间），然后处理临时缓冲区中的行，完成后把该行发送到屏幕上。</p></li><li><p>sed每处理完一行就将其从临时缓冲区删除，然后将下一行读入，进行处理和显示。</p></li><li><p>处理完输入文件的最后一行后，sed便结束运行。</p></li><li><p>sed把每一行都存在临时缓冲区中，对这个副本进行编辑，所以不会修改原文件。</p></li></ol><h1 id="sed语法"><a href="#sed语法" class="headerlink" title="sed语法"></a>sed语法</h1><p>sed的操作过程包括：</p><ol><li>定位。定址用于决定对哪些行进行编辑。地址的形式可以是数字、正则表达式、或二者的结合。如果没有指定地址，sed将处理输入文件的所有行。</li><li></li></ol><p>地址是一个数字，则表示行号；是“$”符号，则表示最后一行。例如： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`sed -n &apos;3p&apos; datafile只打印第三行`</span><br></pre></td></tr></table></figure><p> 只显示指定行范围的文件内容，例如：</p><p># 只查看文件的第100行到第200行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -n &apos;100,200p&apos; mysql_slow_query.log</span><br></pre></td></tr></table></figure><p>地址是逗号分隔的，那么需要处理的地址是这两行之间的范围（包括这两行在内）。范围可以用数字、正则表达式、或二者的组合表示。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`sed &apos;2,5d&apos; datafile#删除第二到第五行sed &apos;/My/,/You/d&apos; datafile#删除包含&quot;My&quot;的行到包含&quot;You&quot;的行之间的行sed &apos;/My/,10d&apos; datafile#删除包含&quot;My&quot;的行到第十行的内容`</span><br></pre></td></tr></table></figure><h1 id="sed实际案例"><a href="#sed实际案例" class="headerlink" title="sed实际案例"></a>sed实际案例</h1><p>sed -n  ‘/;[ ]{1,5}serial/s/[0-9]{1,10}/&amp;+1/;s/;[ ]{1,5}serial[ ][0-9]{1,10}/; serial date+1/;s/[0-9]{1,10}$/no+1/p’ dianwoba.com.zone</p><p>sed -n  ‘/;[ ]{1,5}serial/s/[0-9]{1,10}$/no+1/p’ dianwoba.com.zone</p><p>sed -n  ‘/;[ ]{1,5}serial/s#[0-9]{1,10}#&amp;+1#;/;[ ]{1,5}serial/s#;[ ]{1,5}serial[ ][0-9]{1,10}#; serial date+1#;/;[ ]{1,5}serial/s#[0-9]{1,10}$#no+1#p’ dianwoba.com.zone</p><p>sed -n  ‘/;[ ]{1,5}serial/s/[0-9]{1,10}/&amp;+1/;/;[ ]{1,5}serial/s/;[ ]{1,5}serial[ ][0-9]{1,10}/; serial date+1/;/;[ ]{1,5}serial/s/[0-9]{1,10}$/no+1/p’ dianwoba.com.zone</p><p>sed -n  ‘3s/[0-9]{1,10}/&amp;+1/;3s/;[ ]{1,5}serial[ ][0-9]{1,10}/; serial date+1/;3s/[0-9]{1,10}$/no+1/p’ dianwoba.com.zone</p><p>sed -n  ‘3s/[0-9]{1,10}/&amp;+1/;3s/;[ ]{1,5}serial[ ][0-9]{1,10}/; serial date/;3s/$/no+1/p’ dianwoba.com.zone</p><h1 id="高级知识"><a href="#高级知识" class="headerlink" title="高级知识"></a>高级知识</h1>]]></content>
    
    <summary type="html">
    
      sed命令
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux命令" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="sed" scheme="http://yoursite.com/tags/sed/"/>
    
  </entry>
  
  <entry>
    <title>思维模型</title>
    <link href="http://yoursite.com/2019/01/04/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2019/01/04/个人知识体系/认知升级/学习方法/思维模型/</id>
    <published>2019-01-04T15:09:14.000Z</published>
    <updated>2019-01-04T15:09:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="什么是思维模型"><a href="#什么是思维模型" class="headerlink" title="什么是思维模型"></a>什么是思维模型</h2><p>查理芒格曾说：每个人都需要掌握至少100个思维模型，才能解决生活中的80%、90%的问题。</p><p>那么，思维模型究竟是什么？以及思维模型究竟怎么样在生活中帮助我们解决问题？</p><p>查理芒格本身说：思维模式是重要学科的重要原理，通常是那些不证自明的基础规律</p><p>我的个人理解：思维模型是高级思维方式的底层框架抽象，是一个系统框架</p><p>学习思维模型，关键不在于具体的技巧和答案，而在于思考的过程。</p><h2 id="思维模型的分层"><a href="#思维模型的分层" class="headerlink" title="思维模型的分层"></a>思维模型的分层</h2><p>思维模型其实是分层次的</p><p>从上到下适用范围越来越基础，也就是说适用范围越来越广</p><p><strong>最上层：</strong>解决具体问题的思维模型。比如FFC、SWOT法则、冰山模型等等</p><p><strong>中间层：</strong>某一学科的原理或者规律。比如精益创业、边际效应、价值投资理念等等，解决一个学科中问题的思维模型</p><p><strong>最下层：</strong>最底层的抽象的跨学科的原理和规律。比如哲学上的递弱代偿、物理学的机械论、物理学的熵增定律，生物学的进化论等等</p><p>思维模型越往上就越有用，工具属性就越强，解决某个具体场景的问题</p><p>思维模型越往下就越无用，距离具体问题越远，解释事情的属性更强</p><h2 id="思维模型的作用"><a href="#思维模型的作用" class="headerlink" title="思维模型的作用"></a>思维模型的作用</h2><p>思维模型主要有2个作用：</p><ul><li><p>帮助我们提高做决策的质量和正确率</p><p>生活是一个又一个决定的延续，每个选择做的好与不好对于我们的影响是巨大的。可是我们很少仔细地思考，我们究竟是怎么做决策的，做决策的过程是什么样的。具体看补充知识</p></li><li><p>提升创新力</p><p>我们的创新力往往来自于那些无用的思维模型。</p><p>熊彼特：创新是生产要素的重组，关键在于我们要懂看世界的方式，我们只有掌握了更多理解理解世界的方式，更多解释世界问题的方式，才能够打破我们过去经验世界里各要素的关系，用新的视角来将各个要素进行重新组合，进而产生创新…..</p></li></ul><h2 id="如何发现和学习思维模型？"><a href="#如何发现和学习思维模型？" class="headerlink" title="如何发现和学习思维模型？"></a>如何发现和学习思维模型？</h2><p>查理芒格在《穷查理宝典》中只写了十几个思维模型，那么还有那么多的思维模型我们去哪里学习呢？</p><p>其实在我们的日常生活中，我们可以发现很多很好的思维模型，只不过我们没有方法、没有意识去发现这些思维模型。</p><p>那么，我们如何在生活中发现思维模型呢？</p><h3 id="方法1：启发、问题、思路、模型"><a href="#方法1：启发、问题、思路、模型" class="headerlink" title="方法1：启发、问题、思路、模型"></a>方法1：启发、问题、思路、模型</h3><p>在生活当中，经常会遇到一些让你觉得有启发的事情。大部分人往往不会去深究背后到底在解决什么问题？</p><p>所以，不是碰到问题，再去发现思维模型，而是碰到让你有启发的事情的时候，就可以去思考思维模型。</p><p>分析：</p><ol><li>解决了什么问题</li><li>思路是什么，为什么有效，有哪些基本的要素，本质是什么</li><li>把思路抽象提炼出模型，思考这个思路所调用的更底层的思维模型</li></ol><p>要想实现这个，需要我们做相应的改变：</p><ol><li>心态的转变。需要有好奇心，主动的去问，为什么这个现象的背后有这么一个答案，为什么这个答案起作用</li><li>重点的转变。过去在学习时，时间都主要花在：记笔记、看书、记答案。可是真正重要的地方是将时间花在思考的过程。把时间花在硬问题，打通思维的过程。</li><li>方法的转变。顺着答案不断的和我们过去已有的经验结合。重要的不是答案，重要的是知识之间的联系。</li></ol><h2 id="如何运用思维模型"><a href="#如何运用思维模型" class="headerlink" title="如何运用思维模型?"></a>如何运用思维模型?</h2><p>我们学习了思维模型之后，在我们日常生活中应该怎么去应用呢？</p><p>运用思维模型，关键点在于：多层次、多视角</p><ul><li><p>多层次：把一个问题，使用不同层次的思维模型进行分析。这里的层次可以理解为学科，不同的学科解释问题的层次</p></li><li><p>多视角：在同一个层次当中，用不同的角度来分析问题</p></li></ul><p>欧内斯特-内格尔：各学科就是一系列解释的层次。</p><h2 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h2><h3 id="我们是如何做决策的？"><a href="#我们是如何做决策的？" class="headerlink" title="我们是如何做决策的？"></a>我们是如何做决策的？</h3><p>我们在外部刺激和做出反应之间，并不是简单的刺激行为模式，而是一个ABC模式。</p><ul><li>A: Activatiing event 诱发刺激</li><li>B: beliefs 信念反应，决策依据</li><li>C: consequences 行动结果</li></ul><p>对于同一个刺激A，由于背后的信念B不同，我们会做出不同的行为决策C。我把它理解是一种流式模式，信息源输入一个系统框架（决策依据）中，然后进行运算，得出一个输出结果。</p><p>每个人由于过往的经历、经验、家庭等等因素的不同，会有不同的信念B，而信念往往是很难改变的，因为这个形成的过程往往是自己不自知的，并且容易成为潜意识。</p><p>我们经常说的认知升级，其实本质就是面对同一个问题，你有不同的处理方式，也就是你的中间信念反应，决策依据发生了改变。</p><p>所以，我们成长进步的过程实际上是用更好的决策依据来替换自己之前因为有限知识或经验得出的那些不太可靠的决策依据。</p><p>这个新的，好的决策依据就是我们所说的思维模型。也就是说，我们把这个决策的模型进行了修改，修改之后的实现顺序是：刺激–&gt;思维模型–&gt;行动结果</p><p>总结：我们要把中间的这个黑箱（决策依据）变成我们可以调控的白箱</p><h3 id="多元思维模型"><a href="#多元思维模型" class="headerlink" title="多元思维模型"></a>多元思维模型</h3><p>对于一个系统而言，结构远远大于单个要素本身，系统的性质是取决于要素的结构，而不是要素本身。</p><p>就行C原子，它可以排列成钻石，也可以是石墨，这不是取决于碳元素本身的原因，而是它相互之间关系形成的系统。</p><p>同样的，就算你把查理芒格的思维模型全都学会了，但是你不知道在应用之间它们的关系，结构，权重，先后关系，哪些互相有冲突，你也成为不了查理芒格。最终的结果是你知识知道了很多的思维模型的一个someone。</p><h3 id="如何更高效的学习思维模型"><a href="#如何更高效的学习思维模型" class="headerlink" title="如何更高效的学习思维模型"></a>如何更高效的学习思维模型</h3><p>学习思维模型，重要的不是那些思维模型本身，而不是那些知识点。而是理解我们运用思维模型的思路，它解决问题的过程，所以我们在记笔记的时候可以换一种方法。</p><p>我们记笔记的目的是：描绘出这个思维模型的一个全局框架，而不是零散的看起来非常用来但是不能建立连接的知识点，当问题进入这个框架，出去的时候就是满意的解决。</p><h4 id="七星笔记法"><a href="#七星笔记法" class="headerlink" title="七星笔记法"></a>七星笔记法</h4><p>目的：事先人为的描述整体全局框架的关键点，在过程中，填充着7个关键点，填充完了之后，这个框架也就描绘出来了。也就是说，用你的学习的思维模型去学习其他思维模型</p><p>在学习做记笔记的时候，7个星星，也就是7个问题</p><p>上课或者学习的时候就是回答这7个问题，当这7个问题回答完了，那么笔记也记完了</p><ul><li><p>这门课的目的是什么？也就是：为什么要学习它，它解决什么问题？</p></li><li><p>这门课的核心观点和内容是什么？</p></li><li>目的和这些核心观点是怎么连接的？</li><li>老师或作者讲述的逻辑是什么？</li><li>我在听课学习的过程中，有哪些疑问（说的对吗）和启发（为什么能这么思考）的地方？</li><li>上面的这些疑问和启发背后的思维模型是什么？</li><li>有哪些事情可以让我直接就可以开始找应用场景并采取行动？</li></ul><p>一些说明：</p><ul><li>在学习之前，可以通过上网查资料等方式先了解下这门课，这个领域的核心框架是什么，之后在学习的时候去进行比较。</li><li>老师或者作者的逻辑和我自己理解的有什么差别，重要的不是知识点，重要的是为什么这么组织推演思考过程，为什么这么思考？</li></ul><h4 id="做自己理解的思维导图"><a href="#做自己理解的思维导图" class="headerlink" title="做自己理解的思维导图"></a>做自己理解的思维导图</h4><p>就像上面我说的，要使用自己的框架去记忆这些知识点，如果只是单纯的这些知识点，那么将会是孤立的，没有办法建立连接。</p><h4 id="收集启发点和疑问点"><a href="#收集启发点和疑问点" class="headerlink" title="收集启发点和疑问点"></a>收集启发点和疑问点</h4><p>你在碎片时间进行学习的时候，当碰到启发点和疑问点的时候，简单记录一下，当你有整块时间的时候再去深究它。</p><h4 id="通过预想使用的场景去记忆"><a href="#通过预想使用的场景去记忆" class="headerlink" title="通过预想使用的场景去记忆"></a>通过预想使用的场景去记忆</h4><p>这一点在学习英语等学科中尤为有效，你在记忆单词的时候，最好是在记忆句子的时候顺便记忆单词，如果只是单纯的记忆单词，效果根据不好。</p><p>并且在学习一些语法知识点的时候，最好也是通过一个句子来记忆。</p><p>同样的，在学习其他学科知识的时候，通过结果去记忆这些知识点。</p><h1 id="思维模型"><a href="#思维模型" class="headerlink" title="思维模型"></a>思维模型</h1><h2 id="FFC"><a href="#FFC" class="headerlink" title="FFC"></a>FFC</h2><p>在于他们进行沟通交流的时候，可以使用FFC模型</p><p>F：feeling。描述感觉</p><p>F：fact。描述事实</p><p>C: compare。进行比较</p><p>常规赞美：你好漂亮、今天很漂亮。</p><p>优化：你的打扮让我眼前一亮，你今天的绿色衣服和围巾和项链特别搭配，简直是一股生机盎然的气息，你是今天嘉宾里面最亮眼的。</p>]]></content>
    
    <summary type="html">
    
      思维模型
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="认知升级" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/"/>
    
      <category term="学习方法" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
    
      <category term="思维模型" scheme="http://yoursite.com/tags/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>知识之网理论</title>
    <link href="http://yoursite.com/2019/01/03/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%9F%A5%E8%AF%86%E4%B9%8B%E7%BD%91%E7%90%86%E8%AE%BA/"/>
    <id>http://yoursite.com/2019/01/03/个人知识体系/认知升级/学习方法/知识之网理论/</id>
    <published>2019-01-02T16:19:16.000Z</published>
    <updated>2019-01-02T16:19:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>我把一个人的知识看成是一张知识之网（可以类比为蜘蛛网），那么中心节点就是我这个人，由我这个中心发起的每一条边（实际上射线，在这里不严谨，这么用主要是便于直观理解），就是所有基础学科的知识</p><p>这里放上一张蜘蛛网的图</p><p>这个时候这张网只有边，过于分散，是无法捕捉到猎物的，因此需要使用一定的规则将所有边组合起来，对于蜘蛛网来说，我们直观的感受是一个个的<font color="blue"><strong>同心圆</strong></font>。</p><p>同样的，对于我来说，我怎么把这些分散的知识有机的结合起来，形成为一个整体？我的方法就是使用思维模型，通过跨界思维，将所学的知识结合成为一个整体。</p><p>也就是说，我只把知识分为2类：基础学科的知识和思维模型。</p><p>这里有几个问题我需要说明下：</p><ol><li>思维模型是什么？</li><li>跨界思维是什么意思？</li><li>为什么要构建这张知识之网，有了这张网之后又什么作用？</li></ol><h1 id="第一个问题：思维模型是什么？"><a href="#第一个问题：思维模型是什么？" class="headerlink" title="第一个问题：思维模型是什么？"></a><strong>第一个问题：</strong>思维模型是什么？</h1><p>思维模型可以理解为：<strong>思维方式的抽象</strong>。</p><p>生活是由一个个的选择构成的，那么是什么在背后指导我们做选择？我们决定是否买一个东西时需要考虑各种因素（价钱，必要性，时机等等），我们在思考这些因素的时候就是调用我们过往认知产生的思维模型，只不过我们不自知而已。我们在处理问题时，在做考试题目时，解题的思路和步骤更是思维方式的直接体现。</p><p>而思维模型是思维方式的抽象，很多时候我们拥有某一种思维的方式，但是自己却不清楚是怎么运作的，所以这个时候需要站在更高的维度，把它抽象出来，让它能为更多人学习使用。</p><h1 id="第二个问题：跨界思维是什么意思？"><a href="#第二个问题：跨界思维是什么意思？" class="headerlink" title="第二个问题：跨界思维是什么意思？"></a><strong>第二个问题：</strong>跨界思维是什么意思？</h1><p>关于学习知识，我们需要拉大尺度，在大时间线上，在宏观上看待这件事。</p><p>在人类历史中，一开始根本就没有学科，早期的知识主要是为了生存（如果要分类的话可以理解为生存学科），后来解决了生存危机，有了火，有了农耕畜牧之后，慢慢的知识的总量得到的极大增长，人类开始探索自然，这一个阶段的学科其实就一个-自然科学，然后随着文明的进一步发展，才慢慢有了今天我们所看到的样子</p><p>说了这么多，其实就是想说：<strong>人类目前的所有科目其实都是后天分类出来的</strong>。这一点可能很多人往往会忽略。</p><p>每一个学科之间其实是相互影响的，一个学科的重要基础理论可能也同样适用于另一个学科，能够提高你在学习这个学科时的效率</p><p>所以，将所有的学科看成为一个整体，不要局限于某一个具体的学科，才是真正的有效学习。</p><h1 id="第三个问题：知识之网的作用？"><a href="#第三个问题：知识之网的作用？" class="headerlink" title="第三个问题：知识之网的作用？"></a><strong>第三个问题：</strong>知识之网的作用？</h1><p>当我们把思维+具体的知识编织成为一张网，这个时候我们可以把自己看做是等到猎物的蜘蛛，当有问题（蜘蛛的猎物）来的时候，只要落在这张网上面，我们就能找到方法消灭（解决）</p><p>如果有问题解决不了，这个时候我们就知道，我们需要更新我们的知识系统，加固或者扩大我们的知识之网。</p>]]></content>
    
    <summary type="html">
    
      知识之网理论
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="认知升级" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/"/>
    
      <category term="学习方法" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
    
      <category term="学习方法" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>如何输入和输出</title>
    <link href="http://yoursite.com/2019/01/02/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E5%A6%82%E4%BD%95%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA/"/>
    <id>http://yoursite.com/2019/01/02/个人知识体系/认知升级/学习方法/如何输入和输出/</id>
    <published>2019-01-02T15:02:40.000Z</published>
    <updated>2019-01-02T15:02:40.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><p>就我个人而言，整个学习过程分为以下3个步骤（注意是有顺序的）：</p><ol><li>输入。信息来源</li><li>内化。最核心部分，将所学的知识、思维模型及专业技能存储能够被<strong>直接调用</strong>的资源池中，内化成直觉</li><li>输出。将思维模型或者专业的技能变成直觉的直接输出</li></ol><p>虽然内化是最核心的部分，但是学习是一个完整的系统，输入和输出环境也影响着内化环节。</p><p>我针对我的情况画了一张学习整体结构图，仅供参考：</p><p>下面我们来介绍这三个方面</p><h1 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h1><p>输入也就是信息（知识）的摄入，在日常生活中，我的信息输入源主要有：</p><ul><li><p>书籍</p></li><li><p>视频</p></li><li><p>音频</p></li><li><p>网上获取的知识</p></li><li><p>生活中看到的事情得到的启发</p></li><li><p>自己深度思考得出的知识（也就是说知识的来源可以是本身）</p></li><li><p>交际活动获取的知识</p><blockquote><p>这一部分包含的范围就比较广了，可以是与他人交流时获取的，也可以是参加线下或线上会议、论坛等获取的知识</p></blockquote></li></ul><p>我把通过这些输入源学到的知识主要分为以下2类：</p><ul><li>思维模型。一个思维方式的系统框架。为下面所说的专业领域知识所服务，主要作用是不断优化改善分析和处理问题的逻辑，关于这部分的内容我有专门的文章《思维模型》。</li><li>专业领域的知识。比如计算机科学、英语、数学、历史、心理学、生命科学、经济学、哲学等等学科的知识</li></ul><p>按道理来说，学到的知识应该可以分为很多个类别，为什么我只分了2类？</p><p>这就涉及到个人的知识体系结构问题了，这一点在我的另一篇文章《知识之网理论》有概述。</p><p>因此最佳阅读顺序是：《思维模型》–&gt;《知识之网理论》–&gt;《如何输入和输出》。当然不按照这个顺序来也可以</p><h1 id="内化-关于内化的一些前提知识"><a href="#内化-关于内化的一些前提知识" class="headerlink" title="内化-关于内化的一些前提知识"></a>内化-关于内化的一些前提知识</h1><p>这一章节是全文的重点和核心</p><p>整个内化的过程比较复杂和抽象，因此会花很长的篇幅来进行解释和记录。</p><p>内化是将所学到知识融会贯通的过程，这个过程根据个人的差异（主要是所采取的方法技巧（包括时间管理、一些提升效率的工具的使用等）的差异、思维方式的差异等），整个内化的时间和效果会有非常大的差异性</p><p>下面我要介绍的这些有关学习的基础知识，都是我个人实践过的或者正在实践的，在了解了这些基础知识之后，我们再来说说如何才能达到最佳的内化效果。</p><p>下面我们说一说这些有关内化的基础知识</p><h2 id="大脑结构-神经元连接"><a href="#大脑结构-神经元连接" class="headerlink" title="大脑结构-神经元连接"></a>大脑结构-神经元连接</h2><p>桑代克在《教育心理学》中说：学习就是联结，人之所以善于学习，主要是因为能够形成大量的联结。学习会使人成为异常复杂而精致的联结系统</p><p>一学习之所以有助于另一学习，是因为两种学习具有相同因素的原因</p><p>真正的高手会把模型与模型之间也建立连接，其实这一部分我主要在《知识之网理论》中说明，各个知识或者思维模型可以联结成为一个网站结构，多个网状结构可以形成知识的互联网，这一点其实也和当前宇宙的结构类似。</p><h2 id="艾宾浩斯遗忘曲线"><a href="#艾宾浩斯遗忘曲线" class="headerlink" title="艾宾浩斯遗忘曲线"></a>艾宾浩斯遗忘曲线</h2><p>遗忘曲线的背后实质原因其实还是因为神经元之间没有建立连接</p><h2 id="烧开水理论"><a href="#烧开水理论" class="headerlink" title="烧开水理论"></a>烧开水理论</h2><h2 id="为什么自学比培训好？"><a href="#为什么自学比培训好？" class="headerlink" title="为什么自学比培训好？"></a>为什么自学比培训好？</h2><p>主要的一个原因是神经元无法建立连接以及遗忘曲线的原因。</p><p>这一个部分其实在《知识之网理论》中能够找到答案，在培训班中，大量的知识输入大脑，在现有知识没有建立神经元连接的时候，学习新的知识，不断的恶性循环，就像是在沙子上盖楼，一层水泥还没有干，就开始网上买铺第二层水泥。</p><h2 id="认知升级"><a href="#认知升级" class="headerlink" title="认知升级"></a>认知升级</h2><p>在问题来的时候，原本是走这个神经元通路，经过反复的训练，让大脑走另一个神经元网络通路，新的网络通路越来越强壮，旧的就会慢慢消失。</p><p>所谓的认知升级本质上其实是：建立新的神经网络链路，替换原有的旧的神经网络。修新路，绕旧路。</p><h2 id="内化的5个阶段"><a href="#内化的5个阶段" class="headerlink" title="内化的5个阶段"></a>内化的5个阶段</h2><p>我们在学习新知识的时候，一般来说都会经历这几个阶段</p><ul><li>事前想不到</li><li>事后诸葛亮</li><li>事中有启发。在中某些事的时候，还是用以前的思维的时候，突然会提醒自己，我应该用更好的方式。</li><li>事前会想起</li><li>自然而然。内化成为我们的直觉。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在这里我们对上面的这些知识进行一个总结</p><h1 id="内化-如何达到最佳内化效果"><a href="#内化-如何达到最佳内化效果" class="headerlink" title="内化-如何达到最佳内化效果"></a>内化-如何达到最佳内化效果</h1><p>在这个部分，记录各种学习的方法和基本准则，帮助我们进行有效的内化，提升效率。</p><p>就像我在开头说的，虽然内化是最核心的部分，但是学习是一个完整的系统，输入和输出环境也影响着内化环节。</p><p>所以在这个部分，众多方法我会先讲输入和输出是怎么提升内化的</p><h2 id="通用方法"><a href="#通用方法" class="headerlink" title="通用方法"></a>通用方法</h2><p>学习知识的顺序：</p><ol><li>网上了解，了解粗略的框架</li><li>看视频，视频偏实际的应用，先实践，了解具体是怎么运作的</li><li>看书籍，通过书籍去深入</li></ol><h2 id="输入提升内化"><a href="#输入提升内化" class="headerlink" title="输入提升内化"></a>输入提升内化</h2><p>在这里我们主要以“读书”这个输入方式进行讲解。</p><p>我们在读书的时候，书和书是不一样的，书的类型不同，难度不同，因为所使用的方法也会有所不同。</p><p>下面简单介绍3个方法帮助大家提高阅读时吸收知识的效率。</p><h3 id="熔断不读书法"><a href="#熔断不读书法" class="headerlink" title="熔断不读书法"></a>熔断不读书法</h3><p>在利用碎片时间进行读书的时候，就可以使用这个方法，比如只有十几二十分钟的时候。</p><p>股市中的熔断机制：当股市下跌到某一个指标的时候，就强制不允许买卖交易了，暂停，熔断。</p><p>同样的，当你读书的时候，遇到有疑问或者有启发的地方，立马合上书，然后思考，这里为什么让我有启发，启发点在哪里，我可以把它用在生活中的哪些场景中，这个背后有什么基本原理吗。这个时候其实也就是我在《思维模型》中所说的6星学习法中的后3点。</p><p>使用这种方法，哪怕你只有20分钟的时间，你也可以在书中找到对你有帮助的启发点，我们读书并不需要全部看完，寻找到启发点远比看到毫无收益要好的多。</p><p>总结：每一个单点的知识，都可以让我们真正地去理解思考，通过很短的时间来大幅度提升效率。对于大多数的畅销书而言，使用这个方法去阅读就足够了。</p><p>这种方法的弊端：当你专注于某一个点，你就很容易看不到整个系统。而我们知道，对于一个系统而言，结构远大于单点的要素。</p><p>如果你遇到想深入阅读，理解作者思路和逻辑，看清整个系统的时候，这个时候就不能再使用这个方法。</p><h3 id="关键词读书法"><a href="#关键词读书法" class="headerlink" title="关键词读书法"></a>关键词读书法</h3><p>一本书，无论它的组织思想是什么，它一定是用一些节点串联起来的，而这些节点往往是概念或者关键词的形式。</p><p>你把这些关键词提炼出来，然后寻找它们之间的关系，再结合这本书的主题和目的，梳理出它们之间的关系网络，就找到了作者的思路。</p><p>因为，我们核心要做的就是3件事：</p><ul><li>作者在这本书中想要解决什么问题？</li><li>关于这个问题，他提出了哪些核心观点（观点通常会以关键词的方式展示出来）</li><li>目的和关键词之间的关系是什么？（也就是：要解决的问题，是怎么和观点连接起来的，它们的联系）</li></ul><p>如何获取核心观点或者说关键词，需要我们把整本书读完再去总结吗？</p><p>我们其实可以用这个方法去提炼：封序目尾（封面，序言，目录，结尾）</p><p>换一个视角来看，其实阅读不仅仅是我们去读书，也就是说，不仅仅是我们一个人的事，还有作者和出版社，阅读，其实是3个元素构成的一个系统。就像人际沟通，其实也就是双方与信息三者构成的系统。</p><ul><li>封面：出版社会想尽办法把这本书的重点、主要价值提炼出来。主要是为了更好的销售。</li><li>序言：一般情况在封面之后会有说明，提炼出在这本书中，作者最核心的观点。</li><li>目录：关键词列表，作者在写目录的时候，通常会那些关键的概念提炼出来</li><li>结尾：</li></ul><p>任何一个作者，通常都会在开篇或者结尾的时候，把自己的书的特点、最关键的思想提炼出来。</p><p>所以，我们要找到一本书的关键词，通常情况下，根据不需要读完一本书，通过这4个步骤，通常就能获取。</p><h3 id="经典书籍-里应外合读书法"><a href="#经典书籍-里应外合读书法" class="headerlink" title="经典书籍-里应外合读书法"></a>经典书籍-里应外合读书法</h3><p>里：书里写的文字，阅读书籍的内容</p><p>外：书籍里没有写的内容部分</p><p>我们知道，我们写书籍的目的是，通过书籍这种语言文字符号去表达我们头脑的思想。</p><p>斯蒂芬-平克曾说：写作的难点在于要把网状的思考用树状的结构体现在线性展开的语句里。所以，写作实际上是作者思维层层压缩维度的一个过程。</p><p>因此，黑格尔会说：每当我用语言和符号去表达我的思想，我的思想就发生质变和肤浅化。</p><p>所以说，语言符号这种方式本身会带来一些限制问题，因此我们要精读那些最经典的书籍的时候，就需要注意到这种缺陷，因此，在阅读经典书籍的时候，使用里应外合的方法。</p><p>因此，在这种情况下，我们要知人论世，就是要研究作者的成长背景，他过去的经历对他有什么影响，哪些人的思想对他有很大的影响。他所处的时代，主流思想是什么。文化背景是什么，这些都是我们额外需要去做的功夫。</p><p>我们要把这本书放在时代、人物、文化等大的背景下理解，才能真正理解经典思想。</p><h2 id="输出提升内化-输出倒逼输入"><a href="#输出提升内化-输出倒逼输入" class="headerlink" title="输出提升内化-输出倒逼输入"></a>输出提升内化-输出倒逼输入</h2><h3 id="以教为学"><a href="#以教为学" class="headerlink" title="以教为学"></a>以教为学</h3><p>把教别人当做一个学习的过程，你不懂哪个思维模型，你不会用哪一个，你就去教别人哪一个。</p><p>主要有3个点再驱动你：</p><ul><li>压力。压力转化为动力。</li><li>发现自己的知识阻塞。在准备的过程中，你会发现一些原来自己以为懂但是实际上是不懂的地方。</li><li>通过别人的提问检验反馈。</li></ul><h2 id="具象抽象再具象"><a href="#具象抽象再具象" class="headerlink" title="具象抽象再具象"></a>具象抽象再具象</h2><p>我们所学习到的思维模型，一般情况下来说是已经具象化过的。</p><p>这个时候，我们需要把它进行抽象，抽象出一个系统框架，再填充上我们自己的内容，再重新具象化。</p><p>举例来说，我们在学习查理芒格的“复利”思维模型的时候，如果从表面上学习的话，很难被我们在日常生活中所运用，因为它是已经被查理芒格具象化的，我们所看到的并不是抽象层面的。</p><p>这个时候，我们把他说的这个思维模型进行抽象，可以看到“复利”的本质是：</p><p>做A会导致B，而B反过来又会强化A。所以我们在生活中看到的，凡是符合做A产生B，B又会强化A的都是“复利”这个思维模型的具象表现。</p><p>当我们知道了这个抽象的思维模型之后，我们可以看到，生活中的很多事情都可以用复利来进行解释。</p><p>例如，亚马逊的增长飞轮模式其实就是一个方法的复利的具象应用，是一个更大的综合系统下来思考。</p><p>所以，明白了复利的核心之后，我们就知道，我们需要使用长线思维去做一些事情，而不能短视。</p><h2 id="刻意练习"><a href="#刻意练习" class="headerlink" title="刻意练习"></a>刻意练习</h2><p>先把结论放出来：刻意练习=核心算法*大量练习。最终的结果是把思维模型和专业技能这些转换成为直觉。</p><p>把思维模型和专业技能转化成为直觉是需要大量的训练的。但是应该怎样去训练呢？不断的重复，遵循一万小时定律吗？</p><p>但是我们每天要上班，各种事情，哪有那么多的时间去训练呢？</p><p>就算我有时间，我应该怎么去训练这些思维模型和知识呢？</p><p>《助推》：如果我们想要持续的产生一个行为，那么外部的环境影响是非常重要的。</p><p>也就是说：不同的环境会影响我们某个行为产生的频率。而不断的练习和反省训练思维模型和专业技能也需要这样一个助推的环节。你需要设计一个场景，能够不断的触发我们反省思考</p><p>一个非常重要的工具：《反思日记》。提高我们成长进步斜率的杠杆点</p><h3 id="核心算法1-对标练习"><a href="#核心算法1-对标练习" class="headerlink" title="核心算法1-对标练习"></a>核心算法1-对标练习</h3><p>在日常生活中，经常碰到的一个问题是，学习了一个思维模型或者一些我们觉得非常有用的知识点之后，找不到使用的场景。也就是说，我们学的这些知识和我们是脱节的。</p><p><strong>核心问题：</strong>不是学习的这个思维模型不起作用，而是我们看不到它如何起作用。</p><p>对标：把思维模型当做思考问题的标准。寻找可以用思维模型的场景。</p><h3 id="核心算法2-举一反三"><a href="#核心算法2-举一反三" class="headerlink" title="核心算法2-举一反三"></a>核心算法2-举一反三</h3><p>学习了一个思维模型之后，至少在3个以上的不同场景中练习应用。</p><p>你必须找到不同的场景去运用同一个思维模型，如果找不到，说明还是不理解这个事情。</p><h2 id="七星笔记法"><a href="#七星笔记法" class="headerlink" title="七星笔记法"></a>七星笔记法</h2><p>目的：事先人为的描述整体全局框架的关键点，在过程中，填充着7个关键点，填充完了之后，这个框架也就描绘出来了。也就是说，用你的学习的思维模型去学习其他思维模型</p><p>在学习做记笔记的时候，7个星星，也就是7个问题。上课或者学习的时候就是回答这7个问题，当这7个问题回答完了，那么笔记也记完了</p><ul><li>这门课的目的是什么？也就是：为什么要学习它，它解决什么问题？</li><li>这门课的核心观点和内容是什么？</li><li>目的和这些核心观点是怎么连接的？</li><li>老师或作者讲述的逻辑是什么？</li><li>我在听课学习的过程中，有哪些疑问（说的对吗）和启发（为什么能这么思考）的地方？</li><li>上面的这些疑问和启发背后的思维模型是什么？</li><li>有哪些事情可以让我直接就可以开始找应用场景并采取行动？</li></ul><p>一些说明：</p><ul><li>在学习之前，可以通过上网查资料等方式先了解下这门课，这个领域的核心框架是什么，之后在学习的时候去进行比较。</li><li>老师或者作者的逻辑和我自己理解的有什么差别，重要的不是知识点，重要的是为什么这么组织推演思考过程，为什么这么思考？</li></ul><h2 id="逻辑思维"><a href="#逻辑思维" class="headerlink" title="逻辑思维"></a>逻辑思维</h2><h3 id="star1-学习逻辑的目的"><a href="#star1-学习逻辑的目的" class="headerlink" title="star1:学习逻辑的目的"></a>star1:学习逻辑的目的</h3><p>通过学习逻辑思维的相关知识，提高我们在今后学习的时候，提取知识和梳理脉络的效率。最终目的是为了更好的构建思维模型。</p><h3 id="star2-逻辑思维的核心观点和内容"><a href="#star2-逻辑思维的核心观点和内容" class="headerlink" title="star2:逻辑思维的核心观点和内容"></a>star2:逻辑思维的核心观点和内容</h3><h4 id="什么是逻辑-知识和思考方法"><a href="#什么是逻辑-知识和思考方法" class="headerlink" title="什么是逻辑-知识和思考方法"></a>什么是逻辑-知识和思考方法</h4><p>知识：是问题的答案，比如人有一张嘴、2个耳朵；达尔文的进化论。</p><p>思考的方法：知识背后的。</p><p>举例来说：我们都学了达尔文的演化论，我们是要学习达尔文的演化论究竟说了什么东西吗？演化论里面，它的知识点有哪些吗？我们学习演化论其实是要琢磨这么一个事情：全人类都面对同一个大自然，但是有的人找出的是神造论，那么，为什么达尔文就偏偏能够解读出演化论这件事情，他是怎么找出这个<strong>视角</strong>、怎么从这个视角<strong>推论出道理</strong>、怎么证明这个道理。<font color="red">视角–&gt;道理–&gt;证明</font>。这个系列就是达尔文的思考方法。</p><p>逻辑就是：从找到角度进而论述道理，进而证明道理，这整条的脉络，运算机制就是逻辑。</p><p>总结一下，逻辑思维是分析思考事物的方法，帮我们找出知识的脉络。</p><h4 id="为什么要学逻辑？"><a href="#为什么要学逻辑？" class="headerlink" title="为什么要学逻辑？"></a>为什么要学逻辑？</h4><p>逻辑是每一个人先天就有的，我们常常会误认为不学习逻辑就没有逻辑。</p><p>我们身处其中却又不知自的逻辑通常有2个：</p><ul><li>逻辑1：归纳法。同一件事情，它的因果链条在不同的情况中，高频率的重复出现，我们自然而然的就会把它归纳起来，认为这就是一个道理。此蘑菇有毒。这个道理的整个过程是不需要进行推理的，只需要记忆就可以。</li><li>逻辑2：演绎推理法。例如祈祷这个事情，前提：有病是因为我冒犯了神灵。过程：向神灵沟通，就能够让他宽恕我的罪过。因此结论就是：求神能治病。这个就是演绎法（演绎推理法）的雏形。</li><li>补充：演绎推理是严格的逻辑推理，一般表现为大前提、小前提、结论的三段论模式：即从两个反映客观世界对象的联系和关系的判断中得出新的判断的推理形式。如：“自然界一切物质都是可分的，基本粒子是自然界的物质，因此，基本粒子是可分的。”演绎推理的基本要求是：一是大、小前提的判断必须是真实的；二是推理过程必须符合正确的逻辑形式和规则。演绎推理的正确与否首先取决于大前提的正确与否，如果大前提错了，结论自然不会正确。</li></ul><p>那么，既然逻辑是我们每一个人先天就有的，为什么我们还要学习逻辑呢？</p><p>2个原因：</p><ul><li>直观答案阻碍我们启动思考。只要我们对某一个疑问有了一个答案，那我们很自然的就会让我们的大脑停止思考。例如：学音乐的孩子比较乖。这个说法是不是有点因果倒置了？当我们开始进行推敲的时候，我们往往就能发现潜藏在背后的真正答案。</li><li>世界越来越复杂。很难直观的发现，我们现在的一个行为最终会造成什么样的后果。商场中，所有的决策，永远不会只有一个面的效果，所以我们需要让我们的视角更开阔，让判断更精密。</li></ul><p>头脑中拥有非常多的逻辑知识，不代表你的逻辑能力强。逻辑其实是一个能力，而不是知识</p><p>所以，学逻辑应该说是：<strong>锻炼我们先天既有的逻辑能力，让它变得更精准</strong></p><h4 id="如何启动触发逻辑"><a href="#如何启动触发逻辑" class="headerlink" title="如何启动触发逻辑"></a>如何启动触发逻辑</h4><p>也就是如何运用</p><p>人的大脑是分为两个部分的：</p><ul><li>理性思考。也就是逻辑思维。</li><li>感性直觉。人在碰到问题的时候，最直观的答案。</li></ul><p>人的大脑总是：先感性直觉，再决定要不要启动理性思考。理性思考往往滞后于感性直觉。</p><p>思考工具：为什么、凭什么？前提是方向的确定性。</p><p>4个判断：</p><ul><li>事实判断</li><li>功利判断</li><li>价值判断</li><li>审美判断。主要是感受</li></ul><p>我们在进行思考的时候，往往会有多个判断同时浮现，这个时候方向的确定就显得非常重要。</p><h4 id="提高逻辑的效率"><a href="#提高逻辑的效率" class="headerlink" title="提高逻辑的效率"></a>提高逻辑的效率</h4><h5 id="足够的信息-更多信息"><a href="#足够的信息-更多信息" class="headerlink" title="足够的信息-更多信息"></a>足够的信息-更多信息</h5><p>很多人认为，一个有逻辑的人，他找出的答案一定是正确的。这是不一定的</p><p>案例：例如四方形的面积等于长*宽。如果这个时候只是知道了长，那么是不能就算出面积的。</p><p>也就是说：逻辑思维要能给我们反馈一个准确的答案，还有一个重要的前提就是：我们注入的信息是足够丰富的。</p><p>也就是说表象要足够丰富，我们才能够进行抽象</p><h5 id="封装-更多观念"><a href="#封装-更多观念" class="headerlink" title="封装-更多观念"></a>封装-更多观念</h5><p>掌握更多封装的观念。一个就久经验证的道理，这个道理可以直接为我们所用，不用我们再去麻烦的推演的一套观念。</p><p>例如：勾股定理。供需关系。</p><h5 id="找出更多元的答案"><a href="#找出更多元的答案" class="headerlink" title="找出更多元的答案"></a>找出更多元的答案</h5><p>当我们习惯用一个方法来解决问题之后，就会不由自主的在下一次碰到同类问题的时候会重复沿用。</p><p>但是每一个问题或多或少都是不一样的。人不可能在同一条河中出现两次。</p><p>工具：类比思维。这个事情在其他领域有没有类似性质可以参考。把其他领域的解法引用进来帮助我们解决问题。</p><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>信息—&gt;逻辑—&gt;本质—&gt;逻辑—&gt;方法。</p><h3 id="star3-观点内容和目的是如何连接的？"><a href="#star3-观点内容和目的是如何连接的？" class="headerlink" title="star3:观点内容和目的是如何连接的？"></a>star3:观点内容和目的是如何连接的？</h3><p>目的-内容：</p><ul><li>了解逻辑思维。第一部分的知识和思考方法以及第二部分的为什么要学。说明了什么是逻辑思维，逻辑思维是分析思考事物的方法；以及学习逻辑思维对我们有什么影响，默认内置的2个逻辑思维不够不能满足实际的需求，因为直观答案阻碍我们并且当今世界越来越复杂。</li><li>掌握逻辑思维。首先确定思考的方向，然后使用工具：为什么？凭什么？</li><li>更高效的使用逻辑思维。信息、可以直接调用的封装框架，多元角度。</li></ul><h3 id="star4-讲述的逻辑是什么样的？"><a href="#star4-讲述的逻辑是什么样的？" class="headerlink" title="star4:讲述的逻辑是什么样的？"></a>star4:讲述的逻辑是什么样的？</h3><p><strong>讲述的顺序：</strong></p><ul><li>简介学习的目的</li><li>介绍核心观点和内容(是什么、为什么、怎么做、如何提高)</li></ul><h3 id="star5-有哪些启发点和疑问点"><a href="#star5-有哪些启发点和疑问点" class="headerlink" title="star5:有哪些启发点和疑问点"></a>star5:有哪些启发点和疑问点</h3><p>启发点：主要是在为什么要学习逻辑这一个部分。介绍了我们已经被内置的2个逻辑，也就是归纳法和演绎推理法。但是这2个先天的逻辑在没有经过训练强化的情况下不能满足我们的使用需求，所以我们要做的事情其实上是强化锻炼我们的先天逻辑，让它变得更精准。而不是所谓的创建逻辑思维，它本身就是存在的。</p><h3 id="star6-这些启发点和疑问点背后的本质和思维模型是什么？"><a href="#star6-这些启发点和疑问点背后的本质和思维模型是什么？" class="headerlink" title="star6:这些启发点和疑问点背后的本质和思维模型是什么？"></a>star6:这些启发点和疑问点背后的本质和思维模型是什么？</h3><p>我的理解：其实逻辑还是算是思维模型体系中的一个部分，并不是独立存在的。逻辑其实是我们做决策的一个依据，也就是处理一个事情的脉络，也就是抽象后的单个或多个思维模型的组合。</p><p>而逻辑能力是发现和从构建思维模型的能力。</p><h3 id="star7-有哪些我可以直接运用的应用场景？"><a href="#star7-有哪些我可以直接运用的应用场景？" class="headerlink" title="star7:有哪些我可以直接运用的应用场景？"></a>star7:有哪些我可以直接运用的应用场景？</h3><p>思维模型的抽象有一个前提，就是需要输入大量的具象的信息，有了大量的具象信息之后我们才能进行抽象，依靠唯心主义，凭空创造是不可取的。</p><p>总结：这个逻辑思维的内容部分，我学习完了之后其实是没有多少收获的，说的都是我已经知道的内容，但是在没学之前又生怕错过了什么。如果对你有启发，那就最好。</p><h1 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h1><p>当经历了输入和内化之后，就只剩下输出了。</p><p>在很多人看到，输出很简单，通过文章或者讲解把自己的要表达的这些内容说抛出来就完成了。</p><p>但是，行百里者半九十！良好的输出和输入及内化同等重要！</p><p>但是，行百里者半九十！良好的输出和输入及内化同等重要！</p><p>但是，行百里者半九十！良好的输出和输入及内化同等重要！</p><p>重要的事情说三遍！</p><p>一般人在进行输出的时候，往往是采取：是什么？、为什么？、怎么做？这么3个问题来展开。这种方式有其一定的科学道理，但并不是任何场景都试用的，这些还是在表象层面，我们要做的，是真正的发掘更本质的东西。</p><p>因此，我个人思考得出的观点是在输出的时候，有没有想过一下这些问题：</p><ul><li>说的对吗？你是否正确的把你要表达的内容输出出来了？是否达到了本次输出的目的？</li><li>听/看完了吗？信息接受者有没有真的听或看完你的内容？为什么不能坚持？是输出的方式有问题还是输出结构还是什么问题？</li><li>听/看懂了吗？信息接受者有没有理解你表达出来的内容。</li><li>是科学的吗？<ul><li>你的输出方式是不是合理科学的？有时间的控制还是任意发挥?</li><li>在阐述一些其他人没有接触过的新知识的时候，有没有更好的方法帮助他人吸收？</li><li>输出介质（文章、图片、视频等）的组织结构是否清晰易读，内容是否重点突出（最终的目的是为了更好的理解），是否可以学习下写作技巧等科学的方法进行提升</li></ul></li></ul><p>下面我们进行拆分讲解。</p>]]></content>
    
    <summary type="html">
    
      如何输出和输出
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="认知升级" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/"/>
    
      <category term="学习方法" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
    
      <category term="学习方法" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>如何自学计算机科学</title>
    <link href="http://yoursite.com/2018/12/31/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    <id>http://yoursite.com/2018/12/31/IT科学技术知识体系结构-Linux运维方向/IT基础知识/如何自学计算机科学/如何自学计算机科学/</id>
    <published>2018-12-31T08:49:42.000Z</published>
    <updated>2018-12-31T08:49:42.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1>]]></content>
    
    <summary type="html">
    
      “自学计算机科学“这个系列的文章将会是我工作经验的输出和对IT领域知识领悟后的抽象和提炼，可以说将会包含我个人最核心的思想（就计算机科学这一学科来说）。《如何自学计算机科学》这篇文章，后续如果记录的内容较多时可能会进行拆分；同样的，《IT技术学习网站及学习资料汇总》这篇文章可能也会进行拆分。但是不管怎么样，都是统一归类到“自学计算机科学“这一个系列当中
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="IT基础知识" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="如何自学计算机科学" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
      <category term="计算机科学" scheme="http://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>IT技术学习网站及学习资料汇总</title>
    <link href="http://yoursite.com/2018/12/31/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/IT%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99%E5%8F%8A%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB/"/>
    <id>http://yoursite.com/2018/12/31/IT科学技术知识体系结构-Linux运维方向/IT基础知识/如何自学计算机科学/IT技术学习网站及学习资料汇总/</id>
    <published>2018-12-31T08:46:00.000Z</published>
    <updated>2018-12-31T08:46:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>本文有2个目的：</p><ul><li>记录同级目录下的另一篇文章：《如何自学计算机科学》中所提及的资料，便于检索查找。</li><li>记录在学习及工作中所涉及到的相关网站或者书籍资料等。同样的，也是为了便于检索查找。</li></ul><p>文章内容的一些说明：</p><ul><li>我会尽量说明资料的类型以及对应的作者。这一点也是非常重要的，IT领域经过这么多年的快速发展，资料重名已经是不可避免的了，所以有必要提及作者。</li><li>如果一些书籍存在多个译本，那么我会尽量说明哪一个译本的质量最高（因为是以我个人为主，所以仅供参考）。毕竟如果不能直接看英语的原版，那么对知识的吸收理解以及内化程度和翻译者的水平成正相关。高质量的译本和低质量的相差真的是非常之大</li><li>如果一些书我看过并且有做记录笔记的话，将会在我的另一个目录《个人知识体系》的读书笔记下</li></ul><p>这篇文章的内容其实可以做成一个图形的导航界面，只是当前时间没有这个能力，后续我会实现这个的。</p><h1 id="技术社区类网站"><a href="#技术社区类网站" class="headerlink" title="技术社区类网站"></a>技术社区类网站</h1><p>纯IT技术类：</p><ul><li><a href="https://www.csdn.net/" target="_blank" rel="noopener">csdn</a></li><li><a href="http://edu.51cto.com/" target="_blank" rel="noopener">51cto</a></li><li><a href="http://bbs.chinaunix.net/" target="_blank" rel="noopener">ChinaUnix技术论坛</a></li><li><a href="http://www.cnblogs.com/" target="_blank" rel="noopener">博客园</a></li><li><a href="https://www.oschina.net/" target="_blank" rel="noopener">开源中国</a></li><li><a href="http://www.178linux.com/" target="_blank" rel="noopener">Linux运维部落</a></li><li><a href="http://www.yunweipai.com/" target="_blank" rel="noopener">运维派</a></li><li><a href="https://segmentfault.com/" target="_blank" rel="noopener">SegmentFault</a></li><li><a href="https://stackoverflow.com/" target="_blank" rel="noopener">StackOverflow</a></li></ul><p>其他的像知乎什么的，上面的也有非常多的IT方面的知识可以学习</p><h1 id="工具类网站"><a href="#工具类网站" class="headerlink" title="工具类网站"></a>工具类网站</h1><h1 id="学习网站汇总"><a href="#学习网站汇总" class="headerlink" title="学习网站汇总"></a>学习网站汇总</h1><p>网站汇总如下：</p><ul><li><p><a href="https://www.shiyanlou.com/" target="_blank" rel="noopener">实验楼</a></p><p>还是比较有特色，提供的不是视频，而是配置好的虚拟机，注重实践，通过虚拟的实验环境，可以边看文档边动手操作</p></li><li><p><a href="http://www.runoob.com/" target="_blank" rel="noopener">菜鸟教程</a></p><p>它以<strong>文档教程和查询参考手册为主</strong>。看文档理解稍微费劲点，但相比视频教程，可以节省很多时间。</p></li><li><p><a href="https://www.imooc.com/" target="_blank" rel="noopener">慕课网</a></p><p>课程主要针对目前很热门的职业和内容，整体质量也不错</p></li><li><p><a href="https://www.jisuanke.com/" target="_blank" rel="noopener">计蒜课</a></p><p>不是单纯的为求职快速上手而培训，偏向于真正培养IT技术人才</p></li><li><p><a href="https://www.jikexueyuan.com/" target="_blank" rel="noopener">极客学院</a></p></li><li><p><a href="http://www.51zxw.net/" target="_blank" rel="noopener">我要自学网</a></p><p>比较久的一个网站，学习一些基础类的还可以</p></li><li><p><a href="http://study.163.com" target="_blank" rel="noopener">网易云课堂</a></p></li><li><p><a href="https://ke.qq.com/" target="_blank" rel="noopener">腾讯课堂</a></p></li><li><p><a href="https://open.163.com/" target="_blank" rel="noopener">网易公开课</a></p></li><li><p><a href="http://www.w3school.com.cn/" target="_blank" rel="noopener">W3School</a></p><p>W3School 是因特网上最大的 WEB 开发者资源，主要针对web开发，重点在前端</p></li><li><p><a href="https://www.ichunqiu.com/" target="_blank" rel="noopener">i 春秋</a></p><p>主要是安全方面</p></li><li><p><a href="https://www.khanacademy.org/" target="_blank" rel="noopener">可汗学院</a></p></li><li><p><a href="https://link.jianshu.com/?t=http://ocw.mit.edu/" target="_blank" rel="noopener">麻省理工开放式课程计划(MIT OpenCourseWare | Free Online Course Materials)</a></p></li><li><p><a href="https://link.jianshu.com/?t=https://www.edx.org/" target="_blank" rel="noopener">edX | Free online courses from the world’s best universities</a></p><p>edX是麻省理工和哈佛大学于2012年4月联手创建的大规模开放在线课堂平台。它免费给大众提供大学教育水平的在线课堂。两所大学在这个非盈利性计划各资助三千万美元。2012年秋天，edX在MITx启动。</p></li></ul><h1 id="学习资料汇总"><a href="#学习资料汇总" class="headerlink" title="学习资料汇总"></a>学习资料汇总</h1><h2 id="科普"><a href="#科普" class="headerlink" title="科普"></a>科普</h2><h3 id="计算机科学历史及基础知识科普"><a href="#计算机科学历史及基础知识科普" class="headerlink" title="计算机科学历史及基础知识科普"></a>计算机科学历史及基础知识科普</h3><ul><li>书籍《浪潮之巅》。作者吴军。这本真的是入门必读经典。</li></ul><h2 id="网络知识科普"><a href="#网络知识科普" class="headerlink" title="网络知识科普"></a>网络知识科普</h2><h2 id="数据库技术"><a href="#数据库技术" class="headerlink" title="数据库技术"></a>数据库技术</h2><h3 id="nosql"><a href="#nosql" class="headerlink" title="nosql"></a>nosql</h3><ul><li>书籍《Redis运维与开发》。搜狐视频团队出品，其还开源了cachecloud云平台。不错的一本好书。</li></ul>]]></content>
    
    <summary type="html">
    
      “自学计算机科学“这个系列的文章将会是我工作经验的输出和对IT领域知识领悟后的抽象和提炼，可以说将会包含我个人最核心的思想（就计算机科学这一学科来说）。《如何自学计算机科学》这篇文章，后续如果记录的内容较多时可能会进行拆分；同样的，《IT技术学习网站及学习资料汇总》这篇文章可能也会进行拆分。但是不管怎么样，都是统一归类到“自学计算机科学“这一个系列当中
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="IT基础知识" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="如何自学计算机科学" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
    
      <category term="计算机科学" scheme="http://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
</feed>
