<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Watchmen1992&#39;s Blog</title>
  
  <subtitle>锦瑟年华当与书香为度，是为不负天地人生。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-17T05:21:24.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>XiaoHua WANG</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Zookeeper</title>
    <link href="http://yoursite.com/2018/04/17/Zookeeper/"/>
    <id>http://yoursite.com/2018/04/17/Zookeeper/</id>
    <published>2018-04-17T05:21:24.000Z</published>
    <updated>2018-04-17T05:21:24.000Z</updated>
    
    <summary type="html">
    
      Zookeeper从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Zookeeper" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Zookeeper/"/>
    
    
      <category term="Zookeeper" scheme="http://yoursite.com/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Logstash</title>
    <link href="http://yoursite.com/2018/04/17/Logstash/"/>
    <id>http://yoursite.com/2018/04/17/Logstash/</id>
    <published>2018-04-17T05:21:00.000Z</published>
    <updated>2018-04-17T05:21:00.000Z</updated>
    
    <summary type="html">
    
      Logstash从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Logstash" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Logstash/"/>
    
    
      <category term="Logstash" scheme="http://yoursite.com/tags/Logstash/"/>
    
  </entry>
  
  <entry>
    <title>Kibana</title>
    <link href="http://yoursite.com/2018/04/17/Kibana/"/>
    <id>http://yoursite.com/2018/04/17/Kibana/</id>
    <published>2018-04-17T05:20:54.000Z</published>
    <updated>2018-04-17T05:20:54.000Z</updated>
    
    <summary type="html">
    
      Kibana从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Kibana" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Kibana/"/>
    
    
      <category term="Kibana" scheme="http://yoursite.com/tags/Kibana/"/>
    
  </entry>
  
  <entry>
    <title>Filebeat</title>
    <link href="http://yoursite.com/2018/04/17/Filebeat/"/>
    <id>http://yoursite.com/2018/04/17/Filebeat/</id>
    <published>2018-04-17T05:20:23.000Z</published>
    <updated>2018-04-17T05:20:23.000Z</updated>
    
    <summary type="html">
    
      Filebeat从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Filebeat" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Filebeat/"/>
    
    
      <category term="Filebeat" scheme="http://yoursite.com/tags/Filebeat/"/>
    
  </entry>
  
  <entry>
    <title>Kafka</title>
    <link href="http://yoursite.com/2018/04/17/Kafka/"/>
    <id>http://yoursite.com/2018/04/17/Kafka/</id>
    <published>2018-04-17T05:20:18.000Z</published>
    <updated>2018-04-17T05:20:18.000Z</updated>
    
    <summary type="html">
    
      Kafka从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Kafka" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://yoursite.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Flume</title>
    <link href="http://yoursite.com/2018/04/17/Flume/"/>
    <id>http://yoursite.com/2018/04/17/Flume/</id>
    <published>2018-04-17T05:20:12.000Z</published>
    <updated>2018-04-17T05:20:12.000Z</updated>
    
    <summary type="html">
    
      Flume从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Flume" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Flume/"/>
    
    
      <category term="Flume" scheme="http://yoursite.com/tags/Flume/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch</title>
    <link href="http://yoursite.com/2018/04/17/Elasticsearch/"/>
    <id>http://yoursite.com/2018/04/17/Elasticsearch/</id>
    <published>2018-04-17T05:16:22.000Z</published>
    <updated>2018-04-17T05:16:22.000Z</updated>
    
    <summary type="html">
    
      Elasticsearch从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Elasticsearch" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://yoursite.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>ELK架构之Filebeat+kafka+logstash+Elasticsearch</title>
    <link href="http://yoursite.com/2018/04/17/ELK%E6%9E%B6%E6%9E%84%E4%B9%8BFilebeat-kafka-logstash-Elasticsearch/"/>
    <id>http://yoursite.com/2018/04/17/ELK架构之Filebeat-kafka-logstash-Elasticsearch/</id>
    <published>2018-04-17T02:06:21.000Z</published>
    <updated>2018-04-17T02:06:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-3.png" alt="流程图"></p><p><strong>组件关系说明：</strong></p><p>logstash 和filebeat都具有日志收集功能，filebeat更轻量，占用资源更少，但logstash 具有filter功能，能过滤分析日志。一般结构都是filebeat采集日志，然后发送到消息队列，redis，kafaka。然后logstash去获取，利用filter功能过滤分析，然后存储到elasticsearch中</p><p>filebeat–&gt;kafka集群–&gt;logstash–&gt;(file server文件系统|kafka集群|ES集群)</p><ul><li>Filebeat    日志收集</li><li>kafka        日志接受消息队列</li><li>logstash    将日志进行过滤分析后存储到ES</li><li>ES        存储，检索，分析</li></ul><h1 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a><font color="red">Filebeat</font></h1><h2 id="1-filebeat基础知识"><a href="#1-filebeat基础知识" class="headerlink" title="1. filebeat基础知识"></a>1. filebeat基础知识</h2><blockquote><p>Filebeat consists of two main components: <code>prospectors and harvesters.</code></p><p>These components work together to <code>tail files</code> and send event data to the output that you specify.</p></blockquote><ul><li><p>prospectors:勘探者；探矿者【也就是数据变化的探测者，也就是入向配置】</p></li><li><p>harvesters：收割机；收获者【也就是数据的下游接收端，也就是出向配置】</p></li><li><p>spooler：处理程序；【处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。】</p></li></ul><p>Filebeat工作流程：</p><blockquote><p>当你开启filebeat程序的时候，它会启动一个或多个探测器（prospectors）去检测你指定的日志目录或文件，对于探测器找出的每一个日志文件，filebeat启动收割进程（harvester），每一个收割进程读取一个日志文件的新内容，并发送这些新的日志数据到处理程序（spooler），处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。</p></blockquote><p>流程图如下：</p><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-2.png" alt="流程图"></p><h3 id="1-1-What-is-harvester"><a href="#1-1-What-is-harvester" class="headerlink" title="1.1 What is harvester?"></a>1.1 What is harvester?</h3><blockquote><p>A harvester is responsible for reading the content of a single file. The harvester reads each file, line by line, and sends the content to the output. One harvester is started for each file. T<code>he harvester is responsible for opening and closing the file</code>, which means that the file descriptor remains open while the harvester is running. If a file is removed or renamed while it’s being harvested, Filebeat continues to read the file. This has the side effect that the space on your disk is reserved until the harvester closes. By default, Filebeat keeps the file open until close_inactive is reached.</p><p>Closing a harvester has the following consequences:【关闭时按以下顺序依`次执行，也就是关闭顺序】</p></blockquote><ul><li><p>The file handler is closed, freeing up the underlying resources if the file was deleted while the harvester was still reading the file.<br>The</p></li><li><p>harvesting of the file will only be started again after scan_frequency has elapsed.</p></li></ul><ul><li>If the file is moved or removed while the harvester is closed, harvesting of the file will not continue.</li></ul><p>To control when a harvester is closed, use the close_* configuration options.</p><p>harvester负责打开和关闭文件</p><p>当harvester捕获到一个文件之后，这个文件被删除或者重命名，它将继续读取这个文件。【副作用是占用磁盘空间直到harvester进程关闭】</p><h3 id="1-2-What-is-prospector"><a href="#1-2-What-is-prospector" class="headerlink" title="1.2 What is prospector?"></a>1.2 What is prospector?</h3><blockquote><p>A prospector is responsible for managing the harvesters and finding all sources to read from.</p><p>If the input type is log, the prospector finds all files on the drive that match the defined glob paths and starts a harvester for each file. Each prospector runs in its own Go routine.</p><p>The following example configures Filebeat to harvest lines from all log files that match the specified glob patterns:</p></blockquote><pre><code>filebeat.prospectors:- type: log  paths:    - /var/log/*.log    - /var/path2/*.log</code></pre><p>prospector负责管理harvesters进程以及寻找需要去读取的资源（input设置）</p><p>Filebeat的input type当前有两种设置：<code>log和stdin</code></p><blockquote><p>The log prospector checks each file to see whether a harvester needs to be started, whether one is already running, or whether the file can be ignored (see ignore_older).<br><code>New lines are only picked up if the size of the file has changed since the harvester was closed.</code></p></blockquote><p>注意，Filebeat只能读取本地的文件，也就是需要在每个日志产生端都安装：<br><strong>Filebeat prospectors can only read <code>local files</code>. There is no functionality to connect to remote hosts to read stored files or logs.</strong></p><h3 id="1-3-How-does-Filebeat-keep-the-state-of-files"><a href="#1-3-How-does-Filebeat-keep-the-state-of-files" class="headerlink" title="1.3 How does Filebeat keep the state of files"></a>1.3 How does Filebeat keep the state of files</h3><p>filebeat通过定期去刷新，将状态落地到磁盘的注册文件中，以这种形式来保持文件检测状态</p><blockquote><p>Filebeat keeps the state of each file and frequently flushes the state to disk in the registry file</p><p>The state is used to remember the last offset a harvester was reading from and to ensure all log lines are sent</p></blockquote><p>filebeat的状态信息记录的是最新的读取偏移量，如果下游的接受者（ES、kafka、logstash等不可达），filebeat将会保持这种状态，当检测后可达之后将会重新发送</p><p>当filebeat重启时，将会重新构建这个注册文件</p><p>每个prospector针对每个文件都会保持一个状态，也就是一个注册文件，因为文件可能会被删除或者重命名</p><p>针对每个文件，filebeat存储一个唯一的标识符去发现该文件之前是否有被收集过</p><blockquote><p>For each file, Filebeat stores unique identifiers to detect whether a file was harvested previously.</p></blockquote><h3 id="1-4-how-does-Filebeat-ensure-at-least-once-delivery"><a href="#1-4-how-does-Filebeat-ensure-at-least-once-delivery" class="headerlink" title="1.4 how does Filebeat ensure at-least-once delivery?"></a>1.4 how does Filebeat ensure at-least-once delivery?</h3><p>Filebeat保证一个事件的完整及正确性，它将发送最少一次给设置的下游输出，以保证没有数据丢失。</p><blockquote><p>Filebeat guarantees that events will be delivered to the configured output at least once and with no data loss.</p><p>Filebeat is able to achieve this behavior because it stores the delivery state of each event in the registry file.</p></blockquote><p>Filebeat能够保证这种特性的原因是因为它将分发状态也存储在这个注册文件中。</p><p>当下游因为阻塞或者其他原因，没有对某一个事件进行确认的时候，filebeat将一直尝试去发送这个事件，直到收到ACK</p><blockquote><p>If Filebeat shuts down while it’s in the process of sending events, it does not wait for the output to acknowledge all events before shutting down. Any events that are sent to the output, but not acknowledged before Filebeat shuts down, are sent again when Filebeat is restarted. This ensures that each event is sent at least once, but you can end up with duplicate events being sent to the output. You can configure Filebeat to wait a specific amount of time before shutting down by setting the<code>shutdown_timeout</code> option.</p></blockquote><p>当Filebeat异常关闭，再次启动的时候，它将会重新发送没有接受到ACk的事件。通过这种机制来保证每个事件至少发送一次。</p><p>因此，为了减少重新发送event事件的次数，可以通过设置shutdown_timeout参数来设置当filebeat关闭时，等待多少时间之后再关闭进程，以保证收到尽量多的ACK</p><p>注意：虽然拥有这种机制来保证数据的不丢失，但还是存在一些可能的情况导致数据的丢失（日志轮转和删除文件时）</p><p>例如：</p><ul><li><p>If log files are written to disk and rotated faster than they can be processed by Filebeat 【当日志刚好触发到日志轮转条件时，并且此时filebeat还没有来得及收集的时候，原因是inode节点发生变化】</p></li><li><p>if files are deleted while the output is unavailable 【当该文件被删除时，并且输出不可用时】</p></li></ul><p><strong>总结：filebeat会维护一个注册文件【是落地到磁盘中的】，该注册文件中包含2个信息</strong></p><ul><li>所发送事件的偏移量，精确记录当前的发送情况。        下游断开时，将保持直到连接后再发送</li><li>发送事件的ACk，记录发送事件的接受情况。            没有收到，将一直持续发送。</li></ul><h2 id="2-Filebeat安装部署配置启动"><a href="#2-Filebeat安装部署配置启动" class="headerlink" title="2. Filebeat安装部署配置启动"></a>2. Filebeat安装部署配置启动</h2><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><pre><code>curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.3-x86_64.rpmrpm -vih filebeat-6.2.3-x86_64.rpm</code></pre><h3 id="2-2-编辑配置文件"><a href="#2-2-编辑配置文件" class="headerlink" title="2.2 编辑配置文件"></a>2.2 编辑配置文件</h3><p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/directory-layout.html#_docker" target="_blank" rel="noopener">配置文件生成规则</a></p><p>安装完毕之后，配置文件路径：/etc/filebeat/filebeat.yml<br>参考配置文件为：filebeat.reference.yml</p><p>这里采用的是rpm包方式安装，因此生成规则如下：</p><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-1.png" alt="生成规则"></p><p>filebeat.yml整个配置文件分为几个部分，分别是：</p><ul><li>Modules configuration</li><li>Filebeat prospectors【上游输入设置。这部分包含内容为：type设置|path路径设置，】</li><li>Filebeat autodiscover</li><li>Filebeat global options</li><li>General</li><li>Elastic Cloud</li><li>Outputs【下游输出设置。这部分内容为：ES|kafka|logstash|】</li><li>Paths</li><li>Dashboards</li><li>Template</li><li>Logging</li><li>Xpack Monitoring【xpack监控】</li><li>HTTP Endpoint</li></ul><p>让我们来配置filebeat：</p><p><strong>1、定义你的日志文件的路径（一个或多个）</strong></p><p>对于大多数的基本filebeat配置，你可以定义一个单一探测器针对一个单一的路径，例如：</p><pre><code>filebeat.prospectors:- input_type: log  paths:    - /var/log/*.log</code></pre><p>在这个例子中，探测器会收集/var/log/*.log的所有匹配文件，这意味这filebeat会手机所有的/var/log下以.log结尾的文件，此处还支持Golang Glob支持的所有模式。</p><p>在预定义级别的子目录中获取所有文件，可以使用这个配置：/var/log/<em>/</em>.log，这会找到/var/log下所有子目录中所有的以.log结尾的文件。但它并不会找到/var/log文件夹下的以.log结尾的文件。现在它还不能递归的在所有子目录中获取所有的日志文件。</p><p>如果你设置输出到elasticsearch中，那么你需要在filebeat的配置文件中设置elasticsearch的IP地址与端口。</p><pre><code>output.elasticsearch:  hosts: [&quot;192.168.1.42:9200&quot;]</code></pre><p>如果你设置输出到logstash|kafka等其他程序，那么请参考配置。例如下方</p><pre><code>output.logstash:  hosts: [&quot;127.0.0.1:5044&quot;]</code></pre><p>完整的一个参考案例：</p><pre><code>filebeat.prospectors:- input_type: log            #类型选择log|stdin中的log，在filebeat最新版本中input_type写成type  paths:    - /home/appdeploy/deploy/logs/pinpoint/*-pinpoint.log  document_type: tools.pinpoint.data              scan_frequency: 5s            #prospector每隔5秒去检测日志的生成情况  tail_files: true                #设置之后，filebeat读取新文件时从文件末尾开始读取，而不是开头，如果设置了日志轮转，那么新文件的第一行将会被忽略output.kafka:                    #输出策略采用kafka   hosts: [&quot;10.10.10.92:9092&quot;, &quot;10.10.10.93:9092&quot;, &quot;10.10.10.94:9092&quot;]        #kafka集群的配置信息   topic: &apos;%{[type]}&apos;            #设置topic使用文件类型   partition.round_robin:        #Topic的分区算法     reachable_only: false        # 如果设置为true，那么event将只会推送到leader上，默认设置就是false   required_acks: 1                #ACk可靠性级别，0表示不响应，1表示本地commit，-1表示所有的副本commit。默认为1   compression: gzip            # 设置输出压缩编解码器，可选snappy and gzip。默认就是gzip   max_message_bytes: 1000000    # JSON格式的信息一个传输允许的最大大小上限   codec.format:        string: &apos;%{[message]}&apos;</code></pre><h3 id="2-3-启动"><a href="#2-3-启动" class="headerlink" title="2.3 启动"></a>2.3 启动</h3><pre><code>service filebeat start</code></pre><h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h1><p>在这里，kafka的作用是将</p><p>kafka的配置【其中一台，除了id不同之外，其他均类似】</p><p>[root@qa-bigdata002 config]# egrep  -v ‘^#|^$’ <strong>server.properties</strong></p><pre><code>broker.id=0                # The id of the broker. This must be set to a unique integer for each broker，在一个kafka集群中，每个broker的ID必须不同port=9092host.name=172.24.80.87num.network.threads=3                    #The number of threads handling network requestsnum.io.threads=8                        # The number of threads doing disk I/O，将数据落地到磁盘的线程数量，一般为CPU核数的倍数socket.send.buffer.bytes=102400            #发送缓冲区的大小，单位是字节，这里是1Msocket.receive.buffer.bytes=102400        #接受缓冲区大小，这里是1Msocket.request.max.bytes=104857600        #最大接受的请求数量，防止OOM的出现，out of memory,这里设置为104Mlog.dirs=/home/kafka/kafka-logs            # 落地到磁盘的文件的存储路径num.partitions=2                        # 每个Topic的分区数量num.recovery.threads.per.data.dir=1        #在日志数据恢复时，log.retention.hours=168                    #日志保留小时数，这里的168小时，也就是保留7天。log.segment.bytes=1073741824            #单个日志的文件的最大大小，现在配置为1Glog.retention.check.interval.ms=300000    #每隔5分钟检测日志文件是否可以被删除log.cleaner.enable=false                #设置flase之后，日志保留策略将会采用上面的分段及超时设置，如果为true，zookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181    #ZK的配置zookeeper.connection.timeout.ms=600000            #连接ZK的超时时间</code></pre><p><strong>consumer.properties</strong></p><pre><code># Zookeeper connection string# comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;zookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181# timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000#consumer group idgroup.id=test-consumer-group</code></pre><p><strong>producer.properties</strong></p><pre><code># list of brokers used for bootstrapping knowledge about the rest of the cluster# format: host1:port1,host2:port2 ...metadata.broker.list=172.24.80.87:9092,172.24.80.88:9092,172.24.80.89:9092</code></pre><p><strong>zookeeper.properties</strong></p><pre><code># the directory where the snapshot is stored.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# disable the per-ip limit on the number of connections since this is a non-production configmaxClientCnxns=0</code></pre><h1 id="logstash"><a href="#logstash" class="headerlink" title="logstash"></a>logstash</h1><h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h1><h2 id="ES模板设置"><a href="#ES模板设置" class="headerlink" title="ES模板设置"></a>ES模板设置</h2><p>通过使用ES模板，可以有效的减轻存储压力<br>ES模板：通过对索引中的每个字段做事先的预定义数据类型（例如ID，name等分别使用存储空间最小的数据类型）</p>]]></content>
    
    <summary type="html">
    
      ELk日志处理平台架构的之Filebeat+kafka+logstash+Elasticsearch
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="ELk日志处理平台" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELk%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="Filebeat+kafka+logstash+Elasticsearch" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELk%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0/Filebeat-kafka-logstash-Elasticsearch/"/>
    
    
      <category term="ELK架构" scheme="http://yoursite.com/tags/ELK%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>异地多活机房建设</title>
    <link href="http://yoursite.com/2018/04/17/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9C%BA%E6%88%BF%E5%BB%BA%E8%AE%BE/"/>
    <id>http://yoursite.com/2018/04/17/异地多活机房建设/</id>
    <published>2018-04-17T01:30:16.000Z</published>
    <updated>2018-04-17T01:30:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言概述"><a href="#1-前言概述" class="headerlink" title="1. 前言概述"></a>1. 前言概述</h1><p>当前公司的核心应用都是运行在阿里云上，这种方式存在以下几个缺点：</p><ul><li>星型拓扑结构，所有压力都集中在一套系统之上，整体系统的高可用性还不够充分。新增IDC机房之后，可以将一部分流量引入到就近的云下机房。为核心系统减负，也就是说，同一个应用对应有多个生产环境。</li><li>的</li></ul><h1 id="1-1-思路"><a href="#1-1-思路" class="headerlink" title="1.1 思路"></a>1.1 思路</h1><p>整体思路：</p><ul><li>为什么？</li><li>是什么？</li><li>怎么做？</li></ul><h2 id="1-2-为什么？为什么需要异地机房？"><a href="#1-2-为什么？为什么需要异地机房？" class="headerlink" title="1.2 为什么？为什么需要异地机房？"></a>1.2 为什么？为什么需要异地机房？</h2><h2 id="1-3-是什么？-异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？"><a href="#1-3-是什么？-异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？" class="headerlink" title="1.3 是什么？ 异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？"></a>1.3 是什么？ 异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？</h2><h2 id="1-4-怎么做？-如何实现？"><a href="#1-4-怎么做？-如何实现？" class="headerlink" title="1.4 怎么做？ 如何实现？"></a>1.4 怎么做？ 如何实现？</h2><p>这部分内容将会在下面的章节进行具体的阐述。</p><h1 id="2-具体实施"><a href="#2-具体实施" class="headerlink" title="2. 具体实施"></a>2. 具体实施</h1>]]></content>
    
    <summary type="html">
    
      近期公司在进行异地机房的建设，在不涉及公司机密数据的前提下，在这里记录下整个过程，一方面是便于自己检索，另一方面是给有同样需求的网友一定参考。
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维架构" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/"/>
    
      <category term="异地多活" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB/"/>
    
    
      <category term="异地多活机房建设" scheme="http://yoursite.com/tags/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9C%BA%E6%88%BF%E5%BB%BA%E8%AE%BE/"/>
    
  </entry>
  
  <entry>
    <title>常用软件激活密钥</title>
    <link href="http://yoursite.com/2018/04/16/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    <id>http://yoursite.com/2018/04/16/常用软件激活密钥/</id>
    <published>2018-04-16T12:06:56.000Z</published>
    <updated>2018-04-16T12:06:56.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>vmware workstations 14 pro</strong></p><ul><li>CG54H-D8D0H-H8DHY-C6X7X-N2KG6 【亲测可用】</li></ul><ul><li>ZC3WK-AFXEK-488JP-A7MQX-XL8YF</li></ul><ul><li>AC5XK-0ZD4H-088HP-9NQZV-ZG2R4</li></ul><ul><li>ZC5XK-A6E0M-080XQ-04ZZG-YF08D</li></ul><ul><li>ZY5H0-D3Y8K-M89EZ-AYPEG-MYUA8</li></ul>]]></content>
    
    <summary type="html">
    
      常用软件激活密钥/序列号
    
    </summary>
    
      <category term="常用软件工具" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"/>
    
      <category term="常用软件激活密钥" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    
    
      <category term="软件激活密钥" scheme="http://yoursite.com/tags/%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    
  </entry>
  
  <entry>
    <title>Linux常用命令之curl命令</title>
    <link href="http://yoursite.com/2018/04/16/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2018/04/16/Linux常用命令/</id>
    <published>2018-04-16T02:57:34.000Z</published>
    <updated>2018-04-16T02:57:34.000Z</updated>
    
    <summary type="html">
    
      Linux常用命令之curl命令
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux基础知识" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="Linux常用命令" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="curl命令" scheme="http://yoursite.com/tags/curl%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>IT常用英语记录</title>
    <link href="http://yoursite.com/2018/04/16/%E5%B8%B8%E7%94%A8%E8%8B%B1%E8%AF%AD%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2018/04/16/常用英语记录/</id>
    <published>2018-04-16T01:23:49.000Z</published>
    <updated>2018-04-16T01:23:49.000Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th style="text-align:center">英语</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">side effect</td><td style="text-align:center">副作用</td></tr><tr><td style="text-align:center">properties</td><td style="text-align:center">性能，属性，性质，特性，财产</td></tr><tr><td style="text-align:center">involves</td><td style="text-align:center">包含，牵涉</td></tr><tr><td style="text-align:center">at-least-once</td><td style="text-align:center">至少一次</td></tr><tr><td style="text-align:center">deprecated</td><td style="text-align:center">弃用，废弃，不赞成的</td></tr><tr><td style="text-align:center">shipper</td><td style="text-align:center">托运人；发货人；货主</td></tr><tr><td style="text-align:center">prospectors</td><td style="text-align:center">勘探者；探矿者</td></tr><tr><td style="text-align:center">harvesters</td><td style="text-align:center">收割机；收获者</td></tr><tr><td style="text-align:center">layout</td><td style="text-align:center">布局；设计；安排；陈列</td></tr><tr><td style="text-align:center">keystore</td><td style="text-align:center">密钥库;文件;密码;签名文件</td></tr><tr><td style="text-align:center">permitted</td><td style="text-align:center">被允许的；允许</td></tr><tr><td style="text-align:center">individual</td><td style="text-align:center">个人的；个别的；独特的；个体</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      IT常用英语
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="英语" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%8B%B1%E8%AF%AD/"/>
    
    
      <category term="IT常用英语" scheme="http://yoursite.com/tags/IT%E5%B8%B8%E7%94%A8%E8%8B%B1%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>jumpserver安装部署及使用</title>
    <link href="http://yoursite.com/2018/04/13/jumpserver%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2018/04/13/jumpserver安装部署及使用/</id>
    <published>2018-04-13T07:13:23.000Z</published>
    <updated>2018-04-13T07:13:23.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-安装部署"><a href="#1-安装部署" class="headerlink" title="1. 安装部署"></a>1. 安装部署</h1><p>【注意：务必保证版本及操作一致】</p><p>参考链接：<a href="http://docs.jumpserver.org/zh/latest/step_by_step.html" target="_blank" rel="noopener">一步一步安装文档</a></p><h2 id="1-1-环境准备"><a href="#1-1-环境准备" class="headerlink" title="1.1 环境准备"></a>1.1 环境准备</h2><h3 id="1-1-1-安装依赖关系"><a href="#1-1-1-安装依赖关系" class="headerlink" title="1.1.1 安装依赖关系"></a>1.1.1 安装依赖关系</h3><pre><code>yum -y install wget sqlite-devel xz gcc automake zlib-devel openssl-devel epel-release git  libffi-devel python-devel</code></pre><p><strong>注意：python-deve需要安装对应的版本，我这里安装的是python36-devel</strong> </p><h3 id="1-1-2-建立python虚拟环境"><a href="#1-1-2-建立python虚拟环境" class="headerlink" title="1.1.2 建立python虚拟环境"></a>1.1.2 建立python虚拟环境</h3><p>使用原因：因为 CentOS 6/7 自带的是 Python2，而 Yum 等工具依赖原来的 Python，为了不扰乱原来的环境我们来使用 Python 虚拟环境</p><p><strong>如果服务器上没有python3.6.1+环境，则需要手动安装</strong></p><pre><code>$ wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tar.xz$ tar xvf Python-3.6.1.tar.xz  &amp;&amp; cd Python-3.6.1$ ./configure &amp;&amp; make &amp;&amp; make install$ cd /opt$ python3 -m venv py3$ source /opt/py3/bin/activate</code></pre><p><strong>看到下面的提示符代表成功，以后运行 Jumpserver 都要先运行以上 source 命令，以下所有命令均在该虚拟环境中运行</strong></p><pre><code>(py3) [root@localhost py3]</code></pre><p>在源码安装python3时可能会出现报错，关键字：“ake: <em>*</em> [Objects/unicodeobject.o] Error 4”。<br>这个时候，修改Makefile文件，把‘-DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes’中的‘03’改为‘02’，然后再重新编译安装即可。</p><h2 id="1-2-安装启动-jumpserver"><a href="#1-2-安装启动-jumpserver" class="headerlink" title="1.2 安装启动 jumpserver"></a>1.2 安装启动 jumpserver</h2><h3 id="1-2-1-下载jumpserver"><a href="#1-2-1-下载jumpserver" class="headerlink" title="1.2.1 下载jumpserver"></a>1.2.1 下载jumpserver</h3><pre><code>cd /opt git clone --depth=1 https://github.com/jumpserver/jumpserver.git &amp;&amp; cd jumpserver &amp;&amp; git checkout master</code></pre><p><strong>注意：不要安装在/root、/home 等目录下，以免权限问题</strong></p><h3 id="1-2-2-安装RPM依赖包"><a href="#1-2-2-安装RPM依赖包" class="headerlink" title="1.2.2 安装RPM依赖包"></a>1.2.2 安装RPM依赖包</h3><pre><code>cd requirementsyum -y install $(cat rpm_requirements.txt)</code></pre><h3 id="1-2-3-安装python库依赖"><a href="#1-2-3-安装python库依赖" class="headerlink" title="1.2.3 安装python库依赖"></a>1.2.3 安装python库依赖</h3><pre><code>pip install -r requirements.txt  # 不要指定-i参数，因为镜像上可能没有最新的包，如果没有任何报错请继续</code></pre><h3 id="1-2-4-安装-Redis-Jumpserver-使用-Redis-做-cache-和-celery-broke"><a href="#1-2-4-安装-Redis-Jumpserver-使用-Redis-做-cache-和-celery-broke" class="headerlink" title="1.2.4 安装 Redis, Jumpserver 使用 Redis 做 cache 和 celery broke"></a>1.2.4 安装 Redis, Jumpserver 使用 Redis 做 cache 和 celery broke</h3><pre><code>$ yum -y install redis$ service redis start</code></pre><h3 id="1-2-5-安装配置MySQL"><a href="#1-2-5-安装配置MySQL" class="headerlink" title="1.2.5 安装配置MySQL"></a>1.2.5 安装配置MySQL</h3><pre><code>create database jumpserver default charset &apos;utf8&apos;;grant all on jumpserver.* to &apos;jumpserver&apos;@&apos;127.0.0.1&apos; identified by &apos;Jumpserver_password_123&apos;;</code></pre><h3 id="1-2-6-修改jumpserver配置文件"><a href="#1-2-6-修改jumpserver配置文件" class="headerlink" title="1.2.6 修改jumpserver配置文件"></a>1.2.6 修改jumpserver配置文件</h3><pre><code>$ cd /opt/jumpserver$ cp config_example.py config.py$ vi config.py  # 我们计划修改 DevelopmentConfig中的配置，因为默认jumpserver是使用该配置，它继承自Config</code></pre><p><strong>注意: 配置文件是 Python 格式，不要用 TAB，而要用空格</strong></p><p>在该文件中新添加一个类</p><pre><code>class DevelopmentConfig(Config):    DEBUG = True    DB_ENGINE = &apos;mysql&apos;    DB_HOST = &apos;127.0.0.1&apos;    DB_PORT = 3306    DB_USER = &apos;jumpserver&apos;    DB_PASSWORD = &apos;somepassword&apos;    DB_NAME = &apos;jumpserver&apos;config = DevelopmentConfig()  # 确保使用的是刚才设置的配置文件，该行默认在文件末尾就存在。</code></pre><h3 id="1-2-7-生成数据库表结构和初始化结构"><a href="#1-2-7-生成数据库表结构和初始化结构" class="headerlink" title="1.2.7 生成数据库表结构和初始化结构"></a>1.2.7 生成数据库表结构和初始化结构</h3><pre><code>$ cd /opt/jumpserver/utils$ bash make_migrations.sh</code></pre><h3 id="1-2-8-运行jumpserver"><a href="#1-2-8-运行jumpserver" class="headerlink" title="1.2.8 运行jumpserver"></a>1.2.8 运行jumpserver</h3><pre><code>$ cd /opt/jumpserver$ python3 run_server.py all</code></pre><p>运行不报错，请浏览器访问 <a href="http://192.168.244.144:8080/" target="_blank" rel="noopener">http://192.168.244.144:8080/</a> (这里只是 Jumpserver, 没有 Web Terminal，所以访问 Web Terminal 会报错)</p><p>账号: admin 密码: admin</p><h1 id="2-jumpserver配置"><a href="#2-jumpserver配置" class="headerlink" title="2. jumpserver配置"></a>2. jumpserver配置</h1><h2 id="2-1-安装-SSH-Server-和-WebSocket-Server-Coco"><a href="#2-1-安装-SSH-Server-和-WebSocket-Server-Coco" class="headerlink" title="2.1 安装 SSH Server 和 WebSocket Server: Coco"></a>2.1 安装 SSH Server 和 WebSocket Server: Coco</h2><p>【此时还是在虚拟环境下】</p><pre><code>$ cd /opt$ git clone https://github.com/jumpserver/coco.git &amp;&amp; cd coco &amp;&amp; git checkout master</code></pre><h2 id="2-2-安装-Web-Terminal-前端-Luna"><a href="#2-2-安装-Web-Terminal-前端-Luna" class="headerlink" title="2.2  安装 Web Terminal 前端: Luna"></a>2.2  安装 Web Terminal 前端: Luna</h2><h1 id="3-常用命令"><a href="#3-常用命令" class="headerlink" title="3. 常用命令"></a>3. 常用命令</h1><p>启动 jumpserver</p><pre><code>/opt/jumpserver/service.sh start</code></pre><p>停止 jumpserver</p><pre><code>/opt/jumpserver/service.sh stop</code></pre><p>重启 jumpserver</p><pre><code>/opt/jumpserver/service.sh restart</code></pre><p>查看 jumpserver 状态</p><pre><code>/opt/jumpserver/service.sh status</code></pre><h1 id="4-配置优化-注意事项"><a href="#4-配置优化-注意事项" class="headerlink" title="4. 配置优化/注意事项"></a>4. 配置优化/注意事项</h1><p>配置文件路径：/opt/jumpserver/ jumpserver.conf、</p><p>配置如下：</p><pre><code>\[base]url = access_url（安装时配置）key = o57ev5oc1nwe44r4ip = 0.0.0.0port = 8000log = debug\[db]engine = mysqlhost = mysql_addr（安装时配置）port = 3306user = jumpserverpassword = password（安装时配置）database = jumpserver\[mail]mail_enable = 1email_host = smtp.163.comemail_port = 25email_host_user = name@163.com（安装时配置）email_host_password = password（安装时配置）email_use_tls = Falseemail_use_ssl = False\[connect]nav_sort_by = ip</code></pre><h2 id="问题-总结"><a href="#问题-总结" class="headerlink" title="问题/总结"></a>问题/总结</h2><p><strong>日志压缩删除</strong></p><p>访问服务器记录日志生成路径：/opt/jumpserver/logs/tty</p><p>需要定时压缩文件夹，并保留一段时间的历史日志</p><p>压缩文件夹命令：</p><pre><code>for i in `ls -d 201802*`; do tar czvf ${i}.tar.gz ${i}; done</code></pre><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>连接之后的终端页面如下所示：<br><img src="http://picture.watchmen.xin/jumpserver/jumpserver-1.png" alt="终端页面"></p>]]></content>
    
    <summary type="html">
    
      Jumpserver是全球首款完全开源的堡垒机，使用GNU GPL v2.0开源协议，是符合 4A 的专业运维审计系统。它使用Python / Django 进行开发，遵循 Web 2.0 规范，配备了业界领先的 Web Terminal 解决方案，交互界面美观、用户体验好。并且采纳分布式架构，支持多机房跨区域部署，中心节点提供 API，各机房部署登录节点，可横向扩展、无并发限制。
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维安全" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/"/>
    
      <category term="堡垒机" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/%E5%A0%A1%E5%9E%92%E6%9C%BA/"/>
    
    
      <category term="jumpserver" scheme="http://yoursite.com/tags/jumpserver/"/>
    
  </entry>
  
  <entry>
    <title>Zabbix结合Grafana实现炫酷动态可视化监控</title>
    <link href="http://yoursite.com/2018/04/04/Zabbix%E7%BB%93%E5%90%88Grafana%E5%AE%9E%E7%8E%B0%E7%82%AB%E9%85%B7%E5%8A%A8%E6%80%81%E5%8F%AF%E8%A7%86%E5%8C%96%E7%9B%91%E6%8E%A7/"/>
    <id>http://yoursite.com/2018/04/04/Zabbix结合Grafana实现炫酷动态可视化监控/</id>
    <published>2018-04-04T12:59:39.000Z</published>
    <updated>2018-04-04T12:59:39.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>来源：公众号-运维军团-《10分钟打造炫酷的监控大屏》</strong></p><h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>Grafana是一个开源的<code>数据展示工具</code>，是一个开箱即用的可视化工具，具有功能齐全的度量仪表盘和图形编辑器，有灵活丰富的图形化选项，可以混合多种风格，支持多个数据源，例如Graphite、InfluxDB、Mysql、Zabbix等等。虽然zabbix监控性能毋庸置疑，但zabbix图形显示过于简单、丑，因此利用zabbix作为数据源，结合Grafana作前端展示再好不过了。</p><p>重要的是Grafana的使用也超级简单，安装完成后登陆添加数据源即可，后面的事情就是添加图表等工作了。</p><h1 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h1><p>未更新完，待续</p>]]></content>
    
    <summary type="html">
    
      Zabbix结合Grafana实现炫酷动态可视化监控
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维监控体系" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/"/>
    
      <category term="zabbix" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/zabbix/"/>
    
    
      <category term="Grafana" scheme="http://yoursite.com/tags/Grafana/"/>
    
  </entry>
  
  <entry>
    <title>ditto常用操作</title>
    <link href="http://yoursite.com/2018/04/04/ditto%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2018/04/04/ditto常用操作/</id>
    <published>2018-04-04T09:11:37.000Z</published>
    <updated>2018-04-04T09:11:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Ditto 是一款开源、免费、强大的剪贴板增强工具。可以把复制过的所有内容保存起来（可以设定保存日期或条目总数），快捷地供后续调用。还可以合并粘贴，纯文本粘贴，支持分组、置顶、快速搜索、热键粘贴功能。并且，还可以通过网络共享剪贴板内容。</p><p>主页：<a href="http://ditto-cp.sourceforge.net/" target="_blank" rel="noopener">http://ditto-cp.sourceforge.net/</a></p><p>教程：<a href="http://xbeta.info/ditto.htm" target="_blank" rel="noopener">http://xbeta.info/ditto.htm</a></p><h1 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h1><p>平常情况下，Ditto只是系统托盘中的图标。按下热键（默认 ctrl+`）后，会出现的粘贴主界面；再点击右键会弹出功能丰富的菜单。</p><p>详细请参看教程</p>]]></content>
    
    <summary type="html">
    
      Ditto是一款免费剪贴板增强软件，能有效提高工作效率。
    
    </summary>
    
      <category term="常用软件工具" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Ditto" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/Ditto/"/>
    
    
      <category term="Ditto" scheme="http://yoursite.com/tags/Ditto/"/>
    
  </entry>
  
  <entry>
    <title>fences桌面</title>
    <link href="http://yoursite.com/2018/04/04/fences%E6%A1%8C%E9%9D%A2/"/>
    <id>http://yoursite.com/2018/04/04/fences桌面/</id>
    <published>2018-04-04T06:42:00.000Z</published>
    <updated>2018-04-04T06:42:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h1><p>目前的fences版本都是收费版本，可以下载免费版使用30天之后才酌情是否购买。<br><a href="https://www.stardock.com/products/fences/" target="_blank" rel="noopener">官网</a></p><p>早期Fences免费版本连接：<a href="https://page81.ctfile.com/file/115905479" target="_blank" rel="noopener">下载链接</a>【该版本不是太好用】</p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>fences的使用比较简单，这里介绍3点吧。</p><p>1、右键框选桌面空白处，即可出现桌面小区域。</p><p>这个应该大家都懂吧，基本功能。</p><p>2、桌面空白处双击鼠标左键，隐藏全部桌面图标</p><p>对桌面有洁癖的同学来说，这是个好福音。</p><p>3、设置好你的桌面区域后，可以锁定它们</p><p>当我们已经设置好桌面的区域后，可以将这些区域锁定，这样就无法再调整它们。</p><p>在桌面空白处右键鼠标，“查看”里选择“锁定fences”即可，这样你在桌面设置的这些fences小区域，就跟桌面“结合”在一起了，如果想要调整，取消勾选即可。</p>]]></content>
    
    <summary type="html">
    
      Fences是一款知名度非常高的windows系统桌面图标整理软件，被国外各大it媒体评为最能提高工作效率的软件之一。
    
    </summary>
    
      <category term="常用软件工具" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Fences" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/Fences/"/>
    
    
      <category term="fences" scheme="http://yoursite.com/tags/fences/"/>
    
  </entry>
  
  <entry>
    <title>listary常用操作</title>
    <link href="http://yoursite.com/2018/04/04/listary%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2018/04/04/listary常用操作/</id>
    <published>2018-04-04T05:11:47.000Z</published>
    <updated>2018-04-04T05:11:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><strong>官网</strong></p><p><a href="http://www.listary.com/" target="_blank" rel="noopener">官网链接</a></p><p><strong>网友文章</strong></p><p><a href="https://xuanwo.org/2015/07/28/listary/" target="_blank" rel="noopener">Listary——让文件在指尖流动</a></p><p><a href="https://www.iplaysoft.com/listary.html" target="_blank" rel="noopener">Listary Pro - 能极大幅度提高你 Windows 文件浏览与搜索速度效率的「超级神器」</a></p><h1 id="实际操作"><a href="#实际操作" class="headerlink" title="实际操作"></a>实际操作</h1><p><strong>常用快捷操作</strong></p><pre><code>ctrl敲2下    调出Listary窗口【可以在设置中设置第二种方式】左键双击        在文件夹中双击会调出Listary的收藏，最近文档等。在电脑页面输入e    即可定位到E盘，以此类推目录页面输入名称一部分   定位到该子目录或者文件ctrl+右键        针对选中内容进行动作【例如打开文件夹等】</code></pre><h2 id="智能匹配"><a href="#智能匹配" class="headerlink" title="智能匹配"></a>智能匹配</h2><p>只要输入文件名的一部分就可以找到这个文件，支持中文与英文。 比如，我输入测试 md就可以搜索到测XX试OO.md这个文件。 自然，输入的越多，返回的结果越精确。随着使用记录的积累，常用的文件或程序会获得更高的优先级。</p><h2 id="打开保存文件浏览对话框增强"><a href="#打开保存文件浏览对话框增强" class="headerlink" title="打开保存文件浏览对话框增强"></a>打开保存文件浏览对话框增强</h2><pre><code>Ctrl+G         在打开框中切换到上一次打开的目录Ctrl+O        直接打开上一次打开目录中的文件</code></pre>]]></content>
    
    <summary type="html">
    
      Listary是一款Windows文件搜索浏览增强工具，它为Windows自带的资源管理器添加了很多实用的功能，包括智能命令、最近文档以及收藏功能。与此同时，它还能与很多第三方应用集成，包括鼎鼎大名的Total Commander，还有WinRAR，7zip，FileZilla等等
    
    </summary>
    
      <category term="常用软件工具" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Listary" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/Listary/"/>
    
    
      <category term="Listary" scheme="http://yoursite.com/tags/Listary/"/>
    
  </entry>
  
  <entry>
    <title>简历内容应答</title>
    <link href="http://yoursite.com/2018/04/04/%E7%AE%80%E5%8E%86%E5%86%85%E5%AE%B9%E5%BA%94%E7%AD%94/"/>
    <id>http://yoursite.com/2018/04/04/简历内容应答/</id>
    <published>2018-04-04T00:40:36.000Z</published>
    <updated>2018-04-04T00:40:36.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0-自我介绍"><a href="#0-自我介绍" class="headerlink" title="0. 自我介绍"></a>0. 自我介绍</h2><p>面试官 早上/下午好 我叫汪小华 大学就读于晋中学院 网络工程专业。目前一共有三年工作经验，</p><p>实习和第一份工作都是在亿阳信通<br>在这期间从最基础的桌面运维干起，一直到最后独立接手负责了一个项目从0到1的这么一个整体过程，有很多的收获。这一期间对如何做好运维工作有了一些的感悟。</p><p>第二份工作是被内推到创世漫道，主要负责公司linux平台的调整，主要和我对接的是公司的架构师，因此在这个过程中对运维思想这方面有了很大的提升。</p><p>有关这两部分具体的内容我会在后面和您聊如何通过运维思想做好运维工作时谈及</p><p>我的优点是有一定的网络基础，平时喜欢问为什么，和同事交流谈论的时候喜欢拿纸笔写写画画。<br>最强的技能部分应该是进程管理，这一点我觉得对运维工作来说，至关重要，关于这部分稍后我们可以一块交流探讨。</p><p>我的缺点目前是如何将所学知识有机的结合成为一个整体，构成一张知识之网这种能力还不够，这一点也是在后续的工作中需要去刻意修炼的。</p><p>以上是我的自我介绍，今天我要应聘的岗位是Linux运维工程师，谢谢！</p><h2 id="1-发行版本区别及shell、python"><a href="#1-发行版本区别及shell、python" class="headerlink" title="1. 发行版本区别及shell、python"></a>1. 发行版本区别及shell、python</h2><p>这些发行版本本质上没有什么区别，都是类unix系统。<br>redhat的系统是免费的，但是他服务是收费的，并且有一些类似RHCS等服务只有收费版才支持。<br>而centos是redhat社区版本，国内使用较多，社区相当活跃。<br>SUSE也是分为两种，一种企业版本的SLES，一种是opensuse，sles主要是一些金融国企在使用，安全性较好，opensuse是社区版本，suse使用起来和centos相差不多，软件包形式使用源自redhat的rpm，但是管理工具使用的是zypper。<br>ubuntu源自于debain，国外使用的较多，也是相当热门的一个发型版本，在桌面领域有绝对技术优势，适合开发人员使用。</p><pre><code>**有关shell的问题，做面试题，看abs【每天看一点】。**</code></pre><p>python目前正在学习，目前基础部分已经学完了，正在学习django项目，学完之后，要花钱买一套马哥或者老男孩的python视频来补充，预计下半年能够做项目。</p><h2 id="2-OSI模型、TCP-IP部分；路由交换基本原理"><a href="#2-OSI模型、TCP-IP部分；路由交换基本原理" class="headerlink" title="2. OSI模型、TCP/IP部分；路由交换基本原理"></a>2. OSI模型、TCP/IP部分；路由交换基本原理</h2><h3 id="OSI7层模型"><a href="#OSI7层模型" class="headerlink" title="OSI7层模型"></a>OSI7层模型</h3><p>OSI 7层模式主要是由国际标准化组织（ISO）创建的，是一个国际通用的标准，它被开发出作为一个参照标准，用于指导如何设计网络通信系统。说的简单一点就是统一网络设备商的协议标准，实现不同网络设备和谐共存的环境（主机，路由器，交换机等等都是网络设置，都要遵循同一套的通信标准）<br>它一共分为7层，每一层在网络通信数据传输过程中都定义了不同的功能。</p><p>OSI7层模型主要分为(从下到上)：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。<br>每一层说明：</p><table><thead><tr><th style="text-align:center">layer</th><th style="text-align:left">function</th></tr></thead><tbody><tr><td style="text-align:center">Application</td><td style="text-align:left">data flow；离用户最近的一层，它使一个网络应用能和另一个网络应用相互通信</td></tr><tr><td style="text-align:center">Presentation</td><td style="text-align:left">定义数据格式；数据压缩、加解密等。</td></tr><tr><td style="text-align:center">Session</td><td style="text-align:left">定义如何建立和终止连接，是告诉4层怎么做，4层只管被动的接受然后去做。</td></tr><tr><td style="text-align:center">Transport</td><td style="text-align:left">数据段；将上层的数据流进行分段；建立和终止网络连接；常用于流量控制和数据恢复</td></tr><tr><td style="text-align:center">Network</td><td style="text-align:left">数据包；使用IP地址在Internet上唯一确定一台设备；定义设备路由，寻址</td></tr><tr><td style="text-align:center">Data link</td><td style="text-align:left">数据帧；将上层数据封装成数据帧，其中包含源目MAC地址以及帧校验字段（用于检测传输错误）；它包含2个子层（LLC和MAC）</td></tr><tr><td style="text-align:center">Physical</td><td style="text-align:left">比特流；定义了比特流如何在两台设备之间流通；主要涉及线缆，网卡，</td></tr></tbody></table><p>下面是每一层常见的对应协议</p><table><thead><tr><th style="text-align:center">layer</th><th style="text-align:left">protocol</th></tr></thead><tbody><tr><td style="text-align:center">Application</td><td style="text-align:left">HTTP,FTP,Telnet,SMTP,SNMP</td></tr><tr><td style="text-align:center">Presentation</td><td style="text-align:left">MIME,TIFF,GIF,JPEG,PICT,ASCII,EBCDIC,encryption,MPEG,MIDI,HTML</td></tr><tr><td style="text-align:center">Session</td><td style="text-align:left">SSl/TLS,NetBIOS,RPC</td></tr><tr><td style="text-align:center">Transport</td><td style="text-align:left">TCP,UDP</td></tr><tr><td style="text-align:center">Network</td><td style="text-align:left">IP,ICMP,ARP,RARP</td></tr><tr><td style="text-align:center">Data link</td><td style="text-align:left">PPP,HDLC,IEEE 802.3/802.2,FDDI,ATM,IEEE 802.5/802.2</td></tr><tr><td style="text-align:center">Physical</td><td style="text-align:left">Ethernet</td></tr></tbody></table><h3 id="TCP-IP协议族"><a href="#TCP-IP协议族" class="headerlink" title="TCP/IP协议族"></a>TCP/IP协议族</h3><p>TCP/IP模型类似OSI模型，作用也是描述一套指导标准，实现网络设备之间的通信，它被设计成4层</p><pre><code>ApplicationTransportInternetNetwork Access</code></pre><p>其对应关系为：</p><table><thead><tr><th style="text-align:center">TCP/IP model</th><th style="text-align:left">OSI model</th></tr></thead><tbody><tr><td style="text-align:center">Application</td><td style="text-align:left">Application</td></tr><tr><td style="text-align:center"></td><td style="text-align:left">Presentation</td></tr><tr><td style="text-align:center"></td><td style="text-align:left">Session</td></tr><tr><td style="text-align:center">Transport</td><td style="text-align:left">Transport</td></tr><tr><td style="text-align:center">Internet</td><td style="text-align:left">Network</td></tr><tr><td style="text-align:center">Network Access</td><td style="text-align:left">Data link</td></tr><tr><td style="text-align:center"></td><td style="text-align:left">Physical</td></tr></tbody></table><h3 id="OSI和TCP-IP的区别"><a href="#OSI和TCP-IP的区别" class="headerlink" title="OSI和TCP/IP的区别"></a>OSI和TCP/IP的区别</h3><p>除了层数的区别之外，它们之间最大的区别就是：</p><blockquote><p>OSI模型规定了在一个网络上传输数据所需要的步骤，并且它是非常具体的，定义了每一层使用什么协议以及如何使用；而TCP/IP模型是不特定的。<br>另外一个区别就是，目前TCP/IP是所有网络设备上既定的协议事实，一般分析问题使用OSI模型。</p></blockquote><h3 id="路由技术"><a href="#路由技术" class="headerlink" title="路由技术"></a>路由技术</h3><p>我们在这里说的路由技术一般是指，路由转发。主要涉及设备为路由器或者三层交换机。这些设备上会维护一张路由表，其中的信息可以是通过动态路由协议（例如OSPF，EIGRP，ISIS，RIP，BGP，静态路由，默认路由等）获取组成<br>路由表的内容是：出口接口和对应网段</p><p>路由设备接收到一个数据包之后，会解封装，获取其中的目的IP地址信息（网段信息），然后查找路由表，选择最优路由去转发。<br>路由设备上也会有一张ARP表，根据广播域</p><h3 id="交换技术"><a href="#交换技术" class="headerlink" title="交换技术"></a>交换技术</h3><p>在一个局域网内，也就是一个广播域内使用的技术。通常会涉及到的设备就是交换机。<br>交换机上会维护一张MAC地址转发表，其中的信息是MAC地址和端口的映射关系。交换机根据数据帧中的目的MAC地址进行数据包的转发</p><blockquote><p>注意：在一个广播域内的数据流动是依靠二层MAC来实现的，因为在第一次会涉及到ARP，有了记录之后，交换机会记录他的MAC地址表，后续的速度就会较快</p></blockquote><p>这个时候可以在白板上进行讲解，大致的讲解百度页面打开的整个过程。</p><h2 id="3-高可用-负载均衡"><a href="#3-高可用-负载均衡" class="headerlink" title="3. 高可用+负载均衡"></a>3. 高可用+负载均衡</h2><p><strong>keepalived</strong></p><ul><li>2种角色：master和backup；</li></ul><ul><li>4种状态：stop,master,backup,fault</li></ul><ul><li>检测脚本2种触发机制</li></ul><blockquote><p>当VRRP检测脚本检测到自身所承载应用的返回值不为0的时候，就会触发角色变化，这个时候，VRRP脚本中如果没有设置weight权重值，那么直接进入fault状态，在vrrp组中发送组播通告，宣告自己进入异常状态，让出master角色并且不参与竞选<br>如果脚本中设置了weight权重值，这个时候又会分为两种情况。</p><p>当weight权重值大于0时，master的优先级不变，backup的优先级为weight+现在优先级<br>在wight权重值小于0时，master的优先级为目前的优先级减去weight的绝对值，backup的优先级保持不变。<br>经过我多次的实验，目前保证最佳切换效果的配置是Vrrp检测脚本组中不配置weight，并且所有主机都设置为backup，设置不抢占参数，这种情况下，能有效避免优先级设置不当导致的切换不成功。</p></blockquote><p><strong>Nginx</strong></p><p>Nginx工作在应用层（使用location，通过正则表达表达式进行相关匹配），负载均衡是基于upstream模块实现的，因此配置比较简单。但是对后端服务器的健康检测只能支持端口<br>Nginx的负载均衡算法可以分为两类：内置策略和扩展策略，内置的有轮询，ip_hash等。扩展的有fair，通用hash，一致性hash等。</p><p>Nginx的负载均衡目前支持5种调度算法：</p><ul><li>rr轮询【默认算法】；接受到请求之后，按照时间顺序逐一分配到后端不同的服务器上 </li><li>wrr加权轮询；权重值越大，被分配访问的概率就越大，主要用于后端服务器性能不一致的情况</li><li>ip_hash；每个请求按访问IP的哈希结果分配，计算之后，nginx内部会维护一张哈希表，这样每个访客固定访问一个后端服务器，可以有效的解决动态网页存在的session共享问题。</li><li><p>fair;【第三方算法，需要通过额外安装upstream_fair模块实现】。更智能的一个负载均衡算法，此算法可以根据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。<br><strong>这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。</strong></p></li><li><p>url_hash；【第三方算法，需要通过额外安装hash模块实现】。也是哈希算法，只不过不是基于源IP，而是基于访问的URL来生成这张哈希表。每个URL定向到同一台后端服务器，可以进一步提高后端缓存服务器的效率。</p></li></ul><p>注意：当算法是ip_hash的时候，后端服务器不能被添加weight和backup</p><p>我们在location中配置nginx负载均衡的时候，还需要添加proxy_next_upstream http_500 http_502 error timeout invalid_header; 这一行参数。用于定义故障转移策略。当后端服务器节点返回500、502和执行超时等错误时，自动将请求转发到upstream负载均衡器中的另一台服务器，实现故障转移。</p><p>Nginx负载均衡工作流：</p><ol><li>当客户端访问 xxx 域名时请求会最先到达负载均衡器,负载均衡器就会去读取自己server标签段中的配置</li><li>到location里面一看,原来这是一个要往后端web节点抛的请求</li><li>而后,nginx通过 proxy_pass的配置项 在自己的主配置文件找到了事先定义好的后端web节点</li><li>最后,按照事先设置好的调度算法,把请求带上主机头和客户端原始ip一起抛给后端准备好的web服务器</li></ol><p>nginx负载均衡较适合用于日pv 2000W以下的站点</p><p><strong>HAProxy</strong></p><p>Haproxy能实现基于4层和7层的负载均衡，</p><p>HAproxy的8中负载均衡算法<br>1、roundrobin<br>表示简单的轮询，每个服务器根据权重轮流使用，在服务器的处理时间平均分配的情况下这是最流畅和公平的算法。该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。</p><p>2、leastconn<br>连接数最少的服务器优先接收连接。leastconn建议用于长会话服务，例如LDAP、SQL、TSE等，而不适合短会话协议。如HTTP.该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。</p><p>3、static-rr<br>每个服务器根据权重轮流使用，类似roundrobin，但它是静态的，意味着运行时修改权限是无效的。另外，它对服务器的数量没有限制。</p><p>该算法一般不用；</p><p>4、source<br>对请求源IP地址进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个客户端IP地址总是访问同一个服务器。如果哈希的结果随可用服务器数量而变化，那么客户端会定向到不同的服务器；</p><p>该算法一般用于不能插入cookie的Tcp模式。它还可以用于广域网上为拒绝使用会话cookie的客户端提供最有效的粘连；</p><p>该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。</p><p>5、uri<br>表示根据请求的URI左端（问号之前）进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个URI地址总是访问同一个服务器。一般用于代理缓存和反病毒代理，以最大限度的提高缓存的命中率。该算法只能用于HTTP后端；</p><p>该算法一般用于后端是缓存服务器；</p><p>该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。</p><p>6、url_param<br>在HTTP GET请求的查询串中查找<param>中指定的URL参数，基本上可以锁定使用特制的URL到特定的负载均衡器节点的要求；</p><p>该算法一般用于将同一个用户的信息发送到同一个后端服务器；</p><p>该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。</p><p>7、hdr(name)<br>在每个HTTP请求中查找HTTP头<name>，HTTP头<name>将被看作在每个HTTP请求，并针对特定的节点；</name></name></p><p>如果缺少头或者头没有任何值，则用roundrobin代替；</p><p>该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。</p><p>8、rdp-cookie（name）<br>为每个进来的TCP请求查询并哈希RDP cookie<name>；</name></p><p>该机制用于退化的持久模式，可以使同一个用户或者同一个会话ID总是发送给同一台服务器。如果没有cookie，则使用roundrobin算法代替；</p><p>该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。</p><p>2种配置方式指的是<br>在1.3版本之前，ha的负载均衡配置主要是在listen部分中进行配置<br>在1.3版本之后，为了更好的维护和管理，将负载均衡的配置拆分成为了frotend和backend这两部分，为了保证兼容性，listen部分依然保留，目前主要使用listen部分配置HA的监控页面</p><p>HA通过ACL实现一些7层的功能<br>例如通过path_end的ACl方法实现动静资源分离</p><p>通过hdr_dom(host)和hdr_reg(host)和hdr_beg(host)的方法实现虚拟主机</p><p><strong>LVS</strong><br>关于LVS，它本身只是支持负载均衡，没有检测机制，因此要结合keepalived来使用【keepalived的诞生原因就是为了给LVS提供后端节点检测功能，到后面才添加了高可用的功能】。在这里需要明确一点，它只能转发4层数据包【IP+port】但是检测是能通过7层url进行监测的。<br>LVS的8种算法：<br>1.轮叫调度（Round Robin）<br>调度器通过“轮叫”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载。大锅饭调度：rr - 纯轮询方式，比较垃圾。把每项请求按顺序在真正服务器中分派</p><p>2.加权轮叫（Weighted Round Robin）<br>调度器通过“加权轮叫”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器能处理更多的访问流量。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。<br>带权重的大锅饭调度：wrr -带权重轮询方式。把每项请求按顺序在真正服务器中循环分派，但是给能力较大的服务器分派较多的作业。</p><p>3.最少链接（Least Connections）<br>调度器通过“最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用“最小连接”调度算法可以较好地均衡负载。<br>谁不干活就给谁分配：lc - 根据最小连接数分派</p><p>4.加权最少链接（Weighted Least Connections）<br>在集群系统中的服务器性能差异较大的情况下，调度器采用“加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。<br>带权重的谁不干活就给谁分配：wlc - 带权重的。机器配置好的权重高</p><p>5.基于局部性的最少链接（Locality-Based Least Connections）<br>“基于局部性的最少链接”调度算法是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用“最少链接” 的原则选出一个可用的服务器，将请求发送到该服务器。<br>基于地区的最少连接调度：lblc - 缓存服务器集群。基于本地的最小连接。把请求传递到负载小的服务器上</p><p>6.带复制的基于局部性最少链接（Locality-Based Least Connections with Replication）<br>“带复制的基于局部性最少链接”调度算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。它与LBLC算法的不同之处是它要维护从一个目标 IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。该算法根据请求的目标IP地址找出该目标IP地址对应的服务器组，按“最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。<br>带有复制调度的基于地区的最少连接调度：lblcr - 带复制调度的缓存服务器集群。某页面缓存在服务器A上，被访问次数极高，而其他缓存服务器负载较低，监视是否访问同一页面，如果是访问同一页面则把请求分到其他服务器。</p><p>7.目标地址散列（Destination Hashing）<br>“目标地址散列”调度算法根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。<br>目标散列调度：realserver中绑定两个ip。ld判断来者的ISP商，将其转到相应的IP。</p><p>8.源地址散列（Source Hashing）<br>“源地址散列”调度算法根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。了解这些算法原理能够在特定的应用场合选择最适合的调度算法，从而尽可能地保持Real Server的最佳利用性。当然也可以自行开发算法，不过这已超出本文范围，请参考有关算法原理的资料。<br>源散列调度：源地址散列。基于client地址的来源区分。（用的很少）</p><h3 id="补充：为什么4层性能比7层更好？"><a href="#补充：为什么4层性能比7层更好？" class="headerlink" title="补充：为什么4层性能比7层更好？"></a>补充：为什么4层性能比7层更好？</h3><p>在7层，因为负载均衡器要获取报文内部的内容，因此要先和客户端建立连接，才能收到客户发过来的报文内容，然后获取报文内容之后，再根据调度算法进行负载。也就是说7层负载会和客户端和后端服务器分别建立一个TCP连接，而4层负载均衡只需要一次，因此性能肯定比4层差。</p><h3 id="三种负载均衡产品之间的对比"><a href="#三种负载均衡产品之间的对比" class="headerlink" title="三种负载均衡产品之间的对比"></a>三种负载均衡产品之间的对比</h3><p>HAProxy和LVS的4层负载对比<br>因为LVS是基于Linux内核的，但是HAProxy是属于第三方应用，因此在性能上，LVS占据绝对优势。因此，如果只是做纯4层转发，则使用LVS</p><p>HAProxy对比Nginx<br>HAProxy支持更为丰富的后端节点检测机制，并且性能比Nginx好，因此在并发量较大的情况下，使用HAproxy，日PV并发量较小的情况下可以使用Nginx，配置也较为简单。</p><h2 id="4-Redis"><a href="#4-Redis" class="headerlink" title="4. Redis"></a>4. Redis</h2><p><strong>持久化策略</strong><br>数据持久化策略主要分为RDB和AOF两种</p><ul><li>RDB方式：数据文件内记录的是实际的数据。因此在进行数据恢复的时候，速度较快。适合全量备份。在进行RDB持久化时，会fork出一个单独的进行，因此会CPU的开销较大。</li><li>AOF方式：数据文件内记录的是产生数据变化的命令。因此在进行数据恢复的时候，速度较慢，并且其中的内容可以编辑，因此适合在执行了一些类似flushall或者flushdb等命令时进行数据恢复</li><li>混合持久化：Redis4.0版本之后的持久化，结合了RDB和AOF的有点，当进行AOF重写的时候，将会把当前的数据转变成为RDB形式进行保存，重写之后的数据继续以AOF的格式保存</li></ul><p><strong>主从复制</strong><br>在Redis2.6版本之前，主从复制时，每次传输的都是全量数据，因此会非常占用网络带宽和相关资源。<br>在这之后，在Redis master节点上可以设置复制缓存区，来实现差异的增量复制。但是当缓冲区满了之后，还是会执行全量复制。</p><p><strong>淘汰策略</strong><br>淘汰策略是指当Redis进行即将使用到设置的最大内存量，执行的一个策略，避免出现内存溢出的问题，也就是一种内存回收机制。<br>一般在使用到maxmemory的90%时触发，默认策略是不回收。</p><p>在redis中可以配置的策略主要有以下几种：</p><ul><li>noeviction policy    【默认策略，永不过期策略。】不会删除任何数据，拒绝任何写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时Redis只响应读操作</li><li>volatile-lru        根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止，如果没有可以删除的键对象，则回退到noeviction策略</li><li>allkeys-lru        根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。</li><li>volatile-lfu        根据LFU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止，如果没有可以删除的键对象，则回退到noeviction策略</li><li>allkeys-lfu        根据LFU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。</li><li>volatile-random    随机删除设置了超时属性（expire）的键，直到腾出足够的空间</li><li>allkeys-random    随机删除所有键，知道腾出足够空间为止</li><li>volatile-ttl        根据键值对象的ttl属性，删除最近将要过期的数据，如果没有，则回退到noeviction策略</li></ul><p><strong>常见性能问题</strong></p><p>常见性能问题主要为：</p><ul><li>内存设置不合理</li><li>大量的慢查询</li><li>key值（名称）设置过大</li><li>单个key的value过大</li><li>没有使用Redis的流水线功能</li><li>命令使用不合理，例如可以使用mset等或者禁止使用monitor等命令</li><li>客户端最大连接数设置【需要设置最大描述符，Redis默认会占用32个fd，因此可用的是1024-32】</li><li>TCP积压队列</li><li>定义AOF重写大小</li><li>客户端输出缓冲区</li><li>复制积压缓冲区</li><li>swap优化等等</li></ul><p><strong>哨兵模式</strong></p><p>哨兵模式也就是Redis的高可用模式。<br>一般的配置模式为一对主从，然后配置3个哨兵实例<br>哨兵实例的设置原则：当有(n/2)+1个哨兵宣告需要进行切换时，才进行切换，这一点同样适用于zk等集群选举。因此最好3个以上的奇数个实例，偶数个会浪费一个。【这在5个以上节点时能看出明显的效果】</p><p><strong>分布式集群</strong></p><p>集群采用哈希槽的分配方式，一共有0-16383个槽<br>最小建议配置为3主3从。Redis集群使用的是gossip协议。</p><p><strong>cachecloud云平台</strong></p><p>这是我从github上引入的Redis运维项目</p><h2 id="5-Mysql-Oracle"><a href="#5-Mysql-Oracle" class="headerlink" title="5. Mysql+Oracle"></a>5. Mysql+Oracle</h2><p><strong>Mysql基础知识</strong></p><p><strong>Mysql主从复制原理</strong></p><p>整体上来说，复制有3个步骤： </p><ul><li>A.master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）；</li><li>B.slave将master的binary log events拷贝到它的中继日志(relay log)；</li><li>C.slave重做中继日志中的事件，将改变反映它自己的数据。</li></ul><p><strong>Mysql读写分离</strong></p><p><strong>Mysql高可用和集群</strong><br>有几种高可用方案：<br>Mysql双主+keepalived【优点：架构简单，】</p><p><strong>Mysql备份与恢复</strong></p><p>逻辑备份：备份的是产生数据变化的sql语句。mysqldump能直接进行这个操作，但是因为它在备份过程中会锁表，并且备份的速度也非常的慢因此我们需要选择第三方工具。</p><p>物理备份：备份的是实际的数据，直接拷贝mysql的数据目录。　直接拷贝只适用于myisam类型的表。这种类型的表是与机器独立的。【这种备份的粒度较粗，不能实现更细粒度的数据恢复，特别是对于更新较为频繁的系统。】</p><p>实际生产环境中一般使用完整备份+增量备份<br>每周日凌晨2点进行一次全量备份，之后的每天凌晨2点进行一次增量备份</p><p>然后再每天备份binlog日志【为了粒度更细致的数据恢复】</p><p><strong>Mysql优化</strong></p><p>mysql优化包括其他所有的网络服务优化，思路都是一致的。</p><p>分层次的来进行。【普遍规律+应用需求】</p><p>普遍规律：</p><blockquote><p>首先是硬件层面</p><p>再次是操作系统层面的基础优化，例如文件描述符的数量，swap使用限制，文件系统（目前主流xfs）</p><p>再次是c/s架构方面的优化，例如TCP的连接队列大小，队列的缓存大小。tcp连接超时时间，tcp滑动窗口（发送和接受）</p></blockquote><p>应用需求：<br>数据库通用：最大连接数，索引（优先在where,order group等涉及的列上创建索引），sort，group等排序结果的缓冲区大小，慢查询，sql语句优化（减少使用like等开销大的语句），命令规范等<br>Mysql：存储引擎</p><p>JAVA类：JVM设置，是否设置锁内存策略，堆内还是堆外内存，线程数量等。<br>web类：压缩，静态文件缓存，CDN加速等</p><p>Mysql特殊：存储引擎等</p><p><strong>Mysql常见问题</strong></p><p>慢查询，sql写的有问题</p><p>mha的时候VIP漂移有问题</p><p>连接数问题</p><p>版本不一致问题</p><p><strong>Oracle</strong></p><p>oracle没什么<br>数据库概念上，oracle是只有一个数据库，然后里面有多用户，每个用户多表<br>mysql是多个数据库，多个用户，采取授权的形式来访问</p><h2 id="6-Ansible等自动化工具"><a href="#6-Ansible等自动化工具" class="headerlink" title="6. Ansible等自动化工具"></a>6. Ansible等自动化工具</h2><p><strong>Ad-Hoc</strong></p><p>Ad-Hoc指的是一般性的临时操作</p><p>日常运维中主要使用的模块有：</p><ul><li>shell模块</li><li>yum模块</li><li>copy模块</li><li>service模块</li></ul><p><strong>Playbook</strong><br>Ansible使用YAML语法描述配置文件，这个配置文件就被成为playbook，剧本</p><p>Ansible的核心理念是：极致的简单高效<br>并且Ansbile是使用python编写的，因此在后续的二次开发上更占据优势。<br>另一个趋势是python的运行方式，它和区块链一致，采用的是去中心化的部署方式，不需要安装客户端即可，通过SSH来实现，并且目前还提供了SSH的加速模式，适用于大规模的环境中，可以说，Ansible绝对是未来的趋势主流。</p><p><strong>puppet、chef、slatstack</strong><br>puppet和chef都是使用ruby编写的，并且配置繁琐，都需要配置客户端目前不适合</p><p>slatstack也是通过python编写，但是slatstack适用于更大的规模，因为ansible使用ssh来传输命令，而它使用zeroMQ来传输数据<br>在1000台主机的情况下，MQ用时2秒左右，而ansible的SSH则用时85秒。</p><p><strong>对比</strong><br>ansible默认情况下适用于200台以内的主机，适合中小型企业，如果数量再多可以使用Ansible的加速模式去实现</p><p>选型标准：选择最合适，如果当前的运维环境主机在百台，则ansible是最好的选择，如果上千台，那么无疑使用slatstack。</p><p><strong>cobbler和kickstart</strong><br>kickstart是传统的批量装机方式，配置比较繁琐</p><p>cobbler是较早前的kickstart的升级版本，有点是容易配置</p><p>并且cobbler具有高级功能，可以根据不同机器的MAC地址来进行设置装机</p><p>关闭自动装机这里之前还发生过一个问题，就是有一次在装机的时候使用的是百兆交换机，导致老是有几台装不上，后来都换成千兆之后，就解决了这个问题。</p><p>关闭这个批量装机，因此centos的网卡名称不再是ethx的形式，因此在安装的时候，我们需要再ks文件中添加命令，来调整网卡的命令规则</p><h2 id="7-Nginx，Httpd，tomcat，weblogic，php，gitlab，Jenkins"><a href="#7-Nginx，Httpd，tomcat，weblogic，php，gitlab，Jenkins" class="headerlink" title="7. Nginx，Httpd，tomcat，weblogic，php，gitlab，Jenkins"></a>7. Nginx，Httpd，tomcat，weblogic，php，gitlab，Jenkins</h2><p>这部分和web相关，主要是和电商，互联网公司等核心为web的紧密相关，也就是主要是LNMP这一套</p><h3 id="Nginx基础知识"><a href="#Nginx基础知识" class="headerlink" title="Nginx基础知识"></a>Nginx基础知识</h3><p><strong>基础知识</strong></p><p>Nginx主要分为几个模块</p><ul><li>全局配置【worker数量，worker的最大打开数量，CPU指定等】</li><li>Event模块配置【worker的最大连接数等，网络IO处理模型等】</li><li>Http模块【其中包括upstream段,server段,server中的location段等】</li></ul><p>主要配置的地方就是HTTP模块中的upstream，server中的location段【动静分离等都是在这里进行配置】</p><p>注意：nginx的模块是静态的，在编译时就已经完全编译进去，而不是像Httpd是动态链接的形式</p><h3 id="Nginx常见问题"><a href="#Nginx常见问题" class="headerlink" title="Nginx常见问题"></a>Nginx常见问题</h3><p>日志文件将磁盘存储空间占满了。</p><h3 id="Nginx常见应用场景"><a href="#Nginx常见应用场景" class="headerlink" title="Nginx常见应用场景"></a>Nginx常见应用场景</h3><p>web服务器【一般会做动静分离，rewrite功能（重定向302是临时，301是永久，地址栏都改变，主要看爬虫变不变），防盗链】</p><p>负载均衡服务器</p><h3 id="Nginx优化"><a href="#Nginx优化" class="headerlink" title="Nginx优化"></a>Nginx优化</h3><p><strong>全局优化</strong></p><ul><li>工作进程数量（worker_processes数量）一般等于CPU的核数，因为每个进程是单线程的模式，使用epoll网络IO模型来进行处理。</li><li>worker_rlimit_nofile 60000；每个work进程最大打开文件数量。【这里需要跟操作系统的文件描述符相对应】</li></ul><p><strong>Event模块优化</strong></p><ul><li>worker进程最大连接优化，官方数据是能支持到5W【那么所有的连接数=5W*几个worker】</li><li>网络模型【通常使用epoll模型】</li></ul><p><strong>HTTP模块优化</strong></p><ul><li>不显示版本</li><li>关闭TCP延迟发送数据</li><li>keepalive的超时时间等</li><li>压缩传输的设置【压缩级别，压缩的触发大小】</li></ul><h3 id="Nginx和Httpd"><a href="#Nginx和Httpd" class="headerlink" title="Nginx和Httpd"></a>Nginx和Httpd</h3><p>在这里主要说web，不说nginx的负载均衡，这部分已经在第3条说了。</p><h3 id="tomcat常见问题"><a href="#tomcat常见问题" class="headerlink" title="tomcat常见问题**"></a>tomcat常见问题**</h3><p>数据库连接问题，后端数据库异常，没有连接到<br>tomcat乱码<br>tomcat日志大小问题，<br>权限问题<br>JAVA_HOME没有设置正确</p><h3 id="tomcat优化"><a href="#tomcat优化" class="headerlink" title="tomcat优化**"></a>tomcat优化**</h3><p>主要分为2块，tomcat的JVM内存优化和tomcat的并发优化</p><p>内存优化：<br>Tomcat内存优化主要是对 tomcat 启动参数优化，我们可以在 tomcat 的启动脚本 catalina.sh 中设置 java_OPTS 参数</p><p>JAVA_OPTS参数说明<br>　　-server 启用jdk 的 server 版；<br>　　-Xms Java虚拟机初始化时的最小堆内存；<br>　　-Xmx java虚拟机可使用的最大堆内存； 【堆内存建议设置一致，避免GC回收后再次动态分配，增大系统的开销】<br>　　-XX: PermSize 内存永久保留区域<br>　　-XX:MaxPermSize 内存最大永久保留区域 【这部分，默认64位的是256M】</p><p>JAVA_OPTS=’-Xms1024m -Xmx2048m -XX: PermSize=256M -XX:MaxNewSize=256m -XX:MaxPermSize=256m’</p><p>并发优化/线程优化+缓存优化：</p><p>　在Tomcat 配置文件 server.xml 中的</p><p>　　<connector port="9027" 　　protocol="HTTP/1.1" 　　maxhttpheadersize="8192" 　　minprocessors="100" 　　maxprocessors="1000" 　　acceptcount="1000" 　　redirectport="8443" 　　disableuploadtimeout="true"></connector></p><p>参数说明</p><pre><code>　　maxThreads 客户请求最大线程数 表示最多同时处理多少个连接　　minSpareThreads **Tomcat初始化时创建的 socket 线程数** 　　maxSpareThreads **Tomcat连接器的最大空闲 socket 线程数 **　　enableLookups 若设为true, 则支持域名解析，可把 ip 地址解析为主机名 　　redirectPort 在需要基于安全通道的场合，把客户请求转发到基于SSL 的 redirectPort 端口 　　acceptAccount 监听端口队列最大数，满了之后客户请求会被拒绝（不能小于maxSpareThreads ） 　　connectionTimeout 连接超时 　　minProcessors 服务器创建时的最小处理线程数 　　maxProcessors 服务器同时最大处理线程数 　　URIEncoding URL统一编码　  compression 打开压缩功能 　　compressionMinSize 启用压缩的输出内容大小，这里面默认为2KB 　　compressableMimeType 压缩类型 　　connectionTimeout 定义建立客户连接超时的时间. 如果为 -1, 表示不限制建立客户连接的时间</code></pre><p>参考配置：<br>　　<connector port="9027" 　　protocol="HTTP/1.1" 　　maxhttpheadersize="8192" 　　maxthreads="1000" 　　minsparethreads="100" 　　maxsparethreads="1000" 　　minprocessors="100" 　　maxprocessors="1000" 　　enablelookups="false" 　　compression="on" 　　compressionminsize="2048" 　　compressablemimetype="text/html,text/xml,text/javascript,text/css,text/plain" 　　connectiontimeout="20000" 　　uriencoding="utf-8" 　　acceptcount="1000" 　　redirectport="8443" 　　disableuploadtimeout="true"></connector></p><h3 id="tomcat多实例部署"><a href="#tomcat多实例部署" class="headerlink" title="tomcat多实例部署"></a>tomcat多实例部署</h3><p><a href="http://blog.51cto.com/watchmen/1955972" target="_blank" rel="noopener">http://blog.51cto.com/watchmen/1955972</a></p><p>传统方式复制目录的话，会造成资源浪费，因为lib和bin等公共资源会被多次加载，造成在内存中不必要的重复</p><p>思路：将bin下的文件和lib文件单独拆分出来</p><h3 id="weblogic"><a href="#weblogic" class="headerlink" title="weblogic"></a>weblogic</h3><p>weblogic最开始bea公司的一个JAVA中间件产品，现在归属于oracle<br>功能非常的强大，支持EJB<br>比如在配置程序连接数据库时，不需要再代码中通过jdbc的方式去人工手动指定，而是通过后台管理页面的数据源配置中，进行配置。<br>所以说，在一般的环境中，使用tomcat即可，如果涉及到大型的java应用开发，就要使用weblogic</p><h3 id="PHP"><a href="#PHP" class="headerlink" title="PHP"></a>PHP</h3><p>PHP主要对接Nginx，处理php文件【通过php-fpm来处理】<br>PHP-CGI 解释器每进程消耗 7 至 25 兆内存<br>所以它的优化是进程数量的设置【包括启动时分配的，最小空闲的，最大空闲的，最大值】<br>一般启动时分配5个，最小空闲为5个，最大空闲为32个，最大值为32个</p><h3 id="Gitlab"><a href="#Gitlab" class="headerlink" title="Gitlab"></a>Gitlab</h3><h3 id="Jenkins"><a href="#Jenkins" class="headerlink" title="Jenkins"></a>Jenkins</h3><p>JDK支持<br>tomcat支持<br>maven支持<br>Jenkins支持</p><p>Jenkins的安装一共有3个步骤    </p><ol><li>首先是下载war包到tomcat的webapps目录并将其重命名为ROOT.war，之后就是对其环境变量进行配置。</li><li>设定jenkins的目录及管理用户及编码<br>修改tomcat目录下./conf/context.xml：增加jenkins环境变量</li><li>修改tomcat目录下的./conf/server.xml,是编码符合jenkins</li><li>步骤四：在第一次登陆jenkins页面时，需要输入一串加密数据<br>这串数据位于其家目录下的./secrets/initialAdminPassword之<br>中。</li></ol><p><strong>流程：</strong><br>JDK+tomcat部署Jenkins<br>添加git 源码仓库<br>使用maven进行构建【需要编写触发脚本，当有源码发生变化时，在2分钟后进行构建部署等操作】</p><h2 id="8-消息队列MQ产品"><a href="#8-消息队列MQ产品" class="headerlink" title="8. 消息队列MQ产品"></a>8. 消息队列MQ产品</h2><p><strong>使用MQ产品的原因</strong></p><ul><li>程序异步解耦</li><li>数据冗余</li><li>扩展性，不需要改变程序的代码，就可以扩展性能。</li><li>灵活性，峰值处理能力。</li><li>消息的顺序保证</li><li>异步通信，允许用户把消息放入队列中，但是并不立即处理它</li></ul><ul><li>ActiveMQ；老牌的MQ产品，完全遵守JMS规范。是apache开源的一个MQ产品，比较重量级，没有什么特殊的亮点</li></ul><blockquote><p>ActiveMQ的高可用集群模式通过ZK来实现，为了保证数据的一致性，因此会严重影响性能。从ActiveMQ 5.9开始，它实现了通过ZooKeeper + LevelDB实现高可用集群的部署方式。这种方式，对外只有Master提供服务<br>这种方式实现了可以称之为半事务特性的机制，Master 将会存储并更新然后等待 (2-1)=1 个<strong>Slave</strong>存储和更新完成，才汇报 success</p></blockquote><ul><li>RabbitMQ；遵循AMQP协议，借助erlang的特性在可靠性、稳定性和实时性上比别的MQ做得更好，非常重量级，性能比较好，适合企业级的开发。但是不利于做二次开发和维护<blockquote><p>由于 rabbitmq 是使用 erlang 开发的，而 erlang 就是为分布式而生的。所以 rabbitmq 便于集群。rabbitmq 集群有两种模式：<code>普通模式、镜像模式。</code></p></blockquote></li><li>普通模式：也是默认模式，对于 queue 来说，消息实体只存在与其中的一个节点，A、B 两个节点只有相同的元数据，即队列的结构。当消息在A时，消费中从B中取消息时，消息会从A中传递到B中。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。</li></ul><ul><li>镜像模式：镜像模式是 rabbitmq 的 HA 方案。其与普通模式的唯一不同之处在于消息会在 A，B 两个节点中同步。当然这种模式带来的副作用也是显而易见的。除了降低系统性能以外，如果队列数量过多，网络带宽将会受到影响。所以这种情况只运用到对高可靠性要求的场合上。</li></ul><blockquote><p>集群配置方式：安装erlang,然后同步三台机器上的.erlang.cookie文件内容<br>因为RabbitMQ的集群是依赖erlang集群，而erlang集群是通过这个cookie进行通信认证的，因此我们做集群的第一步就是干cookie。<br>注意：erlang.cookie文件中cookie值一致，且权限为owner只读。因此需要设置为600</p></blockquote><p><strong>注意：</strong> RabbitMQ单节点环境只允许是磁盘节点，防止重启RabbitMQ时丢失系统的配置信息。RabbitMQ集群环境至少要有一个磁盘节点，因为当节点加入或者离开集群时，必须要将该变更通知到至少一个磁盘节点。 </p><ul><li><p>kafka；也是apache基金会的一个MQ产品。高吞吐量，消息的接受和消费都是落地到磁盘，因此适用于大数据环境流处理，对实时性要求不是太高的环境，可以积压非常庞大的数据量（瓶颈在磁盘）</p><blockquote><p>kafka是一种分布式的，基于发布/订阅的消息系统。有主分区和副本分区的概念。<br>并且kafka中的数据是追加的形式，保证了消息的有序性</p></blockquote></li><li><p>rocketmq；阿里开发并开发的一个MQ产品，纯JAVA开发。具有高吞吐量、高可用性、适合大规模分布式系统应用的特点。RocketMQ思路起源于Kafka，但并不是Kafka的一个Copy，它对消息的可靠传输及事务性做了优化，目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binglog分发等场景。</p></li></ul><h2 id="9-flume，zk，es，logstash，kibana系列"><a href="#9-flume，zk，es，logstash，kibana系列" class="headerlink" title="9. flume，zk，es，logstash，kibana系列"></a>9. flume，zk，es，logstash，kibana系列</h2><p><strong>flume</strong></p><p>flume：是一个日志收集软件。flume的agent设计实现这一系列的操作，一个agent就是一个java进程，运行在日志收集节点-也就是日志收集服务器节点。</p><p>agent里面包含3个核心的组件：source—-&gt;channel—–&gt;sink,类似生产者、仓库、消费者的架构。<br>source:收集数据，可以处理各种类型<br>sink：该组件是用于把数据发送到目的地的组件，目的地包括有：hdfs，kafka等等文件系统</p><blockquote><p>工作流：flume的核心是把数据从数据源(source)收集过来，在将收集到的数据送到指定的目的地(sink)。为了保证输送的过程一定成功，在送到目的地(sink)之前，会先缓存数据(channel),待数据真正到达目的地(sink)后，flume在删除自己缓存的数据。 也就是说flume提供了一种类似事务机制。</p></blockquote><p>flume的2种工作模式：主动模式和被动模式【主要是针对客户端来说】。这两种模式和zabbix的两种模式一样</p><p>在进行配置的时候，每个agent实例是通过别名来进行区分的。</p><p><strong>kafka</strong><br>流式消息队列产品，接受flume发送过来的消息，或者日常产生端直接将JSON格式的数据发送到Kafka中。详见上方MQ产品</p><p><strong>zookeeper</strong><br>zk:是一个分布式应用程序协调组件，用于为哪些原生没有提供集群功能的服务实现分布式集群。提供的功能包括：配置维护、域名服务、分布式同步、组服务等。<br>zk的工作流：<br>1、选举Leader。（选举zk集群中的leader）<br>2、同步数据。<br>3、选举Leader过程中算法有很多，但要达到的选举标准是一致的。<br>4、Leader要具有最高的执行ID，类似root权限。<br>5、集群中大多数的机器得到响应并接受选出的Leader。</p><p>注意：zk在3.5.0以上的版本会有一个内嵌的web服务，通过访问<a href="http://localhost:8080/commands来访问以上的命令列表。" target="_blank" rel="noopener">http://localhost:8080/commands来访问以上的命令列表。</a></p><p>一旦Zk集群启动之后，它将等待客户端的连接</p><p><strong>es</strong><br>Es的主要功能是将收集的数据建立索引，方便日后数据的存储于检索。<br>ES不止是一个全文本引擎，他还是一个分布式实时文档存储系统。<br>这里，KCE的数据目的地和ES的数据来源设置成了一个分区，因此避免了磁盘IO的二次开销</p><p><strong>logstash</strong><br>日志收集，需要在日志产生端配置，收集日志，再进行发送，目前使用flume来代替了。</p><p><strong>kibana</strong><br>kibana不多说了，主要是提供了一个连接ES的入口</p><h2 id="10-docker"><a href="#10-docker" class="headerlink" title="10. docker"></a>10. docker</h2><p>docker的核心三大组件是</p><ul><li>镜像</li><li>容器</li><li>仓库</li></ul><p>镜像主要分为几种，一个是官方的或者别人已经写好的镜像文件<br>另一个可以自己产生镜像文件。</p><p>自己产生的镜像文件可以分为两种</p><ul><li>在现有镜像的基础之上commit出来一个新的镜像</li><li>编写dockerfile文件，然后build出来一个镜像</li></ul><p>建议通过dockerfile的形式产生镜像，因为使用commit出来的镜像会存在很多的缓存文件等。</p><p>容器是镜像的运行态，和程序及进程的概念比较像。</p><p>仓库主要分为两种，一个是存储镜像的仓库【里面的 镜像通过tag标签来尽心区分，默认是latest】，另一个是存储仓库名称的注册仓库</p><p>公网上的仓库可以是docker hub，也可以通过官方提供的registry镜像来简单搭建一套本地私有仓库环境:</p><p><strong>dockerfile编写</strong><br>dockerfile主要分为4个部分</p><ul><li>基础镜像信息 from字段，也就是这个应用是以那个镜像为基础的</li><li>维护者信息，maintainer，也就是作者信息</li><li>镜像的操作指令，也就是在制作镜像是要执行的一系列操作，add加入一系列的文件，例如JDK，war包等</li><li>容器启动时执行指令-CMD，在启动时要执行的操作，例如启动项目等</li></ul><p>在cachecloud中，基础镜像是使用的centos7.4-内核基础3.0-1811系统<br>维护者是我，镜像的操作指令是JDK环境等等；容器启动时执行的命令是启动cachecloud项目</p><p><strong>k8s</strong></p><p>k8s是谷歌开源的一个容器集群管理项目<br>k8s对集群中的资源进行了不同级别的抽象，每个资源都是一个rest对象，通过API进行操作，通过JSON/YAML格式的模板文件进行定义<br>要注意的是，k8s并不是直接对容器操作，它的操作最小单位是容器组。容器组由一个或多个容器组成。k8s围绕着容器组进行创建，调度，停止等生命周期管理。</p><p><strong>ESXI,vsphere,xen,kvm</strong></p><p>这些是第一家公司所使用的产品<br>exsi和vsphere是vmware公司的企业虚拟化产品，相比于kvm，它有更好的性能，因此它是直接在物理上安装虚拟化操作系统，不需要第三方软件的实现。<br>esxi是单机版本，vsphere是集中管理版本，支持在线迁移等高级功能。<br>xenserver是思杰公司的一个虚拟化产品，单机的操作比vmware的esxi好，但是在涉及到多机环境时不是太好<br>kvm需要linux系统的支持，然后还要安装一系列的组件，相对来说，更方便，但是不够专业，一般企业使用的相对较少。</p><h2 id="11-监控软件及JMX，JVM"><a href="#11-监控软件及JMX，JVM" class="headerlink" title="11. 监控软件及JMX，JVM"></a>11. 监控软件及JMX，JVM</h2><p>zabbix</p><p><strong>我们的生产是怎么监控的</strong></p><p>首先是监控模板，监控一些基础指标，例如CPU，内存，磁盘等</p><p>一些类似HAproxy，activemq等有web页面的应用我们通过web监控来实现【创建web场景，60秒内，尝试连接3次，如果3次都失败，则报警，这里还会涉及到一些有认证的页面，也是可以实现的。】</p><p>更高级一点的例如redis等应用，需要监控一些特定的指标，我们通过自定义监控项来实现。</p><p>JAVA类的应用，在后期慢慢的开放了JMX端口的情况下，陆续加入了JMX的监控。</p><p><strong>自定义监控项</strong><br>为了简单高效，我们自己编写的脚本，判断引用的状态，将采用所能想到的一切来判断，然后再最后只输出一个0,如果服务不正常的话，则输出为1。</p><p><strong>zabbix的一些优化操作</strong><br>采取zabbix的主动模式来进行监控<br>使用自动发现的功能。</p><p><strong>自动发现等操作</strong></p><p><strong>各监控产品的区别</strong><br>zabbix是一款商业的开源软件，涉及到的东西非常之多，因此官方能够靠咨询，技术服务等来收费运作。<br>而cacti，nagios等是普通的开源软件，自然没有zabbix这么强大。</p><p>nagios的可视化功能非常弱，zabbix是有自己的可视化界面的【一般我们都是通过最新数据哪里查看，为了给zabbix减负，不是非必要的情况下，一般不会给监控项添加图形】<br>它不支持自动发现，并且缺少图形展示工具，也没有历史数据，追查起来非常困难。</p><p>cacti是一个PHP程序<br>它通过使用SNMP 协议获取远端网络设备和相关信息，（其实就是使用Net-SNMP 软件包的snmpget 和snmpwalk 命令获取）并通过RRDTOOL 工具绘图，</p><p>通过SNMP采集数据，并且自定义监控项等非常繁琐，报警方式需要添加插件等。</p><p><strong>JMX监控</strong></p><p>前提条件：需要JAVA类程序开放JMX端口【也就是开放API接口】</p><p>工作流：<br>（1）zabbix_server需要知道一台主机上的特定端口的JMX值时，它会向Zabbix-Java-gateway进程去询问。这个连接进程叫做StartJavaPollers</p><p>（2）Zabbix-Java-gateway使用JMXmanagementAPI这个API去查询特定的应用程序</p><p>注意：在配置的时候，StartJavaPollers线程数量要小于等于START_POLLERS设置的线程数量</p><p>这些操作操作完毕之后，在web页面上进行操作，添加JMX监控模板即可。</p><p><strong>JVM调优</strong></p><p>提到虚拟机的内存结构，可能首先想起来的就是堆栈。对象分配到堆上，栈上用来分配对象的引用以及一些基本数据类型相关的值。</p><p>JAVA虚拟机的内存结构是分了好几个区域的。<br>分区域的好处是：</p><ul><li>便于查找</li><li>便于内存回收【如果不分，回收内存就要全部内存扫描】</li></ul><p>JVM内存分区（5部分）：</p><ul><li>方法区        线程共享【这部分常被成为永久代，除了编译后的字节码之外，方法区中还会存放常量，静态变量以及及时编译器编译后的代码等数据。】</li></ul><ul><li>堆            线程共享【这部分一般是Java虚拟机中最大的一块内存区域，这块存储对象的实例。堆内存是垃圾收集器主要光顾的区域，一般来讲根据使用的垃圾收集器的不同，堆中还会划分为一些区域，<code>比如新生代和老年代</code>。新生代还可以再划分为Eden，Survivor等区域。另外为了性能和安全性的角度，在堆中还会为线程划分单独的区域，称之为线程分配缓冲区。更细致的划分是为了让垃圾收集器能够更高效的工作，提高垃圾收集的效率。】</li></ul><ul><li><p>Java栈        线程独享【每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。在Java虚拟机规范中，对于此区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。】</p></li><li><p>本地方法栈    线程独享【本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。】</p></li></ul><ul><li>程序计数器    线程独享【这部分内存不会内存溢出，字节码行号提示器】</li></ul><p>堆（新生代和老年代等）：</p><blockquote><p>Xms256m 代表堆内存初始值为256MB</p><p>Xmx1024m 代表堆内存最大值为1024MB<br>如果-Xmx不指定或者指定偏小，应用可能会导致java.lang.OutOfMemory错误</p></blockquote><p>方法区（永久代）</p><blockquote><p>PermSize和MaxPermSize指明虚拟机为java永久生成对象（Permanate generation）<br>例如：class对象、方法对象这些可反射（reflective）对象分配内存限制，这些内存不包括在Heap（堆内存）区之中。<br>-XX:PermSize=64MB  最小尺寸，初始分配<br>XX:MaxPermSize=256MB  最大允许分配尺寸，按需分配<br>这部分设置过小会导致：java.lang.OutOfMemoryError: PermGen  space</p><p>MaxPermSize缺省值和-server -client选项相关。<br>-server选项下默认MaxPermSize为64m。 -client选项下默认MaxPermSize为32m </p></blockquote><p>设置-Xms、-Xmx 相等以避免在每次GC 后调整堆的大小</p><h2 id="云产品"><a href="#云产品" class="headerlink" title="云产品"></a>云产品</h2><p>说起阿里云，这期间还发生了一个人为事故。<br>当初京东金融本来是通过我们的平台发送的，但是它要我们给他拉专线直接连接运营商。<br>但是这边没有给他拉，而是买了一台阿里云服务器，暴露出一个公网IP地址让它连接，在这台服务器上面部署HAproxy，还是调整到我们的平台。【上边领导们的决定，我就不评论是非对错了 哈哈】</p><p>然后有一天，突然HAProxy的web监测报警，页面打不开。马上上服务器看，CPU爆了【买的服务器配置一般】<br>检查进程。内存正常，磁盘正常，CPU爆了，然后再查看网络连接，发现有大量的CLOSE_WAIT（400个close_wait;100多个establish）</p><blockquote><p>在TCP关闭时，主动关闭的一方发出 FIN 包，被动关闭的一方响应 ACK 包，此时，被动关闭的一方就进入了 CLOSE_WAIT 状态。如果一切正常，稍后被动关闭的一方也会发出 FIN 包，然后迁移到 LAST_ACK 状态。</p></blockquote><p>导致产生大量close_wait的原因是突然遭遇大量的请求，即便响应速度不慢，但是也来不及消费，导致多余的请求还在队列里就被对方关闭了。（因为对方设置了超时时间）。<br>但是linux没有对close_wait做类似超时控制的设置，如果不重启进程，这个状态很可能会永远的持续下去，</p><p>AWS主要是当初想搭VPN，但是一大堆的限制，最终没成功，所以现在是直接买的商业的，稳定，速度也有保证。<br>七牛云，产品主要是数据存储和CDN加速，我自己的博客目前也是在用七牛云。<br>瑞江云，是公司在做什么业务时和人家合作时，人家送的，具体什么我就不知道了</p><h2 id="13-自身素质"><a href="#13-自身素质" class="headerlink" title="13 自身素质"></a>13 自身素质</h2><p>关于这三个人的管理经验，是在第一家公司公司的时候。<br>亿阳分为很多个部门，其中就有一个对外产品部门，当时是准备和人保合作，进入金融行业。因此拿下了一个标，但是招运维主管的时候的比较难招，差不不行，好的知道是外包驻场的形式一般也不愿意来，到最后实在没办法只能从公司内部要人了，然后就把我派过去了。在那边呆了有7个月左右。<br>当时工作非常艰辛【上一家被换掉是因为政治原因，具体是谁就不知道了】，因此过去需要接受上一家的工作，然后开发二代新产品，中间不能停，也就是起承上启下的作用。<br>当时1个月直接就瘦了10斤，天天加班。</p><h2 id="高效办公系列软件"><a href="#高效办公系列软件" class="headerlink" title="高效办公系列软件"></a>高效办公系列软件</h2><p>TC:资源管理器<br>Autohotey：热键管理器<br>Listary：文件搜索浏览增强工具<br>evernote:云笔记<br>Fences:桌面管理工具<br>Ditto：剪切板增强工具<br>Snipaste：截图工具<br>Everything:文件搜索工具</p><h2 id="运维职业规划-如何通过运维思想做好运维工作"><a href="#运维职业规划-如何通过运维思想做好运维工作" class="headerlink" title="运维职业规划-如何通过运维思想做好运维工作"></a>运维职业规划-如何通过运维思想做好运维工作</h2><h3 id="运维思想-运维核心"><a href="#运维思想-运维核心" class="headerlink" title="运维思想-运维核心"></a>运维思想-运维核心</h3><p><strong>稳定性-网站/平台不宕机【这是运维的核心】</strong><br>一般通过以下方式来实现</p><ul><li>架构使用集群+负载均衡+高可用+应用解耦，微服务等部署方式来保证性能</li><li>安全【】</li><li>运营推广不能在白天高峰期推广，需要和运维打招呼</li><li>前端图片的优化，不能使用大图等，尽量使用缩略图</li><li>数据库优化【加入Redis数据缓存层，sql语句优化等】</li><li>避免随时上线的操作【减少次数】</li><li>测试生产等环境保持一致【系统，软件版本，路径等等】</li><li>流程操作【运维标准和流程】</li><li>等等等等</li></ul><p><strong>数据不丢失</strong></p><ul><li>应用配置数据管理-【考虑使用CMDB等平台】</li><li>数据库数据</li></ul><p><strong>避免人为问题</strong><br>避免人为错误，主要分为两个方面，</p><ol><li>一个是他人(主要是开发不严谨)产生的错误，这部分通过运维流程并结合工具控制。【比如测试不严谨，或者开发人员的代码有问题，直接把服务器资源跑没了】</li></ol><ol><li>一个是自己操作产生的问题，这部分通过一些智能化的自动化工具来尽量避免【避免在执行命令的时候误操作等等，常见的有】</li></ol><p>解决：建立完善的流程制度，对运维来说，包括标准化，对开发测试来说，包括上线的流程化【通过运维制度和一些工具来实现】</p><p><strong>提升运维效率</strong><br>这一点是放在最后的，是在上面都做好的前提下，然后再有这么一层，什么自动化，CICD，devops，不是说招几个运维开发就能解决的。一定是需要一个过程的。运维效率很重要，但是不能盲目的只盯住这个上面</p><h3 id="个人如何做好运维工作"><a href="#个人如何做好运维工作" class="headerlink" title="个人如何做好运维工作"></a>个人如何做好运维工作</h3><p><strong>主动性</strong><br>很多东西如果不主动去找系统负责人去推进，进度根本没法完成。</p><p><strong>划重点的能力</strong><br>写文档，研究技术，培训讲解等，需要将其中最重要的东西给讲述出来。<br>就比如在看书的时候，有时候一些大部头的书，可能一句话非常长，你要从中快速挑出这句话的重点。然后建立知识体系。【这就需要能快速的找出重点，快速浏览说明性的内容，因为有可能这些说明性内容对你目前的水平来说完全来说可以忽略】</p><p><strong>全局观</strong></p><p>比如像我当初对接那么多的系统，在出问题的时候，可能是后面某一个系统出问题，但是导致你直接无法使用，所以你需要根据症状，</p><p><strong>态度</strong><br>某一项技术不会非常正常，要摆正心态，虚心向人学习，比如像开发学习，像DBA学习，等等。构建完善的知识体系。<br>一个技术不会到会其实有时候就是一个月的事，根本没有大家想的那么恐怖，不要怕，大胆的去问。</p><p><strong>换位思考，自身作则</strong></p><p>上面的任务怎么说话去分派下去。怎么安排任务，</p><p>流程制度</p><p><strong>流程化，制度化</strong><br>为了便于管理，减少出错的概率。因此要有流程和制度</p><p>新员工刚进来，可以适当的较少压力，因为有</p><p>分配任务的时候，要求下面的人去重复描述下，确保正确无误</p><p><strong>优秀的思维去分享给团队，让团队一起成长</strong></p><p>比如烧开水理论，</p><p>优秀的团队应该是一列高铁</p><h3 id="个人职业规划"><a href="#个人职业规划" class="headerlink" title="个人职业规划"></a>个人职业规划</h3><p>个人现阶段的努力方向是能够快速解决问题<br>这个要求就非常高，需要具备一定的开发能力。<br>比如开发开发出来的程序，在测试上正常，但是一到生产上，服务器的负载就持续飙升，CPU资源被消耗殆尽，这个时候要能够快速的定位到进程。然后要能分析进程内部的资源消耗情况，比如调用内核的哪些系统调用的情况引起的异常等等，找到之后能不能定位到相应的程序代码，这样才能解决问题，而不是找到进程之后，简单的重启。<br>【这一阶段基本上就是资深运维开发工程师级别，预计3年时间】</p><p>在这之后下一个阶段目标是未雨绸缪，在源头将问题遏制住<br>因此需要具备开发能力，在软件需求评审和软件设计阶段就要参与进来。<br>【在这一阶段基本上就达到了架构师的水平】</p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="HTTP协议"><a href="#HTTP协议" class="headerlink" title="HTTP协议"></a>HTTP协议</h3><p><strong>POST与GET的区别</strong></p><p>GET是从服务器上获取数据，POST是向服务器传送数据</p><p>GET是通过发送HTTP协议通过URl参数传递进行接收，而POST是实体数据，通过表单提交</p><p>GET传送的数据量较小，不能大于2KB。POST传送的数据量较大，一般被默认为不受限制。</p><p>GET安全性非常低，POST安全性较高</p>]]></content>
    
    <summary type="html">
    
      个人简历内容应答
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="职场" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%81%8C%E5%9C%BA/"/>
    
      <category term="简历内容应答" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%81%8C%E5%9C%BA/%E7%AE%80%E5%8E%86%E5%86%85%E5%AE%B9%E5%BA%94%E7%AD%94/"/>
    
    
      <category term="简历内容应答" scheme="http://yoursite.com/tags/%E7%AE%80%E5%8E%86%E5%86%85%E5%AE%B9%E5%BA%94%E7%AD%94/"/>
    
  </entry>
  
  <entry>
    <title>Win10添加指定程序到开机自启动</title>
    <link href="http://yoursite.com/2018/04/03/Win10%E6%B7%BB%E5%8A%A0%E6%8C%87%E5%AE%9A%E7%A8%8B%E5%BA%8F%E5%88%B0%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8/"/>
    <id>http://yoursite.com/2018/04/03/Win10添加指定程序到开机自启动/</id>
    <published>2018-04-03T14:32:41.000Z</published>
    <updated>2018-04-03T14:32:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>打开运行对话框（win键+R），输入命令</p><pre><code>shell:startup</code></pre><p>会直接弹出启动项对应的目录，然后像把应用程序快捷方式(需要对该执行文件右键创建快捷方式)复制或者剪切到启动目录</p><p>注意：该方式的启动项对应的目录是个人目录，也就是说不是针对系统上的所有用户。</p>]]></content>
    
    <summary type="html">
    
      Win10添加指定程序到开机自启动
    
    </summary>
    
      <category term="IT基础知识" scheme="http://yoursite.com/categories/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="Windows" scheme="http://yoursite.com/categories/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Windows/"/>
    
    
      <category term="Win10" scheme="http://yoursite.com/tags/Win10/"/>
    
  </entry>
  
  <entry>
    <title>Http Server 网络处理模型的进化之路</title>
    <link href="http://yoursite.com/2018/04/02/Http-Server-%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%9B%E5%8C%96%E4%B9%8B%E8%B7%AF/"/>
    <id>http://yoursite.com/2018/04/02/Http-Server-网络处理模型的进化之路/</id>
    <published>2018-04-02T15:41:29.000Z</published>
    <updated>2018-04-02T15:41:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h1><p>我刚毕业那会儿，国家还是包分配工作的，我的死党小明被分配到了一个叫数据库的大城市，天天都可以坐在高端大气上档次的机房里，在那里专门执行 SQL查询优化，工作稳定又舒适；</p><p>隔壁宿舍的小白被送到了编译器镇，在那里专门把 C 源文件编译成 EXE 程序，虽然累，但是技术含量非常高，工资高，假期多。</p><p>我成绩不太好，典型的差生，四级补考了两次才过，被发配到了一个不知道什么名字的村庄，据说要处理什么 HTTP请求，这个村庄其实就是一个破旧的电脑，令我欣慰的是可以上网，时不时能和死党们通个信什么的。</p><p>不过辅导员说了，我们都有光明的前途。</p><h1 id="Http-Server-1-0"><a href="#Http-Server-1-0" class="headerlink" title="Http Server 1.0"></a>Http Server 1.0</h1><p>HTTP是个新鲜的事物，能够激起我一点点工作的兴趣，不至于沉沦下去。</p><p>一上班，操作系统老大扔给我一大堆文档： “这是 HTTP协议， 两天看完！”</p><p>我这样的英文水平，这几十页的英文 HTTP协议我不吃不喝不睡两天也看不完， 死猪不怕开水烫，慢慢磨吧。</p><p>两个星期以后，我终于大概明白了这 HTTP是怎么回事：无非是有些电脑上的浏览器向我这个破电脑发送一个预先定义好的文本（Http request）, 然后我这边处理一下（通常是从硬盘上取一个后缀名是 html的文件，然后再把这个文件通过文本方式发回去（http response），就这么简单。</p><p>唯一麻烦的实现，我得请操作系统给我建立 Http 层下面的 TCP 连接通道，  因为所有的文本数据都得通过这些 TCP通道接收和发送，这个通道是用 socket建立的。</p><p>弄明白了原理，我很快就搞出了第一版程序，这个程序长这个样子：</p><p><img src="http://picture.watchmen.xin/epoll/epoll-1.png" alt="第1张图片">    </p><p>看看， 这些 socket, bind, listen , accept… 都是操作系统老大提供的接口， 我能做的也就是把他们组装起来：先在 80端口监听，然后进入无限循环，如果有连接请求来了，就接受 (accept)，创建新的 socket，最后才可以通过这个 socket来接收，发送 http 数据。</p><p>老大给我的程序起了个名称，Http Server 版本 1.0 。</p><p>这个名字听起来挺高端的，我喜欢。</p><p>我兴冲冲的拿来实验，程序启动了，在 80端口“蹲守”，过了一会儿就有连接请求了， 赶紧 Accept ,建立新的 socket ，成功 ！接下来就需要从 socket 中读取 Http Request 了。</p><p>可是这个 receive 调用好慢，我足足等了 100 毫秒还没有响应！我被阻塞 (block) 住了！</p><p>操作系统老大说：“别急啊，我也在等着从网卡那里读数据，读完以后就会复制给你。”</p><p>我乐的清闲，可以休息一下。</p><p>可是操作系统老大说：“别介啊，后边还有很多浏览器要发起连接，你不能在这儿歇着啊。”</p><p>我说不歇着怎么办？receive调用在你这里阻塞着，我除了加入阻塞队列，让出 CPU 让别人用还能干什么？</p><p>老大说： “唉，大学里没听说过多进程吗？你现在很明显是单进程，一旦阻塞就完蛋了，想办法用下多进程，每个进程处理一个请求！”</p><p>老大教训的是，我忘了多进程并发编程了。</p><h1 id="Http-Server-2-0-：多进程"><a href="#Http-Server-2-0-：多进程" class="headerlink" title="Http Server 2.0 ：多进程"></a>Http Server 2.0 ：多进程</h1><p>多进程的思路非常简单，当 accept连接以后，对于这个新的 socket ，不在主进程里处理，而是新创建子进程来接管。这样主进程就不会阻塞在 receive 上，可以继续接受新的连接了。</p><p><img src="http://picture.watchmen.xin/epoll/epoll-2.png" alt="第2张图片"></p><p>我改写了代码，把 Http server 升级为 V2.0，这次运行顺畅了很多，能并发的处理很多连接了。</p><p>这个时候 Web 刚刚兴起，我这个 Http Server 访问的人还不多，每分钟也就那么几十个连接发过来，我轻松应对。</p><p>由于是新鲜事物，我还有资本给搞数据库的小明和做编译的小白吹吹牛，告诉他们我可是网络高手。</p><p>没过几年，Web迅速发展，我所在的破旧机器也不行了，换成了一个性能强悍的服务器，也搬到了四季如春的机房里。</p><p>现在每秒中都有上百个连接请求了，有些连接持续的时间还相当的长，所以我经常得创建成百上千的进程来处理他们，每个进程都得耗费大量的系统资源，很明显操作系统老大已经不堪重负了。</p><p>他说：“咱们不能这么干了，这么多进程，光是做进程切换就把我累死了。”</p><p>“要不对每个 Socket 连接我不用进程了，使用线程？ ”</p><p>“可能好一点，但我还是得切换线程啊，你想想办法限制一下数量吧。”</p><p>我怎么限制？我只能说同一时刻，我只能支持 x个连接，其他的连接只能排队等待了。</p><p>这肯定不是一个好的办法。</p><h1 id="Http-Server-3-0-Select模型"><a href="#Http-Server-3-0-Select模型" class="headerlink" title="Http Server 3.0 : Select模型"></a>Http Server 3.0 : Select模型</h1><p>老大说：“我们仔细合计合计，对我来说，一个 Socket连接就是一个所谓的文件描述符（File Descriptor ,简称 fd , 是个整数），这个 fd 背后是一个简单的数据结构，但是我们用了一个非常重量级的东西 – 进程 –来表示对它的读写操作，有点浪费啊。”</p><p>我说：“要不咱们还切换回单进程模型？但是又会回到老路上去，一个 receive 的阻塞就什么事都干不了了。”</p><p>“单进程也不是不可以，但是我们要改变一下工作方式。”</p><p>“改成什么？” 我想不透老大在卖什么关子。</p><p>“你想想你阻塞的本质原因，还不是因为人家浏览器还没有把数据发过来，我自然也没法给你，而你又迫不及待的想去读，我只好把你阻塞。在单进程情况下，一阻塞，别的事儿都干不了。“</p><p>“对，就是这样”</p><p>“所以你接受了客户端连接以后，不能那么着急的去读，咱们这么办，你的每个 socket fd 都有编号，你把这些编号告诉我，就可以阻塞休息了 。”</p><p>我问道：“这不和以前一样吗？原来是调用 receive 时阻塞，现在还是阻塞。”</p><p>“听我说完，我会在后台检查这些编号的 socket，如果发现这些 socket 可以读写，我会把对应的 socket 做个标记，把你唤醒去处理这些 socket 的数据，你处理完了，再把你的那些 socket fd 告诉我，再次进入阻塞，如此循环往复。”</p><p>我有点明白了：“ 这是我们俩的一种通信方式，我告诉你我要等待什么东西，然后阻塞，如果事件发生了，你就把我唤醒，让我做事情。”</p><p><img src="http://picture.watchmen.xin/epoll/epoll-3.png" alt="第3张图片"></p><p>“对，关键点是你等我的通知，我把你从阻塞状态唤醒后，你一定要去遍历一遍所有的 socket fd，看看谁有标记，有标记的做相应处理。我把这种方式叫做 select  。”</p><p>我用 select 的方式改写了 Http server，抛弃了一个 socket 请求对于一个进程的模式，现在我用一个进程就可以处理所有的 socket了。</p><h1 id="Http-Server4-0-epoll"><a href="#Http-Server4-0-epoll" class="headerlink" title="Http Server4.0 : epoll"></a>Http Server4.0 : epoll</h1><p>这种称为 select 的方式运行了一段时间，效果还不错，我只管把 socket fd 告诉老大，然后等着他通知我就行了。</p><p>有一次我无意中问老大：“我每次最多可以告诉你多少个 socket fd？”</p><p>“1024个。”</p><p>“那就是说我一个进程最多只能监控 1024 个 socket 了？ ”</p><p>“是的，你可以考虑多用几个进程啊！”</p><p>这倒是一个办法，不过”select”的方式用的多了，我就发现了弊端，最大的问题就是我从阻塞中恢复以后，需要遍历这 1000 多个 socket fd，看看有没有标志位需要处理。</p><p>实际的情况是，  很多 socket 并不活跃，  在一段时间内浏览器并没有数据发过来， 这 1000 多个 socket 可能只有那么几十个需要真正的处理，但是我不得不查看所有的 socket fd，这挺烦人的。</p><p>难道老大不能把那些发生了变化的 socket 告诉我吗？</p><p>我把这个想法给老大说了下，他说：“嗯，现在访问量越来越大， select 方式已经不满足要求，我们需要与时俱进了，我想了一个新的方式，叫做 epoll。”</p><p><img src="http://picture.watchmen.xin/epoll/epoll-4.png" alt="第4张图片"></p><p>“看到没有，使用 epoll 和 select 其实类似“  老大接着说 ：”不同的地方是第 3 步和第 4 步，我只会告诉你那些可以读写的 socket , 你呢只需要处理这些 ‘ready’ 的 socket 就可以了“</p><p>“看来老大想的很周全， 这种方式对我来说就简单的多了。  ”</p><p>我用 epoll 把 Http Server 再次升级，由于不需要遍历全部集合，只需要处理哪些有变化的，活跃的 socket 文件描述符，系统的处理能力有了飞跃的提升。</p><p>我的 Http Server 受到了广泛的欢迎，全世界有无数人在使用，最后死党数据库小明也知道了，他问我：“ 大家都说你能轻松的支持好几万的并发连接， 真是这样吗？ ”</p><p>我谦虚的说：“过奖，其实还得做系统的优化啦。”</p><p>他说：“厉害啊，你小子走了狗屎运了啊。”</p><p>我回答： “毕业那会儿辅导员不是说过吗， 每个人都有光明的前途。”</p>]]></content>
    
    <summary type="html">
    
      本文转载自公众号infoQ的文章《Http Server：一个差生的逆袭》
    
    </summary>
    
      <category term="IT基础知识" scheme="http://yoursite.com/categories/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="网络编程" scheme="http://yoursite.com/categories/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"/>
    
      <category term="epoll模型" scheme="http://yoursite.com/categories/IT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/epoll%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="epoll模型" scheme="http://yoursite.com/tags/epoll%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
</feed>
