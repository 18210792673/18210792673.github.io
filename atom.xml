<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Watchmen1992&#39;s Blog</title>
  
  <subtitle>锦瑟年华当与书香为度，是为不负天地人生。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-18T03:38:29.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>XiaoHua WANG</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>服务器硬件知识</title>
    <link href="http://yoursite.com/2018/04/18/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2018/04/18/服务器硬件知识/</id>
    <published>2018-04-18T03:38:29.000Z</published>
    <updated>2018-04-18T03:38:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>##</p>]]></content>
    
    <summary type="html">
    
      服务器硬件知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="服务器硬件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6/"/>
    
      <category term="服务器硬件知识" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="服务器硬件" scheme="http://yoursite.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>进程管理-进程性能分析</title>
    <link href="http://yoursite.com/2018/04/18/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86-%E8%BF%9B%E7%A8%8B%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2018/04/18/进程管理-进程性能分析/</id>
    <published>2018-04-18T02:49:51.000Z</published>
    <updated>2018-04-18T02:49:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>分为两部分</p><ul><li><p>服务器即时数据查看</p></li><li><p>监控趋势数据查看</p></li></ul><p>主要分为以下4个部分</p><pre><code>- CPU        系统整体CPU情况，具体进程占用CPU情况，需要精确进程或者线程调用的系统调用- 内存        系统整体占用情况，具体进程占用内存情况，需要精确进程或者线程调用的系统调用- 磁盘        整体磁盘IO情况，具体进程占用磁盘IO情况，需要精确进程或者线程调用的系统调用- 网络        系统整体网络IO情况，带宽使用情况；具体进程占用的网络IO情况，需要精确进程或者线程调用的系统调用- 系统负载    系统整体占用情况</code></pre><p>本文主要讲述在服务器端的即时数据查看。</p><p>#CPU性能分析#</p><h2 id="即时数据查看"><a href="#即时数据查看" class="headerlink" title="即时数据查看"></a>即时数据查看</h2>]]></content>
    
    <summary type="html">
    
      进程管理之进程性能分析
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="进程管理" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    
      <category term="进程性能分析" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    
    
      <category term="进程管理" scheme="http://yoursite.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>LVS从入门到精通</title>
    <link href="http://yoursite.com/2018/04/18/LVS%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/"/>
    <id>http://yoursite.com/2018/04/18/LVS从入门到精通/</id>
    <published>2018-04-18T01:07:47.000Z</published>
    <updated>2018-04-18T01:07:47.000Z</updated>
    
    <summary type="html">
    
      本文讲述4层负载均衡-LVS的相关知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="负载均衡" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
      <category term="LVS" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/LVS/"/>
    
    
      <category term="LVS" scheme="http://yoursite.com/tags/LVS/"/>
    
  </entry>
  
  <entry>
    <title>Python-django项目</title>
    <link href="http://yoursite.com/2018/04/17/Python-django%E9%A1%B9%E7%9B%AE/"/>
    <id>http://yoursite.com/2018/04/17/Python-django项目/</id>
    <published>2018-04-17T12:07:03.000Z</published>
    <updated>2018-04-17T12:07:03.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>基础环境：</strong></p><ul><li>Python3系列（针对环境变量做好软链接）</li><li>依赖关系（python3-venv）</li></ul><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><h2 id="创建激活虚拟环境"><a href="#创建激活虚拟环境" class="headerlink" title="创建激活虚拟环境"></a>创建激活虚拟环境</h2><p>要使用django，首先需要建立一个虚拟工作环境。虚拟环境是系统的一个位置，你可以在其中安装包，并将其与其他python包隔离。将项目的库与其他项目分离是有益的。</p><pre><code>创建虚拟环境wxh@wxh-virtual-machine:/opt$ source ll_env/bin/activate激活虚拟环境(ll_env) wxh@wxh-virtual-machine:/opt$ source ll_env/bin/activate停止虚拟环境(ll_env) wxh@wxh-virtual-machine:/opt$ deactivate </code></pre><h2 id="安装django"><a href="#安装django" class="headerlink" title="安装django"></a>安装django</h2>]]></content>
    
    <summary type="html">
    
      《Python编程从入门到实践》-Django入门
    
    </summary>
    
      <category term="编程语言" scheme="http://yoursite.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/"/>
    
    
      <category term="django" scheme="http://yoursite.com/tags/django/"/>
    
  </entry>
  
  <entry>
    <title>VPC+专线+IDC网络</title>
    <link href="http://yoursite.com/2018/04/17/VPC-%E4%B8%93%E7%BA%BF-IDC%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2018/04/17/VPC-专线-IDC网络/</id>
    <published>2018-04-17T05:57:23.000Z</published>
    <updated>2018-04-17T05:57:23.000Z</updated>
    
    <summary type="html">
    
      VPC+专线+IDC网络相关知识记录
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="网络" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="VPC+专线+IDC网络" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C/VPC-%E4%B8%93%E7%BA%BF-IDC%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="VPC" scheme="http://yoursite.com/tags/VPC/"/>
    
      <category term="专线" scheme="http://yoursite.com/tags/%E4%B8%93%E7%BA%BF/"/>
    
      <category term="IDC网络" scheme="http://yoursite.com/tags/IDC%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper</title>
    <link href="http://yoursite.com/2018/04/17/Zookeeper/"/>
    <id>http://yoursite.com/2018/04/17/Zookeeper/</id>
    <published>2018-04-17T05:21:24.000Z</published>
    <updated>2018-04-17T05:21:24.000Z</updated>
    
    <summary type="html">
    
      Zookeeper从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Zookeeper" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Zookeeper/"/>
    
    
      <category term="Zookeeper" scheme="http://yoursite.com/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Logstash</title>
    <link href="http://yoursite.com/2018/04/17/Logstash/"/>
    <id>http://yoursite.com/2018/04/17/Logstash/</id>
    <published>2018-04-17T05:21:00.000Z</published>
    <updated>2018-04-17T05:21:00.000Z</updated>
    
    <summary type="html">
    
      Logstash从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Logstash" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Logstash/"/>
    
    
      <category term="Logstash" scheme="http://yoursite.com/tags/Logstash/"/>
    
  </entry>
  
  <entry>
    <title>Kibana</title>
    <link href="http://yoursite.com/2018/04/17/Kibana/"/>
    <id>http://yoursite.com/2018/04/17/Kibana/</id>
    <published>2018-04-17T05:20:54.000Z</published>
    <updated>2018-04-17T05:20:54.000Z</updated>
    
    <summary type="html">
    
      Kibana从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Kibana" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Kibana/"/>
    
    
      <category term="Kibana" scheme="http://yoursite.com/tags/Kibana/"/>
    
  </entry>
  
  <entry>
    <title>Filebeat</title>
    <link href="http://yoursite.com/2018/04/17/Filebeat/"/>
    <id>http://yoursite.com/2018/04/17/Filebeat/</id>
    <published>2018-04-17T05:20:23.000Z</published>
    <updated>2018-04-17T05:20:23.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本文基于Filebeat 6.2.3版本</strong></p><p>参考文献： <a href="https://www.elastic.co/guide/en/beats/filebeat/current/index.html" target="_blank" rel="noopener">官网</a></p><h2 id="1-Filebeat基础知识"><a href="#1-Filebeat基础知识" class="headerlink" title="1. Filebeat基础知识"></a>1. Filebeat基础知识</h2><blockquote><p>Filebeat consists of two main components: <code>prospectors and harvesters.</code></p><p>These components work together to <code>tail files</code> and send event data to the output that you specify.</p></blockquote><ul><li><p>prospectors:勘探者；探矿者【也就是数据变化的探测者，也就是入向配置】</p></li><li><p>harvesters：收割机；收获者【也就是数据的下游接收端，也就是出向配置】</p></li><li><p>spooler：处理程序；【处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。】</p></li></ul><p>Filebeat工作流程：</p><blockquote><p>当你开启filebeat程序的时候，它会启动一个或多个探测器（prospectors）去检测你指定的日志目录或文件，对于探测器找出的每一个日志文件，filebeat启动收割进程（harvester），每一个收割进程读取一个日志文件的新内容，并发送这些新的日志数据到处理程序（spooler），处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。</p></blockquote><p>流程图如下：</p><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-2.png" alt="流程图"></p><h3 id="1-1-What-is-harvester"><a href="#1-1-What-is-harvester" class="headerlink" title="1.1 What is harvester?"></a>1.1 What is harvester?</h3><blockquote><p>A harvester is responsible for reading the content of a single file. The harvester reads each file, line by line, and sends the content to the output. One harvester is started for each file. T<code>he harvester is responsible for opening and closing the file</code>, which means that the file descriptor remains open while the harvester is running. If a file is removed or renamed while it’s being harvested, Filebeat continues to read the file. This has the side effect that the space on your disk is reserved until the harvester closes. By default, Filebeat keeps the file open until close_inactive is reached.</p><p>Closing a harvester has the following consequences:【关闭时按以下顺序依`次执行，也就是关闭顺序】</p></blockquote><ul><li><p>The file handler is closed, freeing up the underlying resources if the file was deleted while the harvester was still reading the file.<br>The</p></li><li><p>harvesting of the file will only be started again after scan_frequency has elapsed.</p></li></ul><ul><li>If the file is moved or removed while the harvester is closed, harvesting of the file will not continue.</li></ul><p>To control when a harvester is closed, use the close_* configuration options.</p><p>harvester负责打开和关闭文件</p><p>当harvester捕获到一个文件之后，这个文件被删除或者重命名，它将继续读取这个文件。【副作用是占用磁盘空间直到harvester进程关闭】</p><h3 id="1-2-What-is-prospector"><a href="#1-2-What-is-prospector" class="headerlink" title="1.2 What is prospector?"></a>1.2 What is prospector?</h3><blockquote><p>A prospector is responsible for managing the harvesters and finding all sources to read from.</p><p>If the input type is log, the prospector finds all files on the drive that match the defined glob paths and starts a harvester for each file. Each prospector runs in its own Go routine.</p><p>The following example configures Filebeat to harvest lines from all log files that match the specified glob patterns:</p></blockquote><pre><code>filebeat.prospectors:- type: log  paths:    - /var/log/*.log    - /var/path2/*.log</code></pre><p>prospector负责管理harvesters进程以及寻找需要去读取的资源（input设置）</p><p>Filebeat的input type当前有两种设置：<code>log和stdin</code></p><blockquote><p>The log prospector checks each file to see whether a harvester needs to be started, whether one is already running, or whether the file can be ignored (see ignore_older).<br><code>New lines are only picked up if the size of the file has changed since the harvester was closed.</code></p></blockquote><p>注意，Filebeat只能读取本地的文件，也就是需要在每个日志产生端都安装：<br><strong>Filebeat prospectors can only read <code>local files</code>. There is no functionality to connect to remote hosts to read stored files or logs.</strong></p><h3 id="1-3-How-does-Filebeat-keep-the-state-of-files"><a href="#1-3-How-does-Filebeat-keep-the-state-of-files" class="headerlink" title="1.3 How does Filebeat keep the state of files"></a>1.3 How does Filebeat keep the state of files</h3><p>filebeat通过定期去刷新，将状态落地到磁盘的注册文件中，以这种形式来保持文件检测状态</p><blockquote><p>Filebeat keeps the state of each file and frequently flushes the state to disk in the registry file</p><p>The state is used to remember the last offset a harvester was reading from and to ensure all log lines are sent</p></blockquote><p>filebeat的状态信息记录的是最新的读取偏移量，如果下游的接受者（ES、kafka、logstash等不可达），filebeat将会保持这种状态，当检测后可达之后将会重新发送</p><p>当filebeat重启时，将会重新构建这个注册文件</p><p>每个prospector针对每个文件都会保持一个状态，也就是一个注册文件，因为文件可能会被删除或者重命名</p><p>针对每个文件，filebeat存储一个唯一的标识符去发现该文件之前是否有被收集过</p><blockquote><p>For each file, Filebeat stores unique identifiers to detect whether a file was harvested previously.</p></blockquote><h3 id="1-4-how-does-Filebeat-ensure-at-least-once-delivery"><a href="#1-4-how-does-Filebeat-ensure-at-least-once-delivery" class="headerlink" title="1.4 how does Filebeat ensure at-least-once delivery?"></a>1.4 how does Filebeat ensure at-least-once delivery?</h3><p>Filebeat保证一个事件的完整及正确性，它将发送最少一次给设置的下游输出，以保证没有数据丢失。</p><blockquote><p>Filebeat guarantees that events will be delivered to the configured output at least once and with no data loss.</p><p>Filebeat is able to achieve this behavior because it stores the delivery state of each event in the registry file.</p></blockquote><p>Filebeat能够保证这种特性的原因是因为它将分发状态也存储在这个注册文件中。</p><p>当下游因为阻塞或者其他原因，没有对某一个事件进行确认的时候，filebeat将一直尝试去发送这个事件，直到收到ACK</p><blockquote><p>If Filebeat shuts down while it’s in the process of sending events, it does not wait for the output to acknowledge all events before shutting down. Any events that are sent to the output, but not acknowledged before Filebeat shuts down, are sent again when Filebeat is restarted. This ensures that each event is sent at least once, but you can end up with duplicate events being sent to the output. You can configure Filebeat to wait a specific amount of time before shutting down by setting the<code>shutdown_timeout</code> option.</p></blockquote><p>当Filebeat异常关闭，再次启动的时候，它将会重新发送没有接受到ACk的事件。通过这种机制来保证每个事件至少发送一次。</p><p>因此，为了减少重新发送event事件的次数，可以通过设置shutdown_timeout参数来设置当filebeat关闭时，等待多少时间之后再关闭进程，以保证收到尽量多的ACK</p><p>注意：虽然拥有这种机制来保证数据的不丢失，但还是存在一些可能的情况导致数据的丢失（日志轮转和删除文件时）</p><p>例如：</p><ul><li><p>If log files are written to disk and rotated faster than they can be processed by Filebeat 【当日志刚好触发到日志轮转条件时，并且此时filebeat还没有来得及收集的时候，原因是inode节点发生变化】</p></li><li><p>if files are deleted while the output is unavailable 【当该文件被删除时，并且输出不可用时】</p></li></ul><p><strong>总结：filebeat会维护一个注册文件【是落地到磁盘中的】，该注册文件中包含2个信息</strong></p><ul><li>所发送事件的偏移量，精确记录当前的发送情况。        下游断开时，将保持直到连接后再发送</li><li>发送事件的ACk，记录发送事件的接受情况。            没有收到，将一直持续发送。</li></ul><h2 id="2-Filebeat安装部署配置启动"><a href="#2-Filebeat安装部署配置启动" class="headerlink" title="2. Filebeat安装部署配置启动"></a>2. Filebeat安装部署配置启动</h2><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><pre><code>curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.3-x86_64.rpmrpm -vih filebeat-6.2.3-x86_64.rpm</code></pre><h3 id="2-2-启动"><a href="#2-2-启动" class="headerlink" title="2.2 启动"></a>2.2 启动</h3><pre><code>service filebeat start</code></pre><h3 id="2-3-命令"><a href="#2-3-命令" class="headerlink" title="2.3 命令"></a>2.3 命令</h3><p>主要提供了8个命令API</p><pre><code>[root@master ~]# filebeat --helpUsage:  filebeat [flags]  filebeat [command]Available Commands:  export      Export current config or index template        #导出ES的索引模板  help        Help about any command  keystore    Manage secrets keystore  modules     Manage configured modules                        #Filebeat的模块相关  run         Run filebeat  setup       Setup index template, dashboards and ML jobs    #设置初始化环境，包括索引模板，kibana的仪表盘等  test        Test config  version     Show current version infoFlags:  -E, --E setting=value      Configuration overwrite  -M, --M setting=value      Module configuration overwrite  -N, --N                    Disable actual publishing for testing  -c, --c string             Configuration file, relative to path.config (default &quot;filebeat.yml&quot;)      --cpuprofile string    Write cpu profile to file  -d, --d string             Enable certain debug selectors  -e, --e                    Log to stderr and disable syslog/file output  -h, --help                 help for filebeat      --httpprof string      Start pprof http server      --memprofile string    Write memory profile to this file      --modules string       List of enabled modules (comma separated)      --once                 Run filebeat only once until all harvesters reach EOF      --path.config string   Configuration path (default &quot;&quot;)      --path.data string     Data path (default &quot;&quot;)      --path.home string     Home path (default &quot;&quot;)      --path.logs string     Logs path (default &quot;&quot;)      --plugin pluginList    Load additional plugins      --setup                Load the sample Kibana dashboards      --strict.perms         Strict permission checking on config files (default true)  -v, --v                    Log at INFO levelUse &quot;filebeat [command] --help&quot; for more information about a command.</code></pre><p>注意： filebeat有：<code>Config File Ownership and Permissions</code></p><blockquote><p>On systems with POSIX file permissions, all Beats configuration files are subject to ownership and file permission checks. The purpose of these checks is to prevent unauthorized users from providing or modifying configurations that are run by the Beat. The owner of the configuration files must be either root or the user who is executing the Beat process. The permissions on each file must disallow writes by anyone other than the owner.</p></blockquote><p>也就是说只有root用户或者文件的属主才有权限执行命令</p><h3 id="2-4-编辑配置文件"><a href="#2-4-编辑配置文件" class="headerlink" title="2.4 编辑配置文件"></a>2.4 编辑配置文件</h3><p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/directory-layout.html#_docker" target="_blank" rel="noopener">配置文件生成规则</a></p><p>安装完毕之后，配置文件路径：/etc/filebeat/filebeat.yml<br>参考配置文件为：filebeat.reference.yml</p><p>这里采用的是rpm包方式安装，因此生成规则如下：</p><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-1.png" alt="生成规则"></p><p>filebeat.yml整个配置文件分为几个部分，分别是：</p><pre><code>- Modules configuration- Filebeat prospectors        【上游输入设置。这部分包含内容为：type设置|path路径设置，】- Filebeat autodiscover- Filebeat global options- General- Elastic Cloud- Outputs                    【下游输出设置。这部分内容为：ES|kafka|logstash|】- Paths- Dashboards- Template                    【ES模板配置】- Kibana- Logging- Xpack Monitoring            【xpack监控】- HTTP Endpoint</code></pre><p>让我们来配置filebeat：</p><h4 id="modules模块设置"><a href="#modules模块设置" class="headerlink" title="modules模块设置"></a>modules模块设置</h4><p>filebeat的模块实现了快速部署的方式。该部分的设置是可选的，你可以选择在后面自己定义prospectors设置相关设置。<br>可以通过以下3种方式开启modules</p><ul><li>Enable module configs in the modules.d directoryedit</li></ul><ul><li>Enable modules when you run Filebeatedit</li></ul><ul><li>Enable module configs in the filebeat.yml file</li></ul><p>使用了模块之后，仍然可以指定变量设置来覆盖模块中的定义【最小局部生效】。并且，可以使用高级设置来覆盖prospector中的相关设置</p><h4 id="prospectors设置"><a href="#prospectors设置" class="headerlink" title="prospectors设置"></a>prospectors设置</h4><p>对于大多数的基本filebeat配置，你可以定义一个单一探测器针对一个单一的路径，例如：</p><pre><code>filebeat.prospectors:- input_type: log  paths:    - /var/log/*.log</code></pre><p>在这个例子中，探测器会收集/var/log/*.log的所有匹配文件，这意味这filebeat会手机所有的/var/log下以.log结尾的文件，此处还支持Golang Glob支持的所有模式。</p><p>在预定义级别的子目录中获取所有文件，可以使用这个配置：/var/log/<em>/</em>.log，这会找到/var/log下所有子目录中所有的以.log结尾的文件。但它并不会找到/var/log文件夹下的以.log结尾的文件。现在它还不能递归的在所有子目录中获取所有的日志文件。</p><h4 id="Outputs设置"><a href="#Outputs设置" class="headerlink" title="Outputs设置"></a>Outputs设置</h4><p>如果你设置输出到elasticsearch中，那么你需要在filebeat的配置文件中设置elasticsearch的IP地址与端口。</p><pre><code>output.elasticsearch:  hosts: [&quot;192.168.1.42:9200&quot;]</code></pre><p>如果要使用Logstash对Filebeat收集的数据执行附加处理，则需要将Filebeat配置为使用Logstash。</p><pre><code>＃----------------------------- Logstash输出------------------ --------------output.logstash：  hosts：[“127.0.0.1:5044”]</code></pre><p>如果您打算使用随Filebeat提供的示例Kibana仪表板，需要配置Kibana，这段是属于kibana设置，不输出output设置</p><pre><code>#============================== Kibana =====================================setup.kibana：  host：“localhost：5601”</code></pre><p>如果设置ES和kibana的安全性设置，使用以下的配置</p><pre><code>output.elasticsearch:  hosts: [&quot;myEShost:9200&quot;]  username: &quot;elastic&quot;  password: &quot;elastic&quot;setup.kibana:  host: &quot;mykibanahost:5601&quot;  username: &quot;elastic&quot;   password: &quot;elastic&quot;</code></pre><h4 id="Template设置"><a href="#Template设置" class="headerlink" title="Template设置"></a>Template设置</h4><p><strong>这一部分主要设置ES的模板</strong></p><p>在Elasticsearch中，索引模板用于定义设置和映射，以确定如何分析字段。<br>通过使用ES模板，可以有效的减轻存储压力<br>ES模板：通过对索引中的每个字段做事先的预定义数据类型（例如ID，name等分别使用存储空间最小的数据类型）</p><p>在安装完毕Filebeat之后，会生成fields.yml这个ES模板文件<br>下游如果是ES的话，Filebeat在启动的时候会自动的加载这个模板文件<br>如果要关闭自动加载功能，则将以下参数设置为false</p><pre><code>setup.template.enabled: false</code></pre><p>注意：如果该模板已经存在，则不会覆盖它，除非您配置Filebeat来指定执行此操作。</p><p>如果下游连接的不是ES而是logstash，那么需要手动导入模板</p><pre><code>filebeat setup --template -E output.logstash.enabled=false -E &apos;output.elasticsearch.hosts=[&quot;localhost:9200&quot;]&apos;</code></pre><p><strong>强制Kibana使用最新的Filebeat索引信息</strong></p><p>如果当前ES中已经有了filebeat的索引信息，那么修改模板之后，因此模板不会被覆盖，因此需要强制刷新生效。</p><pre><code>curl -XDELETE &apos;http://localhost:9200/filebeat-*&apos;</code></pre><p><strong>中转方式导入ES模板</strong></p><p>如果Filebeat没有直接连接到ES，那么可以将模板文件先导出到可以连接到ES的主机上，再通过这台去导入</p><pre><code>filebeat export template &gt; filebeat.template.jsoncurl -XPUT -H &apos;Content-Type: application/json&apos; http://localhost:9200/_template/filebeat-6.2.3 -d@filebeat.template.json</code></pre><p><strong>相关命令</strong></p><pre><code>./filebeat setup -e    导入ES的索引末班./filebeat -e --modules system 导入模块的命令，这里是导入system模块./filebeat -e --modules system,nginx,mysql  一次运行多个模块</code></pre><h4 id="Kibana设置"><a href="#Kibana设置" class="headerlink" title="Kibana设置"></a>Kibana设置</h4><p>再kibana上显示filebeat的索引信息之前，you need to create the index pattern, <code>filebeat-*</code>， and load the dashboards into Kibana.<br>不过在filebeat的6.0.0版本之后，这部分操作通过配置文件中的kibana配置部署来实现<br>也就是上面说到的这一段的配置：</p><pre><code>#============================== Kibana =====================================setup.kibana：  host：“localhost：5601”</code></pre><p>在配置之前请确保kibana已经处于运行状态，然后执行如下命令</p><pre><code>filebeat setup --dashboards</code></pre>]]></content>
    
    <summary type="html">
    
      Filebeat从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Filebeat" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Filebeat/"/>
    
    
      <category term="Filebeat" scheme="http://yoursite.com/tags/Filebeat/"/>
    
  </entry>
  
  <entry>
    <title>Kafka</title>
    <link href="http://yoursite.com/2018/04/17/Kafka/"/>
    <id>http://yoursite.com/2018/04/17/Kafka/</id>
    <published>2018-04-17T05:20:18.000Z</published>
    <updated>2018-04-17T05:20:18.000Z</updated>
    
    <summary type="html">
    
      Kafka从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Kafka" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://yoursite.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Flume</title>
    <link href="http://yoursite.com/2018/04/17/Flume/"/>
    <id>http://yoursite.com/2018/04/17/Flume/</id>
    <published>2018-04-17T05:20:12.000Z</published>
    <updated>2018-04-17T05:20:12.000Z</updated>
    
    <summary type="html">
    
      Flume从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Flume" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Flume/"/>
    
    
      <category term="Flume" scheme="http://yoursite.com/tags/Flume/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch</title>
    <link href="http://yoursite.com/2018/04/17/Elasticsearch/"/>
    <id>http://yoursite.com/2018/04/17/Elasticsearch/</id>
    <published>2018-04-17T05:16:22.000Z</published>
    <updated>2018-04-17T05:16:22.000Z</updated>
    
    <content type="html"><![CDATA[<h3 id="索引模板"><a href="#索引模板" class="headerlink" title="索引模板"></a>索引模板</h3><p>在Elasticsearch中，索引模板用于定义设置和映射，以确定如何分析字段。（例如ID，name等分别使用存储空间最小的数据类型）</p><p>索引模板允许您<code>定义创建新索引</code>时将<code>自动应用</code>的模板。</p><p>模板仅适用于索引创建时。更改模板将不会影响现有的索引。在使用创建索引的API时，如果设置了数据类型，那么将会覆盖模板的设置，也就是最小局部生效</p>]]></content>
    
    <summary type="html">
    
      Elasticsearch从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Elasticsearch" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://yoursite.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>ELK架构之Filebeat+kafka+logstash+Elasticsearch</title>
    <link href="http://yoursite.com/2018/04/17/ELK%E6%9E%B6%E6%9E%84%E4%B9%8BFilebeat-kafka-logstash-Elasticsearch/"/>
    <id>http://yoursite.com/2018/04/17/ELK架构之Filebeat-kafka-logstash-Elasticsearch/</id>
    <published>2018-04-17T02:06:21.000Z</published>
    <updated>2018-04-17T02:06:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-3.png" alt="流程图"></p><p><strong>组件关系说明：</strong></p><p>logstash 和filebeat都具有日志收集功能，filebeat更轻量，占用资源更少，但logstash 具有filter功能，能过滤分析日志。一般结构都是filebeat采集日志，然后发送到消息队列，redis，kafaka。然后logstash去获取，利用filter功能过滤分析，然后存储到elasticsearch中</p><p>filebeat–&gt;kafka集群–&gt;logstash–&gt;(file server文件系统|kafka集群|ES集群)</p><ul><li>Filebeat    日志收集</li><li>kafka        日志接受消息队列</li><li>logstash    将日志进行过滤分析后存储到ES</li><li>ES        存储，检索，分析</li></ul><h1 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a><font color="red">Filebeat</font></h1><p><strong>Filebeat配置文件：</strong></p><pre><code>filebeat.prospectors:- input_type: log  paths:    - /home/appdeploy/deploy/logs/pinpoint/*-pinpoint.log  document_type: tools.pinpoint.data  scan_frequency: 5s  tail_files: trueoutput.kafka:   hosts: [&quot;10.10.10.92:9092&quot;, &quot;10.10.10.93:9092&quot;, &quot;10.10.10.94:9092&quot;]   topic: &apos;%{[type]}&apos;   partition.round_robin:     reachable_only: false   required_acks: 1   compression: gzip   max_message_bytes: 1000000   codec.format:        string: &apos;%{[message]}&apos;</code></pre><p><strong>说明</strong></p><pre><code>filebeat.prospectors:- input_type: log            #类型选择log|stdin中的log，在filebeat最新版本中input_type写成type  paths:    - /home/appdeploy/deploy/logs/pinpoint/*-pinpoint.log  document_type: tools.pinpoint.data              scan_frequency: 5s            #prospector每隔5秒去检测日志的生成情况  tail_files: true                #设置之后，filebeat读取新文件时从文件末尾开始读取，而不是开头，如果设置了日志轮转，那么新文件的第一行将会被忽略output.kafka:                    #输出策略采用kafka   hosts: [&quot;10.10.10.92:9092&quot;, &quot;10.10.10.93:9092&quot;, &quot;10.10.10.94:9092&quot;]        #kafka集群的配置信息   topic: &apos;%{[type]}&apos;            #设置topic使用文件类型   partition.round_robin:        #Topic的分区算法     reachable_only: false        # 如果设置为true，那么event将只会推送到leader上，默认设置就是false   required_acks: 1                #ACk可靠性级别，0表示不响应，1表示本地commit，-1表示所有的副本commit。默认为1   compression: gzip            # 设置输出压缩编解码器，可选snappy and gzip。默认就是gzip   max_message_bytes: 1000000    # JSON格式的信息一个传输允许的最大大小上限   codec.format:        string: &apos;%{[message]}&apos;</code></pre><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a><font color="red">Kafka</font></h1><p>在这里，kafka的作用是将日志接受到消息队列中，以备后续的logstash收取</p><p><strong>kafka的配置【每台的配置除了id不同之外，其他均类似】</strong></p><p>[root@qa-bigdata002 config]# egrep  -v ‘^#|^$’ <strong>server.properties</strong></p><pre><code>broker.id=0port=9092host.name=172.24.80.87num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/home/kafka/kafka-logsnum.partitions=2num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000log.cleaner.enable=falsezookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181zookeeper.connection.timeout.ms=600000</code></pre><p><strong>说明</strong></p><pre><code>broker.id=0                # The id of the broker. This must be set to a unique integer for each broker，在一个kafka集群中，每个broker的ID必须不同port=9092host.name=172.24.80.87num.network.threads=3                    #The number of threads handling network requestsnum.io.threads=8                        # The number of threads doing disk I/O，将数据落地到磁盘的线程数量，一般为CPU核数的倍数socket.send.buffer.bytes=102400            #发送缓冲区的大小，单位是字节，这里是1Msocket.receive.buffer.bytes=102400        #接受缓冲区大小，这里是1Msocket.request.max.bytes=104857600        #最大接受的请求数量，防止OOM的出现，out of memory,这里设置为104Mlog.dirs=/home/kafka/kafka-logs            # 落地到磁盘的文件的存储路径num.partitions=2                        # 每个Topic的分区数量num.recovery.threads.per.data.dir=1        #在日志数据恢复时，log.retention.hours=168                    #日志保留小时数，这里的168小时，也就是保留7天。log.segment.bytes=1073741824            #单个日志的文件的最大大小，现在配置为1Glog.retention.check.interval.ms=300000    #每隔5分钟检测日志文件是否可以被删除log.cleaner.enable=false                #设置flase之后，日志保留策略将会采用上面的分段及超时设置，如果为true，zookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181    #ZK的配置zookeeper.connection.timeout.ms=600000            #连接ZK的超时时间</code></pre><p><strong>consumer.properties</strong></p><pre><code># Zookeeper connection string# comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;zookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181# timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000#consumer group idgroup.id=test-consumer-group</code></pre><p><strong>producer.properties</strong></p><pre><code># list of brokers used for bootstrapping knowledge about the rest of the cluster# format: host1:port1,host2:port2 ...metadata.broker.list=172.24.80.87:9092,172.24.80.88:9092,172.24.80.89:9092</code></pre><p><strong>zookeeper.properties</strong></p><pre><code># the directory where the snapshot is stored.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# disable the per-ip limit on the number of connections since this is a non-production configmaxClientCnxns=0</code></pre><h1 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a><font color="red">Logstash</font></h1><h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a><font color="red">Elasticsearch</font></h1><h2 id="ES模板设置"><a href="#ES模板设置" class="headerlink" title="ES模板设置"></a>ES模板设置</h2><p>通过使用ES模板，可以有效的减轻存储压力<br>ES模板：通过对索引中的每个字段做事先的预定义数据类型（例如ID，name等分别使用存储空间最小的数据类型）</p>]]></content>
    
    <summary type="html">
    
      ELk日志处理平台架构之Filebeat+kafka+logstash+Elasticsearch
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="ELk日志处理平台" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELk%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="Filebeat+kafka+logstash+Elasticsearch" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELk%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0/Filebeat-kafka-logstash-Elasticsearch/"/>
    
    
      <category term="ELK架构" scheme="http://yoursite.com/tags/ELK%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>异地多活机房建设</title>
    <link href="http://yoursite.com/2018/04/17/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9C%BA%E6%88%BF%E5%BB%BA%E8%AE%BE/"/>
    <id>http://yoursite.com/2018/04/17/异地多活机房建设/</id>
    <published>2018-04-17T01:30:16.000Z</published>
    <updated>2018-04-17T01:30:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言概述"><a href="#1-前言概述" class="headerlink" title="1. 前言概述"></a>1. 前言概述</h1><p>当前公司的核心应用都是运行在阿里云上，这种方式存在以下几个缺点：</p><ul><li>星型拓扑结构，所有压力都集中在一套系统之上，整体系统的高可用性还不够充分。新增IDC机房之后，可以将一部分流量引入到就近的云下机房。为核心系统减负，也就是说，同一个应用对应有多个生产环境。</li><li>的</li></ul><h1 id="1-1-思路"><a href="#1-1-思路" class="headerlink" title="1.1 思路"></a>1.1 思路</h1><p>整体思路：</p><ul><li>为什么？</li><li>是什么？</li><li>怎么做？</li></ul><h2 id="1-2-为什么？为什么需要异地机房？"><a href="#1-2-为什么？为什么需要异地机房？" class="headerlink" title="1.2 为什么？为什么需要异地机房？"></a>1.2 为什么？为什么需要异地机房？</h2><h2 id="1-3-是什么？-异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？"><a href="#1-3-是什么？-异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？" class="headerlink" title="1.3 是什么？ 异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？"></a>1.3 是什么？ 异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？</h2><h2 id="1-4-怎么做？-如何实现？"><a href="#1-4-怎么做？-如何实现？" class="headerlink" title="1.4 怎么做？ 如何实现？"></a>1.4 怎么做？ 如何实现？</h2><p>这部分内容将会在下面的章节进行具体的阐述。</p><h1 id="2-具体实施"><a href="#2-具体实施" class="headerlink" title="2. 具体实施"></a>2. 具体实施</h1>]]></content>
    
    <summary type="html">
    
      近期公司在进行异地机房的建设，在不涉及公司机密数据的前提下，在这里记录下整个过程，一方面是便于自己检索，另一方面是给有同样需求的网友一定参考。
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维架构" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/"/>
    
      <category term="异地多活" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB/"/>
    
    
      <category term="异地多活机房建设" scheme="http://yoursite.com/tags/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9C%BA%E6%88%BF%E5%BB%BA%E8%AE%BE/"/>
    
  </entry>
  
  <entry>
    <title>常用软件激活密钥</title>
    <link href="http://yoursite.com/2018/04/16/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    <id>http://yoursite.com/2018/04/16/常用软件激活密钥/</id>
    <published>2018-04-16T12:06:56.000Z</published>
    <updated>2018-04-16T12:06:56.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>vmware workstations 14 pro</strong></p><ul><li>CG54H-D8D0H-H8DHY-C6X7X-N2KG6 【亲测可用】</li></ul><ul><li>ZC3WK-AFXEK-488JP-A7MQX-XL8YF</li></ul><ul><li>AC5XK-0ZD4H-088HP-9NQZV-ZG2R4</li></ul><ul><li>ZC5XK-A6E0M-080XQ-04ZZG-YF08D</li></ul><ul><li>ZY5H0-D3Y8K-M89EZ-AYPEG-MYUA8</li></ul><p><strong>sublime Text 3</strong></p><pre><code>—– BEGIN LICENSE —–TwitterInc200 User LicenseEA7E-8900071D77F72E 390CDD93 4DCBA022 FAF6079061AA12C0 A37081C5 D0316412 4584D13694D7F7D4 95BC8C1C 527DA828 560BB037D1EDDD8C AE7B379F 50C9D69D B35179EF2FE898C4 8E4277A8 555CE714 E1FB0E43D5D52613 C3D12E98 BC49967F 7652EED29D2D2E61 67610860 6D338B72 5CF95C69E36B85CC 84991F19 7575D828 470A92AB—— END LICENSE ——</code></pre><p>使用：</p><p>软件主界面——右下角help——Enter License</p><p>将上面的代码进去即可激活。</p>]]></content>
    
    <summary type="html">
    
      常用软件激活密钥/序列号
    
    </summary>
    
      <category term="常用软件工具" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"/>
    
      <category term="常用软件激活密钥" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    
    
      <category term="软件激活密钥" scheme="http://yoursite.com/tags/%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    
  </entry>
  
  <entry>
    <title>Linux常用命令之curl命令</title>
    <link href="http://yoursite.com/2018/04/16/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2018/04/16/Linux常用命令/</id>
    <published>2018-04-16T02:57:34.000Z</published>
    <updated>2018-04-16T02:57:34.000Z</updated>
    
    <summary type="html">
    
      Linux常用命令之curl命令
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux基础知识" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="Linux常用命令" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="curl命令" scheme="http://yoursite.com/tags/curl%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>IT常用英语记录</title>
    <link href="http://yoursite.com/2018/04/16/%E5%B8%B8%E7%94%A8%E8%8B%B1%E8%AF%AD%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2018/04/16/常用英语记录/</id>
    <published>2018-04-16T01:23:49.000Z</published>
    <updated>2018-04-16T01:23:49.000Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th style="text-align:center">英语</th><th style="text-align:center">释义</th></tr></thead><tbody><tr><td style="text-align:center">side effect</td><td style="text-align:center">副作用</td></tr><tr><td style="text-align:center">properties</td><td style="text-align:center">性能，属性，性质，特性，财产</td></tr><tr><td style="text-align:center">involves</td><td style="text-align:center">包含，牵涉</td></tr><tr><td style="text-align:center">at-least-once</td><td style="text-align:center">至少一次</td></tr><tr><td style="text-align:center">deprecated</td><td style="text-align:center">弃用，废弃，不赞成的</td></tr><tr><td style="text-align:center">shipper</td><td style="text-align:center">托运人；发货人；货主</td></tr><tr><td style="text-align:center">prospectors</td><td style="text-align:center">勘探者；探矿者</td></tr><tr><td style="text-align:center">harvesters</td><td style="text-align:center">收割机；收获者</td></tr><tr><td style="text-align:center">layout</td><td style="text-align:center">布局；设计；安排；陈列</td></tr><tr><td style="text-align:center">keystore</td><td style="text-align:center">密钥库;文件;密码;签名文件</td></tr><tr><td style="text-align:center">permitted</td><td style="text-align:center">被允许的；允许</td></tr><tr><td style="text-align:center">individual</td><td style="text-align:center">个人的；个别的；独特的；个体</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      IT常用英语
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="英语" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%8B%B1%E8%AF%AD/"/>
    
    
      <category term="IT常用英语" scheme="http://yoursite.com/tags/IT%E5%B8%B8%E7%94%A8%E8%8B%B1%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>jumpserver安装部署及使用</title>
    <link href="http://yoursite.com/2018/04/13/jumpserver%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2018/04/13/jumpserver安装部署及使用/</id>
    <published>2018-04-13T07:13:23.000Z</published>
    <updated>2018-04-13T07:13:23.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-安装部署"><a href="#1-安装部署" class="headerlink" title="1. 安装部署"></a>1. 安装部署</h1><p>【注意：务必保证版本及操作一致】</p><p>参考链接：<a href="http://docs.jumpserver.org/zh/latest/step_by_step.html" target="_blank" rel="noopener">一步一步安装文档</a></p><h2 id="1-1-环境准备"><a href="#1-1-环境准备" class="headerlink" title="1.1 环境准备"></a>1.1 环境准备</h2><h3 id="1-1-1-安装依赖关系"><a href="#1-1-1-安装依赖关系" class="headerlink" title="1.1.1 安装依赖关系"></a>1.1.1 安装依赖关系</h3><pre><code>yum -y install wget sqlite-devel xz gcc automake zlib-devel openssl-devel epel-release git  libffi-devel python-devel</code></pre><p><strong>注意：python-deve需要安装对应的版本，我这里安装的是python36-devel</strong> </p><h3 id="1-1-2-建立python虚拟环境"><a href="#1-1-2-建立python虚拟环境" class="headerlink" title="1.1.2 建立python虚拟环境"></a>1.1.2 建立python虚拟环境</h3><p>使用原因：因为 CentOS 6/7 自带的是 Python2，而 Yum 等工具依赖原来的 Python，为了不扰乱原来的环境我们来使用 Python 虚拟环境</p><p><strong>如果服务器上没有python3.6.1+环境，则需要手动安装</strong></p><pre><code>$ wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tar.xz$ tar xvf Python-3.6.1.tar.xz  &amp;&amp; cd Python-3.6.1$ ./configure &amp;&amp; make &amp;&amp; make install$ cd /opt$ python3 -m venv py3$ source /opt/py3/bin/activate</code></pre><p><strong>看到下面的提示符代表成功，以后运行 Jumpserver 都要先运行以上 source 命令，以下所有命令均在该虚拟环境中运行</strong></p><pre><code>(py3) [root@localhost py3]</code></pre><p>在源码安装python3时可能会出现报错，关键字：“ake: <em>*</em> [Objects/unicodeobject.o] Error 4”。<br>这个时候，修改Makefile文件，把‘-DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes’中的‘03’改为‘02’，然后再重新编译安装即可。</p><h2 id="1-2-安装启动-jumpserver"><a href="#1-2-安装启动-jumpserver" class="headerlink" title="1.2 安装启动 jumpserver"></a>1.2 安装启动 jumpserver</h2><h3 id="1-2-1-下载jumpserver"><a href="#1-2-1-下载jumpserver" class="headerlink" title="1.2.1 下载jumpserver"></a>1.2.1 下载jumpserver</h3><pre><code>cd /opt git clone --depth=1 https://github.com/jumpserver/jumpserver.git &amp;&amp; cd jumpserver &amp;&amp; git checkout master</code></pre><p><strong>注意：不要安装在/root、/home 等目录下，以免权限问题</strong></p><h3 id="1-2-2-安装RPM依赖包"><a href="#1-2-2-安装RPM依赖包" class="headerlink" title="1.2.2 安装RPM依赖包"></a>1.2.2 安装RPM依赖包</h3><pre><code>cd requirementsyum -y install $(cat rpm_requirements.txt)</code></pre><h3 id="1-2-3-安装python库依赖"><a href="#1-2-3-安装python库依赖" class="headerlink" title="1.2.3 安装python库依赖"></a>1.2.3 安装python库依赖</h3><pre><code>pip install -r requirements.txt  # 不要指定-i参数，因为镜像上可能没有最新的包，如果没有任何报错请继续</code></pre><h3 id="1-2-4-安装-Redis-Jumpserver-使用-Redis-做-cache-和-celery-broke"><a href="#1-2-4-安装-Redis-Jumpserver-使用-Redis-做-cache-和-celery-broke" class="headerlink" title="1.2.4 安装 Redis, Jumpserver 使用 Redis 做 cache 和 celery broke"></a>1.2.4 安装 Redis, Jumpserver 使用 Redis 做 cache 和 celery broke</h3><pre><code>$ yum -y install redis$ service redis start</code></pre><h3 id="1-2-5-安装配置MySQL"><a href="#1-2-5-安装配置MySQL" class="headerlink" title="1.2.5 安装配置MySQL"></a>1.2.5 安装配置MySQL</h3><pre><code>create database jumpserver default charset &apos;utf8&apos;;grant all on jumpserver.* to &apos;jumpserver&apos;@&apos;127.0.0.1&apos; identified by &apos;Jumpserver_password_123&apos;;</code></pre><h3 id="1-2-6-修改jumpserver配置文件"><a href="#1-2-6-修改jumpserver配置文件" class="headerlink" title="1.2.6 修改jumpserver配置文件"></a>1.2.6 修改jumpserver配置文件</h3><pre><code>$ cd /opt/jumpserver$ cp config_example.py config.py$ vi config.py  # 我们计划修改 DevelopmentConfig中的配置，因为默认jumpserver是使用该配置，它继承自Config</code></pre><p><strong>注意: 配置文件是 Python 格式，不要用 TAB，而要用空格</strong></p><p>在该文件中新添加一个类</p><pre><code>class DevelopmentConfig(Config):    DEBUG = True    DB_ENGINE = &apos;mysql&apos;    DB_HOST = &apos;127.0.0.1&apos;    DB_PORT = 3306    DB_USER = &apos;jumpserver&apos;    DB_PASSWORD = &apos;somepassword&apos;    DB_NAME = &apos;jumpserver&apos;config = DevelopmentConfig()  # 确保使用的是刚才设置的配置文件，该行默认在文件末尾就存在。</code></pre><h3 id="1-2-7-生成数据库表结构和初始化结构"><a href="#1-2-7-生成数据库表结构和初始化结构" class="headerlink" title="1.2.7 生成数据库表结构和初始化结构"></a>1.2.7 生成数据库表结构和初始化结构</h3><pre><code>$ cd /opt/jumpserver/utils$ bash make_migrations.sh</code></pre><h3 id="1-2-8-运行jumpserver"><a href="#1-2-8-运行jumpserver" class="headerlink" title="1.2.8 运行jumpserver"></a>1.2.8 运行jumpserver</h3><pre><code>$ cd /opt/jumpserver$ python3 run_server.py all</code></pre><p>运行不报错，请浏览器访问 <a href="http://192.168.244.144:8080/" target="_blank" rel="noopener">http://192.168.244.144:8080/</a> (这里只是 Jumpserver, 没有 Web Terminal，所以访问 Web Terminal 会报错)</p><p>账号: admin 密码: admin</p><h1 id="2-jumpserver配置"><a href="#2-jumpserver配置" class="headerlink" title="2. jumpserver配置"></a>2. jumpserver配置</h1><h2 id="2-1-安装-SSH-Server-和-WebSocket-Server-Coco"><a href="#2-1-安装-SSH-Server-和-WebSocket-Server-Coco" class="headerlink" title="2.1 安装 SSH Server 和 WebSocket Server: Coco"></a>2.1 安装 SSH Server 和 WebSocket Server: Coco</h2><p>【此时还是在虚拟环境下】</p><pre><code>$ cd /opt$ git clone https://github.com/jumpserver/coco.git &amp;&amp; cd coco &amp;&amp; git checkout master</code></pre><h2 id="2-2-安装-Web-Terminal-前端-Luna"><a href="#2-2-安装-Web-Terminal-前端-Luna" class="headerlink" title="2.2  安装 Web Terminal 前端: Luna"></a>2.2  安装 Web Terminal 前端: Luna</h2><h1 id="3-常用命令"><a href="#3-常用命令" class="headerlink" title="3. 常用命令"></a>3. 常用命令</h1><p>启动 jumpserver</p><pre><code>/opt/jumpserver/service.sh start</code></pre><p>停止 jumpserver</p><pre><code>/opt/jumpserver/service.sh stop</code></pre><p>重启 jumpserver</p><pre><code>/opt/jumpserver/service.sh restart</code></pre><p>查看 jumpserver 状态</p><pre><code>/opt/jumpserver/service.sh status</code></pre><h1 id="4-配置优化-注意事项"><a href="#4-配置优化-注意事项" class="headerlink" title="4. 配置优化/注意事项"></a>4. 配置优化/注意事项</h1><p>配置文件路径：/opt/jumpserver/ jumpserver.conf、</p><p>配置如下：</p><pre><code>\[base]url = access_url（安装时配置）key = o57ev5oc1nwe44r4ip = 0.0.0.0port = 8000log = debug\[db]engine = mysqlhost = mysql_addr（安装时配置）port = 3306user = jumpserverpassword = password（安装时配置）database = jumpserver\[mail]mail_enable = 1email_host = smtp.163.comemail_port = 25email_host_user = name@163.com（安装时配置）email_host_password = password（安装时配置）email_use_tls = Falseemail_use_ssl = False\[connect]nav_sort_by = ip</code></pre><h2 id="问题-总结"><a href="#问题-总结" class="headerlink" title="问题/总结"></a>问题/总结</h2><p><strong>日志压缩删除</strong></p><p>访问服务器记录日志生成路径：/opt/jumpserver/logs/tty</p><p>需要定时压缩文件夹，并保留一段时间的历史日志</p><p>压缩文件夹命令：</p><pre><code>for i in `ls -d 201802*`; do tar czvf ${i}.tar.gz ${i}; done</code></pre><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>连接之后的终端页面如下所示：<br><img src="http://picture.watchmen.xin/jumpserver/jumpserver-1.png" alt="终端页面"></p>]]></content>
    
    <summary type="html">
    
      Jumpserver是全球首款完全开源的堡垒机，使用GNU GPL v2.0开源协议，是符合 4A 的专业运维审计系统。它使用Python / Django 进行开发，遵循 Web 2.0 规范，配备了业界领先的 Web Terminal 解决方案，交互界面美观、用户体验好。并且采纳分布式架构，支持多机房跨区域部署，中心节点提供 API，各机房部署登录节点，可横向扩展、无并发限制。
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维安全" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/"/>
    
      <category term="堡垒机" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/%E5%A0%A1%E5%9E%92%E6%9C%BA/"/>
    
    
      <category term="jumpserver" scheme="http://yoursite.com/tags/jumpserver/"/>
    
  </entry>
  
  <entry>
    <title>Zabbix结合Grafana实现炫酷动态可视化监控</title>
    <link href="http://yoursite.com/2018/04/04/Zabbix%E7%BB%93%E5%90%88Grafana%E5%AE%9E%E7%8E%B0%E7%82%AB%E9%85%B7%E5%8A%A8%E6%80%81%E5%8F%AF%E8%A7%86%E5%8C%96%E7%9B%91%E6%8E%A7/"/>
    <id>http://yoursite.com/2018/04/04/Zabbix结合Grafana实现炫酷动态可视化监控/</id>
    <published>2018-04-04T12:59:39.000Z</published>
    <updated>2018-04-04T12:59:39.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>来源：公众号-运维军团-《10分钟打造炫酷的监控大屏》</strong></p><h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>Grafana是一个开源的<code>数据展示工具</code>，是一个开箱即用的可视化工具，具有功能齐全的度量仪表盘和图形编辑器，有灵活丰富的图形化选项，可以混合多种风格，支持多个数据源，例如Graphite、InfluxDB、Mysql、Zabbix等等。虽然zabbix监控性能毋庸置疑，但zabbix图形显示过于简单、丑，因此利用zabbix作为数据源，结合Grafana作前端展示再好不过了。</p><p>重要的是Grafana的使用也超级简单，安装完成后登陆添加数据源即可，后面的事情就是添加图表等工作了。</p><h1 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h1><p>未更新完，待续</p>]]></content>
    
    <summary type="html">
    
      Zabbix结合Grafana实现炫酷动态可视化监控
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维监控体系" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/"/>
    
      <category term="zabbix" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/zabbix/"/>
    
    
      <category term="Grafana" scheme="http://yoursite.com/tags/Grafana/"/>
    
  </entry>
  
  <entry>
    <title>ditto常用操作</title>
    <link href="http://yoursite.com/2018/04/04/ditto%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2018/04/04/ditto常用操作/</id>
    <published>2018-04-04T09:11:37.000Z</published>
    <updated>2018-04-04T09:11:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>Ditto 是一款开源、免费、强大的剪贴板增强工具。可以把复制过的所有内容保存起来（可以设定保存日期或条目总数），快捷地供后续调用。还可以合并粘贴，纯文本粘贴，支持分组、置顶、快速搜索、热键粘贴功能。并且，还可以通过网络共享剪贴板内容。</p><p>主页：<a href="http://ditto-cp.sourceforge.net/" target="_blank" rel="noopener">http://ditto-cp.sourceforge.net/</a></p><p>教程：<a href="http://xbeta.info/ditto.htm" target="_blank" rel="noopener">http://xbeta.info/ditto.htm</a></p><h1 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h1><p>平常情况下，Ditto只是系统托盘中的图标。按下热键（默认 ctrl+`）后，会出现的粘贴主界面；再点击右键会弹出功能丰富的菜单。</p><p>详细请参看教程</p>]]></content>
    
    <summary type="html">
    
      Ditto是一款免费剪贴板增强软件，能有效提高工作效率。
    
    </summary>
    
      <category term="常用软件工具" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"/>
    
      <category term="Ditto" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/Ditto/"/>
    
    
      <category term="Ditto" scheme="http://yoursite.com/tags/Ditto/"/>
    
  </entry>
  
</feed>
