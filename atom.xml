<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Watchmen1992&#39;s Blog</title>
  
  <subtitle>锦瑟年华当与书香为度，是为不负天地人生。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-28T08:41:14.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>XiaoHua WANG</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>zabbix trapper方式监控</title>
    <link href="http://yoursite.com/2019/07/28/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/zabbix/zabbix-trapper%E6%96%B9%E5%BC%8F%E7%9B%91%E6%8E%A7/"/>
    <id>http://yoursite.com/2019/07/28/IT科学技术知识体系结构-Linux运维方向/运维监控体系/zabbix/zabbix-trapper方式监控/</id>
    <published>2019-07-28T08:41:14.000Z</published>
    <updated>2019-07-28T08:41:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p> zabbix获取数据时有时会出现超时，如果一些数据需要执行比较长的时间才能获取的话，那么zabbix会出现异常，考虑到这种情况，zabbix增加了Trapper功能，客户端自己提交数据给zabbix。</p><p>使用场景：</p><ul><li>例如自定义的网络监控。需要添加ping丢包、延迟、抖动等情况的监控，如果通过server去获取数据，因为存在ping的时间，所以很容易就会导致超时，从而拿不到数据</li><li>监控项比较多，并且比较耗时的情况。例如zk的数据、es的数据等，使用trapper的方式，会比server去获取的效率高很多。</li></ul><h1 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h1><h2 id="实现逻辑"><a href="#实现逻辑" class="headerlink" title="实现逻辑"></a>实现逻辑</h2><ol><li>客户端自己实现获取获取数据的方式，可以是shell脚本、python程序等</li><li>通过zabbix_sender，把数据推送到zabbix server</li><li>客户端上配置定时任务，控制发送的频率</li></ol><h2 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a>配置流程</h2><p>具体到配置，流程是：</p><ol><li>zabbix server添加客户端，客户端的配置文件中要配置主机名</li><li>配置监控项，设置监控类型为：zabbix trapper</li><li>item的key是</li></ol><h2 id="zabbix-sender语法"><a href="#zabbix-sender语法" class="headerlink" title="zabbix_sender语法"></a>zabbix_sender语法</h2><p>语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zabbix_sender -z &lt;server IP address&gt; -p 10051 -s &quot;New host&quot; -k trap -o &quot;test value&quot;</span><br></pre></td></tr></table></figure><p>参数说明：</p><ul><li><p>-z  to specify Zabbix server IP address</p></li><li><p>-p  to specify Zabbix server port number (10051 by default)</p></li><li><p>-s  to specify the host (make sure to use the ‘technical’ <a href="https://www.zabbix.com/documentation/3.0/manual/config/hosts/host#configuration" target="_blank" rel="noopener">host name</a> here, instead of the ‘visible’ name)</p></li></ul><ul><li>-k to specify the key of the item we just defined</li></ul><ul><li>-o to specify the actual value to send</li></ul><p>执行的命令是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./zabbix_sender  -s common010-dev.novalocal -c /usr/local/zabbix/etc/zabbix_agentd.conf  -k trapper-test -o &quot;5&quot;  -p 10051</span><br></pre></td></tr></table></figure><p>或者直接指定zabbix server的地址：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./zabbix_sender  -s common010-dev.novalocal -z 192.168.1.82  -k trapper-test -o &quot;6&quot;</span><br></pre></td></tr></table></figure><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ul><li><p>trapper是被监控主机主动发送数据给zabbix server，与主动模式的区别是可以不需要安装客户端；</p></li><li><p>trapper方式发送数据是以主机名处理，不是IP地址，所以主机名要唯一。</p></li><li><p>接上面一点，-s 后面加的必须是主机名，而不是ip地址</p></li><li><p>指定server地址，可以使用配置文件，也可以直接使用ip</p></li><li>如果使用的是默认端口，那么端口参数可以省略</li></ul>]]></content>
    
    <summary type="html">
    
      zabbix trapper方式监控
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维监控体系" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/"/>
    
      <category term="zabbix" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB/zabbix/"/>
    
    
      <category term="zabbix" scheme="http://yoursite.com/tags/zabbix/"/>
    
  </entry>
  
  <entry>
    <title>python基础知识</title>
    <link href="http://yoursite.com/2019/06/18/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2019/06/18/IT科学技术知识体系结构-Linux运维方向/编程开发/Python/基础知识/python基础知识/</id>
    <published>2019-06-18T12:35:45.000Z</published>
    <updated>2019-06-18T12:35:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考文献：</p><ul><li><a href="https://wiki.python.org/moin/BeginnersGuide/Overview" target="_blank" rel="noopener">https://wiki.python.org/moin/BeginnersGuide/Overview</a></li></ul><h1 id="学习编程的方法"><a href="#学习编程的方法" class="headerlink" title="学习编程的方法"></a>学习编程的方法</h1><p>人学习东西，天然有一种特性，就是学到的知识不马上应用的话，就会很快忘记。因此采集学习大量的知识，再去应用的方式是不可取的，比较浪费时间，而实际情况是，很多人往往就会陷入这种误区。</p><p>特别是现在的IT培训机构，在短时间内，灌输大量的知识，只是做一些简单的案例练习，这样是无法真正掌握这些知识的，只是走马观花的看一遍。</p><p>看了网上的，以及结合自身的实际情况来看，比较合适的一个学习方式是：项目驱动式去学习。</p><p>也就是，由输出来决定输入。实现一个项目，在实现这个项目中，会涉及很多需要学习的知识，在这个时候，再去学习这些知识，学完之后马上就能得到应用。</p><p>把项目驱动式的方式进程拆解，其实就是一种从上到下的树形图。</p><p>根节点是项目，也就是要解决或者要实现的问题或者需求。往下的每一个部分都代表了学习过程中遇到的问题，每个问题其实就是单独的需要去学习的知识点。</p><p>它的好处就是让你知道了你应该去学什么，而不是先学一大堆有用的或者没用的知识，然后再来做项目。</p><p><strong>存在的问题</strong></p><blockquote><p>这种学些方式，存在一个天然的问题，就是学习到的知识都是分散的，可能也就是只是学习了这个项目需要要就好了。每一个部分的知识都是非常零碎的，不成体系和结构。</p></blockquote><h1 id="python特性"><a href="#python特性" class="headerlink" title="python特性"></a>python特性</h1><p>Some programming-language features of Python are:</p><ul><li>A variety of basic data types are available: numbers (floating point, complex, and unlimited-length long integers), strings (both ASCII and Unicode), lists, and dictionaries.</li><li>Python supports object-oriented programming with classes and multiple inheritance.</li><li>Code can be grouped into modules and packages.</li><li>The language supports raising and catching exceptions, resulting in cleaner error handling.</li><li>Data types are strongly and dynamically typed. Mixing incompatible types (e.g. attempting to add a string and a number) causes an exception to be raised, so errors are caught sooner.</li><li>Python contains advanced programming features such as generators and list comprehensions.</li><li>Python’s automatic memory management frees you from having to manually allocate and free memory in your code.</li></ul><p>下面我们会把一些重要的知识点单独拿出来详细说明</p><h2 id="强数据类型以及动态类型"><a href="#强数据类型以及动态类型" class="headerlink" title="强数据类型以及动态类型"></a>强数据类型以及动态类型</h2><p>官方描述：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Data types are strongly and dynamically typed. Mixing incompatible types (e.g. attempting to add a string and a number) causes an exception to be raised, so errors are caught sooner.</span><br></pre></td></tr></table></figure><p><strong>Python是一个强数据类型以及动态类型的编程语言。</strong></p><p><strong>强数据类型</strong>：</p><p>一个变量在被赋值时会获得一个数据类型，如果不经过强制转换，那么它将永远会是这个类型、</p><p>测试代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = 1</span><br><span class="line">b = &quot;2&quot;</span><br><span class="line">print (a+b)</span><br></pre></td></tr></table></figure><p>执行后输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 152, in &lt;module&gt;</span><br><span class="line">    print (a+b)</span><br><span class="line">TypeError: unsupported operand type(s) for +: &apos;int&apos; and &apos;str&apos;</span><br></pre></td></tr></table></figure><p><strong>弱数据类型：</strong></p><p>不允许隐式转换的是强类型，允许隐式转换的是弱类型。</p><p>有强就有弱，弱语言类型的编程语言在执行时，数据类型可以被忽略，我们直接看一个例子</p><p>测试代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜  script cat test.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">a=1</span><br><span class="line">c=ddd</span><br><span class="line">echo $a+$c</span><br><span class="line">➜  script sh test.sh</span><br><span class="line">1+ddd</span><br></pre></td></tr></table></figure><p>也就是说，它与强类型定义语言相反, 一个变量可以赋不同数据类型的值。</p><p><strong>常见的强弱数据类型编程语言</strong></p><ul><li>强数据类型语言：Java/C#/python</li><li>弱数据类型语言：C/C++/PHP/Perl/JavaScript/Unix Shell</li></ul><p><strong>动态类型：</strong></p><p>运行期间才会做数据类型检查。也就是说只会在程序运行时，执行到变量赋值的代码时，才将该变量的数据类型进行记录。</p><p>因此不用在变量定义的时候指定变量的数据类型</p><p><strong>静态类型：</strong></p><p>同样的，有静就有动，静态类型的编程语言，在编译期间就知道变量的类型，例如在C语言中要使用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int age = 18;</span><br></pre></td></tr></table></figure><p>这样的方式来定义变量</p><p><strong>总结</strong></p><p>下图是常见的语言类型的划分：<br><img src="http://picture.watchmen.xin//python/base/base.png" alt=""></p><p>由于强类型语言一般需要在运行时运行一套类型检查系统，因此强类型语言的速度一般比弱类型要慢，动态类型也比静态类型慢，因此常见的四种语言中执行的速度应该是 C &gt; Java &gt; JavaScript &gt; Python。</p><p>强类型，静态类型的语言写起来往往是最安全的。</p><h2 id="生成器及列表解析"><a href="#生成器及列表解析" class="headerlink" title="生成器及列表解析"></a>生成器及列表解析</h2><p>官方描述</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python contains advanced programming features such as generators and list comprehensions.</span><br></pre></td></tr></table></figure><h1 id="unicode问题"><a href="#unicode问题" class="headerlink" title="unicode问题"></a>unicode问题</h1><h1 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h1><h2 id="re-正则匹配模块"><a href="#re-正则匹配模块" class="headerlink" title="re-正则匹配模块"></a>re-正则匹配模块</h2><p>正则表达式是一个特殊的字符序列，它能帮助你方便的检查一个字符串是否与某种模式匹配。</p><p>Python 自1.5版本起增加了re 模块，它提供 Perl 风格的正则表达式模式。</p><h3 id="re-match函数"><a href="#re-match函数" class="headerlink" title="re.match函数"></a>re.match函数</h3><p>re.match 尝试从字符串的<strong>起始位置匹配</strong>一个模式</p><ul><li>如果没有匹配成功的话，match()就返回none。</li><li>如果匹配成功的话，返回匹配对象</li></ul><p><strong>函数语法</strong>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.match(pattern, string, flags=0)</span><br></pre></td></tr></table></figure><p>函数参数说明：</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>pattern</td><td>匹配的正则表达式</td></tr><tr><td>string</td><td>要匹配的字符串。</td></tr><tr><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：<a href="http://www.runoob.com/python/python-reg-expressions.html#flags" target="_blank" rel="noopener">正则表达式修饰符 - 可选标志</a></td></tr></tbody></table><p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p><table><thead><tr><th>匹配对象方法</th><th>描述</th></tr></thead><tbody><tr><td>group(num=0)</td><td>匹配的整个表达式的字符串，group() 可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组。</td></tr><tr><td>groups()</td><td>返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。</td></tr></tbody></table><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">test_str = &quot;wo shi wangxiaohua,wangxiaohua shi wo&quot;</span><br><span class="line"></span><br><span class="line">a = re.match(&apos;wangxiaohua&apos;,test_str)</span><br><span class="line">b = re.match(&apos;w&apos;,test_str)</span><br><span class="line">print (a)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><p>执行后的结果是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">None</span><br><span class="line">&lt;re.Match object; span=(0, 1), match=&apos;w&apos;&gt;</span><br></pre></td></tr></table></figure><p>当执行group方法是，会表现为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">print (a.group())</span><br><span class="line">输出为：</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;/Users/wangxiaohua/PycharmProjects/private_project/learn_python/module-re.py&quot;, line 12, in &lt;module&gt;</span><br><span class="line">    print (a.group())</span><br><span class="line">AttributeError: &apos;NoneType&apos; object has no attribute &apos;group&apos;</span><br><span class="line"></span><br><span class="line">print (b.group())</span><br><span class="line">输出为：</span><br><span class="line">w</span><br></pre></td></tr></table></figure><h3 id="re-search方法"><a href="#re-search方法" class="headerlink" title="re.search方法"></a>re.search方法</h3><p>re.search 扫描整个字符串并返回第一个成功的匹配。</p><p>函数语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.search(pattern, string, flags=0)</span><br></pre></td></tr></table></figure><p>函数参数说明：</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>pattern</td><td>匹配的正则表达式</td></tr><tr><td>string</td><td>要匹配的字符串。</td></tr><tr><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。</td></tr></tbody></table><p>匹配成功re.search方法返回一个匹配的对象，否则返回None。</p><p>我们可以使用group(num) 或 groups() 匹配对象函数来获取匹配表达式。</p><table><thead><tr><th>匹配对象方法</th><th>描述</th></tr></thead><tbody><tr><td>group(num=0)</td><td>匹配的整个表达式的字符串，group() 可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组。</td></tr><tr><td>groups()</td><td>返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。</td></tr></tbody></table><h3 id="re-match与re-search的区别"><a href="#re-match与re-search的区别" class="headerlink" title="re.match与re.search的区别"></a>re.match与re.search的区别</h3><p>re.match只匹配字符串的开始，如果字符串开始不符合正则表达式，则匹配失败，函数返回None；而re.search匹配整个字符串，直到找到一个匹配。</p><h3 id="检索和替换"><a href="#检索和替换" class="headerlink" title="检索和替换"></a>检索和替换</h3><p>Python 的 re 模块提供了re.sub用于替换字符串中的匹配项。</p><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.sub(pattern, repl, string, count=0, flags=0)</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>pattern : 正则中的模式字符串。</li><li>repl : 替换的字符串，也可为一个函数。</li><li>string : 要被查找替换的原始字符串。</li><li>count : 模式匹配后替换的最大次数，默认 0 表示替换所有的匹配。</li></ul><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line"> </span><br><span class="line">import re</span><br><span class="line"> </span><br><span class="line">phone = &quot;2004-959-559 # 这是一个国外电话号码&quot;</span><br><span class="line"> </span><br><span class="line"># 删除字符串中的 Python注释 </span><br><span class="line">num = re.sub(r&apos;#.*$&apos;, &quot;&quot;, phone)</span><br><span class="line">print &quot;电话号码是: &quot;, num</span><br><span class="line"> </span><br><span class="line"># 删除非数字(-)的字符串 </span><br><span class="line">num = re.sub(r&apos;\D&apos;, &quot;&quot;, phone)</span><br><span class="line">print &quot;电话号码是 : &quot;, num</span><br></pre></td></tr></table></figure><p>执行后输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">电话号码是:  2004-959-559 </span><br><span class="line">电话号码是 :  2004959559</span><br></pre></td></tr></table></figure><h3 id="findall"><a href="#findall" class="headerlink" title="findall"></a>findall</h3><p>在字符串中找到正则表达式所匹配的所有子串，并<strong>返回一个列表</strong>，如果没有找到匹配的，则返回空列表。</p><p><strong>注意：</strong> match 和 search 是匹配一次，而 findall是匹配所有。</p><p>语法格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">findall(string[, pos[, endpos]])</span><br></pre></td></tr></table></figure><p>参数：</p><ul><li>string : 待匹配的字符串。</li><li>pos : 可选参数，指定字符串的起始位置，默认为 0。</li><li>endpos : 可选参数，指定字符串的结束位置，默认为字符串的长度。</li></ul><h3 id="re-finditer"><a href="#re-finditer" class="headerlink" title="re.finditer"></a>re.finditer</h3><p>和 findall 类似，在字符串中找到正则表达式所匹配的所有子串，并把它们作为<strong>一个迭代器返回</strong>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.finditer(pattern, string, flags=0)</span><br></pre></td></tr></table></figure><p>参数：</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>pattern</td><td>匹配的正则表达式</td></tr><tr><td>string</td><td>要匹配的字符串。</td></tr><tr><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：<a href="http://www.runoob.com/python/python-reg-expressions.html#flags" target="_blank" rel="noopener">正则表达式修饰符 - 可选标志</a></td></tr></tbody></table><h3 id="re-split"><a href="#re-split" class="headerlink" title="re.split"></a>re.split</h3><p>split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">re.split(pattern, string[, maxsplit=0, flags=0])</span><br></pre></td></tr></table></figure><p>参数：</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>pattern</td><td>匹配的正则表达式</td></tr><tr><td>string</td><td>要匹配的字符串。</td></tr><tr><td>maxsplit</td><td>分隔次数，maxsplit=1 分隔一次，默认为 0，不限制次数。</td></tr><tr><td>flags</td><td>标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等。参见：<a href="http://www.runoob.com/python/python-reg-expressions.html#flags" target="_blank" rel="noopener">正则表达式修饰符 - 可选标志</a></td></tr></tbody></table><h3 id="正则表达式修饰符-可选标志"><a href="#正则表达式修饰符-可选标志" class="headerlink" title="正则表达式修饰符 - 可选标志"></a>正则表达式修饰符 - 可选标志</h3><p>正则表达式可以包含一些可选标志修饰符（属性）来控制匹配的模式。修饰符被指定为一个可选的标志。多个标志可以通过按位 OR(|) 它们来指定。如 re.I | re.M 被设置成 I 和 M 标志：</p><table><thead><tr><th>修饰符</th><th>描述</th></tr></thead><tbody><tr><td>re.I</td><td>大小写不敏感</td></tr><tr><td>re.L</td><td>做本地化识别（locale-aware）匹配</td></tr><tr><td>re.M</td><td>多行匹配，影响 ^ 和 $</td></tr><tr><td>re.S</td><td>使 . 匹配包括换行在内的所有字符</td></tr><tr><td>re.U</td><td>根据Unicode字符集解析字符。这个标志影响 \w, \W, \b, \B.</td></tr><tr><td>re.X</td><td>该标志通过给予你更灵活的格式以便你将正则表达式写得更易于理解。</td></tr></tbody></table><h3 id="正则表达式模式"><a href="#正则表达式模式" class="headerlink" title="正则表达式模式"></a>正则表达式模式</h3><p>模式字符串使用特殊的语法来表示一个正则表达式：</p><p>字母和数字表示他们自身。一个正则表达式模式中的字母和数字匹配同样的字符串。</p><p>多数字母和数字前加一个反斜杠时会拥有不同的含义。</p><p>标点符号只有被转义时才匹配自身，否则它们表示特殊的含义。</p><p>反斜杠本身需要使用反斜杠转义。</p><p>由于正则表达式通常都包含反斜杠，所以你最好使用原始字符串来表示它们。模式元素(如 r’\t’，等价于 ‘\t’)匹配相应的特殊字符。</p><p>下表列出了正则表达式模式语法中的特殊元素。如果你使用模式的同时提供了可选的标志参数，某些模式元素的含义会改变。</p><table><thead><tr><th>模式</th><th>描述</th></tr></thead><tbody><tr><td>^</td><td>匹配字符串的开头</td></tr><tr><td>$</td><td>匹配字符串的末尾。</td></tr><tr><td>.</td><td>匹配任意字符，除了换行符，当re.DOTALL标记被指定时，则可以匹配包括换行符的任意字符。</td></tr><tr><td>[…]</td><td>用来表示一组字符,单独列出：[amk] 匹配 ‘a’，’m’或’k’</td></tr><tr><td>[^…]</td><td>不在[]中的字符：[^abc] 匹配除了a,b,c之外的字符。</td></tr><tr><td>re*</td><td>匹配0个或多个的表达式。</td></tr><tr><td>re+</td><td>匹配1个或多个的表达式。</td></tr><tr><td>re?</td><td>匹配0个或1个由前面的正则表达式定义的片段，非贪婪方式</td></tr><tr><td>re{ n}</td><td>精确匹配 n 个前面表达式。例如， o{2} 不能匹配 “Bob” 中的 “o”，但是能匹配 “food” 中的两个 o。</td></tr><tr><td>re{ n,}</td><td>匹配 n 个前面表达式。例如， o{2,} 不能匹配”Bob”中的”o”，但能匹配 “foooood”中的所有 o。”o{1,}” 等价于 “o+”。”o{0,}” 则等价于 “o*”。</td></tr><tr><td>re{ n, m}</td><td>匹配 n 到 m 次由前面的正则表达式定义的片段，贪婪方式</td></tr><tr><td>a\</td><td>b</td><td>匹配a或b</td></tr><tr><td>(re)</td><td>匹配括号内的表达式，也表示一个组</td></tr><tr><td>(?imx)</td><td>正则表达式包含三种可选标志：i, m, 或 x 。只影响括号中的区域。</td></tr><tr><td>(?-imx)</td><td>正则表达式关闭 i, m, 或 x 可选标志。只影响括号中的区域。</td></tr><tr><td>(?: re)</td><td>类似 (…), 但是不表示一个组</td></tr><tr><td>(?imx: re)</td><td>在括号中使用i, m, 或 x 可选标志</td></tr><tr><td>(?-imx: re)</td><td>在括号中不使用i, m, 或 x 可选标志</td></tr><tr><td>(?#…)</td><td>注释.</td></tr><tr><td>(?= re)</td><td>前向肯定界定符。如果所含正则表达式，以 … 表示，在当前位置成功匹配时成功，否则失败。但一旦所含表达式已经尝试，匹配引擎根本没有提高；模式的剩余部分还要尝试界定符的右边。</td></tr><tr><td>(?! re)</td><td>前向否定界定符。与肯定界定符相反；当所含表达式不能在字符串当前位置匹配时成功</td></tr><tr><td>(?&gt; re)</td><td>匹配的独立模式，省去回溯。</td></tr><tr><td>\w</td><td>匹配字母数字及下划线</td></tr><tr><td>\W</td><td>匹配非字母数字及下划线</td></tr><tr><td>\s</td><td>匹配任意空白字符，等价于 [\t\n\r\f].</td></tr><tr><td>\S</td><td>匹配任意非空字符</td></tr><tr><td>\d</td><td>匹配任意数字，等价于 [0-9].</td></tr><tr><td>\D</td><td>匹配任意非数字</td></tr><tr><td>\A</td><td>匹配字符串开始</td></tr><tr><td>\Z</td><td>匹配字符串结束，如果是存在换行，只匹配到换行前的结束字符串。</td></tr><tr><td>\z</td><td>匹配字符串结束</td></tr><tr><td>\G</td><td>匹配最后匹配完成的位置。</td></tr><tr><td>\b</td><td>匹配一个单词边界，也就是指单词和空格间的位置。例如， ‘er\b’ 可以匹配”never” 中的 ‘er’，但不能匹配 “verb” 中的 ‘er’。</td></tr><tr><td>\B</td><td>匹配非单词边界。’er\B’ 能匹配 “verb” 中的 ‘er’，但不能匹配 “never” 中的 ‘er’。</td></tr><tr><td>\n, \t, 等.</td><td>匹配一个换行符。匹配一个制表符。等</td></tr><tr><td>\1…\9</td><td>匹配第n个分组的内容。</td></tr><tr><td>\10</td><td>匹配第n个分组的内容，如果它经匹配。否则指的是八进制字符码的表达式。</td></tr></tbody></table><hr><h4 id="正则表达式实例"><a href="#正则表达式实例" class="headerlink" title="正则表达式实例"></a>正则表达式实例</h4><h4 id="字符匹配"><a href="#字符匹配" class="headerlink" title="字符匹配"></a>字符匹配</h4><table><thead><tr><th>实例</th><th>描述</th></tr></thead><tbody><tr><td>python</td><td>匹配 “python”.</td></tr></tbody></table><h4 id="字符类"><a href="#字符类" class="headerlink" title="字符类"></a>字符类</h4><table><thead><tr><th>实例</th><th>描述</th></tr></thead><tbody><tr><td>[Pp]ython</td><td>匹配 “Python” 或 “python”</td></tr><tr><td>rub[ye]</td><td>匹配 “ruby” 或 “rube”</td></tr><tr><td>[aeiou]</td><td>匹配中括号内的任意一个字母</td></tr><tr><td>[0-9]</td><td>匹配任何数字。类似于 [0123456789]</td></tr><tr><td>[a-z]</td><td>匹配任何小写字母</td></tr><tr><td>[A-Z]</td><td>匹配任何大写字母</td></tr><tr><td>[a-zA-Z0-9]</td><td>匹配任何字母及数字</td></tr><tr><td>[^aeiou]</td><td>除了aeiou字母以外的所有字符</td></tr><tr><td>[^0-9]</td><td>匹配除了数字外的字符</td></tr></tbody></table><h4 id="特殊字符类"><a href="#特殊字符类" class="headerlink" title="特殊字符类"></a>特殊字符类</h4><table><thead><tr><th>实例</th><th>描述</th></tr></thead><tbody><tr><td>.</td><td>匹配除 “\n” 之外的任何单个字符。要匹配包括 ‘\n’ 在内的任何字符，请使用象 ‘[.\n]’ 的模式。</td></tr><tr><td>\d</td><td>匹配一个数字字符。等价于 [0-9]。</td></tr><tr><td>\D</td><td>匹配一个非数字字符。等价于 [^0-9]。</td></tr><tr><td>\s</td><td>匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。</td></tr><tr><td>\S</td><td>匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。</td></tr><tr><td>\w</td><td>匹配包括下划线的任何单词字符。等价于’[A-Za-z0-9_]’。</td></tr><tr><td>\W</td><td>匹配任何非单词字符。等价于 ‘[^A-Za-z0-9_]’。</td></tr></tbody></table><h1 id="git使用"><a href="#git使用" class="headerlink" title="git使用"></a>git使用</h1><h2 id="git输入用户名密码"><a href="#git输入用户名密码" class="headerlink" title="git输入用户名密码"></a>git输入用户名密码</h2><p>使用如下这种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone http://wangxiaohua:6e2TFHqDt0ab@192.168.1.66/wangxiaohua/es-monitor.git</span><br><span class="line">或者</span><br><span class="line">git clone http://wangxiaohua:6e2TFHqDt0ab@git.nidianwo.com/wangxiaohua/es-monitor.git</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      python基础知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="编程开发" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/"/>
    
      <category term="基础知识" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>ELK部署</title>
    <link href="http://yoursite.com/2019/06/18/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/ELK%E9%83%A8%E7%BD%B2/ELK%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2019/06/18/IT科学技术知识体系结构-Linux运维方向/大数据/ELK/ELK部署/ELK部署/</id>
    <published>2019-06-18T09:19:33.000Z</published>
    <updated>2019-06-18T09:19:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="实现架构"><a href="#实现架构" class="headerlink" title="实现架构"></a>实现架构</h2><p>传统的ELK是使用elasticsearch+logstash+kibana的方式来部署日志收集系统</p><p>但是在数据量较大下，该架构过于单薄存在各种问题，因此，我们这里所使用的架构是：</p><p>Filebeat—&gt;kafka—&gt;logstash—&gt;[elasticsearch、filesystem、kafka]</p><p>也就是说将客户端收集替换成了filebeat，将日志推送到kafka中，然后在用logstash收集kafaka中的数据，logstash的output可以是es、文件服务器等等</p><h2 id="架构说明"><a href="#架构说明" class="headerlink" title="架构说明"></a>架构说明</h2><h1 id="Filebeat部署"><a href="#Filebeat部署" class="headerlink" title="Filebeat部署"></a>Filebeat部署</h1><h2 id="filebeat工作原理"><a href="#filebeat工作原理" class="headerlink" title="filebeat工作原理"></a>filebeat工作原理</h2><p>Filebeat是本地文件的日志数据采集器，作为服务器上的代理安装。</p><p>Filebeat监视指定的日志目录或特定日志文件，使用tail -f file的机制，收集之后将它们转发给Elasticsearch或Logstash或kafka等进行存储。</p><p><strong>Filebeat由两个主要组件组成：</strong></p><ul><li><p>prospector    探勘器、查找器</p></li><li><p>harvester    采集器</p></li></ul><p><strong>工作过程概述：</strong></p><p>启动Filebeat时，启动<strong>一个或多个</strong>prospector，查看指定的日志文件<strong>目录或者单个文件</strong>。</p><p>对于涉及的每个日志文件，prospector 启动对应数量的harvester， 每个harvester会读取到指定文件的新内容，将新数据发送到libbeat，libbeat将聚合事件并将聚合数据发送到你为Filebeat配置的输出。</p><h3 id="prospector"><a href="#prospector" class="headerlink" title="prospector"></a>prospector</h3><p>prospector有2个职责：负责找到所有需要收集的文件对象，以及管理harvester</p><p>注意：prospector只能读取本地文件， 不能连接到远程主机来读取存储的文件或日志。</p><h3 id="harvester"><a href="#harvester" class="headerlink" title="harvester"></a>harvester</h3><p>harvester只有1个职责：负责读取单个文件的内容，并将内容发送到指定的output</p><p>prospector会为每一个要收集的文件都启动一个harvester<br>harvester 负责打开和关闭文件，这意味着在运行时文件描述符保持打开状态，如果文件在读取时被删除或重命名，Filebeat将继续读取文件。也就是说，这会存在一个问题，就是如果文件被删了了，但是在harvester关闭之前，磁盘上的空间将会被保留无法释放。默认情况下，Filebeat将文件保持打开状态，直到达到close_inactive状态</p><h2 id="Filebeat如何保持文件的状态？"><a href="#Filebeat如何保持文件的状态？" class="headerlink" title="Filebeat如何保持文件的状态？"></a>Filebeat如何保持文件的状态？</h2><p>prospector保存每个文件的状态并经常将状态刷新到磁盘上的注册文件(data/registry)中。</p><p>该状态的作用是用于harvester记住正在读取文件的最后偏移量，并确保发送所有日志行。如果输出（例如Elasticsearch或Logstash）无法访问，Filebeat会检测output，并在oputput再次可用时继续读取文件发送。</p><p>在Filebeat运行时，每个prospector内存中也会保存的文件状态信息，<br>当重新启动Filebeat时，将使用注册文件的数据来重建文件状态，每个harvester基于注册文件中记录的最后偏移量继续读取。</p><p>因为文件可以被重命名或移动，因此文件名和路径不足以识别文件，对于每个文件，Filebeat存储唯一标识符以检测文件是否先前已采集过。</p><p>如果每天会创建大量新文件，注册文件增长可能过大。这个时候参阅注册表文件太大相关问题？</p><h2 id="Filebeat如何确保至少一次分发"><a href="#Filebeat如何确保至少一次分发" class="headerlink" title="Filebeat如何确保至少一次分发"></a>Filebeat如何确保至少一次分发</h2><p>Filebeat保证所有的事件至少会被传送到配置的output一次，并且不会丢失数据。 Filebeat之所以能够实现此行为，因为它将每个事件的传递状态存储在注册文件中。</p><p>如果输出（例如Elasticsearch或Logstash）无法访问，Filebeat会检测output，并在oputput再次可用时继续读取文件发送。</p><p>如果Filebeat在发送事件的过程中关闭，它不会等待output确认所有收到事件。发送到output但未确认的任何事件将会在在重新启动Filebeat后再次发送，这可以确保每个事件至少发送一次，但最终可能会将重复发送事件发送到output</p><p>介于这个特性，我们可以配置shutdown_timeout参数来指定，在手动关闭filebeat时，等待多久才停止进程</p><p>注意：Filebeat的至少一次交付保证在日志轮换和删除旧文件时有限制。如果将日志文件写入磁盘并且写入速度超过Filebeat可以处理的速度，或者在output不可用时删除了文件，则可能会丢失数据。<br>在Linux上，Filebeat也可能因inode重用而跳过行</p><h2 id="filebeat安装配置"><a href="#filebeat安装配置" class="headerlink" title="filebeat安装配置"></a>filebeat安装配置</h2><h3 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h3><p>Before running Filebeat, you need to install and configure the Elastic stack. See <a href="http://www.elastic.co/guide/en/beats/libbeat/6.2/getting-started.html" target="_blank" rel="noopener">Getting Started with Beats and the Elastic Stack</a>.</p><p>A regular <em>Beats setup</em> consists of:</p><ul><li>Elasticsearch for storage and indexing. See <a href="https://www.elastic.co/guide/en/beats/libbeat/6.2/elasticsearch-installation.html" target="_blank" rel="noopener">Install Elasticsearch</a>.</li><li>Logstash (optional) for inserting data into Elasticsearch. See <a href="https://www.elastic.co/guide/en/beats/libbeat/6.2/logstash-installation.html" target="_blank" rel="noopener">Installing Logstash</a>.</li><li>Kibana for the UI. See <a href="https://www.elastic.co/guide/en/beats/libbeat/6.2/kibana-installation.html" target="_blank" rel="noopener">Install Kibana</a>.</li><li>One or more Beats. You install the Beats on your servers to capture operational data. See <a href="https://www.elastic.co/guide/en/beats/libbeat/6.2/installing-beats.html" target="_blank" rel="noopener">Install Beats</a>.</li><li>Kibana dashboards for visualizing the data.</li></ul><p>也就是说，在部署filebeat之前，我们需要ELK环境，相当于说filebeat是在ELK的基础之上的一个组件。</p><p>如果还没有ELK环境的，先跳转到ES部分。</p><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>在这里，我们使用源码包的方式安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.3-linux-x86_64.tar.gz</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>默认的配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[appdeploy@node001 filebeat6]$ cat filebeat.yml</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  enabled: false</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/*.log</span><br><span class="line">filebeat.config.modules:</span><br><span class="line">  path: $&#123;path.config&#125;/modules.d/*.yml</span><br><span class="line">  reload.enabled: false</span><br><span class="line">setup.template.settings:</span><br><span class="line">  index.number_of_shards: 3</span><br><span class="line">setup.kibana:</span><br><span class="line">output.elasticsearch:</span><br><span class="line">  hosts: [&quot;localhost:9200&quot;]</span><br></pre></td></tr></table></figure><p>一个实际的案例配置文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">filebeat.shutdown_timeout: 10s</span><br><span class="line">filebeat.config.prospectors:</span><br><span class="line">  enabled: true</span><br><span class="line">  path: conf/*.yml</span><br><span class="line">  reload.enabled: true</span><br><span class="line">  reload.period: 10s</span><br><span class="line">output.kafka:</span><br><span class="line">  hosts: [&quot;172.24.48.76:19092&quot;, &quot;172.24.48.77:19092&quot;, &quot;172.24.48.78:19092&quot;]</span><br><span class="line">  topic: &apos;%&#123;[fields.log_topic]&#125;&apos;</span><br><span class="line">  key: &apos;%&#123;[fields.app_name]&#125; %&#123;[beat.hostname]&#125;&apos;</span><br><span class="line">  required_acks: 1</span><br><span class="line">  workers: 6</span><br><span class="line">  timeout: 120</span><br><span class="line">  compression: snappy</span><br><span class="line">  max_message_bytes: 10240000</span><br><span class="line">  codec.format:</span><br><span class="line">     string: &apos;%&#123;[fields.app_name]&#125; %&#123;[beat.hostname]&#125; %&#123;[message]&#125;&apos;</span><br><span class="line">xpack.monitoring:</span><br><span class="line">  enabled: true</span><br><span class="line">  elasticsearch:</span><br><span class="line">    hosts: [&quot;http://172.24.48.76:9200&quot;, &quot;http://172.24.48.77:9200&quot;, &quot;http://172.24.48.78:9200&quot;]</span><br></pre></td></tr></table></figure><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><pre><code>nohup /home/appdeploy/deploy/tools/filebeat6/filebeat -e -c /home/appdeploy/deploy/tools/filebeat6/applogg.yml &gt;&gt;/home/appdeploy/deploy/tools/filebeat6/applogg.log &amp;</code></pre><h2 id="filebeat的模块"><a href="#filebeat的模块" class="headerlink" title="filebeat的模块"></a>filebeat的模块</h2><p>filebeat的模块简化了收集、解析以及可视化例如nginx、Redis、mysql等通用日志格式这一系列操作。</p><p>也就是说，通过使用这些现成的模块，我们可以快速的进行收集，而免去了比较繁琐的自定义设置。</p><h2 id="filebeat的配置详解"><a href="#filebeat的配置详解" class="headerlink" title="filebeat的配置详解"></a>filebeat的配置详解</h2><h3 id="设置prospectors-探勘器、查找器"><a href="#设置prospectors-探勘器、查找器" class="headerlink" title="设置prospectors- 探勘器、查找器"></a>设置prospectors- 探勘器、查找器</h3><p>filebeat使用prospectors去定位和处理文件。</p><p>在yml配置文件中以”filebeat.prospectors:”开头，下面的列表代表每一个prospectors(一个type就是一个prospectors)</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/apache/httpd-*.log</span><br><span class="line"></span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/messages</span><br><span class="line">    - /var/log/*.log</span><br></pre></td></tr></table></figure><p>filebeat将会为每一个文件都启动一个harvester。</p><p>在prospectors这一栏中，有一些参数可以配置：</p><ul><li><p>type。下面是一些常用的二级参数，归属于type下</p><ul><li><p>paths：文件的路径列表</p></li><li><p>exclude_lines</p></li><li><p>Include_lines</p></li><li><p>tags。tags可以用于后面的logstash过滤</p></li><li><p>fileds</p></li><li><p>scan_frequency：在指定的path下，每隔多久去检测是否有新文件</p></li><li><p>harvester_buffer_size</p></li><li><p>max_bytes。这个参数需要关注下。</p></li><li><p>tail_files</p><blockquote><p>如果这个参数被设置为true，</p></blockquote></li></ul></li></ul><h3 id="Multiline-多行合并管理"><a href="#Multiline-多行合并管理" class="headerlink" title="Multiline-多行合并管理"></a>Multiline-多行合并管理</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/beats/filebeat/6.2/multiline-examples.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/beats/filebeat/6.2/multiline-examples.html</a></p><p>因为在应用的日志输出中，例如java的堆栈信息等，输出是多行的形式，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[beat-logstash-some-name-832-2015.11.28] IndexNotFoundException[no such index]</span><br><span class="line">    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:566)</span><br><span class="line">    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:133)</span><br><span class="line">    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:77)</span><br><span class="line">    at org.elasticsearch.action.admin.indices.delete.TransportDeleteIndexAction.checkBlock(TransportDeleteIndexAction.java:75)</span><br></pre></td></tr></table></figure><p>这几行其实是同一段，我们要放在一起展示，所以需要把这多行的信息进行归纳。这时，就使用到了多行合并的功能</p><p>配置案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /home/appdeploy/deploy/logs/rider-mission-card/rider-mission-card.log</span><br><span class="line">  multiline.pattern: &apos;^[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&apos;</span><br><span class="line">  multiline.negate: true</span><br><span class="line">  multiline.match: after</span><br></pre></td></tr></table></figure><p>上面配置的意思是：不以’^[0-9]{4}-[0-9]{2}-[0-9]{2}’开头的行都合并到上一行的末尾</p><p>配置项说明：</p><ul><li><p>pattern：正则表达式</p></li><li><p>negate：true 或 false；控制是否匹配上面的正则表达式规则</p><p>默认是false，匹配pattern的行，合并到上一行；</p><p>true，匹配到pattern的行，不合并到上一行</p></li><li><p>match：after 或 before，控制如何合并。合并到上一行的末尾或者开头。</p><p>处理java等日志时，我们肯定是合并到上一行的后面。</p></li></ul><h3 id="加载外部的配置文件"><a href="#加载外部的配置文件" class="headerlink" title="加载外部的配置文件"></a>加载外部的配置文件</h3><h4 id="prospector-config"><a href="#prospector-config" class="headerlink" title="prospector config"></a><strong>prospector config</strong></h4><p>探勘器、查找器使用如下的方式去加载外部的配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">filebeat.config.prospectors:</span><br><span class="line">  enabled: true</span><br><span class="line">  path: configs/*.yml</span><br></pre></td></tr></table></figure><p>被加载的外部文件的格式应该是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/mysql.log</span><br><span class="line">  scan_frequency: 10s</span><br><span class="line"></span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/apache.log</span><br><span class="line">  scan_frequency: 5s</span><br></pre></td></tr></table></figure><h4 id="动态重加载"><a href="#动态重加载" class="headerlink" title="动态重加载"></a>动态重加载</h4><p>当配置的，加载外部文件的路径下有文件更新时，filebeat需要能够感知，所以filebeat提供了一个reload的功能。</p><p>配置方式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">filebeat.config.prospectors:</span><br><span class="line">  enabled: true</span><br><span class="line">  path: configs/*.yml</span><br><span class="line">  reload.enabled: true</span><br><span class="line">  reload.period: 10s</span><br></pre></td></tr></table></figure><p>注意：period的值不要设置少于1s，因为修改文件的操作往往在s级左右，</p><h2 id="output配置"><a href="#output配置" class="headerlink" title="output配置"></a>output配置</h2><h3 id="es"><a href="#es" class="headerlink" title="es"></a>es</h3><p>当使用filebeat直接连接es或者kibana时，如果有密码配置，配置文件应该为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">output.elasticsearch:</span><br><span class="line">  hosts: [&quot;myEShost:9200&quot;]</span><br><span class="line">  username: &quot;elastic&quot;</span><br><span class="line">  password: &quot;elastic&quot;</span><br><span class="line">setup.kibana:</span><br><span class="line">  host: &quot;mykibanahost:5601&quot;</span><br><span class="line">  username: &quot;elastic&quot;  </span><br><span class="line">  password: &quot;elastic&quot;</span><br></pre></td></tr></table></figure><h3 id="logstash"><a href="#logstash" class="headerlink" title="logstash"></a>logstash</h3><p>在filebeat的output中指定logstash即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#----------------------------- Logstash output --------------------------------</span><br><span class="line">output.logstash:</span><br><span class="line">  hosts: [&quot;127.0.0.1:5044&quot;]</span><br><span class="line">  loadbalance: true</span><br><span class="line">  worker: 4</span><br></pre></td></tr></table></figure><p>这里有几个比较常用的参数：</p><ul><li>worker：指定为每个主机的工作进程数，例如设置为2，output主机为2，那么总数为4</li><li>loadbalance：当后端有多个logstash主机时，可以设置为true</li></ul><h3 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h3><p>配置格式如下：</p><h2 id="filebeat监控"><a href="#filebeat监控" class="headerlink" title="filebeat监控"></a>filebeat监控</h2><h2 id="配置文件权限问题"><a href="#配置文件权限问题" class="headerlink" title="配置文件权限问题"></a>配置文件权限问题</h2><p>filebeat在启动的时候，可能会出现下面的问题：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2019-08-02T15:57:04.027+0800    ERROR   cfgfile/reload.go:237   Error loading config: invalid config: config file (&quot;/home/appdeploy/deploy/tools/filebeat6/conf/httpdns.yml&quot;) can only be writable by the owner but the permissions are &quot;-rw-rw-r--&quot; (to fix the permissions use: &apos;chmod go-w /home/appdeploy/deploy/tools/filebeat6/conf/httpdns.yml&apos;)</span><br></pre></td></tr></table></figure><p>文件的权限需要是644，在创建文件时，默认的权限是664</p><h2 id="系统日志权限问题"><a href="#系统日志权限问题" class="headerlink" title="系统日志权限问题"></a>系统日志权限问题</h2><p>当收集系统日志时，例如cron、secure、message、kern.log等时，如果filebeat使用的时候非root用户启动，那么默认是没有权限读取这些文件的，这个时候，我们就需要对这些日志进行相应的配置，保证启动用户对系统日志有权限。</p><h1 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h1><h2 id="logstash概述"><a href="#logstash概述" class="headerlink" title="logstash概述"></a>logstash概述</h2><p>logstash是一个具备实时pipelining流水线能力的数据收集引擎，它能动态的统一来自不同数据源的数据，规范化后发往output，</p><h3 id="logstash工作流"><a href="#logstash工作流" class="headerlink" title="logstash工作流"></a>logstash工作流</h3><p>logstash的工作流非常简单：inputs → filters → outputs</p><ul><li>input：</li></ul><h2 id="logstash术语表-glossary-of-terms"><a href="#logstash术语表-glossary-of-terms" class="headerlink" title="logstash术语表-glossary of terms"></a>logstash术语表-glossary of terms</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/logstash/6.2/glossary.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/glossary.html</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>我们一般使用源码包的安装方式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://artifacts.elastic.co/downloads/logstash/logstash-6.2.3.tar.gz</span><br></pre></td></tr></table></figure><p>下载下来之后，解压即可。</p><p>在安装之后，我们可以启动一个最简单的pipeline去测试功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd logstash-6.2.3</span><br><span class="line">bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&apos;</span><br></pre></td></tr></table></figure><p>-e参数可以让我们在命令行直接指定配置，而不是去编辑配置配置，这里的意思是input和output是使用标准输入和标准输出。</p><p>完整的输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[elk@node002 logstash-6.2.3]$ bin/logstash -e &apos;input &#123; stdin &#123; &#125; &#125; output &#123; stdout &#123;&#125; &#125;&apos;</span><br><span class="line"></span><br><span class="line">Sending Logstash&apos;s logs to /home/elk/logstash-6.2.3/logs which is now configured via log4j2.properties</span><br><span class="line">[2019-07-29T10:53:06,777][INFO ][logstash.modules.scaffold] Initializing module &#123;:module_name=&gt;&quot;fb_apache&quot;, :directory=&gt;&quot;/home/elk/logstash-6.2.3/modules/fb_apache/configuration&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:06,874][INFO ][logstash.modules.scaffold] Initializing module &#123;:module_name=&gt;&quot;netflow&quot;, :directory=&gt;&quot;/home/elk/logstash-6.2.3/modules/netflow/configuration&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:08,037][INFO ][logstash.setting.writabledirectory] Creating directory &#123;:setting=&gt;&quot;path.queue&quot;, :path=&gt;&quot;/home/elk/logstash-6.2.3/data/queue&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:08,088][INFO ][logstash.setting.writabledirectory] Creating directory &#123;:setting=&gt;&quot;path.dead_letter_queue&quot;, :path=&gt;&quot;/home/elk/logstash-6.2.3/data/dead_letter_queue&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:11,772][WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified</span><br><span class="line">[2019-07-29T10:53:12,855][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID &#123;:uuid=&gt;&quot;f9f6fb83-176e-4ba1-8065-ca5699df67fa&quot;, :path=&gt;&quot;/home/elk/logstash-6.2.3/data/uuid&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:25,521][INFO ][logstash.runner          ] Starting Logstash &#123;&quot;logstash.version&quot;=&gt;&quot;6.2.3&quot;&#125;</span><br><span class="line">[2019-07-29T10:53:34,693][INFO ][logstash.agent           ] Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;</span><br><span class="line">[2019-07-29T10:54:13,765][INFO ][logstash.pipeline        ] Starting pipeline &#123;:pipeline_id=&gt;&quot;main&quot;, &quot;pipeline.workers&quot;=&gt;4, &quot;pipeline.batch.size&quot;=&gt;125, &quot;pipeline.batch.delay&quot;=&gt;50&#125;</span><br><span class="line">[2019-07-29T10:54:16,628][INFO ][logstash.pipeline        ] Pipeline started succesfully &#123;:pipeline_id=&gt;&quot;main&quot;, :thread=&gt;&quot;#&lt;Thread:0x7028647c run&gt;&quot;&#125;</span><br><span class="line">The stdin plugin is now waiting for input:</span><br><span class="line">[2019-07-29T10:54:19,144][INFO ][logstash.agent           ] Pipelines running &#123;:count=&gt;1, :pipelines=&gt;[&quot;main&quot;]&#125;</span><br><span class="line">2019-07-29T02:54:20.429Z node002</span><br><span class="line">2019-07-29T02:54:20.463Z node002</span><br><span class="line">2019-07-29T02:54:34.399Z node002</span><br><span class="line">hello world</span><br><span class="line">2019-07-29T02:54:39.357Z node002 hello world</span><br></pre></td></tr></table></figure><h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><h3 id="filebeat-logstash配置案例"><a href="#filebeat-logstash配置案例" class="headerlink" title="filebeat+logstash配置案例"></a>filebeat+logstash配置案例</h3><p>filebeat端配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[appdeploy@node001 filebeat6]$ cat filebeat.yml</span><br><span class="line">filebeat.prospectors:</span><br><span class="line">- type: log</span><br><span class="line">  paths:</span><br><span class="line">    - /home/appdeploy/logstash-tutorial.log</span><br><span class="line">output.logstash:</span><br><span class="line">  hosts: [&quot;192.168.101.172:5144&quot;]</span><br><span class="line">[appdeploy@node001 filebeat6]$</span><br></pre></td></tr></table></figure><p>启动filebeat：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./filebeat -e -c filebeat.yml -d "publish"</span><br></pre></td></tr></table></figure><p>logstash端配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[elk@node002 logstash-6.2.3]$ cat config/first-pipeline.conf</span><br><span class="line">input &#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; &quot;5144&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编辑完配置文件之后，我们可以检测一下配置文件的正确性：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[elk@node002 logstash-6.2.3]$ ./bin/logstash -f config/first-pipeline.conf --config.test_and_exit</span><br></pre></td></tr></table></figure><p>执行后的输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Sending Logstash&apos;s logs to /home/elk/logstash-6.2.3/logs which is now configured via log4j2.properties</span><br><span class="line">[2019-07-29T11:22:44,111][INFO ][logstash.modules.scaffold] Initializing module &#123;:module_name=&gt;&quot;fb_apache&quot;, :directory=&gt;&quot;/home/elk/logstash-6.2.3/modules/fb_apache/configuration&quot;&#125;</span><br><span class="line">[2019-07-29T11:22:44,199][INFO ][logstash.modules.scaffold] Initializing module &#123;:module_name=&gt;&quot;netflow&quot;, :directory=&gt;&quot;/home/elk/logstash-6.2.3/modules/netflow/configuration&quot;&#125;</span><br><span class="line">[2019-07-29T11:22:49,059][WARN ][logstash.config.source.multilocal] Ignoring the &apos;pipelines.yml&apos; file because modules or command line options are specified</span><br><span class="line">Configuration OK</span><br><span class="line">[2019-07-29T11:23:29,319][INFO ][logstash.runner          ] Using config.test_and_exit mode. Config Validation Result: OK. Exiting Logstash</span><br><span class="line">[elk@node002 logstash-6.2.3]$</span><br></pre></td></tr></table></figure><p>检测通过之后，我们可以启动logsatsh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/logstash -f config/first-pipeline.conf --config.reload.automatic</span><br></pre></td></tr></table></figure><p>—config.reload.automatic参数的作用是，当我们修改了配置文件之后，进程能够自动的reload</p><h3 id="grok过滤"><a href="#grok过滤" class="headerlink" title="grok过滤"></a>grok过滤</h3><p>查看当前logstash已安装的所有插件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 logstash-6.2.3]$ bin/logstash-plugin list</span><br></pre></td></tr></table></figure><p>grok插件能够帮助你解析结构凌乱的日志，转变成有结构的以及可查询的。</p><p>从源数据中拆分出我们需要的字段进行展示。</p><p>grok使用正则表达式去匹配源的数据</p><p>一个简单的案例：</p><p>我们使用logstash内置的%{COMBINEDAPACHELOG}进行匹配</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 config]$ cat first-pipeline.conf</span><br><span class="line">input &#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; &quot;5144&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    stdout &#123; codec =&gt; rubydebug &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>reload或者重启后，在filebeat节点上删除注册文件之后，在重新启动filebeat，logstash端的显示为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">     &quot;@timestamp&quot; =&gt; 2019-07-29T08:53:35.835Z,</span><br><span class="line">        &quot;message&quot; =&gt; &quot;192.1.76.62 - - [04/Jan/2015:05:30:37 +0000] \&quot;GET /style2.css HTTP/1.1\&quot; 200 4877 \&quot;http://www.semicomplete.com/projects/xdotool/\&quot; \&quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\&quot;&quot;,</span><br><span class="line">          &quot;ident&quot; =&gt; &quot;-&quot;,</span><br><span class="line">     &quot;prospector&quot; =&gt; &#123;</span><br><span class="line">        &quot;type&quot; =&gt; &quot;log&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">      &quot;timestamp&quot; =&gt; &quot;04/Jan/2015:05:30:37 +0000&quot;,</span><br><span class="line">       &quot;clientip&quot; =&gt; &quot;192.1.76.62&quot;,</span><br><span class="line">       &quot;referrer&quot; =&gt; &quot;\&quot;http://www.semicomplete.com/projects/xdotool/\&quot;&quot;,</span><br><span class="line">           &quot;verb&quot; =&gt; &quot;GET&quot;,</span><br><span class="line">         &quot;source&quot; =&gt; &quot;/home/appdeploy/logstash-tutorial.log&quot;,</span><br><span class="line">           &quot;beat&quot; =&gt; &#123;</span><br><span class="line">        &quot;hostname&quot; =&gt; &quot;node001&quot;,</span><br><span class="line">         &quot;version&quot; =&gt; &quot;6.2.3&quot;,</span><br><span class="line">            &quot;name&quot; =&gt; &quot;node001&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">       &quot;@version&quot; =&gt; &quot;1&quot;,</span><br><span class="line">           &quot;host&quot; =&gt; &quot;node001&quot;,</span><br><span class="line">       &quot;response&quot; =&gt; &quot;200&quot;,</span><br><span class="line">          &quot;bytes&quot; =&gt; &quot;4877&quot;,</span><br><span class="line">          &quot;agent&quot; =&gt; &quot;\&quot;Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20140205 Firefox/24.0 Iceweasel/24.3.0\&quot;&quot;,</span><br><span class="line">        &quot;request&quot; =&gt; &quot;/style2.css&quot;,</span><br><span class="line">         &quot;offset&quot; =&gt; 24898,</span><br><span class="line">           &quot;tags&quot; =&gt; [</span><br><span class="line">        [0] &quot;beats_input_codec_plain_applied&quot;</span><br><span class="line">    ],</span><br><span class="line">           &quot;auth&quot; =&gt; &quot;-&quot;,</span><br><span class="line">    &quot;httpversion&quot; =&gt; &quot;1.1&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>%{COMBINEDAPACHELOG}包含的格式是：</p><table><thead><tr><th><strong>Information</strong></th><th><strong>Field Name</strong></th></tr></thead><tbody><tr><td>IP Address</td><td><code>clientip</code></td></tr><tr><td>User ID</td><td><code>ident</code></td></tr><tr><td>User Authentication</td><td><code>auth</code></td></tr><tr><td>timestamp</td><td><code>timestamp</code></td></tr><tr><td>HTTP Verb</td><td><code>verb</code></td></tr><tr><td>Request body</td><td><code>request</code></td></tr><tr><td>HTTP Version</td><td><code>httpversion</code></td></tr><tr><td>HTTP Status Code</td><td><code>response</code></td></tr><tr><td>Bytes served</td><td><code>bytes</code></td></tr><tr><td>Referrer URL</td><td><code>referrer</code></td></tr><tr><td>User agent</td><td><code>agent</code></td></tr></tbody></table><p>注意：</p><ul><li>使用了grok之后，生成了我们需要的自定义字段之后，发往output的这个event依旧包含这个原始的未被拆分的message</li></ul><h3 id="设置output为es"><a href="#设置output为es" class="headerlink" title="设置output为es"></a>设置output为es</h3><p>在配置文件中，配置输出为es:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [ &quot;localhost:9200&quot; ]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在整体的配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[elk@node004 logstash-6.2.3]$ cat config/first-pipeline.conf</span><br><span class="line">input &#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; &quot;5144&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;COMBINEDAPACHELOG&#125;&quot; &#125;</span><br><span class="line">&#125;</span><br><span class="line">    geoip &#123;</span><br><span class="line">        source =&gt; &quot;clientip&quot;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [ &quot;192.168.100.113:9500&quot; ]</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="启动参数"><a href="#启动参数" class="headerlink" title="启动参数"></a>启动参数</h3><p>主要需要关注的参数有：</p><ul><li>-f：指定配置文件</li><li>-w：指定pipeline的工作进程数量。</li><li>-b：指定每个工作线程最大处理的event数量，默认是125。调大这个数量也就以为着更大的内存消耗，这个需要参考JVM参数进行配置。</li><li><p>—pipeline.unsafe_shutdown：强制logstash在还有event没有处理完成的情况下就退出。</p></li><li><p>-r, —config.reload.automatic：在配置文件修改之后，自动reload配置文件</p></li></ul><h3 id="提取字段已经转变数据"><a href="#提取字段已经转变数据" class="headerlink" title="提取字段已经转变数据"></a>提取字段已经转变数据</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/logstash/6.2/field-extraction.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/field-extraction.html</a></p><p>当输入是通用的日志格式时，我们可以使用grok去进行拆解</p><p>当输出是不规则的日志格式时，我们可以使用dissect去自定义我们的字段</p><h2 id="logstash的-metadata字段"><a href="#logstash的-metadata字段" class="headerlink" title="logstash的@metadata字段"></a>logstash的@metadata字段</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/logstash/6.2/event-dependent-configuration.html#metadata" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/event-dependent-configuration.html#metadata</a></p><p>每一种类型的input，logstash都会生成对应的@metadata字段，具体的信息在input部分会有记录</p><p>默认情况下，如果不进行特殊设置，我们是看不到@metadata的内容的：</p><p>添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123; metadata =&gt; true &#125;</span><br></pre></td></tr></table></figure><p>在调试模式下，output的设置是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    stdout &#123; codec =&gt; rubydebug &#123; metadata =&gt; true &#125; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在input为filebeat时，输出为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  &quot;@metadata&quot; =&gt; &#123;</span><br><span class="line">          &quot;beat&quot; =&gt; &quot;filebeat&quot;,</span><br><span class="line">       &quot;version&quot; =&gt; &quot;6.2.3&quot;,</span><br><span class="line">          &quot;type&quot; =&gt; &quot;doc&quot;,</span><br><span class="line">    &quot;ip_address&quot; =&gt; &quot;192.168.100.113&quot;</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><h2 id="input部分"><a href="#input部分" class="headerlink" title="input部分"></a>input部分</h2><h3 id="Common-option"><a href="#Common-option" class="headerlink" title="Common option"></a>Common option</h3><p>下面这些是通用配置，在所有的input中都支持</p><table><thead><tr><th>Setting</th><th>Input type</th><th>Required</th></tr></thead><tbody><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-add_field" target="_blank" rel="noopener"><code>add_field</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#hash" target="_blank" rel="noopener">hash</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-codec" target="_blank" rel="noopener"><code>codec</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#codec" target="_blank" rel="noopener">codec</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-enable_metric" target="_blank" rel="noopener"><code>enable_metric</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#boolean" target="_blank" rel="noopener">boolean</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-id" target="_blank" rel="noopener"><code>id</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#string" target="_blank" rel="noopener">string</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-tags" target="_blank" rel="noopener"><code>tags</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#array" target="_blank" rel="noopener">array</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-inputs-kafka.html#plugins-inputs-kafka-type" target="_blank" rel="noopener"><code>type</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#string" target="_blank" rel="noopener">string</a></td><td>No</td></tr></tbody></table><h3 id="beats"><a href="#beats" class="headerlink" title="beats"></a>beats</h3><p>参考配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">  beats &#123;</span><br><span class="line">    port =&gt; 5044</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  elasticsearch &#123;</span><br><span class="line">    hosts =&gt; &quot;localhost:9200&quot;</span><br><span class="line">    manage_template =&gt; false</span><br><span class="line">    index =&gt; &quot;%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">    document_type =&gt; &quot;%&#123;[@metadata][type]&#125;&quot; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="kafka-1"><a href="#kafka-1" class="headerlink" title="kafka"></a>kafka</h3><p>本质上是logstash启动一个kafka的客户端，因为存在一定的版本兼容性问题，这里需要注意</p><p>在kafka中，主要关注这些参数：</p><ul><li><p>auto_offset_reset</p><blockquote><p>当没有最初始的偏移量或者偏移量超出范围了，这个时候，做什么操作</p><ul><li>earliest：reset偏移量为最早的</li><li>latest：reset偏移量为最晚的，也就是最新的。</li></ul></blockquote></li><li><p>bootstrap_servers</p><blockquote><p>kafka集群的地址。格式是：host1:port1,host2:port2</p></blockquote></li><li><p>group_id</p><blockquote><p>默认值是logstash。设置消费组的名称。</p></blockquote></li><li><p>session_timeout_ms</p><blockquote><p>如果poll_timeout_ms时间（等待kafka推送消息的超时时间，默认是100ms）超时，过多长时间之后，这个消费者将会被标记为dead。</p></blockquote></li><li><p>request_timeout_ms</p><blockquote><p>logstash上的kafka客户端等待响应的超时时间。</p></blockquote></li><li><p>max_poll_records</p><blockquote><p>单次调用的最大值</p></blockquote></li><li><p>consumer_threads</p><blockquote><p>默认值为1。最理想的情况是线程总数与topic的partition总数相同。如果大于partition总数，则会产生线程空闲，导致资源浪费。</p></blockquote></li><li><p>topics</p><blockquote><p>监听的topic列表，默认值是logstash。</p></blockquote></li></ul><h2 id="filter部分"><a href="#filter部分" class="headerlink" title="filter部分"></a>filter部分</h2><h3 id="grok"><a href="#grok" class="headerlink" title="grok"></a>grok</h3><p>解析非结构化的日志，将日志拆分成为结构化的可查询的字段数据。</p><p>grok中预先定义了很多的正则表达式，在使用的时候只需要调用即可。</p><p>grok 表达式的打印复制格式的完整语法是下面这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%&#123;PATTERN_NAME:capture_name:data_type&#125;</span><br></pre></td></tr></table></figure><ul><li>PATTERN_NAME。代表匹配值的类型,例如3.44可以用NUMBER类型所匹配,127.0.0.1可以使用IP类型匹配。 </li><li>capture_name。代表存储该值的一个变量名称,例如 3.44 可能是一个事件的持续时间,127.0.0.1可能是请求的client地址。所以这两个值可以用 %{NUMBER:duration} %{IP:client_ip} 来匹配。</li></ul><p>案例1:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input &#123;stdin&#123;&#125;&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;%&#123;WORD&#125; %&#123;NUMBER:request_time:float&#125; %&#123;WORD&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;stdout&#123;&#125;&#125;</span><br></pre></td></tr></table></figure><p>运行如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">         &quot;message&quot; =&gt; &quot;begin 123.456 end&quot;,</span><br><span class="line">        &quot;@version&quot; =&gt; &quot;1&quot;,</span><br><span class="line">      &quot;@timestamp&quot; =&gt; &quot;2014-08-09T12:23:36.634Z&quot;,</span><br><span class="line">            &quot;host&quot; =&gt; &quot;raochenlindeMacBook-Air.local&quot;,</span><br><span class="line">    &quot;request_time&quot; =&gt; 123.456</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把 request_time 变成数值类型。如果不使用这个，使用下面这种，那么将会拆分为字符串</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input &#123;stdin&#123;&#125;&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;\s+(?&lt;request_time&gt;\d+(?:\.\d+)?)\s+&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;stdout&#123;&#125;&#125;</span><br></pre></td></tr></table></figure><p>注意：</p><p>grok match本质是一个正则匹配,默认出来的数据都是String.有些时候我们知道某个值其实是个数据类型,这时候可以直接指定数据类型. 不过match中仅支持直接转换成int ,float,语法是 %{NUMBER:response_time:int}</p><p>案例2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  grok &#123;</span><br><span class="line">    match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:bytes&#125; %&#123;NUMBER:duration&#125;&quot; &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下是filter结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">● client: <span class="number">55.3</span><span class="number">.244</span><span class="number">.1</span></span><br><span class="line">● method: GET</span><br><span class="line">● request: /index.html</span><br><span class="line">● bytes: <span class="number">15824</span></span><br><span class="line">● duration: <span class="number">0.043</span></span><br></pre></td></tr></table></figure><h4 id="自定义pattern"><a href="#自定义pattern" class="headerlink" title="自定义pattern"></a>自定义pattern</h4><p><strong>引入文件方法</strong></p><p>很多时候logstash grok没办法提供你所需要的匹配类型，这个时候我们可以使用自定义</p><p>grok里面的match的message，其实是定义在<a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns" target="_blank" rel="noopener">这里</a>的各种pattern。<br>我们可以自定义pattern。</p><p>形式如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">USERNAME [a-zA-Z0-9._-]+</span><br><span class="line">USER %&#123;USERNAME&#125;</span><br><span class="line">EMAILLOCALPART [a-zA-Z][a-zA-Z0-9_.+-=:]+</span><br><span class="line">EMAILADDRESS %&#123;EMAILLOCALPART&#125;@%&#123;HOSTNAME&#125;</span><br><span class="line">INT (?:[+-]?(?:[0-9]+))</span><br></pre></td></tr></table></figure><p>将这些pattern保存在文件中，然后在logstash的config中制定读取pattern的目录即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  grok &#123;</span><br><span class="line">    patterns_dir =&gt; [&quot;/usr/local/logstash/patterns&quot;]</span><br><span class="line">match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;USER: user&#125; %&#123;INT: age&#125; %&#123;EMAILADDRESS: email&#125;&quot;&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，我们输出的时候可以获得到message,user,age,email这几个field。</p><p>配置文件内即时配置方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">语法：(?&lt;field_name&gt;the pattern here)</span><br></pre></td></tr></table></figure><p>就是上面的这个案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">input &#123;stdin&#123;&#125;&#125;</span><br><span class="line">filter &#123;</span><br><span class="line">    grok &#123;</span><br><span class="line">        match =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;\s+(?&lt;request_time&gt;\d+(?:\.\d+)?)\s+&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;stdout&#123;&#125;&#125;</span><br></pre></td></tr></table></figure><p>拆分出来，就是这个：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">?&lt;request_time&gt;\d+(?:\.\d+)?</span><br><span class="line"></span><br><span class="line">\d+(?:\.\d+)? 这个就是这个字段的匹配规则</span><br></pre></td></tr></table></figure><p>\s：匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。+表示匹配次数为1次或者多次</p><p>(?<request_time>  )：这个是grok语法,request_time表示要将捕获的字符定义成的字段名</request_time></p><p>\d+：匹配一个或者多个数字</p><p>(?:.\d+)：为正则表达式，</p><p>(?: pattern):非获取匹配，匹配pattern但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分是很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。</p><p>.\d+：表示点后面跟一个或者多个 数字，(?:.\d+)?表示点后面跟一个或多个数字这种情况出现0次或者多次，如果为0次，则request_time为一个整数。所以匹配到的结果可能为123.456或者123或者123.4.5.6，这些都满足条件</p><h4 id="overwrite"><a href="#overwrite" class="headerlink" title="overwrite"></a>overwrite</h4><p>如果原本的字段需要重写掉，那么：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  grok &#123;</span><br><span class="line">    match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;SYSLOGBASE&#125; %&#123;DATA:message&#125;&quot; &#125;</span><br><span class="line">    overwrite =&gt; [ &quot;message&quot; ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="add-field"><a href="#add-field" class="headerlink" title="add_field"></a>add_field</h4><h4 id="remove-field"><a href="#remove-field" class="headerlink" title="remove_field"></a>remove_field</h4><p>#### </p><h3 id="dissect"><a href="#dissect" class="headerlink" title="dissect"></a>dissect</h3><p>dissect主要用于切割操作。dissect不使用正则表达式去进行匹配，因此，它的处理速度是非常快的。</p><p>如果你的内容每一行都是比较规则的，那么grok是更合适的。</p><p>分隔字段的这个动作，我们叫做解刨<strong>dissection</strong></p><p>语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%&#123;a&#125; - %&#123;b&#125; - %&#123;c&#125;</span><br></pre></td></tr></table></figure><p>{}内的是拆分之后的字段名称</p><p>一个案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">filter &#123;</span><br><span class="line">  dissect &#123;</span><br><span class="line">    mapping =&gt; &#123;</span><br><span class="line">      &quot;message&quot; =&gt; &quot;%&#123;ts&#125; %&#123;+ts&#125; %&#123;+ts&#125; %&#123;src&#125; %&#123;&#125; %&#123;prog&#125;[%&#123;pid&#125;]: %&#123;msg&#125;&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="字段追加"><a href="#字段追加" class="headerlink" title="字段追加"></a>字段追加</h4><p>使用+号</p><h3 id="mutate"><a href="#mutate" class="headerlink" title="mutate"></a>mutate</h3><p>mutate过滤器能够允许你修改、优化你的event。包括：rename、remove、replace、modify字段</p><h3 id="通用参数"><a href="#通用参数" class="headerlink" title="通用参数"></a>通用参数</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-grok.html#plugins-filters-grok-common-options" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-grok.html#plugins-filters-grok-common-options</a></p><p>The following configuration options are supported by all filter plugins:</p><table><thead><tr><th>Setting</th><th>Input type</th><th>Required</th></tr></thead><tbody><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-add_field" target="_blank" rel="noopener"><code>add_field</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#hash" target="_blank" rel="noopener">hash</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-add_tag" target="_blank" rel="noopener"><code>add_tag</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#array" target="_blank" rel="noopener">array</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-enable_metric" target="_blank" rel="noopener"><code>enable_metric</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#boolean" target="_blank" rel="noopener">boolean</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-id" target="_blank" rel="noopener"><code>id</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#string" target="_blank" rel="noopener">string</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-periodic_flush" target="_blank" rel="noopener"><code>periodic_flush</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#boolean" target="_blank" rel="noopener">boolean</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-remove_field" target="_blank" rel="noopener"><code>remove_field</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#array" target="_blank" rel="noopener">array</a></td><td>No</td></tr><tr><td><a href="https://www.elastic.co/guide/en/logstash/6.2/plugins-filters-dissect.html#plugins-filters-dissect-remove_tag" target="_blank" rel="noopener"><code>remove_tag</code></a></td><td><a href="http://www.elastic.co/guide/en/logstash/6.2/configuration-file-structure.html#array" target="_blank" rel="noopener">array</a></td><td>No</td></tr></tbody></table><h3 id="if条件判断"><a href="#if条件判断" class="headerlink" title="if条件判断"></a>if条件判断</h3><p>参考链接：</p><p><a href="https://www.elastic.co/guide/en/logstash/6.2/event-dependent-configuration.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/6.2/event-dependent-configuration.html</a></p><h2 id="output部分"><a href="#output部分" class="headerlink" title="output部分"></a>output部分</h2><h3 id="kafka-2"><a href="#kafka-2" class="headerlink" title="kafka"></a>kafka</h3><p>只要关注的参数有：</p><ul><li><p>bootstrap_servers</p><blockquote><p>kafka集群的地址。格式是：host1:port1,host2:port2</p></blockquote></li><li><p>topic_id</p><blockquote><p>topic的名称</p></blockquote></li><li><p>compression_type</p><blockquote><p>默认值为none。取值范围为：none、gzip、snappy、lz4</p><p>在logstash向后端kafka传输数据时，可以对数据进行压缩。这里定义使用压缩的算法</p></blockquote></li><li><p>codec</p><blockquote><p>定义输出的编码，默认是明文plain。</p></blockquote></li></ul><p>一个案例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;172.24.48.63:19092,172.24.48.64:19092,172.24.48.65:19092&quot;</span><br><span class="line">        topic_id =&gt; &quot;%&#123;topicname&#125;&quot;</span><br><span class="line">        compression_type =&gt; &quot;lz4&quot;</span><br><span class="line">        codec =&gt; plain &#123;</span><br><span class="line">           format =&gt; &quot;%&#123;topicinfo&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><h3 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h3><p>一个实际的案例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        codec =&gt; &quot;plain&quot;</span><br><span class="line">        group_id =&gt; &quot;kafkatoes&quot;</span><br><span class="line">        bootstrap_servers =&gt; &quot;172.24.48.76:19092,172.24.48.77:19092,172.24.48.78:19092&quot;</span><br><span class="line">        auto_offset_reset =&gt; &quot;earliest&quot;</span><br><span class="line">        consumer_threads =&gt; 4</span><br><span class="line">        topics =&gt; &quot;applog6&quot;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">filter  &#123;</span><br><span class="line">    dissect &#123;</span><br><span class="line">        mapping =&gt; &#123;</span><br><span class="line">            &quot;message&quot; =&gt; &quot;%&#123;type&#125; %&#123;host&#125; %&#123;logtime&#125; %&#123;+logtime&#125; %&#123;level&#125; %&#123;content&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if &quot;_dissectfailure&quot; in [tags] &#123;</span><br><span class="line">      drop &#123; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    if [type] !~ &quot;^[A-Za-z]&quot; &#123;</span><br><span class="line">             drop &#123;&#125;</span><br><span class="line">          &#125;</span><br><span class="line">    if [logtime] !~ &quot;^[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&quot; &#123;</span><br><span class="line">             drop &#123;&#125;</span><br><span class="line">          &#125;</span><br><span class="line">    mutate &#123;</span><br><span class="line">        add_field =&gt; &#123;</span><br><span class="line">            &quot;[@metadata][type]&quot; =&gt; &quot;%&#123;type&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">        remove_field =&gt; [&quot;type&quot;]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">       date  &#123;</span><br><span class="line">        match =&gt; [&quot;logtime&quot;, &quot;yyyy-MM-dd HH:mm:ss,SSS&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSS&quot;, &quot;yyyy-MM-dd HH:mm:ss:SSS&quot;, &quot;ISO8601&quot;]</span><br><span class="line">        #timezone =&gt; &quot;+08:00&quot;</span><br><span class="line">        remove_field =&gt; [&quot;message&quot;,&quot;logtime&quot;,&quot;@version&quot;]</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">output &#123;</span><br><span class="line">     elasticsearch &#123;</span><br><span class="line">        hosts =&gt; [&quot;10.10.10.86:9200&quot;,&quot;10.10.10.87:9200&quot;,&quot;10.10.10.88:9200&quot;]</span><br><span class="line">        index =&gt; &quot;%&#123;[@metadata][type]&#125;-logstash-%&#123;+YYYY.MM.dd&#125;&quot;</span><br><span class="line">        template_overwrite =&gt; true</span><br><span class="line">        document_type =&gt; &quot;doc&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一些参数说明：</p><ul><li><p>template_overwrite</p><blockquote><p>布尔类型，取值为true|false。</p></blockquote></li><li><p>document_type</p></li></ul><h3 id="file"><a href="#file" class="headerlink" title="file"></a>file</h3><p>官网的案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line"> file &#123;</span><br><span class="line">   path =&gt; ...</span><br><span class="line">   codec =&gt; line &#123; format =&gt; &quot;custom format: %&#123;message&#125;&quot;&#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个实际的案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">  if [logdate] =~ &quot;^[0-9]&#123;4&#125;-[0-9]&#123;2&#125;-[0-9]&#123;2&#125;&quot; and [loghour] =~ &quot;^[0-9]&#123;2&#125;&quot;  &#123;</span><br><span class="line">    file &#123;</span><br><span class="line">        path =&gt; &quot;/nas/logs/%&#123;type&#125;/%&#123;logdate&#125;/%&#123;host&#125;/%&#123;type&#125;.log-%&#123;logdate&#125;-%&#123;loghour&#125;&quot;</span><br><span class="line">        codec =&gt; line &#123;</span><br><span class="line">            format =&gt; &quot;%&#123;logdate&#125; %&#123;loghour&#125;:%&#123;logms&#125; %&#123;content&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="codec部分"><a href="#codec部分" class="headerlink" title="codec部分"></a>codec部分</h2><p>codec插件，改变了event中的数据展示方式/格式，codecs本质上也是一个过滤器，可以作用在input和output阶段</p><p>Codec 是 logstash 从 1.3.0 版开始新引入的概念(<em>Codec</em> 来自 <em>Co</em>der/<em>dec</em>oder 两个单词的首字母缩写)。</p><p>在此之前，logstash 只支持纯文本形式输入，然后以<em>过滤器</em>处理它。但现在，我们可以在<em>输入</em> 期处理不同类型的数据，这全是因为有了 <strong>codec</strong> 设置。</p><p>Logstash 不只是一个<code>input | filter | output</code> 的数据流，而是一个 <code>input | decode | filter | encode | output</code> 的数据流！<em>codec</em> 就是用来 decode、encode 事件的。</p><p>简单说，就是在logstash读入的时候，通过codec编码解析日志为相应格式，从logstash输出的时候，通过codec解码成相应格式。</p><p>codec 的引入，使得 logstash 可以更好更方便的与其他有自定义数据格式的运维产品共存，比如 graphite、fluent、netflow、collectd，以及使用 msgpack、json、edn 等通用数据格式的其他产品等。</p><p>事实上，我们在第一个 “hello world” 用例中就已经用过 <em>codec</em> 了 —— <em>rubydebug</em> 就是一种 <em>codec</em>！虽然它一般只会用在 stdout 插件中，作为配置测试或者调试的工具。</p><h3 id="plain"><a href="#plain" class="headerlink" title="plain"></a>plain</h3><p>用于event之间没有分隔的文本</p><p>在消息队列时，例如kafka，input一般都是plain</p><p>format设置，指定输出的内容，例如在output是kafka时：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">output &#123;</span><br><span class="line">    kafka &#123;</span><br><span class="line">        bootstrap_servers =&gt; &quot;172.24.48.63:19092,172.24.48.64:19092,172.24.48.65:19092&quot;</span><br><span class="line">        topic_id =&gt; &quot;%&#123;topicname&#125;&quot;</span><br><span class="line">        compression_type =&gt; &quot;lz4&quot;</span><br><span class="line">        codec =&gt; plain &#123;</span><br><span class="line">           format =&gt; &quot;%&#123;topicinfo&#125;&quot;</span><br><span class="line">        &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="line"><a href="#line" class="headerlink" title="line"></a>line</h3><h2 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h2><h3 id="公网服务器日志收集"><a href="#公网服务器日志收集" class="headerlink" title="公网服务器日志收集"></a>公网服务器日志收集</h3><p>公网服务器的filebeat，将日志发送到有对外IP的logstash，然后由logstash去处理数据，获取到数据之后，再将数据写入到kafka集群中。</p><h1 id="Elasticsearch部署"><a href="#Elasticsearch部署" class="headerlink" title="Elasticsearch部署"></a>Elasticsearch部署</h1><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/getting-started.html#getting-started" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/getting-started.html#getting-started</a></p><h2 id="ES工作原理"><a href="#ES工作原理" class="headerlink" title="ES工作原理"></a>ES工作原理</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p><strong>Near Realtime (NRT)</strong></p><blockquote><p>ES是一个接近实时的搜索平台，也就是说有些许的延迟，从索引文件到能够检索出结果的延迟一般在秒内</p></blockquote><p><strong>Cluser</strong></p><blockquote><p>集群由一个或多个node节点组成，这些节点协同存储所有的条目数据，并且都支持检索的功能以提高性能。</p><p>一个集群由一个唯一的名称标识，<strong>默认为：elasticsearch</strong>。一个节点只能够属于一个集群</p></blockquote><p><strong>Node</strong></p><blockquote><p>集群中的每一个服务器/服务节点叫做node。在一个集群中，每一个node都通过一个唯一的名称去标识(默认是一个随机的UUID)。每一个node会加到一个es集群当中，默认的集群名称是elasticsearch，可以指定集群的名称以创建多个不同的es集群。</p><p>一个集群可以只有一个node节点</p></blockquote><p><strong>Index</strong></p><blockquote><p>索引是一批收集的拥有相似特征的<strong>文件集合</strong>。</p><p>索引通过不同的名称去标识(必须为小写)，这个索引名称用于后续的检索、更新、删除文件内容等操作</p></blockquote><p><strong>Type</strong></p><blockquote><p>在一个索引中，可以定义一个或多个type类型，type就相当于是索引数据的分类字段。例如你的索引内容一个博客系统，你可以分别定义用户字段、评论字段、内容字段。</p><p>在5版本中有，6版本中只能设置一个，7版本中废弃。</p><p>index相当于是一个数据库，type相当于是表。</p></blockquote><p><strong>Document</strong></p><blockquote><p>document是存储信息以及创建索引的基本单元。document通常是以JSON的方式存在的。document其实也可以理解是一段内容</p><p>注意：document在索引中存在时，必须被分配或者说指定给某一个type</p><p>document是一条记录，其中包含各个字段。</p></blockquote><p><strong>Shard &amp; Replicas</strong></p><blockquote><p>每一个索引可以存储大量的数据。这些数据在落地到物理磁盘上时，很有可能超出单个node的限制。为了解决这个问题，ES提供了把索引分割的功能，每一个被分割出来的部分我们叫做shard分片。</p><p>在创建index的时候，我们可以指定分片的数量。</p><p>副本是为了提供分片的高可用，并且在查询的时候可以并行执行</p><p>这一部分比较核心，我们会有单独的篇幅讲解。</p></blockquote><h3 id="集群状态"><a href="#集群状态" class="headerlink" title="集群状态"></a>集群状态</h3><p>ES集群有3种状态：green，yellow，red。其中green状态表明集群是健康的。yellow表示集群可用，但是有部分索引的shard有异常。red状态表示集群有索引异常。</p><h2 id="ES安装配置"><a href="#ES安装配置" class="headerlink" title="ES安装配置"></a>ES安装配置</h2><h3 id="基础环境配置"><a href="#基础环境配置" class="headerlink" title="基础环境配置"></a>基础环境配置</h3><p><strong>JAVA配置</strong></p><p>ES的运行需要java作为基础，最低版本要求为java 8。</p><p>根据以下命令操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# tar -zxvf jdk1.8.0_77.tar.gz  -C /usr/local/</span><br><span class="line">[root@node001 ~]# ln -s /usr/local/jdk1.8.0_77 /usr/local/jdk</span><br><span class="line">[root@node001 ~]# vim /etc/profile# 在文件末尾添加一下内容</span><br><span class="line">JAVA_HOME=/usr/local/jdk</span><br><span class="line">PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">CLASSPATH=.:$JAVA_HOME/lib</span><br><span class="line">JRE_HOME=$JAVA_HOME/jre</span><br><span class="line">export JAVA_HOME PATH CLASSPATH JRE_HOME</span><br><span class="line"></span><br><span class="line">[root@node001 ~]# source /etc/profile</span><br><span class="line">[root@node001 ~]# java -version</span><br><span class="line">java version &quot;1.8.0_77&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_77-b03)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.77-b03, mixed mode)</span><br></pre></td></tr></table></figure><p><strong>系统环境配置</strong></p><ol><li>打开服务器的/etc/sysctl.conf文件，增加下面内容：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# vim /etc/sysctl.conf</span><br><span class="line">fs.file-max=65536</span><br><span class="line">vm.max_map_count=655360</span><br><span class="line">vm.zone_reclaim_mode=0</span><br></pre></td></tr></table></figure><p>保存后，执行命令: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# sysctl  -p</span><br></pre></td></tr></table></figure><ol><li>创建elk用户，创建数据目录，设置数据目录的权限</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# useradd  elk</span><br><span class="line">[root@node001 ~]# su - elk</span><br><span class="line">[elk@node001 ~]$ mkdir data</span><br></pre></td></tr></table></figure><p>注意，一般我们会将数据目录放在其他盘中，这个时候需要注意权限问题，此时的操作类型：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# mkdir  -p /data1/elk</span><br><span class="line">[root@node001 ~]# chown -R elk:elk /data1/elk</span><br></pre></td></tr></table></figure><ol><li>配置/etc/security/limits.conf，修改文件描述符以及进程数限制</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# vim /etc/security/limits.conf</span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 655360</span><br><span class="line">elk soft memlock unlimited</span><br><span class="line">elk hard memlock unlimited</span><br><span class="line"></span><br><span class="line">[root@node001 ~]# vim  /etc/security/limits.d/90-nproc.conf</span><br><span class="line">*       soft    nproc   65536</span><br><span class="line">root       soft    nproc     unlimited</span><br><span class="line"></span><br><span class="line"># *       hard    nproc   65536这个可选</span><br></pre></td></tr></table></figure><p>注意：在limits.conf文件中的nproc的设置和/etc/security/limits.d/90-nproc.conf中proc设置有关</p><ul><li>当在limits.conf中使用*号让全局用户生效的时候，生效的nproc的值大小受后者制约</li><li>当在limits.conf中指定用户时，生效的nproc值不受该文件制约</li></ul><h3 id="下载-1"><a href="#下载-1" class="headerlink" title="下载"></a>下载</h3><p>执行以下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.1.2.tar.gz</span><br><span class="line">[elk@node001 ~]$ tar -xvf elasticsearch-5.1.2.tar.gz</span><br></pre></td></tr></table></figure><p>在做测试时，我们可以不经过任何配置直接启动，执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ cd elasticsearch-5.1.2/bin</span><br><span class="line">[elk@node001 bin]$ ./elasticsearch</span><br></pre></td></tr></table></figure><p>如果需要使用守护进程方式启动，执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 bin]$ ./elasticsearch -d -p pid.file</span><br><span class="line">[elk@node001 bin]$ cat pid.file</span><br><span class="line">3104</span><br><span class="line">注：-p可以指定将pid记录到某一个文件中</span><br></pre></td></tr></table></figure><h3 id="ES配置及配置文件详解"><a href="#ES配置及配置文件详解" class="headerlink" title="ES配置及配置文件详解"></a>ES配置及配置文件详解</h3><p>Elasticsearch loads its configuration from the <code>$ES_HOME/config/elasticsearch.yml</code> file by default. The format of this config file is explained in <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/settings.html" target="_blank" rel="noopener"><em>Configuring Elasticsearch</em></a>.</p><p>Any settings that can be specified in the config file can also be specified on the command line, using the <code>-E</code> syntax as follows:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch -d -Ecluster.name=my_cluster -Enode.name=node_1</span><br></pre></td></tr></table></figure><p>ES在启动的时候，默认会从ES目录下的config目录下，读取elasticsearch.yml文件。</p><p>但是，除了从配置文件读取之外，也可以在启动的时候，手动的指定一些配置。</p><p>注意：</p><ul><li>建议都从elasticsearch.yml配置文件中读取，不建议命令行指定。</li><li>建议将配置文件目录、数据目录、日志目录进行分离。</li></ul><h4 id="ES目录结构"><a href="#ES目录结构" class="headerlink" title="ES目录结构"></a>ES目录结构</h4><p>解压出来的es目录结构如下所示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 elasticsearch-5.1.2]$ pwd</span><br><span class="line">/home/elk/elasticsearch-5.1.2</span><br><span class="line">[elk@node001 elasticsearch-5.1.2]$ ll</span><br><span class="line">total 56</span><br><span class="line">drwxr-xr-x.  2 elk elk  4096 Jun 28 15:56 bin</span><br><span class="line">drwxr-xr-x.  3 elk elk  4096 Jun 20 17:16 config</span><br><span class="line">drwxrwxr-x.  3 elk elk  4096 Jun 20 17:16 data</span><br><span class="line">drwxr-xr-x.  2 elk elk  4096 Jan 12  2017 lib</span><br><span class="line">-rw-r--r--.  1 elk elk 11358 Jan 12  2017 LICENSE.txt</span><br><span class="line">drwxrwxr-x.  2 elk elk  4096 Jun 28 15:20 logs</span><br><span class="line">drwxr-xr-x. 12 elk elk  4096 Jan 12  2017 modules</span><br><span class="line">-rw-r--r--.  1 elk elk   150 Jan 12  2017 NOTICE.txt</span><br><span class="line">drwxr-xr-x.  2 elk elk  4096 Jan 12  2017 plugins</span><br><span class="line">-rw-r--r--.  1 elk elk  9108 Jan 12  2017 README.textile</span><br></pre></td></tr></table></figure><p>下面是官方的定义：</p><table><thead><tr><th style="text-align:left">Type</th><th style="text-align:left">Description</th><th style="text-align:left">Default Location</th><th style="text-align:left">Setting</th></tr></thead><tbody><tr><td style="text-align:left"><strong>home</strong></td><td style="text-align:left">Elasticsearch home directory or <code>$ES_HOME</code></td><td style="text-align:left">Directory created by unpacking the archive</td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><strong>bin</strong></td><td style="text-align:left">Binary scripts including <code>elasticsearch</code> to start a node and <code>elasticsearch-plugin</code> to install plugins</td><td style="text-align:left"><code>$ES_HOME/bin</code></td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><strong>conf</strong></td><td style="text-align:left">Configuration files including <code>elasticsearch.yml</code></td><td style="text-align:left"><code>$ES_HOME/config</code></td><td style="text-align:left"><code>path.conf</code></td></tr><tr><td style="text-align:left"><strong>data</strong></td><td style="text-align:left">The location of the data files of each index / shard allocated on the node. Can hold multiple locations.</td><td style="text-align:left"><code>$ES_HOME/data</code></td><td style="text-align:left"><code>path.data</code></td></tr><tr><td style="text-align:left"><strong>logs</strong></td><td style="text-align:left">Log files location.</td><td style="text-align:left"><code>$ES_HOME/logs</code></td><td style="text-align:left"><code>path.logs</code></td></tr><tr><td style="text-align:left"><strong>plugins</strong></td><td style="text-align:left">Plugin files location. Each plugin will be contained in a subdirectory.</td><td style="text-align:left"><code>$ES_HOME/plugins</code></td><td style="text-align:left"></td></tr><tr><td style="text-align:left"><strong>repo</strong></td><td style="text-align:left">Shared file system repository locations. Can hold multiple locations. A file system repository can be placed in to any subdirectory of any directory specified here.</td><td style="text-align:left">Not configured</td><td style="text-align:left"><code>path.repo</code></td></tr><tr><td style="text-align:left"><strong>script</strong></td><td style="text-align:left">Location of script files.</td><td style="text-align:left"><code>$ES_HOME/scripts</code></td><td style="text-align:left"><code>path.scripts</code></td></tr></tbody></table><h4 id="如何配置ES"><a href="#如何配置ES" class="headerlink" title="如何配置ES"></a>如何配置ES</h4><p>Elasticsearch ships with good defaults and requires very little configuration. Most settings can be changed on a running cluster using the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/cluster-update-settings.html" target="_blank" rel="noopener"><em>Cluster Update Settings</em></a> API.</p><p>The configuration files should contain settings which are node-specific (such as <code>node.name</code> and paths), or settings which a node requires in order to be able to join a cluster, such as <code>cluster.name</code>and <code>network.host</code>.</p><p>注意：</p><ul><li>ES的大部分配置可以使用ES提供的接口在集群运行过程中动态的修改。</li><li>配置文件中应该要包含node节点相关的配置(例如node.name和path)，如果要加入es集群的话还需要添加集群相关的配置</li></ul><p><strong>配置文件：</strong></p><p>ES需要关注的配置文件有一下2个：</p><ul><li>elasticsearch.yml    # ES的主配置文件</li><li>log4j2.properties    # ES的日志相关配置</li></ul><p>默认这两个配置文件在$ES_HOME/config/路径下，但是，我们也可以在启动的时候手动指定配置文件的加载路径，启动命令为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch -Epath.conf=/path/to/my/config/</span><br></pre></td></tr></table></figure><p><strong>配置格式：</strong></p><p>ES的相关配置都是使用YAML语法格式，下面是两种配置方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path:</span><br><span class="line">    data: /var/lib/elasticsearch</span><br><span class="line">    logs: /var/log/elasticsearch</span><br></pre></td></tr></table></figure><p>等价于</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path.data: /var/lib/elasticsearch</span><br><span class="line">path.logs: /var/log/elasticsearch</span><br></pre></td></tr></table></figure><p><strong>环境变量引用</strong></p><p>如果需要在配置文件中引入系统的环境变量，可以使用下面这种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node.name:    $&#123;HOSTNAME&#125;</span><br><span class="line">network.host: $&#123;ES_NETWORK_HOST&#125;</span><br></pre></td></tr></table></figure><p><strong>根据提示输入配置</strong></p><p>ES的配置文件支持交互式的输入配置，可以配置在启动的时候手动输入对应的配置，配置方式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node:</span><br><span class="line">  name: $&#123;prompt.text&#125;</span><br></pre></td></tr></table></figure><p>放前台启动es的时候，会有下面这种提示信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Enter value for [node.name]:</span><br></pre></td></tr></table></figure><p>注意：这种方式在启动方式为后台守护进程启动时是无效的。</p><p><strong>设置默认配置</strong></p><p>一些默认配置如果不想让es自动生成，那么我们可以进行自定义，命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch -Edefault.node.name=My_Node</span><br></pre></td></tr></table></figure><p>注意：默认值只是在配置文件中没有配置，并且没有在命令行手动指定时生效。</p><p><strong>日志相关配置</strong></p><p>Elasticsearch uses <a href="http://logging.apache.org/log4j/2.x/" target="_blank" rel="noopener">Log4j 2</a> for logging. Log4j 2 can be configured using the log4j2.properties file. Elasticsearch exposes a single property <code>${sys:es.logs}</code> that can be referenced in the configuration file to determine the location of the log files; this will resolve to a prefix for the Elasticsearch log file at runtime.</p><p>For example, if your log directory (<code>path.logs</code>) is <code>/var/log/elasticsearch</code> and your cluster is named <code>production</code> then <code>${sys:es.logs}</code> will resolve to <code>/var/log/elasticsearch/production</code>.</p><p>ES使用java的log4J 2日志框架。ES在内部维护了一个变量：${sys:es.logs}，该变量记录的是es的集群名称</p><p>在输出日志时，这个日志框架将会调用这个变量生成对应的文件。</p><p>例如：</p><p>log4j2.properties配置文件是这个内容时</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">appender.rolling.type = RollingFile </span><br><span class="line">appender.rolling.name = rolling</span><br><span class="line">appender.rolling.fileName = $&#123;sys:es.logs&#125;.log</span><br></pre></td></tr></table></figure><p>例如es集群名称为：testes，那么生成的日志文件名称将会是：testes.log</p><p>下面拿配置文件中的一段配置进行举例说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">appender.rolling.type = RollingFile</span><br><span class="line">appender.rolling.name = rolling</span><br><span class="line">appender.rolling.fileName = $&#123;sys:es.logs&#125;.log</span><br><span class="line">appender.rolling.layout.type = PatternLayout</span><br><span class="line">appender.rolling.layout.pattern = [%d&#123;ISO8601&#125;][%-5p][%-25c&#123;1.&#125;] %marker%.-10000m%n</span><br><span class="line">appender.rolling.filePattern = $&#123;sys:es.logs&#125;-%d&#123;yyyy-MM-dd&#125;.log</span><br><span class="line">appender.rolling.policies.type = Policies</span><br><span class="line">appender.rolling.policies.time.type = TimeBasedTriggeringPolicy</span><br><span class="line">appender.rolling.policies.time.interval = 1</span><br><span class="line">appender.rolling.policies.time.modulate = true</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>appender.rolling.filePattern。给这个配置参数赋值时，如果添加：.gz或者.zip这种后缀，那么在进行日志轮转的时候将会自动被压缩</li></ul><p><strong>deprecation log </strong></p><p>In addition to regular logging, Elasticsearch allows you to enable logging of deprecated actions. For example this allows you to determine early, if you need to migrate certain functionality in the future. By default, deprecation logging is enabled at the WARN level, the level at which all deprecation log messages will be emitted.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logger.deprecation.level = warn</span><br></pre></td></tr></table></figure><p>This will create a daily rolling deprecation log file in your log directory. Check this file regularly, especially when you intend to upgrade to a new major version.</p><p>The default logging configuration has set the roll policy for the deprecation logs to roll and compress after 1 GB, and to preserve a maximum of five log files (four rolled logs, and the active log).</p><p>You can disable it in the <code>config/log4j2.properties</code> file by setting the deprecation log level to <code>error</code>.</p><p>在ES中，还专门定义了这么一个日志文件：查看被废弃或者被修改的功能的调用日志</p><p>当你在调用ES时，如果涉及到一些在后续版本中要废弃或者要修改的配置项时，ES将会将该内容，以便管理员知悉并判断是否需要升级<br>例如 _all 即将被废弃，如果你某一个索引启用了 _all，则可能会有一条 deprecation log；<br>通过这个日志的内容，可以指导你决定是否迁移到新的版本</p><h4 id="重要配置参数说明"><a href="#重要配置参数说明" class="headerlink" title="重要配置参数说明"></a>重要配置参数说明</h4><h5 id="path-data和path-logs"><a href="#path-data和path-logs" class="headerlink" title="path.data和path.logs"></a><strong>path.data和path.logs</strong></h5><p>在默认情况下，数据目录和日志目录在es的主目录下，如果我们修改了路径，那么在升级es版本的时候，这些目录可能被删除</p><p>但是，实际情况是，我们一般都会把这两个目录自定义出来</p><p>如果数据目录只需要一个，那么可以是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">path:</span><br><span class="line">  logs: /var/log/elasticsearch</span><br><span class="line">  data: /var/data/elasticsearch</span><br></pre></td></tr></table></figure><p>但是，es的数据目录可以设置为多个，如果我们有这方面的需求，我们可以设置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">path:</span><br><span class="line">  data:</span><br><span class="line">    - /mnt/elasticsearch_1</span><br><span class="line">    - /mnt/elasticsearch_2</span><br><span class="line">    - /mnt/elasticsearch_3</span><br></pre></td></tr></table></figure><p>注意：一个索引的分片只会存储在某一个目录中，不会分散存储。</p><h5 id="cluster-name"><a href="#cluster-name" class="headerlink" title="cluster.name"></a><strong>cluster.name</strong></h5><p>一个es节点只能加入到一个es集群当中，es集群的默认名称为：elasticsearch。在实际使用时，你应该将它修改为符合用途的名称</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster.name: logging-prod</span><br></pre></td></tr></table></figure><h5 id="node-name"><a href="#node-name" class="headerlink" title="node.name"></a><strong>node.name</strong></h5><p>如果在配置文件中没有配置，es默认将会分配一个随机的7个字符对节点进行标识。</p><p>注意，一旦分配，在这个node后续重启时，也将使用这个字符串，不会再重新生成。</p><p>这个配置参数建议是最好进行配置，配置方式例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node.name: prod-data-2</span><br></pre></td></tr></table></figure><p>如果想把node的名称定义为系统的主机名，es也提供了这个功能，使用这种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node.name: $&#123;HOSTNAME&#125;</span><br></pre></td></tr></table></figure><h5 id="bootstrap-memory-lock"><a href="#bootstrap-memory-lock" class="headerlink" title="bootstrap.memory_lock"></a><strong>bootstrap.memory_lock</strong></h5><p>It is vitally important to the health of your node that none of the JVM is ever swapped out to disk. One way of achieving that is set the <code>bootstrap.memory_lock</code> setting to <code>true</code>.</p><p>For this setting to have effect, other system settings need to be configured first. See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/setup-configuration-memory.html#mlockall" target="_blank" rel="noopener">Enable <code>bootstrap.memory_lock</code></a> for more details about how to set up memory locking correctly.</p><p>我们一般称之为锁内存配置。这个在ES中是及其重要的一个参数，开启了该参数后，能够保证，JVM内存被锁定在内存中，其中的数据永远不会被添加到swap交换分区中。</p><p>注意：如要要正确的开启这个参数，对系统的一些配置有要求。可以点击这个链接进行查看</p><p>开启配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bootstrap.memory_lock: true</span><br></pre></td></tr></table></figure><p>在es启动之后，我们可以通过下面的接口来确认是否正确开启：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _nodes?filter_path=**.mlockall</span><br></pre></td></tr></table></figure><p>If you see that <code>mlockall</code> is <code>false</code>, then it means that the <code>mlockall</code> request has failed. You will also see a line with more information in the logs with the words <code>Unable to lock JVM Memory</code>.</p><p>The most probable reason, on Linux/Unix systems, is that the user running Elasticsearch doesn’t have permission to lock memory. This can be granted as follows:</p><p>如果接口的返回结果是false，那么，我们可以在日志文件中根据关键字：”Unable to lock JVM Memory”进行搜索，查看具体原因</p><p>有许多原因会导致开启失败，罗列为：</p><ul><li><p>Set <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/setting-system-settings.html#ulimit" target="_blank" rel="noopener"><code>ulimit -l unlimited</code></a> as root before starting Elasticsearch, or set <code>memlock</code> to <code>unlimited</code> in<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/setting-system-settings.html#limits.conf" target="_blank" rel="noopener"><code>/etc/security/limits.conf</code></a>.</p><p>需要打开涉及用户对内存的限制，如果没有配置，需要按照下方格式配置，这一部分我们在上面的基础环境配置时有记录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">elk soft memlock unlimited</span><br><span class="line">elk hard memlock unlimited</span><br></pre></td></tr></table></figure></li><li><p>Another possible reason why <code>mlockall</code> can fail is that the temporary directory (usually <code>/tmp</code>) is mounted with the <code>noexec</code> option. This can be solved by specifying a new temp directory using the <code>ES_JAVA_OPTS</code> environment variable:</p><p>如果系统在挂载临时目录(通常为/tmp)时，添加了noexec（禁止执行二进制文件）参数，也会引起这个问题，我们可以通过自定义临时目录进行解决，配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ES_JAVA_OPTS=&quot;$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir&quot;</span><br><span class="line">./bin/elasticsearch</span><br></pre></td></tr></table></figure><p>如果想永久生效，可以把这个配置记录到<code>jvm.options</code>配置文件中。</p></li></ul><p>注意：因为我们是源码包安装形式，所以这里我们不关注通过rpm包以及yum等管理工具安装的情况</p><p>锁内存问题分析：</p><blockquote><p>大多数操作系统都会将在内存中没有使用的数据转移到swap中，如果没有配置上述的参数，那么在es运行过程中，那么可能就会出现es占用的java堆内存中的数据被转移到swap中，也就是磁盘上。</p><p>我们知道，磁盘的读写性能和内存有非常大的差距，当在执行gc的时候，可能会导致gc时间从ms级别变成min级别，这么长的gc时间是绝对不能接受的，很有可能就会导致这个node节点响应变慢，甚至从集群中脱离。</p></blockquote><p>通过上面的问题分析，我们知道，以下方式也是能杜绝这个问题</p><ul><li>安装系统时不设置swap</li><li>如有swap，关闭swap</li><li>降低使用swap的倾向</li></ul><p>关闭swap的操作如下：</p><ul><li><p>临时生效，执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo swapoff -a</span><br></pre></td></tr></table></figure></li><li><p>永久生效，也就是系统重启后还生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">编辑/etc/fstab文件，将挂载swap的配置注释</span><br></pre></td></tr></table></figure></li></ul><p>降低使用swap的倾向：</p><ul><li><p>临时生效，执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w vm.swappiness=1</span><br></pre></td></tr></table></figure></li><li><p>永久生效，也就是系统重启后还生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;vm.swappiness = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure></li></ul><h5 id="network-host"><a href="#network-host" class="headerlink" title="network.host"></a><strong>network.host</strong></h5><p>默认情况下，es将服务监听在本机的回环地址，我们可以使用下列参数修改监听地址</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">network.host: 192.168.1.10</span><br></pre></td></tr></table></figure><p>注意：</p><p>默认情况下，es假定你是工作在开发模式，假如你有一些配置没有配置正确，es也能正常启动，并且将这些配置记录到日志文件中(日志级别为warning)</p><p>但是，一旦你配置了网络相关的配置，例如network.host，那么es将判断你从开发者模式提升为生产模式，这个时候如果有一些配置没有配置正确，那么es将产生异常，并且启动失败。</p><p>这种一种非常重要的安全机制，能够确保你不会因为错误的配置而导致数据丢失。</p><p>下面是当作为生产模式运行时，具体要检测的依赖配置</p><p>Ideally, Elasticsearch should run alone on a server and use all of the resources available to it. In order to do so, you need to configure your operating system to allow the user running Elasticsearch to access more resources than allowed by default.</p><p>The following settings <strong>must</strong> be addressed before going to production:</p><ul><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/heap-size.html" target="_blank" rel="noopener">Set JVM heap size</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/setup-configuration-memory.html" target="_blank" rel="noopener">Disable swapping</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/file-descriptors.html" target="_blank" rel="noopener">Increase file descriptors</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/vm-max-map-count.html" target="_blank" rel="noopener">Ensure sufficient virtual memory</a></li><li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/max-number-of-threads.html" target="_blank" rel="noopener">Ensure sufficient threads</a></li></ul><p>网络相关的配置，除了这个常见的监听地址的配置，还有很多，我们在下面会进行汇总讲解</p><h5 id="discovery-zen-ping-unicast-hosts"><a href="#discovery-zen-ping-unicast-hosts" class="headerlink" title="discovery.zen.ping.unicast.hosts"></a><strong>discovery.zen.ping.unicast.hosts</strong></h5><p>当在组成一个es集群的时候，需要添加其他集群节点，这个时候需要如下的配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">discovery.zen.ping.unicast.hosts:</span><br><span class="line">   - 192.168.1.10:9300</span><br><span class="line">   - 192.168.1.11 </span><br><span class="line">   - seeds.mydomain.com</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>如果没有指定端口，则默认为：transport.profiles.default.port和transport.tcp.port(这里指的是TCP端口)</li><li>如果一个主机名映射了多个ip，那么会把解析出来的所有ip都添加进来</li></ul><h5 id="discovery-zen-minimum-master-nodes"><a href="#discovery-zen-minimum-master-nodes" class="headerlink" title="discovery.zen.minimum_master_nodes"></a><strong>discovery.zen.minimum_master_nodes</strong></h5><p>为了防止数据的丢失，需要确保每一个主节点都知晓：组成一个集群最少可以有几个主节点</p><p>如果没有这个配置，当集群遭遇到网络问题导致各个集群节点之间的通信出现问题时，整个集群可能会变成2个独立的集群，这个现象我们称之为：a split brain(脑裂)，这会导致数据的丢失。</p><p>配置规则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(master_eligible_nodes / 2) + 1</span><br></pre></td></tr></table></figure><p>举例说明，例如当前集群有3个节点，那么配置就应该是(3 / 2) + 1或者2(注意，我们是取整数)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">discovery.zen.minimum_master_nodes: 2</span><br></pre></td></tr></table></figure><p>除了在配置文件中配置，在运行过程中，我们可以通过接口临时修改</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;transient&quot;: &#123;</span><br><span class="line">    &quot;discovery.zen.minimum_master_nodes&quot;: 2</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>a split brain详解：</p><blockquote><p>假定集群有2个节点，minimum_master_nodes的值设置为1，当网络出现问题时，每个节点都会把自己提升为集群的主节点(认为另一个节点已经终止)，结果就是会产生2个集群。</p><p>当网络恢复时，节点不会重新加入集群。只有当节点重启的时候，才会重新加入集群，但是，重启节点上的数据会丢失。</p><p>也正是因为这个原因，所以，我们的集群主节点最好是3个以上</p></blockquote><h5 id="网络相关配置汇总"><a href="#网络相关配置汇总" class="headerlink" title="网络相关配置汇总"></a>网络相关配置汇总</h5><p>es配置文件中，有以下网络相关配置</p><ul><li><strong>network.host</strong>。略。</li><li><p><strong>discovery.zen.ping.unicast.hosts</strong>。略</p></li><li><p><strong>http.port</strong></p><p>Port to bind to for incoming HTTP requests. Accepts a single value or a range. If a range is specified, the node will bind to the first available port in the range.</p><p>Defaults to <code>9200-9300</code>.</p><p>设置节点的http端口，提供接口处理相对应的请求，可以赋值为单个值或者一个范围，如果是一个范围，那么将会使用第一个值。</p></li><li><p><strong>transport.tcp.port</strong></p><p>Port to bind for communication between nodes. Accepts a single value or a range. If a range is specified, the node will bind to the first available port in the range.</p><p>Defaults to <code>9300-9400</code>.</p><p>设置节点的TCP接口，用于集群之间的通信，和上面类似，可以赋值为单个值或者一个范围，如果是一个范围，那么将会使用第一个值。</p></li></ul><h2 id="ES的启动引导检查"><a href="#ES的启动引导检查" class="headerlink" title="ES的启动引导检查"></a>ES的启动引导检查</h2><p>在ES的早期版本，一些es和系统配置不符合要求时，只是输出到日志文件中，供用户查看，但是考虑到很多用户不去看这些日志文件，因此，在后续版本中，es把这些检查放到了启动过程中，当有配置不符合要求时，就是在启动过程中显示出来(注意，只针对生产模式，开发模式只是记录日志)</p><p>下面是一些检测指标，对应的详细配置会在下面的<strong>重要的系统配置</strong>中说明</p><ul><li><p>Heap size check</p><p>JVM初始值和最大值必须要设置一致。</p></li><li><p>File descriptor check</p><p>ES需要大量的文件描述符(Linux中一切皆文件)，是否&gt;=65535</p></li><li><p>Memory lock check</p><p>锁内存配置是否开启。这个在前面的配置参数中有说明了。</p></li><li><p>Maximum number of threads check</p><p>最大线程数限制。ES将接收到处理请求拆分成为多个步骤，每个步骤都会使用不同的线程池。</p><p>因此，ES需要创建大量的线程，在启动前的check操作能够保证es在运行过程中有足够多的资源。</p><p>系统需要保证用户至少能创建2048个线程。</p><p>这个的配置在/etc/security/limits.conf和/etc/security/limits.d/90-nproc.conf配置文件中，参数是nproc，建议配置&gt;=65536</p></li><li><p>Maximum size virtual memory check</p><p>虚拟内存限制。需要把内存限制打开</p><p>这个的配置在/etc/security/limits.conf配置文件中，参数是memlock，设置为unlimited</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ cat /etc/security/limits.conf</span><br><span class="line">elk soft memlock unlimited</span><br><span class="line">elk hard memlock unlimited</span><br></pre></td></tr></table></figure><p>vm.max_map_count</p></li><li><p>还是内存相关的配置，这个是内存参数配置。</p><p>配置文件：/etc/sysctl.conf，配置参数：vm.max_map_count，默认值是262144，建议配置&gt;=655360</p></li></ul><h2 id="重要的系统配置"><a href="#重要的系统配置" class="headerlink" title="重要的系统配置"></a>重要的系统配置</h2><h3 id="JVM堆内存"><a href="#JVM堆内存" class="headerlink" title="JVM堆内存"></a>JVM堆内存</h3><p>ES的JVM内存配置有以下注意事项</p><ul><li>每个节点的Xms和Xmx设置为相等的值</li><li>更大的内存设置可能会导致gc时间变长，需要考虑一个平衡</li><li>JVM最大内存设置不要超过系统物理内存的一半，需要确保给内核文件系统缓存留有足够的物理内存</li><li>上限不要超过32GB</li><li>26G是一个非常合理设置</li></ul><h3 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h3><p>当文件描述符不足时，造成的后果将会是灾难性的，可以造成数据的丢失。</p><p>这个的配置在/etc/security/limits.conf配置文件中，参数是nofile，建议配置&gt;=65536</p><p>确保为启动es服务的用户设置的值&gt;=65536</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ cat /etc/security/limits.conf</span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 65536</span><br></pre></td></tr></table></figure><p>可以不需要登录服务器，通过以下接口获取当前的配置值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _nodes/stats/process?filter_path=**.max_file_descriptors</span><br></pre></td></tr></table></figure><h3 id="关闭swap"><a href="#关闭swap" class="headerlink" title="关闭swap"></a>关闭swap</h3><p>这部分在es的配置讲解部分（bootstrap.memory_lock部分）记录了</p><h3 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h3><p>和ES使用内存映射系统有关，需要我们优化内核参数</p><p>默认值为262144</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ sysctl  -a | grep vm.max_map_count</span><br><span class="line">vm.max_map_count = 262144</span><br></pre></td></tr></table></figure><p>建议配置为&gt;=655360</p><ul><li><p>临时生效，执行命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w vm.max_map_count=655360</span><br></pre></td></tr></table></figure></li><li><p>永久生效，也就是系统重启后还生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;vm.max_map_count = 655360&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure></li></ul><h3 id="最大线程数"><a href="#最大线程数" class="headerlink" title="最大线程数"></a>最大线程数</h3><p>其实也就是最大进程数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ cat /etc/security/limits.d/90-nproc.conf</span><br><span class="line">*       soft    nproc   65536</span><br><span class="line">*       hard    nproc   65536</span><br></pre></td></tr></table></figure><p>注意：如果设置为所有用户生效，则需要修改90-nproc.conf配置文件，如果是指定某个用户生效，则修改/etc/security/limits.conf即可，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 logs]$ cat /etc/security/limits.conf</span><br><span class="line">elk       soft    nproc   65536</span><br><span class="line">elk       hard    nproc   65536</span><br></pre></td></tr></table></figure><h2 id="ES集群部署"><a href="#ES集群部署" class="headerlink" title="ES集群部署"></a>ES集群部署</h2><h3 id="ES集群配置"><a href="#ES集群配置" class="headerlink" title="ES集群配置"></a>ES集群配置</h3><p>在使用最简化的3节点时，master和data参数都设置为true</p><p>下面以一个节点的配置为例，每个节点上的配置基本相同，就只有监听的ip不一致。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> cluster.name: testelk</span><br><span class="line">http.port: 9500</span><br><span class="line">transport.tcp.port: 9600-9700</span><br><span class="line">path:</span><br><span class="line"> logs: /home/elk/logs-5.3.0</span><br><span class="line"> data: /home/elk/data-5.3.0</span><br><span class="line">node.master: true</span><br><span class="line">node.data: true</span><br><span class="line">node.name: node001</span><br><span class="line">network.host: 192.168.100.113</span><br><span class="line">bootstrap.memory_lock: true</span><br><span class="line">discovery.zen.ping.unicast.hosts: [&quot;192.168.100.113&quot;, &quot;192.168.101.172&quot;, &quot;192.168.103.133&quot;]</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">transport.tcp.compress: true</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br><span class="line">thread_pool:</span><br><span class="line">  search:</span><br><span class="line">    size: 200</span><br><span class="line">    queue_size: 2000</span><br><span class="line">  bulk:</span><br><span class="line">    queue_size: 2000</span><br></pre></td></tr></table></figure><h3 id="kibana配置"><a href="#kibana配置" class="headerlink" title="kibana配置"></a>kibana配置</h3><h2 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h2><p>mapping的作用是定义document，包括：</p><ul><li>包含哪些字段</li><li>哪些字段需要存储</li><li>哪些字段能被索引</li></ul><p>例如：</p><ul><li>哪一个字符串字段被定义为full text fields</li><li>哪个字段包含数字、日志、地理位置</li><li>是否所有的字段都能被索引(通过<code>_all</code>参数)</li><li>日期格式</li><li>自定义规则</li></ul><p>每一个索引拥有一个或者多个的mapping type，这些mapping通常用于区分不同逻辑组的document，例如：用户相关的document通常type设置为user，博客相关的document通常type设置为blog。每一个type可以定义一个mapping</p><h3 id="mapping-type"><a href="#mapping-type" class="headerlink" title="mapping type"></a>mapping type</h3><p>每一个mapping类型都会有以下的字段：</p><ul><li><p>元类型字段</p><p>mapping的元类型字段，主要是作用于定义document的元字段，例如：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-index-field.html" target="_blank" rel="noopener"><code>_index</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-type-field.html" target="_blank" rel="noopener"><code>_type</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-id-field.html" target="_blank" rel="noopener"><code>_id</code></a>, and <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/mapping-source-field.html" target="_blank" rel="noopener"><code>_source</code></a> fields.</p></li><li><p>字段或者自定义属性</p><p>每一个mapping类型都包含一组字段。例如user type包含<code>title</code>, <code>name</code>, and <code>age</code> fields，a <code>blogpost</code> type might contain <code>title</code>, <code>body</code>, <code>user_id</code>and <code>created</code> fields</p></li></ul><p>注意：在一个索引中，两个不同的type中如果有一个同名的字段，那么这个字段必须使用相同的mapping</p><h3 id="字段数据类型"><a href="#字段数据类型" class="headerlink" title="字段数据类型"></a>字段数据类型</h3><p>有以下数据类型可以供字段选择</p><ul><li>基础类型：like text, keyword, date, long, double, boolean or ip.</li><li>json类型： object or nested.</li><li>专门的类型：like geo_point, geo_shape, or completion.</li></ul><h3 id="动态mapping"><a href="#动态mapping" class="headerlink" title="动态mapping"></a>动态mapping</h3><p>mapping type以及具体的字段在使用的时候，可以不需要提前指定配置，而是可以动态自动生成。</p><p>自动发现并且给字段添加相对应的类型我们称之为：”<em>dynamic mapping</em>“</p><p>动态mapping规则可以根据你的需求进行下自定义，有以下几种：</p><ul><li><p><code>_default_</code> mapping</p><p>为新的mapping配置基础的mapping配置。相当于是继承关系</p></li><li><p>Dynamic field mappings</p><p>这个规则管理动态字段发现</p></li><li><p>Dynamic templates</p><p>动态添加字段</p></li></ul><h4 id="default-mapping"><a href="#default-mapping" class="headerlink" title="_default_ mapping"></a><code>_default_</code> mapping</h4><p>default mapping的作用是定义一些全局的配置，在后续的多个mapping定义的时候如果没有手动的指定这个配置，那么会继承这个默认配置。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_default_&quot;: &#123; </span><br><span class="line">      &quot;_all&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;user&quot;: &#123;&#125;, </span><br><span class="line">    &quot;blogpost&quot;: &#123; </span><br><span class="line">      &quot;_all&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: true</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>设置全局的配置：将_all字段的标志位设置为false</p><ul><li>user这个type的mapping将会继承这个配置</li><li>blogpost这个type的mapping将会重写这个配置为true</li></ul><p>注意：尽管这个配置可以在索引已经存在的情况下执行，但是执行之后只是影响后来生成的mapping。</p><p>同样的，这个功能也可以用于索引的模板中</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">PUT _template/logging</span><br><span class="line">&#123;</span><br><span class="line">  &quot;template&quot;:   &quot;logs-*&quot;, </span><br><span class="line">  &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 1 &#125;, </span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_default_&quot;: &#123;</span><br><span class="line">      &quot;_all&quot;: &#123; </span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;dynamic_templates&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;strings&quot;: &#123; </span><br><span class="line">            &quot;match_mapping_type&quot;: &quot;string&quot;,</span><br><span class="line">            &quot;mapping&quot;: &#123;</span><br><span class="line">              &quot;type&quot;: &quot;text&quot;,</span><br><span class="line">              &quot;fields&quot;: &#123;</span><br><span class="line">                &quot;raw&quot;: &#123;</span><br><span class="line">                  &quot;type&quot;:  &quot;keyword&quot;,</span><br><span class="line">                  &quot;ignore_above&quot;: 256</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">测试：</span><br><span class="line">PUT logs-2015.10.01/event/1</span><br><span class="line">&#123; &quot;message&quot;: &quot;error:16&quot; &#125;</span><br></pre></td></tr></table></figure><h3 id="明确mapping-Explicit-mappings"><a href="#明确mapping-Explicit-mappings" class="headerlink" title="明确mapping- Explicit mappings"></a>明确mapping- Explicit mappings</h3><p>实际情况下，我们会比es更了解我们的数据，因此，我们可以在创建索引的时候就定义好mapping</p><p>我们可以：</p><ul><li>在创建索引的时候，初始化定义mapping </li><li>当索引已存在时，可以新增字段</li></ul><p>注意：不能更新现有的mapping的字段，更新通过下面的方式</p><h3 id="更新已存在的mapping"><a href="#更新已存在的mapping" class="headerlink" title="更新已存在的mapping"></a>更新已存在的mapping</h3><p>已经存在的mapping中的字段是不能直接被update的，如果修改mapping则意味着现有索引中的document都会成为无效数据，因此，如果我们想要更新mapping：</p><ol><li>新建一个mapping</li><li>重建索引</li><li>reindex：索引数据迁移</li></ol><h3 id="字段共享mapping"><a href="#字段共享mapping" class="headerlink" title="字段共享mapping"></a>字段共享mapping</h3><p>不同的mapping通常用于划分和组织字段组，但是以下的这些字段不会只作用于单个mapping局部</p><ul><li>字段的名称相同</li><li>位于同一个索引中</li><li>在不同的mapping  type中</li><li>mapping内部有相同的字段</li><li>必须拥有相同的mapping</li></ul><p>举例说明：</p><blockquote><p>如果title字段同时存在于user和blogpost这两个mapping type中，那么这个字段在两个mapping type中就必须保持一致的mapping</p><p>但是存在这些例外，直接看官方原文即可：</p><p>The only exceptions to this rule are the <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/copy-to.html" target="_blank" rel="noopener"><code>copy_to</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/dynamic.html" target="_blank" rel="noopener"><code>dynamic</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/enabled.html" target="_blank" rel="noopener"><code>enabled</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/ignore-above.html" target="_blank" rel="noopener"><code>ignore_above</code></a>, <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/include-in-all.html" target="_blank" rel="noopener"><code>include_in_all</code></a>, and <a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/properties.html" target="_blank" rel="noopener"><code>properties</code></a> parameters, which may have different settings per field.</p></blockquote><h3 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h3><p>下面是一个案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index </span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;user&quot;: &#123; </span><br><span class="line">      &quot;_all&quot;:       &#123; &quot;enabled&quot;: false  &#125;, </span><br><span class="line">      &quot;properties&quot;: &#123; </span><br><span class="line">        &quot;title&quot;:    &#123; &quot;type&quot;: &quot;text&quot;  &#125;, </span><br><span class="line">        &quot;name&quot;:     &#123; &quot;type&quot;: &quot;text&quot;  &#125;, </span><br><span class="line">        &quot;age&quot;:      &#123; &quot;type&quot;: &quot;integer&quot; &#125;  </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;blogpost&quot;: &#123; </span><br><span class="line">      &quot;_all&quot;:       &#123; &quot;enabled&quot;: false  &#125;, </span><br><span class="line">      &quot;properties&quot;: &#123; </span><br><span class="line">        &quot;title&quot;:    &#123; &quot;type&quot;: &quot;text&quot;  &#125;, </span><br><span class="line">        &quot;body&quot;:     &#123; &quot;type&quot;: &quot;text&quot;  &#125;, </span><br><span class="line">        &quot;user_id&quot;:  &#123;</span><br><span class="line">          &quot;type&quot;:   &quot;keyword&quot; </span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;created&quot;:  &#123;</span><br><span class="line">          &quot;type&quot;:   &quot;date&quot;, </span><br><span class="line">          &quot;format&quot;: &quot;strict_date_optional_time||epoch_millis&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="元数据类型字段"><a href="#元数据类型字段" class="headerlink" title="元数据类型字段"></a>元数据类型字段</h3><h3 id="字段数据类型-1"><a href="#字段数据类型-1" class="headerlink" title="字段数据类型"></a>字段数据类型</h3><h4 id="keyword数据类型"><a href="#keyword数据类型" class="headerlink" title="keyword数据类型"></a>keyword数据类型</h4><p>这个数据类型适用于例如：</p><ul><li>email addresses  email地址</li><li>Hostnames 主机名</li><li>Status code  状态码</li><li>zip codes  编码</li><li>tags  指定的标志</li></ul><p>这种数据类型，主要的作用是过滤功能(例如博客文章中可以通过status为<em>published</em>已发布的来进行过滤)、sort排序功能、以及聚合。</p><p>keyword是唯一一种类型：他们的值可以被检索</p><p>下面是一个例子：创建索引的实时设定mapping，mapping中包含一个字段属性，其类型为keyword</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;my_type&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;tags&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;keyword&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>keyword中有以下这些参数，需要重点关注一下：</p><ul><li><p>ignore_above</p><blockquote><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/ignore-above.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/ignore-above.html</a></p></blockquote></li></ul><h4 id="Text数据类型"><a href="#Text数据类型" class="headerlink" title="Text数据类型"></a>Text数据类型</h4><p>顾名思义，这个数据类型主要是作用于例如：邮件内容、产品描述信息等不规则的并且数据量较大的文本内容。</p><p>案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;my_type&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;full_name&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="二级字段类型-fields配置"><a href="#二级字段类型-fields配置" class="headerlink" title="二级字段类型-fields配置"></a>二级字段类型-fields配置</h3><p>参考连接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/multi-fields.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/multi-fields.html</a></p><h2 id="ES-API"><a href="#ES-API" class="headerlink" title="ES API"></a>ES API</h2><h3 id="API约定及惯例"><a href="#API约定及惯例" class="headerlink" title="API约定及惯例"></a>API约定及惯例</h3><h4 id="multiple-indices"><a href="#multiple-indices" class="headerlink" title="multiple indices"></a>multiple indices</h4><p>大部分涉及索引的api都支持匹配多个index操作,有如下这些方式实现</p><ul><li>多个索引：test1,test2,test3</li><li>所有索引：_all</li><li>通配符匹配：例如：<code>test*</code>、<code>*test</code> 、 <code>te*t</code> 、 <code>*test*</code></li><li>加减： “add” (<code>+</code>) and “remove” (<code>-</code>), for example: <code>+test*,-test3</code>.</li></ul><p>All multi indices API support the following url query string parameters:</p><p>使用这种方式的api都有一下参数</p><ul><li><p><strong>ignore_unavailable</strong></p><p>是否忽略不可用(不存在或者异常的)的索引，取值为true|false</p></li><li><p><strong>allow_no_indices</strong></p><p>控制当使用通配符匹配时，如果没有结果，是否返回fail。取值为true|false</p><p>不止针对通配符情况，也支持_all以及不指定任何index的情况</p><p>这个配置同样支持aliases</p></li><li><p><strong>expand_wildcards</strong></p><p>取值为open|closed|(open,closed)</p><p>控制通配符匹配到的索引，当设置为open时，将只会匹配到open的索引，也就是正常的索引，当设置为closed时，将只会匹配到closed的索引。</p><p>也可以设置为open+closed，以匹配所以的索引</p><p>注意：如果设置为none，这个功能将会被disable。如果设置为all，那么等价于open+closed</p></li></ul><p>注意：只作用于单个索引的api（例如document api等等），没有上面这些参数</p><h4 id="Date-math-support-in-index-names"><a href="#Date-math-support-in-index-names" class="headerlink" title="Date math support in index names"></a>Date math support in index names</h4><p>后续涉及时再进行补充。</p><h4 id="Common-option-1"><a href="#Common-option-1" class="headerlink" title="Common option"></a>Common option</h4><p>通用选项。</p><h4 id="URL-based-access-control"><a href="#URL-based-access-control" class="headerlink" title="URL-based access control"></a>URL-based access control</h4><p>后续补充</p><h3 id="Document-APIs"><a href="#Document-APIs" class="headerlink" title="Document APIs"></a>Document APIs</h3><h4 id="Reading-and-Writing-documents-读写document"><a href="#Reading-and-Writing-documents-读写document" class="headerlink" title="Reading and Writing documents-读写document"></a>Reading and Writing documents-读写document</h4><p>链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/docs-replication.html#_introduction" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/docs-replication.html#_introduction</a></p><p>每一个索引在ES中都会被分割成为shard分片，并且每一个shard都会有不等的copies副本。</p><p>当有多个副本的时候，这多个副本，我们就称之为<strong>replication group</strong>-副本组，当document有新增或者删除的时候，我们需要保证这个组中的每个副本的数据和分片是同步的，防止出现数据不一致的情况</p><p>保证分片和副本之间的数据同步的进程，我们称之为：<em>data replication model</em></p><h5 id="基础写模型-Basic-write-model"><a href="#基础写模型-Basic-write-model" class="headerlink" title="基础写模型- Basic write model"></a>基础写模型- Basic write model</h5><p>ES接收索引写请求，首先根据路由服务（根据document为处理依据），将请求转发给副本组。</p><p>副本组收到请求之后，这个请求将会被转发给副本组中的主分片(每个副本组中还会区分主从关系)，这个副本主分片转发请求给其他的副本，</p><p>主分片按照下面的流程处理：</p><ol><li>检验请求是否符合标准，拒绝无效的请求</li><li>在本地执行这个操作(写document的操作)</li><li>转发这个请求给所有的副本，这个过程是同步的，而不是异步</li><li>一旦所有的副本都执行完毕，并且返回结构给主分片，主分片返回ack给客户端。</li></ol><h5 id="写失败处理"><a href="#写失败处理" class="headerlink" title="写失败处理"></a>写失败处理</h5><p>暂时略</p><h5 id="基础读模型"><a href="#基础读模型" class="headerlink" title="基础读模型"></a>基础读模型</h5><p>读操作的时候，可以是非常轻量级的根据document的id进行，也可以是非常重的请求(非常复杂的聚合条件)</p><p>当一个node节点接收到一个读请求时，这个node负责转发这个请求给具有相关分片的node，并且收集响应，然后返回给客户端，我们称这样的node为坐标node(<em>coordinating node</em>)</p><p>这个node的基本的工作流为：</p><ul><li>解析请求，获取这个请求涉及哪些分片，因为很多读请求会涉及到多个索引，他们也就需要读取到多个分片</li><li>从对应分片的副本组中选择一个活跃状态的副本，这个副本可以使主或者从角色，默认情况下，es会轮询调度到这些副本</li><li>发送请求到这个指定的副本</li><li>坐标node，汇总所有副本返回的结果，然后响应客户端。</li></ul><h5 id="读失败处理"><a href="#读失败处理" class="headerlink" title="读失败处理"></a>读失败处理</h5><p>暂时略</p><h4 id="新建document"><a href="#新建document" class="headerlink" title="新建document"></a>新建document</h4><p>案例：</p><p>新建一个document</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT twitter/tweet/1</span><br><span class="line">&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行之后，es的响应返回为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;_shards&quot; : &#123;</span><br><span class="line">        &quot;total&quot; : 3,</span><br><span class="line">        &quot;failed&quot; : 0,</span><br><span class="line">        &quot;successful&quot; : 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;_index&quot; : &quot;twitter&quot;,</span><br><span class="line">    &quot;_type&quot; : &quot;tweet&quot;,</span><br><span class="line">    &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">    &quot;_version&quot; : 1,</span><br><span class="line">    &quot;created&quot; : true,</span><br><span class="line">    &quot;result&quot; : created</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为，这个索引之前在创建的时候设置为3个分片，所以这里的shard为3，_shards这一个块展示的是复制过程相关的结果信息，success表示所有的副本都是成功状态的。</p><p>分片数量可以根据索引相关的接口的进行查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[elk@node003 ~]$ curl http://192.168.103.133:9500/_cat/indices?v</span><br><span class="line">health status index           uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">green  open   twitter         2Gxyl8acRa222-gdYhE4ig   3   2          1            0     14.1kb          4.7kb</span><br><span class="line">green  open   .kibana         JjZFr5NvTXSOUv6DjwyF0w   1   1          1            0      6.3kb          3.1kb</span><br><span class="line">green  open   logs-2015.10.01 Ubo73cz5RRO4ipU33zdCqQ   1   1          0            0       318b           159b</span><br></pre></td></tr></table></figure><p>不手动指定id，使用自动增长的序列号(注意使用POST代替PUT)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST twitter/tweet/</span><br><span class="line">&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>返回结果为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;twitter&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;tweet&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;AWu2sgI5Rw8iDPJNYgMY&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;result&quot; : &quot;created&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 3,</span><br><span class="line">    &quot;successful&quot; : 3,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，document的为：AWu2sgI5Rw8iDPJNYgMY</p><h4 id="查询document"><a href="#查询document" class="headerlink" title="查询document"></a>查询document</h4><p>根据document的id进行查询</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/tweet/0</span><br><span class="line"></span><br><span class="line">[elk@node003 ~]$ curl http://192.168.103.133:9500/twitter/tweet/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;twitter&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;tweet&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="删除document"><a href="#删除document" class="headerlink" title="删除document"></a>删除document</h4><p>基础document的id进行删除</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">格式例如：curl -XDELETE &apos;http://localhost:9200/twitter/tweet/1&apos;</span><br></pre></td></tr></table></figure><h3 id="Indices-APIs-索引api"><a href="#Indices-APIs-索引api" class="headerlink" title="Indices APIs-索引api"></a>Indices APIs-索引api</h3><h4 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a><strong>创建索引</strong></h4><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">PUT twitter</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;index&quot; : &#123;</span><br><span class="line">            &quot;number_of_shards&quot; : 3, </span><br><span class="line">            &quot;number_of_replicas&quot; : 2 </span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">或者可以省略index</span><br><span class="line">PUT twitter</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : 3,</span><br><span class="line">        &quot;number_of_replicas&quot; : 2</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建索引并指定mapping</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">PUT test</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot; : &#123;</span><br><span class="line">        &quot;number_of_shards&quot; : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;mappings&quot; : &#123;</span><br><span class="line">        &quot;type1&quot; : &#123;</span><br><span class="line">            &quot;properties&quot; : &#123;</span><br><span class="line">                &quot;field1&quot; : &#123; &quot;type&quot; : &quot;text&quot; &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建索引并设置alias</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">PUT test</span><br><span class="line">&#123;</span><br><span class="line">    &quot;aliases&quot; : &#123;</span><br><span class="line">        &quot;alias_1&quot; : &#123;&#125;,</span><br><span class="line">        &quot;alias_2&quot; : &#123;</span><br><span class="line">            &quot;filter&quot; : &#123;</span><br><span class="line">                &quot;term&quot; : &#123;&quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">            &#125;,</span><br><span class="line">            &quot;routing&quot; : &quot;kimchy&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a><strong>删除索引</strong></h4><p>执行下面的接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /twitter</span><br></pre></td></tr></table></figure><p>索引可以是：</p><ul><li>单个索引</li><li>_all 所有索引</li><li>通配符表达式，例如添加*等</li></ul><p>因为可以批量的删除，所以存在一定的风险，当我们希望关闭这个功能的时候，设置action.destructive_requires_name的值为true。这个配置也可以在集群运行过程中被修改。</p><h4 id="查看索引"><a href="#查看索引" class="headerlink" title="查看索引"></a><strong>查看索引</strong></h4><p>接口为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET twitter</span><br></pre></td></tr></table></figure><p>查看twitter索引，注意可以使用通配符、alias、_all等匹配多个索引</p><p>过滤索引的特殊配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GET twitter/_settings</span><br><span class="line">GET twitter/_mappings</span><br><span class="line">GET twitter/_aliases</span><br></pre></td></tr></table></figure><h4 id="索引是否存在"><a href="#索引是否存在" class="headerlink" title="索引是否存在"></a><strong>索引是否存在</strong></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HEAD twitter</span><br></pre></td></tr></table></figure><p>接口返回404为不存在，200则为存在。</p><h4 id="put-mapping-mapping的新增"><a href="#put-mapping-mapping的新增" class="headerlink" title="put mapping-mapping的新增"></a><strong>put mapping-mapping的新增</strong></h4><p>我们可以实现：</p><ul><li><p>在现有的索引上新增type的mapping</p></li><li><p>创建索引时指定mapping</p></li><li>在现有的mapping基础上新增字段</li></ul><p>案例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"># 创建索引时指定mapping</span><br><span class="line">PUT twitter </span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;tweet&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;message&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;text&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 在现有索引上新增mapping type</span><br><span class="line">PUT twitter/_mapping/user </span><br><span class="line">&#123;</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;name&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: &quot;text&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 现有mapping上新增字段</span><br><span class="line">PUT twitter/_mapping/tweet </span><br><span class="line">&#123;</span><br><span class="line">  &quot;properties&quot;: &#123;</span><br><span class="line">    &quot;user_name&quot;: &#123;</span><br><span class="line">      &quot;type&quot;: &quot;text&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="get-mapping"><a href="#get-mapping" class="headerlink" title="get mapping"></a><strong>get mapping</strong></h4><p>语法格式为：host:port/{index}/_mapping/{type}</p><p>案例为:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GET /_mapping/tweet,kimchy</span><br><span class="line">=</span><br><span class="line">GET /_all/_mapping/tweet,book</span><br><span class="line"></span><br><span class="line">GET /_all/_mapping</span><br><span class="line">=</span><br><span class="line">GET /_mapping</span><br></pre></td></tr></table></figure><h4 id="获取具体字段的mapping"><a href="#获取具体字段的mapping" class="headerlink" title="获取具体字段的mapping"></a><strong>获取具体字段的mapping</strong></h4><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/_mapping/tweet/field/field1,field2,...</span><br></pre></td></tr></table></figure><h4 id="判断mapping-type是否存在"><a href="#判断mapping-type是否存在" class="headerlink" title="判断mapping type是否存在"></a><strong>判断mapping type是否存在</strong></h4><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HEAD twitter/_mapping/tweet</span><br></pre></td></tr></table></figure><p>返回值为404或者200</p><h4 id="索引别名-index-aliases"><a href="#索引别名-index-aliases" class="headerlink" title="索引别名-index aliases"></a><strong>索引别名-index aliases</strong></h4><p>索引别名允许给索引重新定义一个名称，当在调用这个alias的时候，es会自动的把这个alias转换为真实的index,</p><p>一个alias可以被映射到多个index上，</p><p>添加alias:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;test1&quot;, &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;,</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;test2&quot;, &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">或者</span><br><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;indices&quot; : [&quot;test1&quot;, &quot;test2&quot;], &quot;alias&quot; : &quot;alias1&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">或者</span><br><span class="line">POST /_aliases</span><br><span class="line">&#123;</span><br><span class="line">    &quot;actions&quot; : [</span><br><span class="line">        &#123; &quot;add&quot; : &#123; &quot;index&quot; : &quot;test*&quot;, &quot;alias&quot; : &quot;all_test_indices&quot; &#125; &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="获取索引alias"><a href="#获取索引alias" class="headerlink" title="获取索引alias"></a><strong>获取索引alias</strong></h4><p>语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">语法格式：/&#123;index&#125;/_alias/&#123;alias&#125;</span><br><span class="line">例如：GET /logs_20162801/_alias/*</span><br></pre></td></tr></table></figure><p>在所有index中搜索alias为2016</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_alias/2016</span><br></pre></td></tr></table></figure><p>下面的方式可以检查alias是否存在：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HEAD /_alias/2016</span><br><span class="line">HEAD /_alias/20*</span><br><span class="line">HEAD /logs_20162801/_alias/*</span><br></pre></td></tr></table></figure><h4 id="索引模板"><a href="#索引模板" class="headerlink" title="索引模板"></a><strong>索引模板</strong></h4><p>作用：新建的index能够继承这一套的配置</p><p>模板中包括setting、mapping等配置，以及控制哪些index可以继承这个模板配置。</p><p>例如：</p><p>新建索引模板：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">PUT _template/template_1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;template&quot;: &quot;te*&quot;,</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;number_of_shards&quot;: 1</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;type1&quot;: &#123;</span><br><span class="line">      &quot;_source&quot;: &#123;</span><br><span class="line">        &quot;enabled&quot;: false</span><br><span class="line">      &#125;,</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;host_name&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;created_at&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">          &quot;format&quot;: &quot;EEE MMM dd HH:mm:ss Z YYYY&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个生产案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">PUT _template/realtime_baobei_order</span><br><span class="line">&#123;</span><br><span class="line">  &quot;order&quot;: 0,</span><br><span class="line">  &quot;template&quot;: &quot;realtime_baobei_order-*&quot;,</span><br><span class="line">  &quot;settings&quot;: &#123;</span><br><span class="line">    &quot;index&quot;: &#123;</span><br><span class="line">        &quot;max_result_window&quot;: &quot;30000&quot;,</span><br><span class="line">        &quot;codec&quot;: &quot;best_compression&quot;,</span><br><span class="line">        &quot;refresh_interval&quot;: &quot;-1&quot;,</span><br><span class="line">        &quot;number_of_shards&quot;: &quot;6&quot;,</span><br><span class="line">        &quot;number_of_replicas&quot;: &quot;0&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;aliases&quot;: &#123;&#125;,</span><br><span class="line">    &quot;mappings&quot;: &#123;</span><br><span class="line">      &quot;order&quot;:&#123;</span><br><span class="line">        &quot;properties&quot;: &#123;</span><br><span class="line">            &quot;cancel_reason&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;cook_tm&quot;: &#123;</span><br><span class="line">          &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">          &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;customer_name&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;customer_tel&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;expect_send_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;finish_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;food_agg&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;join_expire_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;leave_shop_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;location_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;location_name&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;order_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;package_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;pay_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;place_tm&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;date&quot;,</span><br><span class="line">            &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;pt&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;remark&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;serial_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_1&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_2&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_4&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_5&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_6&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_7&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_998&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;settment_cost_999&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;float&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;shop_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;shop_name&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;shop_tel&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;keyword&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;status&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">          &quot;user_id&quot;: &#123;</span><br><span class="line">            &quot;type&quot;: &quot;long&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p>删除索引模板：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DELETE /_template/template_1</span><br></pre></td></tr></table></figure><p>查看索引模板信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GET /_template/template_1</span><br><span class="line">GET /_template/temp*</span><br><span class="line">GET /_template/template_1,template_2</span><br><span class="line">获取所有的模板：</span><br><span class="line">GET /_template</span><br></pre></td></tr></table></figure><p>判断索引模板是否存在：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HEAD _template/template_1</span><br></pre></td></tr></table></figure><h4 id="索引状态"><a href="#索引状态" class="headerlink" title="索引状态"></a><strong>索引状态</strong></h4><p>语法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 查看所有的索引的状态</span><br><span class="line">GET /_stats</span><br><span class="line"></span><br><span class="line"># 查看指定索引的状态</span><br><span class="line">GET /index1,index2/_stats</span><br></pre></td></tr></table></figure><h4 id="refresh"><a href="#refresh" class="headerlink" title="refresh"></a><strong>refresh</strong></h4><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 刷新一个index</span><br><span class="line">POST /twitter/_refresh</span><br><span class="line"># 刷新多个index</span><br><span class="line">POST /kimchy,elasticsearch/_refresh</span><br><span class="line"># 刷新所有的index</span><br><span class="line">POST /_refresh</span><br></pre></td></tr></table></figure><h3 id="cat-apis"><a href="#cat-apis" class="headerlink" title="cat apis"></a>cat apis</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>尽管json格式是一种非常好的数据格式，但是在shh终端上，不利于人类的可读，在终端界面，我们需要线性的显示。那么cat api就是干这个的，它可以把输出转换为方便人类查看的格式</p><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h4><p>在cat api中，支持一下参数</p><ul><li><p>verbose。输出全量信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 无参数</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/master</span><br><span class="line">Mb1156xHRuSYgSZ3RG1n8Q 192.168.101.172 192.168.101.172 node002</span><br><span class="line"></span><br><span class="line"># 有参数</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/master?v</span><br><span class="line">id                     host            ip              node</span><br><span class="line">Mb1156xHRuSYgSZ3RG1n8Q 192.168.101.172 192.168.101.172 node002</span><br></pre></td></tr></table></figure></li><li><p>help，每一个方法都可以使用help查看可以获得哪些输出信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/master?help</span><br><span class="line">id   |   | node id</span><br><span class="line">host | h | host name</span><br><span class="line">ip   |   | ip address</span><br><span class="line">node | n | node name</span><br></pre></td></tr></table></figure></li><li><p>Headers，可以指定要输出的字段，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># 获取支持的字段信息</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/nodes?help</span><br><span class="line"></span><br><span class="line"># 默认的全量输出</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/nodes?v</span><br><span class="line">ip              heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name</span><br><span class="line">192.168.103.133           12          97   0    0.39    0.37     0.26 mdi       -      node003</span><br><span class="line">192.168.100.113           12          96   0    0.16    0.29     0.22 mdi       -      node001</span><br><span class="line">192.168.101.172           14          96   1    0.40    0.37     0.25 mdi       *      node002</span><br><span class="line"></span><br><span class="line"># 指定字段输出</span><br><span class="line">[elk@node003 bin]$ curl http://192.168.103.133:9500/_cat/nodes?h=ip,port,heapPercent,name</span><br><span class="line">192.168.103.133 9600 12 node003</span><br><span class="line">192.168.100.113 9600 12 node001</span><br><span class="line">192.168.101.172 9600 14 node002</span><br></pre></td></tr></table></figure></li></ul><h4 id="具体接口"><a href="#具体接口" class="headerlink" title="具体接口"></a>具体接口</h4><p>链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/cat.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/cat.html</a></p><h3 id="ES常用API"><a href="#ES常用API" class="headerlink" title="ES常用API"></a>ES常用API</h3><ul><li><p>集群健康状态：GET /_cat/health?v</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl http://127.0.0.1:9200/_cat/health?v</span><br><span class="line">epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent</span><br><span class="line">1561023164 17:32:44  elasticsearch green           1         1      0   0    0    0        0             0                  -                100.0%</span><br></pre></td></tr></table></figure></li><li><p>集群节点：GET /_cat/nodes?v</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl http://127.0.0.1:9200/_cat/nodes?v</span><br><span class="line">ip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name</span><br><span class="line">127.0.0.1           10          96   0    0.00    0.06     0.08 mdi       *      Jd3JKT1</span><br></pre></td></tr></table></figure></li><li><p>创建索引：PUT /customer?pretty</p></li><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl -X PUT  http://127.0.0.1:9200/customer?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot; : true,</span><br><span class="line">  &quot;shards_acknowledged&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>查看所有的索引：GET /_cat/indices?v</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[elk@node001 ~]$ curl -X GET http://127.0.0.1:9200/_cat/indices?v</span><br><span class="line">health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size</span><br><span class="line">yellow open   customer cDDJVvowS-uZs0um21huWw   5   1          0            0       650b           650b</span><br></pre></td></tr></table></figure></li><li><p>传输document到index中：PUT /customer/external/1?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# curl -X PUT http://127.0.0.1:9200/customer/external/1?pretty -d &apos;&#123;&quot;name&quot;:&quot;John Doe&quot;&#125;&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;result&quot; : &quot;created&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot; : true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：customer是index索引，external是type，1是id。POST方式是自增id，put方式必须要加上id。</p><p>这个操作，相当于是给这个索引新增一行数据</p></li><li><p>查看document：/customer/external/1?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# curl -X GET http://127.0.0.1:9200/customer/external/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 1,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;name&quot; : &quot;John Doe&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查看id为1的document的具体内容</p></li><li><p>删除索引：DELETE /customer?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# curl -X DELETE  http://127.0.0.1:9200/customer?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;acknowledged&quot; : true</span><br><span class="line">&#125;</span><br><span class="line">[root@node001 ~]# curl -X GET http://127.0.0.1:9200/_cat/indices?v</span><br><span class="line">health status index uuid pri rep docs.count docs.deleted store.size pri.store.size</span><br></pre></td></tr></table></figure><p>注意：上面这些接口路径中的?pretty均可以省略，这个的作用只是为了显示美观，没有实际意义。</p></li><li><p>更新document：POST /customer/external/1/_update?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]# curl -X POST  http://127.0.0.1:9200/customer/external/1?pretty -d &apos;&#123;&quot;doc&quot;:&quot;John Doe&quot;&#125;&apos;</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 2,</span><br><span class="line">  &quot;result&quot; : &quot;updated&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;created&quot; : false</span><br><span class="line">&#125;</span><br><span class="line">[root@node001 ~]#  curl -X GET http://127.0.0.1:9200/customer/external/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 2,</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_source&quot; : &#123;</span><br><span class="line">    &quot;doc&quot; : &quot;John Doe&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：这里所说的更新操作，实际上在ES内部部署更新替换，而是删除之后再重新创建</p></li><li><p>删除document：DELETE /customer/external/2?pretty</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 ~]#  curl -X DELETE http://127.0.0.1:9200/customer/external/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;found&quot; : true,</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;_version&quot; : 6,</span><br><span class="line">  &quot;result&quot; : &quot;deleted&quot;,</span><br><span class="line">  &quot;_shards&quot; : &#123;</span><br><span class="line">    &quot;total&quot; : 2,</span><br><span class="line">    &quot;successful&quot; : 1,</span><br><span class="line">    &quot;failed&quot; : 0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">[root@node001 ~]#  curl -X GET http://127.0.0.1:9200/customer/external/1?pretty</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_index&quot; : &quot;customer&quot;,</span><br><span class="line">  &quot;_type&quot; : &quot;external&quot;,</span><br><span class="line">  &quot;_id&quot; : &quot;1&quot;,</span><br><span class="line">  &quot;found&quot; : false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>查看node上有哪些shard</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://172.16.1.129:9500/_cat/shards|  grep node004</span><br></pre></td></tr></table></figure></li><li><p>关闭打开索引</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">关闭：curl -XPOST localhost:9200/xxx_indices/_close</span><br><span class="line">打开：</span><br></pre></td></tr></table></figure></li><li><p>关闭集群的reroute-(有新节点新增之后，不要立马挪动shards)</p><p>这里是控制集群中的shard的移动，一般是在新增节点之后，如果不想马上就进行shards的挪动，那么可以暂停这个功能</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;persistent&quot;: &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">如果想取消，那么设置为null即可。</span><br></pre></td></tr></table></figure></li><li><p>集群统计信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET _cluster/stats</span><br></pre></td></tr></table></figure><p>包括索引数量、shard的数量、主、副shard的比例等等、docs的数量、存储使用量、插件情况</p></li><li><p>cluster reroute</p><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/cluster-reroute.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.3/cluster-reroute.html</a></p><p>主要是涉及集群的一些内部路由，主要是shards分片的移动（move）、重新分片未分配的副本分片（allocate_replica）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST /_cluster/reroute</span><br><span class="line">&#123;</span><br><span class="line">    &quot;commands&quot; : [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;move&quot; : &#123;</span><br><span class="line">                &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 0,</span><br><span class="line">                &quot;from_node&quot; : &quot;node1&quot;, &quot;to_node&quot; : &quot;node2&quot;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;allocate_replica&quot; : &#123;</span><br><span class="line">                &quot;index&quot; : &quot;test&quot;, &quot;shard&quot; : 1,</span><br><span class="line">                &quot;node&quot; : &quot;node3&quot;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>修改副本分片数量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT applog-prod-2016.12.18/_settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;index&quot;:&#123;</span><br><span class="line">    &quot;number_of_replicas&quot;:0</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>查看每个node上的task</p><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.3/tasks.html#_current_tasks_information" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.3/tasks.html#_current_tasks_information</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GET _tasks </span><br><span class="line">GET _tasks?nodes=nodeId1,nodeId2 </span><br><span class="line">GET _tasks?nodes=nodeId1,nodeId2&amp;actions=cluster:*</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>cluster allocation explain API</p><p>集群内部分配相关的解释api，可以解释未分配shard的原因等等，在诊断shard问题的时候非常有用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> </span><br></pre></td></tr></table></figure></li></ul><h3 id="Search-api"><a href="#Search-api" class="headerlink" title="Search api"></a>Search api</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/_the_search_api.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/_the_search_api.html</a></p><p>ES检索相关-【这部分相当重要】</p><p>这个api允许你执行一些查询请求，</p><h4 id="参数形式"><a href="#参数形式" class="headerlink" title="参数形式"></a>参数形式</h4><p>查找twitter索引下的tweet,user这2个type中user为kimchy的document</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/tweet,user/_search?q=user:kimchy</span><br><span class="line">实际执行为：</span><br><span class="line"></span><br><span class="line">[elk@node003 ~]$ curl http://192.168.103.133:9500/twitter/tweet,user/_search?q=user:kimchy</span><br><span class="line">&#123;&quot;took&quot;:31,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:3,&quot;successful&quot;:3,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:3,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;AWu2sYdrRw8iDPJNYgMX&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;,&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;AWu2sgI5Rw8iDPJNYgMY&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;,&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;]&#125;&#125;[elk@node003 ~]$</span><br></pre></td></tr></table></figure><p>查找所有索引中type为tweet的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_all/tweet/_search?q=tag:wow</span><br></pre></td></tr></table></figure><p>查找所有索引所有type</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_search?q=tag:wow</span><br></pre></td></tr></table></figure><h4 id="请求体形式"><a href="#请求体形式" class="headerlink" title="请求体形式"></a>请求体形式</h4><p>除了上面的在url请求中携带参数去search，es还支持在get请求使用body的方式</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GET /twitter/tweet/_search</span><br><span class="line">&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行后的输出和上面是一致的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[elk@node003 ~]$ curl -XGET http://192.168.103.133:9500/twitter/tweet/_search -d &apos;&#123;</span><br><span class="line">    &quot;query&quot; : &#123;</span><br><span class="line">        &quot;term&quot; : &#123; &quot;user&quot; : &quot;kimchy&quot; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;&apos;</span><br><span class="line">&#123;&quot;took&quot;:48,&quot;timed_out&quot;:false,&quot;_shards&quot;:&#123;&quot;total&quot;:3,&quot;successful&quot;:3,&quot;failed&quot;:0&#125;,&quot;hits&quot;:&#123;&quot;total&quot;:3,&quot;max_score&quot;:0.2876821,&quot;hits&quot;:[&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;AWu2sYdrRw8iDPJNYgMX&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;,&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;AWu2sgI5Rw8iDPJNYgMY&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;,&#123;&quot;_index&quot;:&quot;twitter&quot;,&quot;_type&quot;:&quot;tweet&quot;,&quot;_id&quot;:&quot;1&quot;,&quot;_score&quot;:0.2876821,&quot;_source&quot;:&#123;</span><br><span class="line">    &quot;user&quot; : &quot;kimchy&quot;,</span><br><span class="line">    &quot;post_date&quot; : &quot;2009-11-15T14:12:12&quot;,</span><br><span class="line">    &quot;message&quot; : &quot;trying out Elasticsearch&quot;</span><br><span class="line">&#125;&#125;]&#125;&#125;[elk@node003 ~]$</span><br></pre></td></tr></table></figure><h4 id="count"><a href="#count" class="headerlink" title="count"></a>count</h4><p>只获取搜索结果的条数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[elk@node003 ~]$ curl http://192.168.103.133:9500/twitter/tweet/_count?q=user:kimchy</span><br><span class="line">&#123;&quot;count&quot;:3,&quot;_shards&quot;:&#123;&quot;total&quot;:3,&quot;successful&quot;:3,&quot;failed&quot;:0&#125;&#125;[elk@node003 ~]$</span><br></pre></td></tr></table></figure><h3 id="Cluster-api-集群api"><a href="#Cluster-api-集群api" class="headerlink" title="Cluster api-集群api"></a>Cluster api-集群api</h3><h2 id="Analyis-分词"><a href="#Analyis-分词" class="headerlink" title="Analyis-分词"></a>Analyis-分词</h2><p>在安装完插件之后，如果不确定插件的名称，可以通过这个接口查看信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GET /_nodes</span><br><span class="line"># 插件部分的内容</span><br><span class="line">      &quot;plugins&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;name&quot;: &quot;analysis-ik&quot;,</span><br><span class="line">          &quot;version&quot;: &quot;5.1.2&quot;,</span><br><span class="line">          &quot;description&quot;: &quot;IK Analyzer for Elasticsearch&quot;,</span><br><span class="line">          &quot;classname&quot;: &quot;org.elasticsearch.plugin.analysis.ik.AnalysisIkPlugin&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br></pre></td></tr></table></figure><h3 id="Ik分词器"><a href="#Ik分词器" class="headerlink" title="Ik分词器"></a>Ik分词器</h3><p>IK分词器，是一个针对中文的分词器。</p><p>IK分词器github项目地址：<a href="https://link.zhihu.com/?target=https%3A//github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">medcl/elasticsearch-analysis-ik</a></p><p>IK分词器有两种分词模式：ik_max_word和ik_smart模式。</p><ul><li><p>ik_max_word</p><p>会将文本做最细粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为“中华人民共和国、中华人民、中华、华人、人民共和国、人民、共和国、大会堂、大会、会堂等词语。</p></li><li><p>ik_smart</p><p>会做最粗粒度的拆分，比如会将“中华人民共和国人民大会堂”拆分为中华人民共和国、人民大会堂。</p></li></ul><p>测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST /_analyze</span><br><span class="line">&#123;&quot;text&quot;:&quot;中华人民共和国人民大会堂&quot;,&quot;analyzer&quot;:&quot;ik_smart&quot; &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">POST /_analyze</span><br><span class="line">&#123;&quot;text&quot;:&quot;中华人民共和国人民大会堂&quot;,&quot;analyzer&quot;:&quot;ik_max_word&quot; &#125;</span><br></pre></td></tr></table></figure><p>两种分词器使用的最佳实践是：</p><ul><li>索引时用ik_max_word</li><li>在搜索时用ik_smart</li></ul><p>即：索引时最大化的将文章内容分词，搜索时更精确的搜索到想要的结果。</p><h2 id="插件管理"><a href="#插件管理" class="headerlink" title="插件管理"></a>插件管理</h2><p>如何看es中安装了哪些插件？</p><p>GET _cat/plugins</p><h2 id="Index-Modules-索引模块"><a href="#Index-Modules-索引模块" class="headerlink" title="Index Modules-索引模块"></a>Index Modules-索引模块</h2><h3 id="slow-log"><a href="#slow-log" class="headerlink" title="slow log"></a>slow log</h3><p>slow log分为两种</p><ul><li>search slow log</li><li>index slow log</li></ul><p><strong>search slow log</strong></p><p>es支持记录分片级别的查询（包括query和fetch两个阶段）慢查询日志。</p><p>慢查询的阈值设置</p><p>在search中分为query和fetch两个部分</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">index.search.slowlog.threshold.query.warn: 10s</span><br><span class="line">index.search.slowlog.threshold.query.info: 5s</span><br><span class="line">index.search.slowlog.threshold.query.debug: 2s</span><br><span class="line">index.search.slowlog.threshold.query.trace: 500ms</span><br><span class="line"></span><br><span class="line">index.search.slowlog.threshold.fetch.warn: 1s</span><br><span class="line">index.search.slowlog.threshold.fetch.info: 800ms</span><br><span class="line">index.search.slowlog.threshold.fetch.debug: 500ms</span><br><span class="line">index.search.slowlog.threshold.fetch.trace: 200ms</span><br></pre></td></tr></table></figure><p>上面的这些配置可以在配置文件中指定，也可以通过接口去动态的设置</p><p>在默认情况下，上面这些参数没有一个是enabled的（默认值是 <code>-1</code>），提供的日志级别(<code>warn</code>, <code>info</code>, <code>debug</code>, <code>trace</code>)允许我们灵活的控制哪些级别是我们要打印输出的</p><p>上面这些配置并不是所有的都必须要设置。</p><p>上面是定义慢查询的阈值，除了这里，我们还需要再日志文件中进行配置</p><p>注意：日志中记录的shard级别的日志，也就是分片级别，这就意味着，这个es实例的日志可能不是一个完整的查询，而只是查询的一部分。使用这种方式的好处是可以毕竟精细的看到是哪一个节点的问题。</p><p>默认的日志配置（log4j2.properties）如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">appender.index_search_slowlog_rolling.type = RollingFile</span><br><span class="line">appender.index_search_slowlog_rolling.name = index_search_slowlog_rolling</span><br><span class="line">appender.index_search_slowlog_rolling.fileName = $&#123;sys:es.logs&#125;_index_search_slowlog.log</span><br><span class="line">appender.index_search_slowlog_rolling.layout.type = PatternLayout</span><br><span class="line">appender.index_search_slowlog_rolling.layout.pattern = [%d&#123;ISO8601&#125;][%-5p][%-25c] %marker%.-10000m%n</span><br><span class="line">appender.index_search_slowlog_rolling.filePattern = $&#123;sys:es.logs&#125;_index_search_slowlog-%d&#123;yyyy-MM-dd&#125;.log</span><br><span class="line">appender.index_search_slowlog_rolling.policies.type = Policies</span><br><span class="line">appender.index_search_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy</span><br><span class="line">appender.index_search_slowlog_rolling.policies.time.interval = 1</span><br><span class="line">appender.index_search_slowlog_rolling.policies.time.modulate = true</span><br><span class="line"></span><br><span class="line">logger.index_search_slowlog_rolling.name = index.search.slowlog</span><br><span class="line">logger.index_search_slowlog_rolling.level = trace</span><br><span class="line">logger.index_search_slowlog_rolling.appenderRef.index_search_slowlog_rolling.ref = index_search_slowlog_rolling</span><br><span class="line">logger.index_search_slowlog_rolling.additivity = false</span><br></pre></td></tr></table></figure><p>这里的配置根据版本的不同可能会不同</p><p><strong>index low log</strong></p><p>Indexing slow log的相关内容和上面的类似，文件名称也是以_index_indexing_slowlog.log结尾</p><p>阈值的配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">index.indexing.slowlog.threshold.index.warn: 10s</span><br><span class="line">index.indexing.slowlog.threshold.index.info: 5s</span><br><span class="line">index.indexing.slowlog.threshold.index.debug: 2s</span><br><span class="line">index.indexing.slowlog.threshold.index.trace: 500ms</span><br><span class="line">index.indexing.slowlog.level: info</span><br><span class="line">index.indexing.slowlog.source: 1000</span><br></pre></td></tr></table></figure><p>这些配置也是一样，可以在配置文件中设置，也可以通过接口进行设置。</p><p>注意：</p><ul><li>在默认情况下，es将只会把 _source 中的前1000个字符输出到日志文件中。如果有额外的需求，我们可以通过接口去进行设置。如果设置为false或者0，那么es将会忽略整个<code>source</code>。如果设置为true，那么将会无视size的限制。</li><li>最原始状态的<code>_source</code>将会被重新格式化，以便能够输出为单行的格式。如果document的格式非常重要，不能被重新格式化，那么我们可以将index.indexing.slowlog.reformat设置为false。</li></ul><p>同样的，我们也需要在日志文件中进行设置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">appender.index_indexing_slowlog_rolling.type = RollingFile</span><br><span class="line">appender.index_indexing_slowlog_rolling.name = index_indexing_slowlog_rolling</span><br><span class="line">appender.index_indexing_slowlog_rolling.fileName = $&#123;sys:es.logs&#125;_index_indexing_slowlog.log</span><br><span class="line">appender.index_indexing_slowlog_rolling.layout.type = PatternLayout</span><br><span class="line">appender.index_indexing_slowlog_rolling.layout.pattern = [%d&#123;ISO8601&#125;][%-5p][%-25c] %marker%.10000m%n</span><br><span class="line">appender.index_indexing_slowlog_rolling.filePattern = $&#123;sys:es.logs&#125;_index_indexing_slowlog-%d&#123;yyyy-MM-dd&#125;.log</span><br><span class="line">appender.index_indexing_slowlog_rolling.policies.type = Policies</span><br><span class="line">appender.index_indexing_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy</span><br><span class="line">appender.index_indexing_slowlog_rolling.policies.time.interval = 1</span><br><span class="line">appender.index_indexing_slowlog_rolling.policies.time.modulate = true</span><br><span class="line"></span><br><span class="line">logger.index_indexing_slowlog.name = index.indexing.slowlog.index</span><br><span class="line">logger.index_indexing_slowlog.level = trace</span><br><span class="line">logger.index_indexing_slowlog.appenderRef.index_indexing_slowlog_rolling.ref = index_indexing_slowlog_rolling</span><br><span class="line">logger.index_indexing_slowlog.additivity = false</span><br></pre></td></tr></table></figure><p>这里的配置根据版本的不同可能会不同</p><h3 id="slow-log实际案例"><a href="#slow-log实际案例" class="headerlink" title="slow log实际案例"></a>slow log实际案例</h3><p>我们可以通过api去动态的调整</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT /my_index/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index.search.slowlog.threshold.query.warn&quot; : &quot;10s&quot;, </span><br><span class="line">    &quot;index.search.slowlog.threshold.fetch.debug&quot;: &quot;500ms&quot;, </span><br><span class="line">    &quot;index.indexing.slowlog.threshold.index.info&quot;: &quot;5s&quot; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里设置的是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">查询慢于 10 秒输出一个 WARN 日志。</span><br><span class="line">获取慢于 500 毫秒输出一个 DEBUG 日志。</span><br><span class="line">索引慢于 5 秒输出一个 INFO 日志。</span><br></pre></td></tr></table></figure><p>实际案例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT testindex/_settings</span><br><span class="line">&#123;</span><br><span class="line">    &quot;index.search.slowlog.threshold.query.info&quot; : &quot;200ms&quot;, </span><br><span class="line">    &quot;index.search.slowlog.threshold.query.warn&quot; : &quot;500ms&quot;,</span><br><span class="line">    &quot;index.search.slowlog.threshold.fetch.info&quot;: &quot;200ms&quot;, </span><br><span class="line">    &quot;index.search.slowlog.threshold.fetch.warn&quot;: &quot;500ms&quot;, </span><br><span class="line">    &quot;index.indexing.slowlog.threshold.index.info&quot;: &quot;800ms&quot;,</span><br><span class="line">    &quot;index.indexing.slowlog.threshold.index.warn&quot;: &quot;1s&quot; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="查询DSL"><a href="#查询DSL" class="headerlink" title="查询DSL"></a>查询DSL</h2><h3 id="查询语句以及过滤语句"><a href="#查询语句以及过滤语句" class="headerlink" title="查询语句以及过滤语句"></a>查询语句以及过滤语句</h3><p>查询语句的处理行为取决于这个语句是在查询上下文中还是在过滤上下文中</p><p>两个的匹配级别不一样</p><ul><li><strong>Query context</strong>：关注于document和查询语句的匹配程度，也就是说目的是匹配出document</li><li><strong>Filter context</strong>：关注于document中的一些字段的过滤，例如过滤出document之后，过滤status字段为<em>published</em>的、<em>timestamp</em>字段的范围在2015到2016之间的</li></ul><p>案例:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123; </span><br><span class="line">    &quot;bool&quot;: &#123; </span><br><span class="line">      &quot;must&quot;: [</span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;title&quot;:   &quot;Search&quot;        &#125;&#125;, </span><br><span class="line">        &#123; &quot;match&quot;: &#123; &quot;content&quot;: &quot;Elasticsearch&quot; &#125;&#125;  </span><br><span class="line">      ],</span><br><span class="line">      &quot;filter&quot;: [ </span><br><span class="line">        &#123; &quot;term&quot;:  &#123; &quot;status&quot;: &quot;published&quot; &#125;&#125;, </span><br><span class="line">        &#123; &quot;range&quot;: &#123; &quot;publish_date&quot;: &#123; &quot;gte&quot;: &quot;2015-01-01&quot; &#125;&#125;&#125; </span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="full-text-query-全文查询"><a href="#full-text-query-全文查询" class="headerlink" title="full-text query-全文查询"></a>full-text query-全文查询</h3><h3 id="Term-Query-术语查询"><a href="#Term-Query-术语查询" class="headerlink" title="Term Query-术语查询"></a>Term Query-术语查询</h3><p>term 查询可以包含指定术语的document</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">POST _search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot; : &#123; &quot;user&quot; : &quot;Kimchy&quot; &#125; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在查询的时候可以给查询添加添加优先级，也就是紧急程度：boost字段</p><p>例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">GET _search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;bool&quot;: &#123;</span><br><span class="line">      &quot;should&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;term&quot;: &#123;</span><br><span class="line">            &quot;status&quot;: &#123;</span><br><span class="line">              &quot;value&quot;: &quot;urgent&quot;,</span><br><span class="line">              &quot;boost&quot;: 2.0 </span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;term&quot;: &#123;</span><br><span class="line">            &quot;status&quot;: &quot;normal&quot; </span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>默认语句的boost值为1.0</p><p>注意: </p><blockquote><p>在es中，在进行查询的时候，会把text类型的字段进行分割，例如：</p><p>“Quick Brown Fox!” 会被切割成术语：[<code>quick</code>, <code>brown</code>, <code>fox</code>]</p><p>因此，在进行term查询的时候，使用完整的字符串是查不到东西的</p></blockquote><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># 生成数据</span><br><span class="line">PUT my_index</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;my_type&quot;: &#123;</span><br><span class="line">      &quot;properties&quot;: &#123;</span><br><span class="line">        &quot;full_text&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;text&quot; </span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;exact_value&quot;: &#123;</span><br><span class="line">          &quot;type&quot;:  &quot;keyword&quot; </span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PUT my_index/my_type/1</span><br><span class="line">&#123;</span><br><span class="line">  &quot;full_text&quot;:   &quot;Quick Foxes!&quot;, </span><br><span class="line">  &quot;exact_value&quot;: &quot;Quick Foxes!&quot;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">查询数据</span><br><span class="line"></span><br><span class="line"># 查询成功</span><br><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;exact_value&quot;: &quot;Quick Foxes!&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询失败</span><br><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;full_text&quot;: &quot;Quick Foxes!&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询成功</span><br><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;full_text&quot;: &quot;foxes&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 查询成功</span><br><span class="line">GET my_index/my_type/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;full_text&quot;: &quot;Quick Foxes!&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：match查询方式的处理逻辑和term的方式是不一样的,match是属于全文查询级别。</p><h2 id="批处理-Batch-Processing"><a href="#批处理-Batch-Processing" class="headerlink" title="批处理-Batch Processing"></a>批处理-Batch Processing</h2><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.1/_batch_processing.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.1/_batch_processing.html</a></p><p>ES的批处理主要使用bulk api来实现。</p><h2 id="Modules-ES组件"><a href="#Modules-ES组件" class="headerlink" title="Modules-ES组件"></a>Modules-ES组件</h2><h3 id="node"><a href="#node" class="headerlink" title="node"></a>node</h3><p>集群中的每一个节点都能感知到其他节点，并且，在收到请求之后，能够转发请求到对应的node节点上。</p><p><strong>master node-主节点</strong></p><p>主节点主要用于集群的控制以及元数据的处理，例如索引的新增、删除、分片的分配信息等等</p><ul><li>创建或删除索引</li><li>跟踪哪些节点是集群的一部分</li><li>决定要分配给哪些节点哪些分片</li></ul><p>配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node.master=true</span><br><span class="line">node.data=false</span><br><span class="line">node.ingest=false</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>虽然有多个节点开启了这个配置，但是一个集群只有一个主节点，其他的都是master候选节点</li></ul><p><strong>data node-数据节点</strong></p><p>数据节点保存数据(索引)分片，它负责数据相关操作，涉及：</p><ul><li><p>CRUD，以及搜索和聚合</p></li><li><p>因此，数据节点的CPU、内存、IO以及存储资源都消耗</p></li><li>如果数据节点的资源负载过高，则需要添加数据节点</li></ul><p>配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node.master=false</span><br><span class="line">node.data=true</span><br><span class="line">node.ingest=false</span><br></pre></td></tr></table></figure><p><strong>client node-路由节点</strong></p><p>可以看做是一个负载均衡器，负责：</p><ul><li>处理路由请求</li><li>处理搜索聚合节点</li><li>分发批量索引请求</li></ul><p>设置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node.master=false</span><br><span class="line">node.data=false</span><br><span class="line">node.ingest=false</span><br></pre></td></tr></table></figure><p>如果es集群不是规模很大的话，我们一般不设置client节点，使用master提供类似的功能即可。</p><h3 id="线程池-Thread-Pool"><a href="#线程池-Thread-Pool" class="headerlink" title="线程池-Thread Pool"></a>线程池-Thread Pool</h3><p>es中，定义了许多种类的线程池，为的是更好的控制线程的内存消耗</p><p>注意：</p><ul><li><p>所有的线程池都会队列的方式，这将允许在线程池满了之后，之后的请求将会排队，而不是直接被丢弃。</p></li><li><p>线程池类型分类固定的数值的（fixed），可以自行动态调整的(也就是说有上下限)（scaling）</p></li><li>进程数量（available_processors）一般会自动识别，上限为32个，也就是在超过32核的机器上，最多使用32个进程。有这个限制的原因是防止产生太多的线程，如果你修改系统的ulimit上限，那么可以手动调整这个上限。可以使用node的api去check具体的进程数量</li></ul><p>固定数值的配置案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">thread_pool:</span><br><span class="line">    index:</span><br><span class="line">        size: 30</span><br><span class="line">        queue_size: 1000</span><br></pre></td></tr></table></figure><p>注意：当queue_size设置为-1的时候，就意味着关闭队列功能，当线程池满了之后，后面来的请求都会被丢弃</p><p>弹性数值的配置案例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">thread_pool:</span><br><span class="line">    warmer:</span><br><span class="line">        core: 1</span><br><span class="line">        max: 8</span><br><span class="line">        keep_alive: 2m</span><br></pre></td></tr></table></figure><p>工作线程数量的范围是：core-max。keep_alive的作用是：当多长时间线程池没有任务后，不保持可用的工作线程</p><p>进程数量设置，如果需要手动指定，可以使用下列的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">processors: 2</span><br></pre></td></tr></table></figure><p>目前有以下这些种类的线程池</p><ul><li><p>generic</p><p>可动态调整类型</p><p>通用操作，例如：用于后台的node发现</p></li><li><p>index</p><p>固定类型</p><p>用于索引的新增删除操作，size的数量是进程数量(available processors)，最大的数量是<code>1 + # of available processors</code>.队列长度queue_size默认为200</p></li><li><p>search </p><p>固定类型。</p><p>用于统计、检索等操作，默认配置值为：int((# of available_processors * 3) / 2) + 1，队列长度默认为1000。</p></li><li><p>下面还有很多略，看文档</p></li></ul><h3 id="zen-discovery-集群发现过程"><a href="#zen-discovery-集群发现过程" class="headerlink" title="zen discovery-集群发现过程"></a>zen discovery-集群发现过程</h3><p>暂时略</p><h2 id="ES的Merge功能"><a href="#ES的Merge功能" class="headerlink" title="ES的Merge功能"></a>ES的Merge功能</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/index-modules-merge.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.5/index-modules-merge.html</a></p><h3 id="基本概念："><a href="#基本概念：" class="headerlink" title="基本概念："></a>基本概念：</h3><p>ES中的shard分片，其实是lucene中的index索引。在lucene中，每一个index都会被分解成segments段，segments是index内部的基本存储单元</p><p>一些比较小的segment会被周期性的merge（合并）成为一个比较大的segment，为的是保持index的大小在一个稳定的范围，在合并之后将会删除这些小segment</p><p>segment是lucene索引的一种存储结构，每个segment都是一部分数据的完整索引，它是lucene每次flush或merge时候形成。每次flush就是将内存中的索引写出一个独立segment的过程。所以随着数据的不断增加，会形成越来越多的segment。因为segment是不可变的，删除操作不会改变segment内部数据，只是会在另外的地方记录某些数据删除，这样可能会导致segment中存在大量无用数据。搜索时，每个segment都需要一个reader来读取里面的数据，大量的segment会严重影响搜索效率。而merge过程，会将小的segment写到一起形成一个大的segment，减少其数量。同时重写过程会抛弃那些已经删除的数据。因此segment的merge是有利于查询效率的。</p><p>总结：大量的分段留在Lucene索引里面，意味着较慢的搜索和占用更多的内存。分段合并设计用来减少分段数量，但是合并动作是非常昂贵的，尤其是在低IO环境中，可能会受到存储性能上的限制。</p><h3 id="merge-scheduling"><a href="#merge-scheduling" class="headerlink" title="merge scheduling"></a>merge scheduling</h3><p>merge scheduler（并行调度方式）控制了我们在什么时候需要去执行merge操作。</p><p>merge使用单独的线程去实现，当到达了设定的最大线程数，余下到来的merge任务将会排队等候。</p><p>merge scheduler可以按照下面的这种方式进行动态的设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">index.merge.scheduler.max_thread_count</span><br></pre></td></tr></table></figure><p>elasticsearch的merge其实就是lucene的merge机制。merge过程是lucene有一个后台线程，它会根据merge策略来决定是否进行merge，一旦merge的条件满足，就会启动后台merge。merge策略分为两种，这也是大多数大数据框架所采用的，segment的大小和segment中doc的数量。以这两个标准为基础实现了三种merge策略：TieredMergePolicy、LogDocMergePolicy 及LogByteSizeMergePolicy。elasticsearch这一部分就是对这三种合并策略的封装，并提供了对于的配置。</p><h3 id="forcemerge"><a href="#forcemerge" class="headerlink" title="forcemerge"></a>forcemerge</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/indices-forcemerge.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.5/indices-forcemerge.html</a></p><p>调用接口：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">POST /twitter/_forcemerge</span><br></pre></td></tr></table></figure><h3 id="merge优化"><a href="#merge优化" class="headerlink" title="merge优化"></a>merge优化</h3><p>merge的优化可以是整个集群的调整，也可以是某些索引的调整，一般建议是索引级别。</p><p>merge操作是一个很消耗性能的过程，特别是对于磁盘的IO</p><p>因为如果有某个节点的io出现问题时，通过热线程定位，发现是merge导致的时，可以针对当前比较大的索引，修改一下merge相关的配置。</p><h2 id="ES监控"><a href="#ES监控" class="headerlink" title="ES监控"></a>ES监控</h2><p>zabbix上的配置：</p><p>key：</p><p>集群相关接口：GET /_cat/health?v、/_cat/allocation?v、GET /_cat/master?v</p><ul><li>集群颜色状态（非绿色报警）：es_status[9002,cluster,status]</li><li>集群分片健康度（非100%报警）：es_status[9002,cluster,active_shards_percent]</li><li>集群节点总数（有变化报警）：es_status[9002,cluster,total_node]</li><li>集群data节点总数（有变化报警）：es_status[9002,cluster,total_datanode]</li><li>集群未分配的分片数量（大于0报警）：es_status[9002,cluster,unassigned_shards]</li><li>集群的磁盘存储空间（打到80%报警）：es_status[9002,cluster,disk_used_percent]</li><li>集群master节点（有变化报警）：es_status[9002,cluster,masternode]</li><li>集群的写入速度</li><li>集群的读写速度</li><li>线程池的监控，总数以及每个线程池的监控</li><li>gc的情况</li></ul><p>节点相关：</p><p>相关api：</p><ul><li>es_status[9002,node,xx]</li><li>JVM内存占用超过90</li><li>负载</li><li>cpu使用率</li><li>日志中有报错就报警</li></ul><p>索引相关：</p><ul><li><p>索引总数：</p></li><li><p>es_status[9002,index,]</p></li></ul><p>主机相关监控，流量，cpu什么的，怎么能按照一个集群的维度-添加到grafana中</p><p>可以添加一下监控，针对每一个es集群：</p><ol><li><p>集群的磁盘使用情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_cat/allocation?v</span><br></pre></td></tr></table></figure></li><li><p>集群的健康性检查，例如红色和黄色、分片的状态等等</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GET /_cat/health?v</span><br></pre></td></tr></table></figure><p>集群的不健康可能是多种原因导致的，这里不区分具体的原因，如果有问题，则报警，收到报警之后再去查看具体是什么原因。</p><p>具体的指标有：</p><ul><li></li></ul></li></ol><ol><li><p>监控数据节点的负载情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure></li><li><p>node的可用性监控</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure></li><li><p>node的性能监控</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure></li></ol><ol><li><p>集群负载情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1</span><br></pre></td></tr></table></figure></li><li><p>集群的索引监控</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dd</span><br></pre></td></tr></table></figure><p>监控指标主要是索引的请求速率、请求处理延迟、索引大小等、索引异常等</p></li><li><p>ES的jmx监控(因为是java进程)</p></li></ol><h2 id="ES调优"><a href="#ES调优" class="headerlink" title="ES调优"></a>ES调优</h2><p>refresh时间间隔：refresh_interval</p><p>replica数目设置：在bulk大量数据到ES集群的可以把副本数设置为0，在数据导入完成之后再设置为1或者你集群的适合的数目。</p><h2 id="ES常见问题"><a href="#ES常见问题" class="headerlink" title="ES常见问题"></a>ES常见问题</h2><h3 id="慢查慢写日志设置及收集"><a href="#慢查慢写日志设置及收集" class="headerlink" title="慢查慢写日志设置及收集"></a>慢查慢写日志设置及收集</h3><p><strong>设置</strong></p><h3 id="热线程"><a href="#热线程" class="headerlink" title="热线程"></a>热线程</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.5/cluster-nodes-hot-threads.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.5/cluster-nodes-hot-threads.html</a></p><p>当有一些节点的cpu、负载、io等有异常时，我们可以通过热线程来定位到具体的产生原因。</p><p>使用格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[elk@es13.dwb.dgt ~]$ curl http://10.10.10.83:9200/_nodes/es13-data/hot_threads</span><br><span class="line"></span><br><span class="line">或者添加上时间，指定抓取多久时间内占用资源的热线程</span><br><span class="line">GET /_nodes/hot_threads&amp;interval=30s</span><br></pre></td></tr></table></figure><p>执行后的输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">[elk@es13.dwb.dgt ~]$ curl http://10.10.10.83:9200/_nodes/es13-data/hot_threads</span><br><span class="line">::: &#123;es13-data&#125;&#123;76c2DSkdRRqTyHUCoK1pyQ&#125;&#123;egVogFoJRzuFvJxUX1VnWQ&#125;&#123;10.10.10.83&#125;&#123;10.10.10.83:9300&#125;&#123;ml.machine_memory=270056525824, xpack.installed=true, ml.max_open_jobs=20, ml.enabled=true&#125;</span><br><span class="line">   Hot threads at 2019-07-23T07:21:24.850, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:</span><br><span class="line"></span><br><span class="line">   54.7% (273.5ms out of 500ms) cpu usage by thread &apos;elasticsearch[es13-data][[app-publishing-logstash-2019.07.23][1]: Lucene Merge Thread #983]&apos;</span><br><span class="line">     2/10 snapshots sharing following 24 elements</span><br><span class="line">       sun.misc.Unsafe.park(Native Method)</span><br><span class="line">       java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)</span><br><span class="line">       java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)</span><br><span class="line">       org.apache.lucene.index.MergePolicy$OneMergeProgress.pauseNanos(MergePolicy.java:156)</span><br><span class="line">       org.apache.lucene.index.MergeRateLimiter.maybePause(MergeRateLimiter.java:148)</span><br><span class="line">       org.apache.lucene.index.MergeRateLimiter.pause(MergeRateLimiter.java:93)</span><br><span class="line">       org.apache.lucene.store.RateLimitedIndexOutput.checkRate(RateLimitedIndexOutput.java:78)</span><br><span class="line">       org.apache.lucene.store.RateLimitedIndexOutput.writeBytes(RateLimitedIndexOutput.java:72)</span><br><span class="line">       org.apache.lucene.store.DataOutput.writeBytes(DataOutput.java:52)</span><br><span class="line">       org.apache.lucene.store.RAMOutputStream.writeTo(RAMOutputStream.java:90)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlock(BlockTreeTermsWriter.java:820)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlocks(BlockTreeTermsWriter.java:624)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.pushTerm(BlockTreeTermsWriter.java:905)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.write(BlockTreeTermsWriter.java:869)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:343)</span><br><span class="line">       org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)</span><br><span class="line">       org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:164)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:231)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:116)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4446)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)</span><br><span class="line">       org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)</span><br><span class="line">     5/10 snapshots sharing following 11 elements</span><br><span class="line">       org.apache.lucene.index.FilterLeafReader$FilterTermsEnum.next(FilterLeafReader.java:189)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:335)</span><br><span class="line">       org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)</span><br><span class="line">       org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:164)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:231)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:116)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4446)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)</span><br><span class="line">       org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)</span><br><span class="line">     2/10 snapshots sharing following 13 elements</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlocks(BlockTreeTermsWriter.java:633)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.pushTerm(BlockTreeTermsWriter.java:905)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.write(BlockTreeTermsWriter.java:869)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:343)</span><br><span class="line">       org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)</span><br><span class="line">       org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:164)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:231)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:116)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4446)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)</span><br><span class="line">       org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)</span><br><span class="line">     unique snapshot</span><br><span class="line">       sun.nio.ch.FileDispatcherImpl.write0(Native Method)</span><br><span class="line">       sun.nio.ch.FileDispatcherImpl.write(FileDispatcherImpl.java:60)</span><br><span class="line">       sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93)</span><br><span class="line">       sun.nio.ch.IOUtil.write(IOUtil.java:65)</span><br><span class="line">       sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:211)</span><br><span class="line">       java.nio.channels.Channels.writeFullyImpl(Channels.java:78)</span><br><span class="line">       java.nio.channels.Channels.writeFully(Channels.java:101)</span><br><span class="line">       java.nio.channels.Channels.access$000(Channels.java:61)</span><br><span class="line">       java.nio.channels.Channels$1.write(Channels.java:174)</span><br><span class="line">       org.apache.lucene.store.FSDirectory$FSIndexOutput$1.write(FSDirectory.java:417)</span><br><span class="line">       java.util.zip.CheckedOutputStream.write(CheckedOutputStream.java:73)</span><br><span class="line">       java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)</span><br><span class="line">       java.io.BufferedOutputStream.write(BufferedOutputStream.java:126)</span><br><span class="line">       org.apache.lucene.store.OutputStreamIndexOutput.writeBytes(OutputStreamIndexOutput.java:53)</span><br><span class="line">       org.elasticsearch.common.lucene.store.FilterIndexOutput.writeBytes(FilterIndexOutput.java:59)</span><br><span class="line">       org.apache.lucene.store.RateLimitedIndexOutput.writeBytes(RateLimitedIndexOutput.java:73)</span><br><span class="line">       org.apache.lucene.store.DataOutput.writeBytes(DataOutput.java:52)</span><br><span class="line">       org.apache.lucene.store.RAMOutputStream.writeTo(RAMOutputStream.java:90)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlock(BlockTreeTermsWriter.java:820)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.writeBlocks(BlockTreeTermsWriter.java:624)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.pushTerm(BlockTreeTermsWriter.java:905)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter$TermsWriter.write(BlockTreeTermsWriter.java:869)</span><br><span class="line">       org.apache.lucene.codecs.blocktree.BlockTreeTermsWriter.write(BlockTreeTermsWriter.java:343)</span><br><span class="line">       org.apache.lucene.codecs.FieldsConsumer.merge(FieldsConsumer.java:105)</span><br><span class="line">       org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsWriter.merge(PerFieldPostingsFormat.java:164)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.mergeTerms(SegmentMerger.java:231)</span><br><span class="line">       org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:116)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4446)</span><br><span class="line">       org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:4068)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:625)</span><br><span class="line">       org.elasticsearch.index.engine.ElasticsearchConcurrentMergeScheduler.doMerge(ElasticsearchConcurrentMergeScheduler.java:99)</span><br><span class="line">       org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:662)</span><br><span class="line"></span><br><span class="line">    5.2% (26ms out of 500ms) cpu usage by thread &apos;elasticsearch[es13-data][[transport_server_worker.default]][T#16]&apos;</span><br><span class="line">     4/10 snapshots sharing following 2 elements</span><br><span class="line">       io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:897)</span><br><span class="line">       java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure><p>输出分析：</p><h2 id="ES扩容及缩容"><a href="#ES扩容及缩容" class="headerlink" title="ES扩容及缩容"></a>ES扩容及缩容</h2><h3 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h3><p>扩容比较简单，在配置文件中指定现有es节点的地址，启动之后就会自动添加进当前的集群，注意cluster name需要一致。</p><p>在新节点添加进来之后，shard会自动挪动，如果集群压力较大，数据量较多，在挪动的时候可能会影响集群的读写，那么，这个时候我可以自定义的选择合适的时间去操作，配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;persistent&quot;: &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>避免集群shard移动，待到合适的时间，设置：</p><figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings &#123; "persistent": &#123; "cluster.routing.allocation.enable": null &#125; &#125;</span><br></pre></td></tr></table></figure><p>恢复shard移动</p><p>具体可以参考：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.2/rolling-upgrades.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/6.2/rolling-upgrades.html</a></p><p>注意：</p><ul><li>设置为none之后，如果创建了新的索引，那么该索引的分片将不会被分配，会被置为：UNASSIGNED。也就意味着无法往这个新索引中写入数据</li><li>在设置之前的索引，数据写入不受影响。</li></ul><h3 id="缩容"><a href="#缩容" class="headerlink" title="缩容"></a>缩容</h3><p>使用exclude：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">PUT _cluster/settings</span><br><span class="line">&#123;</span><br><span class="line">  &quot;transient&quot; : &#123;</span><br><span class="line">    &quot;cluster.routing.allocation.exclude._ip&quot; : &quot;10.0.0.1&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把要下线的机器exclude，然后数据会自动迁移到其他节点并且自动rebalance，集群不需要重启。</p><p>迁移完后可以重新划分节点角色。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#通过IP，排除集群中的某个节点：节点IP：10.100.0.11</span><br><span class="line">curl -XPUT http://&lt;domain&gt;:&lt;port&gt;/_cluster/settings?pretty -d &apos;&#123;&quot;transient&quot;:&#123;&quot;cluster.routing.allocation.exclude._ip&quot;:&quot;10.100.0.11&quot;&#125;&#125;&apos;</span><br><span class="line"></span><br><span class="line">#通过IP，排除集群中的多个节点：节点IP：10.10.0.11,10.100.0.12</span><br><span class="line">curl -XPUT http://&lt;domain&gt;:&lt;port&gt;/_cluster/settings?pretty -d &apos;&#123;&quot;transient&quot;:&#123;&quot;cluster.routing.allocation.exclude._ip&quot;:&quot;10.100.0.11,10.100.0.12&quot;&#125;&#125;&apos;</span><br><span class="line"></span><br><span class="line">#取消节点排除的限制</span><br><span class="line">curl -XPUT http://&lt;domain&gt;:&lt;port&gt;/_cluster/settings?pretty -d &apos;&#123;&quot;transient&quot;:&#123;&quot;cluster.routing.allocation.exclude._ip&quot;: null&#125;&#125;&apos;</span><br></pre></td></tr></table></figure><p>注意：当迁移过程中，其他节点的负载较高时，可以先取消，就是上面的设置为null</p><p>所以，整个的下线操作是：</p><ol><li>exclude掉要下线的节点</li><li>确认shard，待该节点上没有shard之后，停止该节点</li><li>将exclude设置为null</li></ol><p>问题：如何查看和控制shard的移动速度，防止数据量过大时出现问题。</p><h3 id="相关参数"><a href="#相关参数" class="headerlink" title="相关参数"></a>相关参数</h3><p>除了上面提到的哪些，还有一些集群级别的参数可以动态定义</p><p>迁移相关：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cluster.routing.allocation.cluster_concurrent_rebalance</span><br></pre></td></tr></table></figure><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/shards-allocation.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/shards-allocation.html</a></p><p>主要是modules中的集群部分内容</p><p>索引相关：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">indices.recovery.max_bytes_per_sec</span><br></pre></td></tr></table></figure><p>参考链接：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.3/recovery.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/5.3/recovery.html</a></p><h1 id="kibana部署"><a href="#kibana部署" class="headerlink" title="kibana部署"></a>kibana部署</h1><h2 id="ES数据如何展示在kibana上"><a href="#ES数据如何展示在kibana上" class="headerlink" title="ES数据如何展示在kibana上"></a>ES数据如何展示在kibana上</h2><p>如何将es的索引数据展示在kibana上？</p><h2 id="ES的监控指标如何展示在kibana上"><a href="#ES的监控指标如何展示在kibana上" class="headerlink" title="ES的监控指标如何展示在kibana上"></a>ES的监控指标如何展示在kibana上</h2><h2 id="kibana监控"><a href="#kibana监控" class="headerlink" title="kibana监控"></a>kibana监控</h2><h2 id="kibana搜索"><a href="#kibana搜索" class="headerlink" title="kibana搜索"></a>kibana搜索</h2><p>参考链接：<a href="https://www.elastic.co/guide/en/kibana/6.5/kuery-query.html#_new_simplified_syntax" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/6.5/kuery-query.html#_new_simplified_syntax</a></p><h2 id="xpack-monitor监控"><a href="#xpack-monitor监控" class="headerlink" title="xpack-monitor监控"></a>xpack-monitor监控</h2><p>默认情况下，在kibana界面是不展示各es节点的负载、资源使用率、索引信息等指标的，我们可以添加上这个功能，这在排查问题时还是挺有效果的。</p><p>除了能监控es，xpack体系还能监控filebeat、logstash等组件</p><h3 id="在线方式安装"><a href="#在线方式安装" class="headerlink" title="在线方式安装"></a>在线方式安装</h3><p>es端配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch-plugin install x-pack</span><br></pre></td></tr></table></figure><p>如果es设置了关闭自动创建index，那么还需要添加下面这行配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history*</span><br></pre></td></tr></table></figure><p>kibana端配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kibana-plugin install x-pack</span><br></pre></td></tr></table></figure><h3 id="离线方式安装"><a href="#离线方式安装" class="headerlink" title="离线方式安装"></a>离线方式安装</h3><p>参考链接：<a href="https://www.elastic.co/guide/en/x-pack/5.1/installing-xpack.html#xpack-installing-offline" target="_blank" rel="noopener">https://www.elastic.co/guide/en/x-pack/5.1/installing-xpack.html#xpack-installing-offline</a></p><p>如果服务器不能直连公网等，那么可以把相关的包文件下载下来上次到服务器上。</p><p>首先下载文件，并传输到服务器上。</p><p>然后执行以下命令</p><p><strong>es：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/elasticsearch-plugin install file:///path/to/file/x-pack-5.1.2.zip</span><br></pre></td></tr></table></figure><p><strong>kibana：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kibana-plugin install file:///path/to/file/x-pack-5.1.2.zip</span><br></pre></td></tr></table></figure><h3 id="xpack相关配置参数"><a href="#xpack相关配置参数" class="headerlink" title="xpack相关配置参数"></a>xpack相关配置参数</h3><p>有以下相关参数：</p><table><thead><tr><th>Setting</th><th>Description</th></tr></thead><tbody><tr><td><code>xpack.security.enabled</code></td><td>Set to <code>false</code> to disable X-Pack security. Configure in both <code>elasticsearch.yml</code> and <code>kibana.yml</code>.</td></tr><tr><td><code>xpack.monitoring.enabled</code></td><td>Set to <code>false</code> to disable X-Pack monitoring. Configure in both <code>elasticsearch.yml</code> and <code>kibana.yml</code>.</td></tr><tr><td><code>xpack.graph.enabled</code></td><td>Set to <code>false</code> to disable X-Pack graph. Configure in both <code>elasticsearch.yml</code> and <code>kibana.yml</code>.</td></tr><tr><td><code>xpack.watcher.enabled</code></td><td>Set to <code>false</code> to disable Watcher. Configure in <code>elasticsearch.yml</code>only.</td></tr><tr><td><code>xpack.reporting.enabled</code></td><td>Set to <code>false</code> to disable X-Pack reporting. Configure in <code>kibana.yml</code> only.</td></tr></tbody></table><p>默认情况下，所有的参数功能都是打开的，可以根据实际情况去选择开启</p><p>我们一般的实际配置是：</p><p><strong>es节点</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[elk@es032.ecs.east1-e config]$ grep xpack elasticsearch.yml</span><br><span class="line">xpack.security.audit.enabled: false</span><br><span class="line">xpack.monitoring.enabled: true</span><br><span class="line">xpack.security.enabled: false</span><br><span class="line">xpack.graph.enabled: false</span><br><span class="line">xpack.watcher.enabled: false</span><br></pre></td></tr></table></figure><p><strong>kibana</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[elk@redis2.dwb.dgt config]$ grep xpack kibana.yml</span><br><span class="line">xpack.monitoring.elasticsearch.url: &quot;http://172.24.48.34:9200&quot;</span><br><span class="line">xpack.monitoring.enabled: true</span><br><span class="line">xpack.security.enabled: false</span><br><span class="line">xpack.graph.enabled: false</span><br><span class="line">xpack.reporting.enabled: false</span><br></pre></td></tr></table></figure><h1 id="补充-yaml语法"><a href="#补充-yaml语法" class="headerlink" title="补充-yaml语法"></a>补充-yaml语法</h1><p>YAML语言的设计参考了JSON，XML和SDL等语言。也是一种数据交互的格式语言，YAML 强调以<strong>数据为中心</strong>,简洁易读,编写简单。</p><p>YAML主要的作用是作为程序的配置文件。</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>yaml语言有以下特点：</p><ul><li>大小写敏感</li><li>通过缩进表示层级关系</li><li><strong>禁止使用tab缩进，只能使用空格键</strong> （个人感觉这条最重要）</li><li>缩进的空格数目不重要，只要相同层级左对齐即可</li><li>使用#表示注释</li></ul><h2 id="支持的数据结构"><a href="#支持的数据结构" class="headerlink" title="支持的数据结构"></a>支持的数据结构</h2><p>支持以下数据结构：</p><ul><li>对象：键值对的<strong>集合</strong>，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary）</li><li>数组：一组按次序排列的值，又称为序列（sequence） / 列表（list）</li><li>纯量（scalars）：单个的、不可再分的值</li></ul><h2 id="数据结构的书写形式"><a href="#数据结构的书写形式" class="headerlink" title="数据结构的书写形式"></a>数据结构的书写形式</h2><h3 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h3><p>Map（属性和值）（键值对）的形式： key:(空格)v ：表示一堆键值对，空格不可省略。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">car:</span><br><span class="line">    color: red</span><br><span class="line">    brand: BMW</span><br></pre></td></tr></table></figure><p>一行写法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">car:&#123;color: red，brand: BMW&#125;</span><br></pre></td></tr></table></figure><p>相当于JSON格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;color&quot;:&quot;red&quot;,&quot;brand&quot;:&quot;BMW&quot;&#125;</span><br></pre></td></tr></table></figure><h3 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h3><p>一组连词线开头的行，构成一个数组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">brand:</span><br><span class="line">   - audi</span><br><span class="line">   - bmw</span><br><span class="line">   - ferrari</span><br></pre></td></tr></table></figure><p>一行写法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brand: [audi,bmw,ferrari]</span><br></pre></td></tr></table></figure><p>相当于JSON</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&quot;auri&quot;,&quot;bmw&quot;,&quot;ferrari&quot;]</span><br></pre></td></tr></table></figure><h3 id="纯量"><a href="#纯量" class="headerlink" title="纯量"></a>纯量</h3><p>纯量是最基本的、不可再分的值。以下数据类型都属于 JavaScript 的纯量。</p><ul><li>字符串</li><li>布尔值</li><li>整数</li><li>浮点数</li><li>Null</li><li>时间</li><li>日期</li></ul><h1 id="补充-kafka安装部署"><a href="#补充-kafka安装部署" class="headerlink" title="补充-kafka安装部署"></a>补充-kafka安装部署</h1><h2 id="kafka-3"><a href="#kafka-3" class="headerlink" title="kafka"></a>kafka</h2><p>参考文档：</p><ul><li><a href="https://kafka.apache.org/11/documentation.html#quickstart" target="_blank" rel="noopener">https://kafka.apache.org/11/documentation.html#quickstart</a></li></ul><h3 id="启动-1"><a href="#启动-1" class="headerlink" title="启动"></a>启动</h3><p>启动zk</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</span><br><span class="line">可以是：</span><br><span class="line">nohup bin/zookeeper-server-start.sh config/zookeeper.properties &gt; zk.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>启动kafka</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure><h2 id="kafka-manager"><a href="#kafka-manager" class="headerlink" title="kafka-manager"></a>kafka-manager</h2><p>参考链接：</p><ul><li><a href="https://github.com/yahoo/kafka-manager/tree/1.3.3.16" target="_blank" rel="noopener">https://github.com/yahoo/kafka-manager/tree/1.3.3.16</a></li><li><a href="https://www.cnblogs.com/frankdeng/p/9584870.html" target="_blank" rel="noopener">https://www.cnblogs.com/frankdeng/p/9584870.html</a></li></ul><p>注意：.sbt/repositories文件中，每行后面不能有空格，每行都是以换行结尾的。如果存在空格，那么使用delete键删除。</p><h3 id="启动-2"><a href="#启动-2" class="headerlink" title="启动"></a>启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[admin@node21 kafka-manager-1.3.3.18]$ nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=8080 &amp;</span><br></pre></td></tr></table></figure><h1 id="补充-logrotate"><a href="#补充-logrotate" class="headerlink" title="补充-logrotate"></a>补充-logrotate</h1><p>参考链接：</p><ul><li><a href="https://linux.cn/article-4126-1.html" target="_blank" rel="noopener">https://linux.cn/article-4126-1.html</a></li><li><a href="https://linux.cn/article-8227-1.html" target="_blank" rel="noopener">https://linux.cn/article-8227-1.html</a></li></ul><p>注意：</p><p>在一个配置文件中，如果指定了多个日志文件，那么当第一个文件不需要进行轮转的时候，下面的文件就算需要进行轮转，也都会跳过，也就是说：当有多个日志文件时，下一个文件的操作，完全依赖上一个文件是否已经存在，当已经存在的时候，下面就不会再进行操作。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@node001 logrotate.d]# cat /etc/logrotate.d/syslog</span><br><span class="line">/var/log/cron</span><br><span class="line">/var/log/maillog</span><br><span class="line">&#123;</span><br><span class="line">    sharedscripts</span><br><span class="line">    create 0664 root root</span><br><span class="line">    postrotate</span><br><span class="line">/bin/kill -HUP `cat /var/run/syslogd.pid 2&gt; /dev/null` 2&gt; /dev/null || true</span><br><span class="line">    endscript</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logrotate /etc/logrotate.conf  -f</span><br></pre></td></tr></table></figure><p>强制生成新文件的时候，当cron的轮询文件已经存在，但是maillog不存在的时候，这个时候，将会不操作，也就是，不会对maillog进行日志轮转。</p>]]></content>
    
    <summary type="html">
    
      ELK部署
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="ELK" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/"/>
    
      <category term="ELK部署" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELK/ELK%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="ELK" scheme="http://yoursite.com/tags/ELK/"/>
    
  </entry>
  
  <entry>
    <title>大数据科普</title>
    <link href="http://yoursite.com/2019/06/18/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E6%99%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E6%99%AE/"/>
    <id>http://yoursite.com/2019/06/18/IT科学技术知识体系结构-Linux运维方向/大数据/大数据科普/大数据科普/</id>
    <published>2019-06-18T05:57:57.000Z</published>
    <updated>2019-06-18T05:57:57.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考文献：</p><ul><li><a href="https://wiki.mbalib.com/wiki/%E5%A4%A7%E6%95%B0%E6%8D%AE" target="_blank" rel="noopener">https://wiki.mbalib.com/wiki/%E5%A4%A7%E6%95%B0%E6%8D%AE</a></li></ul><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h2><p>大数据定义：<strong>大数据</strong>是指<strong>无法</strong>在一定时间内用<strong>常规软件工具</strong>对其内容进行抓取、管理(存储等)和处理(分析等)的<strong>数据集合</strong>。</p><p>大数据意义：有人把数据比喻为蕴藏能量的煤矿。煤炭按照性质有焦煤、无烟煤、肥煤、贫煤等分类，而露天煤矿、深山煤矿的挖掘成本又不一样。与此类似，大数据并不在“大”，而在于“有用”。价值含量、挖掘成本比数量更为重要。对于很多行业而言，如何利用这些大规模数据是赢得竞争的关键</p><p>大数据特征：一般来说，大数据具有以下几个特征</p><ul><li><strong>数据体量巨大。</strong></li><li><strong>数据类型复杂多样。</strong>现在的数据类型不仅是文本形式，更多的是图片、视频、音频、地理位置信息等多类型的数据，个性化数据占绝对多数。</li><li><strong>价值密度低。</strong>以视频为例，一小时的视频，在不间断的监控过程中，可能有用的数据仅仅只有一两秒。</li></ul><h2 id="大数据技术"><a href="#大数据技术" class="headerlink" title="大数据技术"></a>大数据技术</h2><p>大数据技术是指从各种各样类型的数据中，快速获得有价值信息的能力。</p><h2 id="常见问题及误区"><a href="#常见问题及误区" class="headerlink" title="常见问题及误区"></a>常见问题及误区</h2><h3 id="数据不等于信息"><a href="#数据不等于信息" class="headerlink" title="数据不等于信息"></a>数据不等于信息</h3><p>经常有人把数据和信息当作同义词来用。其实不然，数据指的是一个原始的数据点（无论是通过数字，文字，图片还是视频等等），信息则直接与内容挂钩，需要有资讯性（informative）。数据越多，不一定就能代表信息越多，更不能代表信息就会成比例增多。有两个简单的例子：</p><p>备份。很多人如今已经会定期的对自己的硬盘进行备份。这个没什么好多解释的，每次备份都会创造出一组新的数据，但信息并没有增多。</p><p>多个社交网站上的信息。我们当中的很多人在多个社交网站上活跃，随着我们上的社交网站越多，我们获得的数据就会成比例的增多，我们获得的信息虽然也会增多，但却不会成比例的增多。不单单因为我们会互相转发好友的微博（或者其他社交网站上的内容），更因为很多内容会十分类似，有些微博虽然具体文字不同，但表达的内容十分相似。</p>]]></content>
    
    <summary type="html">
    
      大数据科普知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据科普" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E6%99%AE/"/>
    
    
      <category term="大数据" scheme="http://yoursite.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>tcpdump</title>
    <link href="http://yoursite.com/2019/06/04/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%91%BD%E4%BB%A4/tcpdump/"/>
    <id>http://yoursite.com/2019/06/04/IT科学技术知识体系结构-Linux运维方向/Linux命令/tcpdump/</id>
    <published>2019-06-04T09:09:11.000Z</published>
    <updated>2019-06-04T09:09:11.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h1 id="命令语法"><a href="#命令语法" class="headerlink" title="命令语法"></a>命令语法</h1><p>tcpdump命令的使用格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump [-adeflnNOpqStvx][-c&lt;数据包数目&gt;][-dd][-ddd][-F&lt;表达文件&gt;][-i&lt;网络界面&gt;][-r&lt;数据包文件&gt;][-s&lt;数据包大小&gt;][-tt][-T&lt;数据包类型&gt;][-vv][-w&lt;数据包文件&gt;][输出数据栏位]</span><br></pre></td></tr></table></figure><p><strong>参数说明</strong>：</p><ul><li>-a 尝试将网络和广播地址转换成名称。</li><li>-c&lt;数据包数目&gt; 收到指定的数据包数目后，就停止进行倾倒操作。</li><li>-d 把编译过的数据包编码转换成可阅读的格式，并倾倒到标准输出。</li><li>-dd 把编译过的数据包编码转换成C语言的格式，并倾倒到标准输出。</li><li>-ddd 把编译过的数据包编码转换成十进制数字的格式，并倾倒到标准输出。</li><li>-e 在每列倾倒资料上显示连接层级的文件头。</li><li>-f 用数字显示网际网络地址。</li><li>-F&lt;表达文件&gt; 指定内含表达方式的文件。</li><li>-i&lt;网络界面&gt; 使用指定的网络截面送出数据包。</li><li>-l 使用标准输出列的缓冲区。</li><li>-n 不把主机的网络地址转换成名字。</li><li>-N 不列出域名。</li><li>-O 不将数据包编码最佳化。</li><li>-p 不让网络界面进入混杂模式。</li><li>-q 快速输出，仅列出少数的传输协议信息。</li><li>-r&lt;数据包文件&gt; 从指定的文件读取数据包数据。</li><li>-s&lt;数据包大小&gt; 设置每个数据包的大小。</li><li>-S 用绝对而非相对数值列出TCP关联数。</li><li>-t 在每列倾倒资料上不显示时间戳记。</li><li>-tt 在每列倾倒资料上显示未经格式化的时间戳记。</li><li>-T&lt;数据包类型&gt; 强制将表达方式所指定的数据包转译成设置的数据包类型。</li><li>-v 详细显示指令执行过程。</li><li>-vv 更详细显示指令执行过程。</li><li>-x 用十六进制字码列出数据包资料。</li><li>-w&lt;数据包文件&gt; 把数据包数据写入指定的文件。</li></ul><h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><p>有以下案例</p><ul><li><p>案例1：指定对端ip地址的流量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tcpdump -i eth0 -nnn -s0 host 172.24.0.20 -w /root/dhub-api.pcap</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      tcpdump命令
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux命令" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="tcpdump" scheme="http://yoursite.com/tags/tcpdump/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper从入门到实践</title>
    <link href="http://yoursite.com/2019/04/08/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/zookeeper/zookeeper%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2019/04/08/IT科学技术知识体系结构-Linux运维方向/运维架构/分布式/zookeeper/zookeeper日志管理/</id>
    <published>2019-04-08T08:43:59.000Z</published>
    <updated>2019-04-08T08:43:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="zookeeper基础知识"><a href="#zookeeper基础知识" class="headerlink" title="zookeeper基础知识"></a>zookeeper基础知识</h1><h1 id="zookeeper日志管理"><a href="#zookeeper日志管理" class="headerlink" title="zookeeper日志管理"></a>zookeeper日志管理</h1><h2 id="日志分类"><a href="#日志分类" class="headerlink" title="日志分类"></a>日志分类</h2><p>zookeeper服务器会产生三类日志：</p><ul><li>事务日志</li><li>快照日志</li><li>log4j日志。</li></ul><p>在zookeeper默认配置文件zoo.cfg（可以修改文件名）中有一个配置项dataDir，该配置项用于配置zookeeper<strong>快照日志和事务日志</strong>的存储地址。</p><p>在官方提供的默认参考配置文件zoo_sample.cfg中，只有dataDir配置项。</p><p>其实在实际应用中，还可以为事务日志专门配置存储地址，配置项名称为<strong>dataLogDir</strong>，在zoo_sample.cfg中并未体现出来。在没有dataLogDir配置项的时候，zookeeper默认将事务日志文件和快照日志文件都存储在dataDir对应的目录下。</p><p>建议将事务日志（dataLogDir）与快照日志（dataLog）单独配置，因为当zookeeper集群进行频繁的数据读写操作是，会产生大量的事务日志信息，将两类日志分开存储会提高系统性能，而且，可以允许将两类日志存在在不同的存储介质上，减少磁盘压力。</p><h2 id="log4j-运行日志"><a href="#log4j-运行日志" class="headerlink" title="log4j-运行日志"></a>log4j-运行日志</h2><p>log4j用于记录zookeeper集群服务器运行日志，该日志的配置地址在conf/目录下的log4j.properties文件中，该文件中有一个配置项为“zookeeper.log.dir=.”，表示log4j日志文件在与执行程序（<a href="http://zkserver.sh/" target="_blank" rel="noopener">zkServer.sh</a>）在同一目录下。<a href="http://xn--zkserver-fm2pi0w5y6i.sh/" target="_blank" rel="noopener">当执行zkServer.sh</a> 时，在该文件夹下会产生zookeeper.out日志文件。下面主要介绍事务日志与快照日志。</p><h2 id="事务日志"><a href="#事务日志" class="headerlink" title="事务日志"></a>事务日志</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>事务日志指zookeeper系统在正常运行过程中，针对所有的更新操作，在返回客户端“更新成功”的响应前，zookeeper会保证已经将本次更新操作的事务日志已经写到磁盘上，只有这样，整个更新操作才会生效。</p><p>根据上文所述，可以通过zoo.cfg文件中的dataLogDir配置项找到事物日志存储地点：<br>dataDir=/home/kafka/data/zookeeper<br>在datalog/目录下存在一个文件夹version-2，该文件夹中保存着事物日志文件:<br>log.504e25800<br>日志文件的命名规则为log.<strong>，文件大小为64MB，</strong>表示写入该日志的第一个事务的ID，十六进制表示。</p><h3 id="事务日志可视化"><a href="#事务日志可视化" class="headerlink" title="事务日志可视化"></a>事务日志可视化</h3><p>zookeeper的事务日志为二进制文件，不能通过vim等工具直接访问。其实可以通过zookeeper自带的jar包读取事务日志文件。<br>首先将libs中的slf4j-api-1.6.1.jar文件和zookeeper根目录下的zookeeper-3.4.8.jar文件复制到临时文件夹tmplibs中，然后执行如下命令,将日志内容输出至a.txt文件中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># java -classpath .:slf4j-api-1.6.1.jar:zookeeper-3.4.8.jar org.apache.zookeeper.server.LogFormatter /home/zookeeper/2181/data/version-2/log.2f019aaf7f &gt; a.txt</span><br></pre></td></tr></table></figure><h3 id="日志分析"><a href="#日志分析" class="headerlink" title="日志分析"></a><strong>日志分析</strong></h3><p>第一行：ZooKeeper Transactional Log File with dbid 0 txnlog format version 2</p><p>上面的代码分析中有说到每个日志文件都有一个这就是那里所说的日志头，这里magic没有输出，只输出了dbid还有version；</p><p>第二行：15-8-12 下午03时59分53秒 session 0x14f20ea71c10000 cxid 0x0 zxid 0x1 createSession 4000这也就是具体的事务日志内容了，这里是说xxx时间有一个sessionid为0x14f20ea71c10000、cxid为0x0、zxid 为0x1、类型为createSession、超时时间为4000毫秒</p><p>第三行：15-8-12 下午03时59分54秒 session 0x14f20ea71c10000 cxid 0x1 zxid 0x2 create ‘/solinx0000000000,#736f6c696e78,v{s{31,s{‘world,’anyone}}},F,1sessionID 为0x14f20ea71c10000，cxid：0x01、zxid：0x02、创建了一个节点路径为：/solinx0000000000、节点内容 为：#736f6c696e78(经过ASCII，实际内容为solinx)、acl为world:anyone任何人都可以管理该节点、节点不是 ephemeral节点的、父节点子版本：1</p><p>第四行：15-8-12 下午04时15分56秒 session 0x14f20ea71c10000 cxid 0x0 zxid 0x3 closeSession null这里是说xxx时间有一个sessionid为0x14f20ea71c10000、cxid为0x0、zxid为0x3、类型为 closeSession</p><h2 id="快照日志"><a href="#快照日志" class="headerlink" title="快照日志"></a>快照日志</h2><p>zookeeper的数据在内存中是以树形结构进行存储的，而快照就是每隔一段时间就会把整个DataTree的数据序列化后存储在磁盘中，这就是zookeeper的快照文件。</p><p>zookeeper快照日志的存储路径同样可以在zoo.cfg中查看，如上文截图所示。访问dataDir路径可以看到version-2文件夹:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/home/zookeeper/2181/data</span><br></pre></td></tr></table></figure><p>zookeeper快照文件的命名规则为snapshot.<strong>，其中</strong>表示zookeeper触发快照的那个瞬间，提交的最后一个事务的ID。</p><p>与上面说的事务日志文件一样，Zookeeper也为快照文件提供了可视化的工具：org.apache.zookeeper.server包中的SnapshotFormatter类，接下来就使用该工具输出该事务日志文件，并解释该数据；</p><h3 id="SnapshotFormatter工具使用"><a href="#SnapshotFormatter工具使用" class="headerlink" title="SnapshotFormatter工具使用"></a>SnapshotFormatter工具使用</h3><p>命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># java -classpath .:slf4j-api-1.6.1.jar:zookeeper-3.4.8.jar org.apache.zookeeper.server.SnapshotFormatter /home/zookeeper/2181/data/version-2/snapshot.2f019b7bc0 |less</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">ZNode Details (count=105078):</span><br><span class="line">----</span><br><span class="line">/</span><br><span class="line">  cZxid = 0x00000000000000</span><br><span class="line">  ctime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">  mZxid = 0x00000000000000</span><br><span class="line">  mtime = Thu Jan 01 08:00:00 CST 1970</span><br><span class="line">  pZxid = 0x00002c05e92d48</span><br><span class="line">  cversion = 71</span><br><span class="line">  dataVersion = 0</span><br><span class="line">  aclVersion = 0</span><br><span class="line">  ephemeralOwner = 0x00000000000000</span><br><span class="line">  dataLength = 0</span><br><span class="line">----</span><br><span class="line">/com</span><br><span class="line">  cZxid = 0x0000010003a93a</span><br><span class="line">  ctime = Mon Mar 06 00:26:24 CST 2017</span><br><span class="line">  mZxid = 0x0000010003a93a</span><br><span class="line">  mtime = Mon Mar 06 00:26:24 CST 2017</span><br><span class="line">  pZxid = 0x0000010003a93b</span><br><span class="line">  cversion = 1</span><br><span class="line">  dataVersion = 0</span><br><span class="line">  aclVersion = 0</span><br><span class="line">  ephemeralOwner = 0x00000000000000</span><br><span class="line">  dataLength = 0</span><br><span class="line">  </span><br><span class="line">......</span><br></pre></td></tr></table></figure><h3 id="快照分析"><a href="#快照分析" class="headerlink" title="快照分析"></a>快照分析</h3><p>快照文件就很容易看得懂了，这就是Zookeeper整个节点数据的输出；<br>第一行：ZNode Details (count=105078):ZNode节点数总共有105078个<br>/<br>cZxid = 0x00000000000000<br>ctime = Thu Jan 01 08:00:00 CST 1970<br>mZxid = 0x00000000000000<br>mtime = Thu Jan 01 08:00:00 CST 1970<br>pZxid = 0x00002c05e92d48<br>cversion = 71<br>dataVersion = 0<br>aclVersion = 0<br>ephemeralOwner = 0x00000000000000<br>dataLength = 0</p><p>这么一段数据是说：</p><p>根节点/：<br>cZxid：创建节点时的ZXID<br>ctime：创建节点的时间<br>mZxid：节点最新一次更新发生时的zxid<br>mtime：最近一次节点更新的时间<br>pZxid：父节点的zxid<br>cversion：子节点更新次数<br>dataVersion：节点数据更新次数<br>aclVersion：节点acl更新次数<br>ephemeralOwner：如果节点为ephemeral节点则该值为sessionid，否则为0<br>dataLength：该节点数据的长度<br>快照文件的末尾：<br>Session Details (sid, timeout, ephemeralCount): 0x14f211584840000, 4000, 0 0x14f211399480001, 4000, 0</p><p>这里是说当前抓取快照文件的时间Zookeeper中Session的详情，有两个session超时时间都是4000毫秒ephemeral节点为0；</p><h3 id="日志清理"><a href="#日志清理" class="headerlink" title="日志清理"></a>日志清理</h3><p>在zookeeper 3.4.0以后，zookeeper提供了自动清理snapshot和事务日志功能</p><p>通过配置zoo.cfg下的autopurge.snapRetainCount和autopurge.purgeInterval这两个参数实现日志文件的定时清理。</p><ul><li>autopurge.snapRetainCount这个参数指定了需要保留的文件数目，默认保留3个；</li><li>autopurge.purgeInterval这个参数指定了清理频率，单位是小时，需要填写一个1或者更大的数据，默认0表示不开启自动清理功能。</li></ul><h2 id="日志管理配置修改"><a href="#日志管理配置修改" class="headerlink" title="日志管理配置修改"></a>日志管理配置修改</h2><p><strong>注意，如果Zookeeper集群只有3个实例，那么日志修改务必先修改follower 节点的配置，再修改leader 节点的配置，否则可能会导致问题。</strong></p><h3 id="配置集群运行日志并设置切割"><a href="#配置集群运行日志并设置切割" class="headerlink" title="配置集群运行日志并设置切割"></a>配置集群运行日志并设置切割</h3><p>操作文件：log4j.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">zookeeper.root.logger=INFO, ROLLINGFILE</span><br><span class="line"></span><br><span class="line">log4j.appender.ROLLINGFILE.MaxFileSize=100MB # 每个日志文件的最大size为100M</span><br><span class="line">log4j.appender.ROLLINGFILE.MaxBackupIndex=50 # 保留5个G的日志</span><br></pre></td></tr></table></figure><p>操作文件：bin/zkEnv.sh文件</p><p>将</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ]</span><br><span class="line">then</span><br><span class="line">    ZOO_LOG_DIR=&quot;.&quot;</span><br><span class="line">fi</span><br><span class="line">if [ &quot;x$&#123;ZOO_LOG4J_PROP&#125;&quot; = &quot;x&quot; ]</span><br><span class="line">then</span><br><span class="line">    ZOO_LOG4J_PROP=&quot;INFO,CONSOLE&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>修改成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ]</span><br><span class="line">then</span><br><span class="line">    ZOO_LOG_DIR=&quot;/home/zookeeper/2181/logs&quot;</span><br><span class="line">fi</span><br><span class="line">if [ &quot;x$&#123;ZOO_LOG4J_PROP&#125;&quot; = &quot;x&quot; ]</span><br><span class="line">then</span><br><span class="line">    ZOO_LOG4J_PROP=&quot;INFO,ROLLINGFILE&quot;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>注意：log4j.properties中的zookeeper.root.logger的值需要和zkEnv.sh文件的配置ZOO_LOG4J_PROP保持一致。</p><p>去除<strong>zookeeper.out 文件</strong></p><p>操作文件：bin/zkServer.sh</p><p>注释如下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># _ZOO_DAEMON_OUT=&quot;$ZOO_LOG_DIR/zookeeper.out&quot;</span><br></pre></td></tr></table></figure><p>将如下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup &quot;$JAVA&quot; &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \</span><br><span class="line">    -cp &quot;$CLASSPATH&quot; $JVMFLAGS $ZOOMAIN &quot;$ZOOCFG&quot; &gt; &quot;$_ZOO_DAEMON_OUT&quot; 2&gt;&amp;1 &lt; /dev/null &amp;</span><br></pre></td></tr></table></figure><p>修改为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup &quot;$JAVA&quot; &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \</span><br><span class="line">    -cp &quot;$CLASSPATH&quot; $JVMFLAGS $ZOOMAIN &quot;$ZOOCFG&quot; &gt;&amp;1 &lt; /dev/null &amp;</span><br></pre></td></tr></table></figure><p>然后重启zk即可</p><h3 id="事务日志-1"><a href="#事务日志-1" class="headerlink" title="事务日志"></a>事务日志</h3><p>操作文件：zoo.cfg</p><p>在zoo.cfg文件的中添加如下这行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataLogDir=/home/zookeeper/2181/data/event</span><br></pre></td></tr></table></figure><p>这部分是可选操作，默认不配置的话就会使用快照日志的配置。一般不进行额外配置</p><h3 id="快照日志-1"><a href="#快照日志-1" class="headerlink" title="快照日志"></a>快照日志</h3><p>操作文件：zoo.cfg</p><p>快照日志不需要额外的处理，默认的配置就是针对快照日志，也就是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/home/zookeeper/2181/data</span><br><span class="line">autopurge.snapRetainCount=10# 需要保留的文件数目，默认设置为3个；</span><br><span class="line">autopurge.purgeInterval=24# 清理频率，默认单位是小时</span><br></pre></td></tr></table></figure><h1 id="zk配置文件详解"><a href="#zk配置文件详解" class="headerlink" title="zk配置文件详解"></a>zk配置文件详解</h1><h3 id="zoo-cfg"><a href="#zoo-cfg" class="headerlink" title="zoo.cfg"></a>zoo.cfg</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@common001-dev.novalocal conf]$ cat zoo.cfg</span><br><span class="line"></span><br><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line"># synchronization phase can take</span><br><span class="line">initLimit=10</span><br><span class="line"># The number of ticks that can pass between</span><br><span class="line"># sending a request and getting an acknowledgement</span><br><span class="line">syncLimit=5</span><br><span class="line"># the directory where the snapshot is stored.</span><br><span class="line"># do not use /tmp for storage, /tmp here is just</span><br><span class="line"># example sakes.</span><br><span class="line">dataDir=/home/zookeeper/2181/data</span><br><span class="line"># the port at which the clients will connect</span><br><span class="line">clientPort=2181</span><br><span class="line"># the maximum number of client connections.</span><br><span class="line"># increase this if you need to handle more clients</span><br><span class="line">maxClientCnxns=0</span><br><span class="line">#</span><br><span class="line"># Be sure to read the maintenance section of the</span><br><span class="line"># administrator guide before turning on autopurge.</span><br><span class="line">#</span><br><span class="line"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span><br><span class="line">#</span><br><span class="line"># The number of snapshots to retain in dataDir</span><br><span class="line">autopurge.snapRetainCount=3</span><br><span class="line"># Purge task interval in hours</span><br><span class="line"># Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">autopurge.purgeInterval=1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">server.1=192.168.11.29:2888:3888</span><br><span class="line">server.2=192.168.11.32:2888:3888</span><br><span class="line">server.3=192.168.11.20:2888:3888</span><br></pre></td></tr></table></figure><h3 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h3><ul><li>tickTime 基本事件单元，以毫秒为单位。它用来控制心跳和超时，默认情况下最小的会话超时时间为两倍的 tickTime。</li><li>dataDir是存放内存数据库快照的位置；</li><li>dataLogDir 是事务日志目录；</li><li>clientPort是client连接的端口。</li><li>initLimit：这个配置项是用来配置 Zookeeper 接受客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过5个心跳的时间（也就是 tickTime）长度后 Zookeeper服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 5 * 2000=10 秒</li><li>syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是 2 * 2000=4 秒</li></ul><h3 id="server段"><a href="#server段" class="headerlink" title="server段"></a>server段</h3><p>server.X代表组成整个服务的机器，当服务启动时，会在数据目录下查找这个文件myid,这个文件中存有服务器的号码。</p><p>配置格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server.A=B：C：D</span><br></pre></td></tr></table></figure><ul><li>A 是一个数字，表示这个是第几号服务器；</li><li>B 是这个服务器的 ip 地址；</li><li>C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；</li><li>D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。</li></ul><p>除了修改 zoo.cfg 配置文件，集群模式下还要配置一个文件 myid，这个文件在 dataDir 目录下，这个文件里面就有一个数据就是 A 的值，Zookeeper 启动时会读取这个文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是那个 server。</p><h3 id="myid配置"><a href="#myid配置" class="headerlink" title="myid配置"></a>myid配置</h3><p>在dataDir所定义的目录下新建myid文件，本例中在/home/zookeeper/2181/data下新建myid文件，填入各主机之ID。如192.168.11.29主机的myid文件内容为1。</p><h3 id="maxClientCnxns"><a href="#maxClientCnxns" class="headerlink" title="maxClientCnxns"></a>maxClientCnxns</h3><p>maxClientCnxns默认值60，这个连接数不是针对某个ip的，请注意这个限制的使用范围</p><p>指的是单台客户端机器与单台zookeeper服务器之间的连接数限制，不是针对指定客户端IP，也不是zookeeper集群的连接数限制</p>]]></content>
    
    <summary type="html">
    
      zookeeper
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维架构" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/"/>
    
      <category term="分布式" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="zookeeper" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%88%86%E5%B8%83%E5%BC%8F/zookeeper/"/>
    
    
      <category term="zookeeper" scheme="http://yoursite.com/tags/zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>PostgreSQL安装部署及使用</title>
    <link href="http://yoursite.com/2019/03/27/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PostgreSQL%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%8F%8A%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2019/03/27/IT科学技术知识体系结构-Linux运维方向/数据库/PostgreSQL/PostgreSQL安装部署及使用/</id>
    <published>2019-03-27T14:52:37.000Z</published>
    <updated>2019-03-27T14:52:37.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h1 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h1><p>下载页面：<a href="https://www.postgresql.org/download/" target="_blank" rel="noopener">https://www.postgresql.org/download/</a></p><p>本文以安装version 11为例</p><h2 id="centos6"><a href="#centos6" class="headerlink" title="centos6"></a>centos6</h2><p>安装repo源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install https://download.postgresql.org/pub/repos/yum/11/redhat/rhel-6-x86_64/pgdg-centos11-11-2.noarch.rpm</span><br></pre></td></tr></table></figure><p>安装client</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install postgresql11</span><br></pre></td></tr></table></figure><p>安装server</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install postgresql11-server</span><br></pre></td></tr></table></figure><p>初始化数据库以及启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">service postgresql-11 initdb</span><br><span class="line">chkconfig postgresql-11 on</span><br><span class="line">service postgresql-11 start</span><br></pre></td></tr></table></figure><h2 id="centos7"><a href="#centos7" class="headerlink" title="centos7"></a>centos7</h2><p>安装repo源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install https://download.postgresql.org/pub/repos/yum/11/redhat/rhel-7-x86_64/pgdg-centos11-11-2.noarch.rpm</span><br></pre></td></tr></table></figure><p>安装client</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install postgresql11</span><br></pre></td></tr></table></figure><p>安装server</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install postgresql11-server</span><br></pre></td></tr></table></figure><p>初始化数据库以及启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/usr/pgsql-11/bin/postgresql-11-setup initdb</span><br><span class="line">systemctl enable postgresql-11</span><br><span class="line">systemctl start postgresql-11</span><br></pre></td></tr></table></figure><p>在启动之后，默认监控的端口是127.0.0.1:5432</p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>在初次安装后，默认生成一个名为<code>postgres</code>的数据库和一个名为<code>postgres</code>的数据库用户。这里需要注意的是，同时还生成了一个名为<code>postgres</code>的Linux系统用户。<br>有两种方式为PostgreSQL添加用户和添加数据库</p><h2 id="设置登录密码"><a href="#设置登录密码" class="headerlink" title="设置登录密码"></a>设置登录密码</h2><p>在启动之后，默认是没有密码的，因此我们首先要创建密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node010-dev data]# su - postgres</span><br><span class="line">-bash-4.2$ psql</span><br><span class="line">psql (11.2)</span><br><span class="line">输入 &quot;help&quot; 来获取帮助信息.</span><br><span class="line">postgres=# \password postgres</span><br></pre></td></tr></table></figure><p>注意，这里虽然设置了，但是不允许直接登录，需要进行一下设置</p><h3 id="配置监听ip"><a href="#配置监听ip" class="headerlink" title="配置监听ip"></a>配置监听ip</h3><p>编辑<code>/var/lib/pgsql/11/data/postgresql.conf</code> 文件</p><p>将<code>#listen_addresses = &#39;localhost&#39;</code>修改为<code>listen_addresses=&#39;*&#39;</code> （当然，此处‘*’也可以改为任何你想开放的服务器IP）</p><h3 id="配置允许登录"><a href="#配置允许登录" class="headerlink" title="配置允许登录"></a>配置允许登录</h3><p>默认情况下PostgreSQL不支持密码登录，在登录的时候会有如下报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@node010-dev data]# psql -U postgres</span><br><span class="line">psql: 致命错误:  对用户&quot;postgres&quot;的对等认证失败</span><br></pre></td></tr></table></figure><p>如需支持需要修改配置文件</p><p>编辑该文件，将未注释的peer都替换成为md5</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># vim /var/lib/pgsql/11/data/pg_hba.conf</span><br></pre></td></tr></table></figure><p>重启服务之后即可正常登录数据库</p><h3 id="配置允许远程登录"><a href="#配置允许远程登录" class="headerlink" title="配置允许远程登录"></a>配置允许远程登录</h3><p>在进行了上面的配置之后，是可以进行本地端的登录的，但是在远端使用连接命令，例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># psql -U devuser -d registry -h 192.168.1.196 -p 5432</span><br></pre></td></tr></table></figure><p>会产生报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">psql: 致命错误:  没有用于主机 &quot;192.168.1.219&quot;, 用户 &quot;devuser&quot;, 数据库 &quot;registry&quot;, SSL 关闭 的 pg_hba.conf 记录</span><br></pre></td></tr></table></figure><p>解决：在server端的pg_hba.conf文件末尾添加以下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># TYPE DATABASE USER CIDR-ADDRESS METHOD</span><br><span class="line">host    all             all              0.0.0.0/0              md5</span><br><span class="line"></span><br><span class="line">全网段换成指定的网段也可以</span><br></pre></td></tr></table></figure><p>然后重启服务即可。</p><h1 id="数据库使用"><a href="#数据库使用" class="headerlink" title="数据库使用"></a>数据库使用</h1><p>数据库使用首先需要psql -U postgres进入数据后再执行</p><h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><p>创建用户并设置密码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE USER dbuser WITH PASSWORD &apos;password&apos;;</span><br><span class="line">例如：</span><br><span class="line">postgres=# create user devuser with password &apos;Devuser123&apos;;</span><br><span class="line">postgres=# create user prouser with password &apos;Prouser123&apos;;</span><br></pre></td></tr></table></figure><p>注意：如果只设置了数据库用户，那么在系统的shell登录的时候需要使用-U指定登录用户，如果还在系统中useradd了同名用户，那么可以切换到这个同名用户然后执行psql即可。</p><h2 id="创建数据库及授权"><a href="#创建数据库及授权" class="headerlink" title="创建数据库及授权"></a>创建数据库及授权</h2><p>创建数据库并指定用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE exampledb OWNER dbuser;</span><br><span class="line">例如：</span><br><span class="line">postgres=# create database  registry owner devuser;</span><br><span class="line">postgres=# create database  registry owner prouser;</span><br></pre></td></tr></table></figure><p>进行用户授权，将指定数据库的所有权限都赋予dbuser，否则dbuser只能登录控制台，没有任何数据库操作权限。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GRANT ALL PRIVILEGES ON DATABASE exampledb to dbuser;</span><br><span class="line">例如：</span><br><span class="line">postgres=# grant all privileges on database registry to devuser;</span><br><span class="line">postgres=# grant all privileges on database registry to prouser;</span><br></pre></td></tr></table></figure><h2 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DROP DATABASE chado</span><br><span class="line">删除名为 chado 的数据库</span><br></pre></td></tr></table></figure><h2 id="登录数据库"><a href="#登录数据库" class="headerlink" title="登录数据库"></a>登录数据库</h2><p>添加了新用户和新数据库后，以新用户的身份登陆数据库。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">psql -U dbuser -d exampledb -h 127.0.0.1 -p 5432</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>psql命令存在简写形式，如果当前的Linux系统用户存在于postgreSQL中，则可以省略用户名，不需要使用-U参数，只需要其他参数。</li><li>PostgreSQL内部还存在与当前系统用户同名的数据库，则连数据库名都可以省略。</li></ul><h2 id="数据导入导出"><a href="#数据导入导出" class="headerlink" title="数据导入导出"></a>数据导入导出</h2><h3 id="从sql文件导入数据"><a href="#从sql文件导入数据" class="headerlink" title="从sql文件导入数据"></a>从sql文件导入数据</h3><p>命令格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">psql exampledb &lt; exampledb.sql</span><br></pre></td></tr></table></figure><h1 id="postgreSQL命令"><a href="#postgreSQL命令" class="headerlink" title="postgreSQL命令"></a>postgreSQL命令</h1><p>pg常用命令：</p><ul><li>\h：查看SQL命令的详细解释，例如 \h select</li><li>?：查看psql命令列表</li><li>\l：列出所有数据库</li><li>\c [database_name]：连接其他数据库</li><li>\d ：列出数据库的所有表</li><li>\du：列出所有数据库用户</li><li>\conninfo：列出连接</li></ul>]]></content>
    
    <summary type="html">
    
      PostgreSQL安装部署及使用
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="数据库" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="PostgreSQL" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/"/>
    
    
      <category term="PostgreSQL" scheme="http://yoursite.com/tags/PostgreSQL/"/>
    
  </entry>
  
  <entry>
    <title>NFS网络存储</title>
    <link href="http://yoursite.com/2019/03/25/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/NFS/NFS%E7%BD%91%E7%BB%9C%E5%AD%98%E5%82%A8/"/>
    <id>http://yoursite.com/2019/03/25/IT科学技术知识体系结构-Linux运维方向/网络知识及网络服务/网络服务/NFS/NFS网络存储/</id>
    <published>2019-03-25T08:35:33.000Z</published>
    <updated>2019-03-25T08:35:33.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>NFS（Network File System）即<a href="https://baike.baidu.com/item/%E7%BD%91%E7%BB%9C%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/9719420" target="_blank" rel="noopener">网络文件系统</a>，是FreeBSD支持的文件系统中的一种，它允许网络中的计算机之间通过TCP/IP网络共享资源。在NFS的应用中，本地NFS的客户端应用可以透明地读写位于远端NFS服务器上的文件，就像访问本地文件一样。</p><p><code>NFS</code>与<code>Samba</code>服务类似，但一般<code>Samba</code>服务常用于办公局域网共享，而<code>NFS</code>常用于互联网中小型网站集群架构后端的数据共享。</p><p><code>NFS</code>客户端将<code>NFS</code>服务端设置好的共享目录挂载到本地某个挂载点，对于客户端来说，共享的资源就相当于在本地的目录下。</p><h2 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h2><p><code>NFS</code>在传输数据时使用的端口是随机选择的，依赖<code>RPC</code>服务来与外部通信，要想正常使用<code>NFS</code>,就必须保证<code>RPC</code>正常。</p><h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><p><code>RPC</code>（<em>Remote Procedure Call Protocol</em>）远程过程调用协议。它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。<br> 在<code>NFS</code>服务端和<code>NFS</code>客户端之间，<code>RPC</code>服务扮演一个中介角色，<code>NFS</code>客户端通过<code>RPC</code>服务得知<code>NFS</code>服务端使用的端口，从而双方可以进行数据通信。</p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>当<code>NFS</code>服务端启动服务时会随机取用若干端口，并主动向<code>RPC</code>服务注册取用相关端口及功能信息，这样，<code>RPC</code>服务就知道<code>NFS</code>每个端口对应的的<code>NFS</code>功能了，然后<code>RPC</code>服务使用固定的111端口来监听<code>NFS</code>客户端提交的请求，并将正确的<code>NFS</code>端口信息回复给请求的<code>NFS</code>客户端。这样，<code>NFS</code>客户就可以与<code>NFS</code>服务端进行数据传输了。</p><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><h2 id="服务端部署"><a href="#服务端部署" class="headerlink" title="服务端部署"></a>服务端部署</h2><h3 id="安装nfs-与-rpc-相关软件包"><a href="#安装nfs-与-rpc-相关软件包" class="headerlink" title="安装nfs 与 rpc 相关软件包"></a>安装nfs 与 rpc 相关软件包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum -y install nfs-utils rpcbind</span><br></pre></td></tr></table></figure><p>注意：在centos7下其实只需要安装nfs-utils即可，因为rpcbind 属于它的依赖，yum会自动安装上。</p><p>根据官网说明 <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/ch-nfs" target="_blank" rel="noopener">Chapter 8. Network File System (NFS) - Red Hat Customer Portal</a>，CentOS 7.4 以后，支持 NFS v4.2 不需要 rpcbind 了，但是如果客户端只支持 NFC v3 则需要 rpcbind 这个服务。</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h4><p>NFS默认的配置文件是 ：/etc/exports </p><p><strong>配置格式为：</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">NFS共享目录绝对路径    NFS客户端1地址范围（参数）NFS客户端2地址范围（参数）.....</span><br><span class="line"></span><br><span class="line">注意：客户端IP范围配置中，* 代表所有，即没有限制。</span><br></pre></td></tr></table></figure><p><strong>常用参数：</strong></p><ul><li>rw             read-write   读写</li><li>ro             read-only    只读</li><li>sync           请求或写入数据时，数据同步写入到NFS server的硬盘后才返回。数据安全，但性能降低了</li><li>async          优先将数据保存到内存，硬盘有空档时再写入硬盘，效率更高，但可能造成数据丢失。</li><li>root_squash    当NFS 客户端使用root 用户访问时，映射为NFS 服务端的匿名用户。NFS为了安全考虑，默认会将root账户降权为普通匿名账户。所以，如果不进行配置的话，这个将会是默认值</li><li>no_root_squash 当NFS 客户端使用root 用户访问时，映射为NFS 服务端的root 用户</li><li>all_squash     不论NFS 客户端使用任何帐户，均映射为NFS 服务端的匿名用户</li></ul><h4 id="配置案例"><a href="#配置案例" class="headerlink" title="配置案例"></a>配置案例</h4><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># vim  /etc/exports</span><br><span class="line">/sharedir 192.168.0.0/16(rw,sync,root_squash)</span><br></pre></td></tr></table></figure><p>创建共享目录以及测试文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /sharedir</span><br><span class="line">touch /sharedir/Welcom.file</span><br><span class="line">echo &quot;Welcome to onlylink.top&quot; &gt;/sharedir/Welcom.file</span><br></pre></td></tr></table></figure><p>给共享目录添加权限：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chown -R nfsnobody.nfsnobody /sharedir/</span><br></pre></td></tr></table></figure><p>把NFS共享目录赋予 NFS默认用户nfsnobody用户和用户组权限，如不设置，会导致NFS客户端无法在挂载好的共享目录中写入数据</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>启动 rpc服务并设置成开机自启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># /etc/init.d/rpcbind start</span><br><span class="line"># chkconfig rpcbind on</span><br></pre></td></tr></table></figure><p>启动 nfs服务并设置成开机自启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># /etc/init.d/nfs start</span><br><span class="line"># chkconfig nfs on</span><br></pre></td></tr></table></figure><p>在centos 7下的操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># systemctl enable rpcbind</span><br><span class="line"># systemctl enable nfs</span><br><span class="line"></span><br><span class="line"># systemctl start rpcbind</span><br><span class="line"># systemctl start nfs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">如果开启了防火墙，还需要进行设置</span><br><span class="line"># firewall-cmd --zone=public --permanent --add-service=rpc-bind</span><br><span class="line">success</span><br><span class="line"># firewall-cmd --zone=public --permanent --add-service=mountd</span><br><span class="line">success</span><br><span class="line"># firewall-cmd --zone=public --permanent --add-service=nfs</span><br><span class="line">success</span><br><span class="line"># firewall-cmd --reload</span><br><span class="line">success</span><br></pre></td></tr></table></figure><h2 id="客户端部署"><a href="#客户端部署" class="headerlink" title="客户端部署"></a>客户端部署</h2><h3 id="安装nfs-与-rpc-相关软件包-1"><a href="#安装nfs-与-rpc-相关软件包-1" class="headerlink" title="安装nfs 与 rpc 相关软件包"></a>安装nfs 与 rpc 相关软件包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum -y install nfs-utils rpcbind</span><br></pre></td></tr></table></figure><p>注意：在centos7下其实只需要安装nfs-utils即可，因为rpcbind 属于它的依赖，yum会自动安装上。</p><h3 id="配置启动"><a href="#配置启动" class="headerlink" title="配置启动"></a>配置启动</h3><p>设置 rpcbind 服务的开机启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#  systemctl enable rpcbind</span><br></pre></td></tr></table></figure><p>启动 NFS 服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#  systemctl start rpcbind</span><br></pre></td></tr></table></figure><p>注意：</p><ul><li>客户端不需要打开防火墙，因为客户端时发出请求方，网络能连接到服务端即可。 </li><li>客户端也不需要开启 NFS 服务，因为不共享目录。</li></ul><h2 id="客户端挂载服务端"><a href="#客户端挂载服务端" class="headerlink" title="客户端挂载服务端"></a>客户端挂载服务端</h2><p>客户端连接服务端其实就是正常的挂载操作，只不过对象从本地变成了远端</p><p>先查服务端的共享目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># showmount -e 192.168.0.101</span><br><span class="line">Export list for 192.168.0.101:</span><br><span class="line">/data 192.168.0.0/24</span><br></pre></td></tr></table></figure><p>在客户端创建目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># mkdir /data</span><br></pre></td></tr></table></figure><p>挂载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># mount -t nfs 192.168.0.101:/data /data</span><br></pre></td></tr></table></figure><p>当然，可以写到fstab中，设置为开机自启动。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># cat /etc/fstab</span><br><span class="line">在文件末尾添加一下内容</span><br><span class="line"></span><br><span class="line">192.168.0.101:/data /data nfs defaults 0 0</span><br></pre></td></tr></table></figure><h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><ul><li><p>showmount -e 服务器的IP地址        #查看服务端的的共享配置</p></li><li><p>mount  -t nfs IP地址:/目录   /目录             # 挂载</p><p>例如：mount 192.168.4.5:/common  /common</p></li><li><p>exportfs</p><ul><li>-a：表示全部挂载或者全部卸载</li><li>-r：表示重新挂载</li><li>-u：表示卸载某一个目录</li><li>-v：表示显示共享目录</li></ul></li></ul><h1 id="其他配置案例"><a href="#其他配置案例" class="headerlink" title="其他配置案例"></a>其他配置案例</h1><h2 id="案例1"><a href="#案例1" class="headerlink" title="案例1"></a>案例1</h2><p>共享/common目录，192.168.0.0网络的主机均可以只读访问</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#vim  /etc/exports</span><br><span class="line"></span><br><span class="line">/common 192.168.0.0/24(ro)</span><br></pre></td></tr></table></figure><h2 id="案例2"><a href="#案例2" class="headerlink" title="案例2"></a>案例2</h2><p>192.168.0.1可以读写的方式访问/abc,<br>192.168.0.2可以只读的方式访问/abc</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/abc    192.168.0.1(rw) 192.168.0.2(ro)</span><br></pre></td></tr></table></figure><h2 id="案例3"><a href="#案例3" class="headerlink" title="案例3"></a>案例3</h2><p>任何人均可以只读的形式访问/dvd</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/dvd    *(ro)</span><br></pre></td></tr></table></figure><h2 id="案例4-root权限管理"><a href="#案例4-root权限管理" class="headerlink" title="案例4-root权限管理"></a>案例4-root权限管理</h2><p>客户端使用root登录系统，访问服务器的NFS，则会以root身份访问NFS共享，<br>如果客户端系统使用tom登录，访问服务器的NFS，则会以tom身份访问NFS共享。</p><p>实现客户端可读写的方式：</p><ol><li>修改目录本身的权限（exports已经设置好了rw）</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod  777  目录名称 </span><br><span class="line">或者其他值，但是需要读写</span><br></pre></td></tr></table></figure><ol><li>仅让root可以写，则需要修改exports,让NFS不对root进行降权</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#vim  /etc/exports</span><br><span class="line">/abc*(rw,no_root_squash)</span><br><span class="line"></span><br><span class="line">#service nfs  restart</span><br></pre></td></tr></table></figure><p>客户端使用root登录系统后，cd到NFS共享目录，则可以获得root权限</p><h2 id="案例5-触发挂载"><a href="#案例5-触发挂载" class="headerlink" title="案例5-触发挂载"></a>案例5-触发挂载</h2><p>在客户端实现触发挂载NFS服务器共享的/usr/src目录到本地/data/nfsdir</p><ol><li><p>安装软件包</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># rpm -q autofs</span><br><span class="line"># yum -y install autofs</span><br></pre></td></tr></table></figure></li></ol><ol><li><p>修改主配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># grep mnt /etc/auto.master </span><br><span class="line">/data/etc/auto.data</span><br><span class="line"></span><br><span class="line"># cat /etc/auto.data</span><br><span class="line">nfsdir2-fstype=nfs,rw192.168.10.10:/usr/src</span><br></pre></td></tr></table></figure></li><li><p>启动服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># service autofs restart</span><br><span class="line"># chkconfig autofs on</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      NFS网络存储
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="网络知识及网络服务" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="网络服务" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="NFS" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/NFS/"/>
    
    
      <category term="NFS网络存储" scheme="http://yoursite.com/tags/NFS%E7%BD%91%E7%BB%9C%E5%AD%98%E5%82%A8/"/>
    
  </entry>
  
  <entry>
    <title>python多线程</title>
    <link href="http://yoursite.com/2019/03/25/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/python%E5%A4%9A%E7%BA%BF%E7%A8%8B/python%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/03/25/IT科学技术知识体系结构-Linux运维方向/编程开发/Python/python多线程/python多线程/</id>
    <published>2019-03-25T03:10:25.000Z</published>
    <updated>2019-03-25T03:10:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考文献：</p><ul><li><a href="http://www.runoob.com/python/python-multithreading.html" target="_blank" rel="noopener">python多线程</a></li></ul><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>多线程类似于同时执行多个不同程序，多线程运行有如下优点：</p><ul><li>使用线程可以把占据长时间的程序中的任务放到后台去处理。</li><li>用户界面可以更加吸引人，这样比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度</li><li>程序的运行速度可能加快</li><li>在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下我们可以释放一些珍贵的资源如内存占用等等。</li></ul><p>线程在执行过程中与进程还是有区别的。每个独立的进程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。</p><p>每个线程都有他自己的一组CPU寄存器，称为线程的上下文，该上下文反映了线程上次运行该线程的CPU寄存器的状态。</p><p>指令指针和堆栈指针寄存器是线程上下文中两个最重要的寄存器，线程总是在进程得到上下文中运行的，这些地址都用于标志拥有线程的进程地址空间中的内存。</p><ul><li>线程可以被抢占（中断）。</li><li>在其他线程正在运行时，线程可以暂时搁置（也称为睡眠） – 这就是线程的退让。</li></ul>]]></content>
    
    <summary type="html">
    
      python多线程
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="编程开发" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/"/>
    
      <category term="python多线程" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/python%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
    
      <category term="python多线程" scheme="http://yoursite.com/tags/python%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>Centos7的firewalld配置</title>
    <link href="http://yoursite.com/2019/03/15/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/%E9%98%B2%E7%81%AB%E5%A2%99/Centos7%E7%9A%84firewalld%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2019/03/15/IT科学技术知识体系结构-Linux运维方向/运维安全/防火墙/Centos7的firewalld配置/</id>
    <published>2019-03-15T03:11:00.000Z</published>
    <updated>2019-03-15T03:11:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考文献：</p><ul><li><a href="https://linux.cn/article-8098-1.html" target="_blank" rel="noopener">CentOS 上的 FirewallD 简明指南</a></li></ul><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p><a href="http://www.firewalld.org/" target="_blank" rel="noopener">FirewallD</a> 是 iptables 的前端控制器，用于实现持久的网络流量规则。它提供命令行和图形界面，在大多数 Linux 发行版的仓库中都有。与直接控制 iptables 相比，使用 FirewallD 有两个主要区别：</p><ol><li>FirewallD 使用区域和服务而不是链式规则。</li><li>它动态管理规则集，允许更新规则而不破坏现有会话和连接。</li></ol><p>注意：FirewallD 是 iptables 的一个封装，可以让你更容易地管理 iptables 规则 - 它并<em>不是</em> iptables 的替代品。虽然 iptables 命令仍可用于 FirewallD，但建议使用 FirewallD 时仅使用 FirewallD 命令。</p><h1 id="启停查看相关命令"><a href="#启停查看相关命令" class="headerlink" title="启停查看相关命令"></a>启停查看相关命令</h1><p>1、 启动服务，并在系统引导时启动该服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start firewalld</span><br><span class="line">sudo systemctl enable firewalld</span><br></pre></td></tr></table></figure><p>要停止并禁用：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop firewalld</span><br><span class="line">sudo systemctl disable firewalld</span><br></pre></td></tr></table></figure><p>2、 检查防火墙状态。输出应该是 <code>running</code> 或者 <code>not running</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --state</span><br></pre></td></tr></table></figure><p>3、 要查看 FirewallD 守护进程的状态：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl status firewalld</span><br></pre></td></tr></table></figure><p>示例输出</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewalld.service - firewalld - dynamic firewall daemon   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled)   Active: active (running) since Wed 2015-09-02 18:03:22 UTC; 1min 12s ago Main PID: 11954 (firewalld)   CGroup: /system.slice/firewalld.service   └─11954 /usr/bin/python -Es /usr/sbin/firewalld --nofork --nopid</span><br></pre></td></tr></table></figure><p>4、 重新加载 FirewallD 配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><h1 id="配置firewalld"><a href="#配置firewalld" class="headerlink" title="配置firewalld"></a>配置firewalld</h1><p>FirewallD 使用 XML 进行配置。除非是非常特殊的配置，你不必处理它们，而应该使用 <code>firewall-cmd</code>。</p><p>配置文件位于两个目录中：</p><ul><li><code>/usr/lib/FirewallD</code> 下保存默认配置，如默认区域和公用服务。 避免修改它们，因为每次 firewall 软件包更新时都会覆盖这些文件。</li><li><code>/etc/firewalld</code> 下保存系统配置文件。 这些文件将覆盖默认配置。</li></ul><h2 id="配置集"><a href="#配置集" class="headerlink" title="配置集"></a>配置集</h2><p>FirewallD 使用两个<em>配置集</em>：“运行时”和“持久”。 在系统重新启动或重新启动 FirewallD 时，不会保留运行时的配置更改，而对持久配置集的更改不会应用于正在运行的系统。</p><p><strong>小总结：</strong>2种配置方式，当前的实时生效和永久生效，实时是直接写入到内存中，永久是写入到配置文件当中</p><p>默认情况下，<code>firewall-cmd</code> 命令适用于运行时配置，但使用 <code>--permanent</code> 标志将保存到持久配置中。要添加和激活持久性规则，你可以使用两种方法之一。</p><p>1、 将规则同时添加到持久规则集和运行时规则集中。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-service=http --permanentsudo firewall-cmd --zone=public --add-service=http</span><br></pre></td></tr></table></figure><p>2、 将规则添加到持久规则集中并重新加载 FirewallD。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-service=http --permanentsudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><p><strong>特别注意</strong>：<code>reload</code> 命令会删除所有运行时配置并应用永久配置。因为 firewalld 动态管理规则集，所以它不会破坏现有的连接和会话。</p><h2 id="防火墙的区域"><a href="#防火墙的区域" class="headerlink" title="防火墙的区域"></a>防火墙的区域</h2><p>“区域”是针对给定位置或场景（例如家庭、公共、受信任等）可能具有的各种信任级别的预构建规则集。不同的区域允许不同的网络服务和入站流量类型，而拒绝其他任何流量。 首次启用 FirewallD 后，<code>public</code> 将是默认区域。</p><p>区域也可以用于不同的网络接口。例如，要分离内部网络和互联网的接口，你可以在 <code>internal</code> 区域上允许 DHCP，但在<code>external</code> 区域仅允许 HTTP 和 SSH。未明确设置为特定区域的任何接口将添加到默认区域。</p><p>要找到默认区域： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-default-zone</span><br></pre></td></tr></table></figure><p>要修改默认区域：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --set-default-zone=internal</span><br></pre></td></tr></table></figure><p>要查看你网络接口使用的区域：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-active-zones</span><br></pre></td></tr></table></figure><p>示例输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public  interfaces: eth0</span><br></pre></td></tr></table></figure><p>要得到特定区域的所有配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --list-all</span><br></pre></td></tr></table></figure><p>示例输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public (default, active)  interfaces: ens160  sources:  services: dhcpv6-client http ssh  ports: 12345/tcp  masquerade: no  forward-ports:  icmp-blocks:  rich rules:</span><br></pre></td></tr></table></figure><p>要得到所有区域的配置： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --list-all-zones</span><br></pre></td></tr></table></figure><p>示例输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">block  interfaces:  sources:  services:  ports:  masquerade: no  forward-ports:  icmp-blocks:  rich rules:  ...work  interfaces:  sources:  services: dhcpv6-client ipp-client ssh  ports:  masquerade: no  forward-ports:  icmp-blocks:  rich rules:</span><br></pre></td></tr></table></figure><h2 id="与服务一起使用"><a href="#与服务一起使用" class="headerlink" title="与服务一起使用"></a>与服务一起使用</h2><p>FirewallD 可以根据特定网络服务的预定义规则来允许相关流量。你可以创建自己的自定义系统规则，并将它们添加到任何区域。 默认支持的服务的配置文件位于 <code>/usr/lib /firewalld/services</code>，用户创建的服务文件在 <code>/etc/firewalld/services</code> 中。</p><p>要查看默认的可用服务：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --get-services</span><br></pre></td></tr></table></figure><p>比如，要启用或禁用 HTTP 服务： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-service=http --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --remove-service=http --permanent</span><br></pre></td></tr></table></figure><h2 id="与端口一起使用"><a href="#与端口一起使用" class="headerlink" title="与端口一起使用"></a>与端口一起使用</h2><p>比如：允许或者禁用 12345 端口的 TCP 流量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-port=12345/tcp --permanent</span><br><span class="line">sudo firewall-cmd --zone=public --remove-port=12345/tcp --permanent</span><br></pre></td></tr></table></figure><h2 id="端口转发"><a href="#端口转发" class="headerlink" title="端口转发"></a>端口转发</h2><p>下面是在同一台服务器上将 80 端口的流量转发到 12345 端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=&quot;public&quot; --add-forward-port=port=80:proto=tcp:toport=12345</span><br></pre></td></tr></table></figure><p>要将端口转发到另外一台服务器上：</p><p>1、 在需要的区域中激活 masquerade。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-masquerade</span><br></pre></td></tr></table></figure><p>2、 添加转发规则。例子中是将本地的 80 端口的流量转发到 IP 地址为 ：123.456.78.9 的<em>远程服务器上的</em>  8080 端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=&quot;public&quot; --add-forward-port=port=80:proto=tcp:toport=8080:toaddr=123.456.78.9</span><br></pre></td></tr></table></figure><p>要删除规则，用 <code>--remove</code> 替换 <code>--add</code>。比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --remove-masquerade</span><br></pre></td></tr></table></figure><h2 id="用-FirewallD-构建规则集"><a href="#用-FirewallD-构建规则集" class="headerlink" title="用 FirewallD 构建规则集"></a>用 FirewallD 构建规则集</h2><p>例如，以下是如何使用 FirewallD 为你的服务器配置基本规则（如果您正在运行 web 服务器）。</p><ol><li>将 <code>eth0</code> 的默认区域设置为 <code>dmz</code>。 在所提供的默认区域中，dmz（非军事区）是最适合于这个程序的，因为它只允许 SSH 和 ICMP。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --set-default-zone=dmzsudo firewall-cmd --zone=dmz --add-interface=eth0</span><br></pre></td></tr></table></figure><p>2、 把 HTTP 和 HTTPS 添加永久的服务规则到 dmz 区域中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=dmz --add-service=http --permanentsudo firewall-cmd --zone=dmz --add-service=https --permanent</span><br></pre></td></tr></table></figure><p> 3、 重新加载 FirewallD 让规则立即生效：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --reload</span><br></pre></td></tr></table></figure><p> 如果你运行 <code>firewall-cmd --zone=dmz --list-all</code>， 会有下面的输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dmz (default)  interfaces: eth0  sources:  services: http https ssh  ports:  masquerade: no  forward-ports:  icmp-blocks:  rich rules:</span><br></pre></td></tr></table></figure><p> 这告诉我们，<code>dmz</code> 区域是我们的默认区域，它被用于 <code>eth0</code> 接口中所有网络的源地址和端口。 允许传入 HTTP（端口 80）、HTTPS（端口 443）和 SSH（端口 22）的流量，并且由于没有 IP 版本控制的限制，这些适用于 IPv4 和 IPv6。 不允许IP 伪装以及端口转发。 我们没有 ICMP 块，所以 ICMP 流量是完全允许的。没有丰富Rich规则，允许所有出站流量。</p><h1 id="高级配置"><a href="#高级配置" class="headerlink" title="高级配置"></a>高级配置</h1><p>服务和端口适用于基本配置，但对于高级情景可能会限制较多。 Rich规则和Direct接口允许你为任何端口、协议、地址和操作向任何区域 添加完全自定义的防火墙规则。</p><h2 id="rich规则"><a href="#rich规则" class="headerlink" title="rich规则"></a>rich规则</h2><p>rich规则的语法有很多，但都完整地记录在 <a href="https://jpopelka.fedorapeople.org/firewalld/doc/firewalld.richlanguage.html" target="_blank" rel="noopener">firewalld.richlanguage(5)</a> 的手册页中（或在终端中 <code>man firewalld.richlanguage</code>）。 使用 <code>--add-rich-rule</code>、<code>--list-rich-rules</code> 、 <code>--remove-rich-rule</code> 和 firewall-cmd 命令来管理它们。</p><p>这里有一些常见的例子：</p><p>允许来自主机 192.168.0.14 的所有 IPv4 流量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=192.168.0.14 accept&apos;</span><br></pre></td></tr></table></figure><p>拒绝来自主机 192.168.1.10 到 22 端口的 IPv4 的 TCP 流量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=&quot;192.168.1.10&quot; port port=22 protocol=tcp reject&apos;</span><br></pre></td></tr></table></figure><p>允许来自主机 10.1.0.3 到 80 端口的 IPv4 的 TCP 流量，并将流量转发到 6532 端口上。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-rich-rule &apos;rule family=ipv4 source address=10.1.0.3 forward-port port=80 protocol=tcp to-port=6532&apos;</span><br></pre></td></tr></table></figure><p>将主机 172.31.4.2 上 80 端口的 IPv4 流量转发到 8080 端口（需要在区域上激活 masquerade）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --zone=public --add-rich-rule &apos;rule family=ipv4 forward-port port=80 protocol=tcp to-port=8080 to-addr=172.31.4.2&apos;</span><br></pre></td></tr></table></figure><p>列出你目前的丰富规则：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --list-rich-rules</span><br></pre></td></tr></table></figure><h1 id="实例案例"><a href="#实例案例" class="headerlink" title="实例案例"></a>实例案例</h1><p>IDC机房机器，有以下需求：</p><ul><li>ssh只允许内网网段访问，拒绝所有其他网段</li><li>开放指定的端口（8080、9000）给所有网段</li></ul><p>注意，因为使用的是public这个zone，所有在配置都配置完成之后，需要将默认的ssh服务remove掉</p><p>具体的命令如下：</p><ul><li>添加内网网段</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">即时生效</span><br><span class="line"></span><br><span class="line"># firewall-cmd   --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=172.24.0.0/16 accept&apos;</span><br><span class="line"></span><br><span class="line">#firewall-cmd   --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=10.11.0.0/16 accept&apos;</span><br><span class="line"></span><br><span class="line">#firewall-cmd   --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=10.11.10.0/24 accept&apos;</span><br><span class="line"></span><br><span class="line">永久生效</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=172.24.0.0/16 accept&apos;</span><br><span class="line"></span><br><span class="line">#firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=10.11.0.0/16 accept&apos;</span><br><span class="line"></span><br><span class="line">#firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=10.10.10.0/24 accept&apos;</span><br></pre></td></tr></table></figure><ul><li>开放指定端口</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">即时生效</span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=60.191.68.43 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=60.191.68.43 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=183.129.221.128/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=183.129.221.128/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=122.224.251.144/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=122.224.251.144/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">永久生效</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=60.191.68.43 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=60.191.68.43 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=183.129.221.128/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=183.129.221.128/29 port port=9000 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=122.224.251.144/29 port port=8080 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=122.224.251.144/29 port port=9000 protocol=tcp accept&apos;</span><br></pre></td></tr></table></figure><ul><li>删除ssh服务</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># firewall-cmd --zone=public --remove-service=ssh </span><br><span class="line"></span><br><span class="line"># firewall-cmd --zone=public --remove-service=ssh --permanent</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># firewall-cmd --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=443 protocol=tcp accept&apos;</span><br><span class="line"></span><br><span class="line"># firewall-cmd --permanent --zone=public --add-rich-rule &apos;rule family=&quot;ipv4&quot; source address=101.68.94.0/29 port port=443 protocol=tcp accept&apos;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      Centos7的firewalld配置
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维安全" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/"/>
    
      <category term="防火墙" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/%E9%98%B2%E7%81%AB%E5%A2%99/"/>
    
    
      <category term="firewalld" scheme="http://yoursite.com/tags/firewalld/"/>
    
  </entry>
  
  <entry>
    <title>centos升级openssh</title>
    <link href="http://yoursite.com/2019/02/19/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/centos%E5%8D%87%E7%BA%A7openssh/"/>
    <id>http://yoursite.com/2019/02/19/IT科学技术知识体系结构-Linux运维方向/Linux系统管理/centos升级openssh/</id>
    <published>2019-02-19T02:04:55.000Z</published>
    <updated>2019-02-19T02:04:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>主要对象分为2个版本，一个是centos6.8，一个是centos7.3和7.4.</p><h1 id="升级原因"><a href="#升级原因" class="headerlink" title="升级原因"></a>升级原因</h1><p>7.4以下openssh版本存在严重漏洞：</p><p>1.OpenSSH 远程权限提升漏洞(CVE-2016-10010)<br>2.OpenSSH J-PAKE授权问题漏洞(CVE-2010-4478)<br>3.Openssh MaxAuthTries限制绕过漏洞(CVE-2015-5600)<br>OpenSSL&gt;=1.0.1可以不用升级OpenSSL</p><h1 id="当前版本"><a href="#当前版本" class="headerlink" title="当前版本"></a>当前版本</h1><p><strong>6.8</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@app018-dev.novalocal ~]# cat /etc/redhat-release</span><br><span class="line">CentOS release 6.8 (Final)</span><br><span class="line">[root@app018-dev.novalocal ~]# rpm -qa | grep openssh</span><br><span class="line">openssh-clients-5.3p1-118.1.el6_8.x86_64</span><br><span class="line">openssh-5.3p1-118.1.el6_8.x86_64</span><br><span class="line">openssh-server-5.3p1-118.1.el6_8.x86_64</span><br></pre></td></tr></table></figure><p><strong>7</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">de</span><br></pre></td></tr></table></figure><p>可以看到，当前的版本是：</p><ul><li>centos6.8：5.3p1</li><li>centos7：7.4p1</li></ul><h1 id="目标版本"><a href="#目标版本" class="headerlink" title="目标版本"></a>目标版本</h1><p>要求的目标版本是7.5及以上</p><p>在当前时间节点（2019年02月19日10:09:56），最高版本为：<a href="https://www.openssh.com/txt/release-7.9" target="_blank" rel="noopener">OpenSSH 7.9</a>/<a href="https://www.openssh.com/txt/release-7.9" target="_blank" rel="noopener">7.9p1</a> (2018-10-19)</p><p>在这里，我们选择升级到最新版本</p><p>整个的升级操作是server和client都要升级</p><h1 id="实际操作"><a href="#实际操作" class="headerlink" title="实际操作"></a>实际操作</h1><h2 id="依赖关系"><a href="#依赖关系" class="headerlink" title="依赖关系"></a>依赖关系</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum -y install gcc pam-devel zlib-devel openssl openssl-devel wget telnet-server* telnet</span><br></pre></td></tr></table></figure><h2 id="安装及配置telnet"><a href="#安装及配置telnet" class="headerlink" title="安装及配置telnet"></a>安装及配置telnet</h2><p><strong>安装</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum -y install telnet-server* telnet</span><br></pre></td></tr></table></figure><p><strong>配置</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># vi /etc/xinetd.d/telnet </span><br><span class="line">将其中disable字段的yes改为no以启用telnet服务 </span><br><span class="line"></span><br><span class="line"># mv /etc/securetty /etc/securetty.old    #允许root用户通过telnet登录 </span><br><span class="line"></span><br><span class="line"># service xinetd start                    #启动telnet服务 </span><br><span class="line"></span><br><span class="line"># chkconfig xinetd on                    #使telnet服务开机启动，避免升级过程中服务器意外重启后无法远程登录系统</span><br></pre></td></tr></table></figure><p>在centos7下的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># mv /etc/securetty /etc/securetty.old </span><br><span class="line"></span><br><span class="line"># systemctl start telnet.socket</span><br><span class="line"></span><br><span class="line"># systemctl enable telnet.socket</span><br></pre></td></tr></table></figure><p><strong>测试</strong></p><p>测试telnet能否正常登入系统</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@common001-dev.novalocal ~]# telnet 192.168.11.27</span><br></pre></td></tr></table></figure><h2 id="安装ssh"><a href="#安装ssh" class="headerlink" title="安装ssh"></a>安装ssh</h2><p><strong>下载软件包</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># wget https://cdn.openbsd.org/pub/OpenBSD/OpenSSH/portable/openssh-7.9p1.tar.gz</span><br></pre></td></tr></table></figure><p><strong>解压安装</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># tar zxvf openssh-7.4p1.tar.gz</span><br><span class="line"># cd openssh-7.4p1</span><br><span class="line"># ./configure</span><br><span class="line"># make</span><br><span class="line"># make install</span><br></pre></td></tr></table></figure><p>我们使用默认的安装，不加指定路径，在安装完毕之后sshd将会安装到/usr/local/sbin/下。而ssh、ssh-keygen等都会安装到/usr/local/bin目录下。</p><p>而操作系统的PATH路径是优先选择/usr/local/的，所以普通命令都可以使用到最新的，但是server端的sshd我们还需要做额外的配置</p><p><strong>修改sshd启动脚本</strong></p><p>将sshd启动脚本中的sshd命令路径修改为指定版本的路径：</p><p>centos6下就一个启动脚本文件的内容需要替换</p><ul><li>/etc/init.d/sshd</li></ul><p>#  vim /etc/init.d/sshd</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">将</span><br><span class="line">KEYGEN=/usr/bin/ssh-keygen</span><br><span class="line">SSHD=/usr/sbin/sshd</span><br><span class="line"></span><br><span class="line">修改成为：</span><br><span class="line">KEYGEN=/usr/local/bin/ssh-keygen</span><br><span class="line">SSHD=/usr/local/sbin/sshd</span><br></pre></td></tr></table></figure><p>centos7下有一下几个文件的内容需要替换</p><ul><li>/usr/lib/systemd/system/sshd-keygen.service</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">将</span><br><span class="line">ExecStart=/usr/sbin/sshd-keygen</span><br><span class="line"></span><br><span class="line">替换为：</span><br><span class="line">ExecStart=/usr/local/bin/sshd-keygen</span><br></pre></td></tr></table></figure><ul><li>/usr/lib/systemd/system/sshd.service</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">将</span><br><span class="line">ExecStart=/usr/sbin/sshd $OPTIONS</span><br><span class="line"></span><br><span class="line">替换为：</span><br><span class="line">ExecStart=/usr/local/sbin/sshd $OPTIONS</span><br></pre></td></tr></table></figure><ul><li>/usr/lib/systemd/system/sshd@.service</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">将</span><br><span class="line">ExecStart=-/usr/sbin/sshd -i $OPTIONS</span><br><span class="line"></span><br><span class="line">替换为：</span><br><span class="line">ExecStart=-/usr/local/sbin/sshd -i $OPTIONS</span><br></pre></td></tr></table></figure><h2 id="重启服务"><a href="#重启服务" class="headerlink" title="重启服务"></a>重启服务</h2><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><h2 id="防火墙问题"><a href="#防火墙问题" class="headerlink" title="防火墙问题"></a>防火墙问题</h2><p>有防火墙的要添加一条23端口的记录</p>]]></content>
    
    <summary type="html">
    
      centos升级openssh
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux系统管理" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"/>
    
    
      <category term="centos升级openssh" scheme="http://yoursite.com/tags/centos%E5%8D%87%E7%BA%A7openssh/"/>
    
  </entry>
  
  <entry>
    <title>redis集群</title>
    <link href="http://yoursite.com/2019/02/16/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E9%9B%86%E7%BE%A4/redis%E9%9B%86%E7%BE%A4/"/>
    <id>http://yoursite.com/2019/02/16/IT科学技术知识体系结构-Linux运维方向/数据库/Redis/Redis集群/redis集群/</id>
    <published>2019-02-16T03:20:59.000Z</published>
    <updated>2019-02-16T03:20:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="数据分布"><a href="#数据分布" class="headerlink" title="数据分布"></a>数据分布</h2><p>常见的数据分布方式有：哈希分区和顺序分区。Redis集群使用的是哈希分析，因此这里主要关注哈希分区。</p><p>Hash（哈希）也叫散列，指的是一类特征，也就是把任意长度的<a href="https://baike.baidu.com/item/%E8%BE%93%E5%85%A5/5481954" target="_blank" rel="noopener">输入</a>（又叫做预映射pre-image）通过散列算法变换成固定长度的<a href="https://baike.baidu.com/item/%E8%BE%93%E5%87%BA/11056752" target="_blank" rel="noopener">输出</a>，该输出就是散列值或者叫hash值。</p><p>因此只要是符合这个特征的方式（因为会存在很多不同的算法实现）都可以叫做哈希方式。</p><p>常见的哈希分区主要有以下几种（Redis集群使用的是第三种）：</p><ul><li><p>节点取余。使用特定的值，例如Redis的key名称或者指定id，然后根据节点数量计算出哈希值（hash(key)%N）。但是这种方式在节点数量变化时，映射关系会变化，会涉及到数据牵引。</p></li><li><p>一致性哈希。可以参考这篇文章：<a href="https://www.jianshu.com/p/e8fb89bb3a61" target="_blank" rel="noopener">https://www.jianshu.com/p/e8fb89bb3a61</a></p></li><li>虚拟槽分区（优化后的一致性哈希）。在一个哈希环之后，定义出16364个节点，然后将这些物理的节点动态的分配给集群节点，让每一个节点负责一定数量的slot。在数据写入的时候，hash（key）–&gt;[0,16383]，实际的计算公式为：slot=CRC16(key)&amp;16383。<ul><li>一个slot实际上一个物理的存储节点，由于这些slot是不会发生变化的（在默认的一致性哈希中数量会发生变化，由此会对数据产生影响），所有也就保证了集群数据的可靠性和平衡性。</li></ul></li></ul><p>Redis集群使用虚拟槽分区的特点：</p><ul><li>解耦数据和节点之间的关系，简化了扩容和缩容的难度。因此实际存储的slot数量是不变的，变化的只是分配关系。</li><li>每一个集群节点本身去维护节点和slot的映射关系，不需要客户端或者代理服务去维护这个映射关系。</li><li>支持集群节点、slot、key等之间的映射关系查询，通过获取这些信息，可以用于数据路由、在线伸缩等场景。</li></ul><p>Redis集群中的每一个节点会分配若干个slot。</p><p>作为分布式解决方案，需要为每一个集群节点定义一个固定的id，也就是上面说的哈希值，外层哈希计算之后然后进行分布式的存储。</p><h2 id="集群功能的限制"><a href="#集群功能的限制" class="headerlink" title="集群功能的限制"></a>集群功能的限制</h2><p>Redis集群相对于单实例模式，在功能上会有一些限制</p><ul><li>不支持链式复制。也就是从节点只能复制主节点，不能复制从节点。</li><li>key的批量操作，只支持在同一个slot中的key。</li><li>key的事务操作，只支持在同一个slot中，当多个key分布在不同槽时无法使用事务功能。</li><li>只支持db0</li></ul><h1 id="集群创建"><a href="#集群创建" class="headerlink" title="集群创建"></a>集群创建</h1><p>集群的创建过程也比较简单，只需要3个步骤：</p><ol><li>准备节点</li><li>节点握手，组成集群</li><li>为每个节点分配slot槽</li><li>创建主从关系</li></ol><h2 id="集群节点创建"><a href="#集群节点创建" class="headerlink" title="集群节点创建"></a>集群节点创建</h2><p>在配置文件中开启：cluster-enabled yes即可让节点运行在集群模式之下。</p><p>建议为所有的集群节点规划统一的配置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@common007-dev.novalocal conf]# cat redis-cluster-6379.conf # 以下只显示部分核心的配置</span><br><span class="line">daemonize yes</span><br><span class="line">dir &quot;/home/cachecloud/data&quot;</span><br><span class="line">port 6379</span><br><span class="line">protected-mode no</span><br><span class="line">bind 0.0.0.0</span><br><span class="line"></span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-node-timeout 15000</span><br><span class="line">cluster-config-file &quot;nodes-6379.conf&quot;</span><br></pre></td></tr></table></figure><h3 id="关于集群配置文件"><a href="#关于集群配置文件" class="headerlink" title="关于集群配置文件"></a>关于集群配置文件</h3><p>集群模式的Redis除了原有的配置文件之外，又加了一份集群配置文件。当集群内节点信息发生变化，例如添加节点、节点下线、故障转移等时，节点会自动保存这些信息到集群配置文件。</p><p>需要注意的是：</p><ul><li><p>Redis实例会自动维护集群配置文件，不要手动修改。防止节点重启时产生集群信息错乱。</p></li><li><p>集群配置文件会存储在指定的dir路径下。也就是说和aof、rdb等数据文件再同一个路径下。</p></li></ul><h2 id="集群节点握手"><a href="#集群节点握手" class="headerlink" title="集群节点握手"></a>集群节点握手</h2><p>节点握手是指一批运行在集群模式下的节点通过gossip协议彼此通信，感知对方的过程。</p><p>使用命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; cluster meet 127.0.0.1 6380</span><br></pre></td></tr></table></figure><p>注意：我们只需要在其中一个节点执行cluster meet命令即可，握手状态会通过消息在集群内进行传播，最终所有的节点都会发现其他节点并发起握手流程。最后我们执行cluster nodes命令去查看验证效果即可。</p><p>所有集群节点都握手建立连接之后，此时集群处于下线状态。</p><h2 id="为集群节点分配slot"><a href="#为集群节点分配slot" class="headerlink" title="为集群节点分配slot"></a>为集群节点分配slot</h2><p>Redis集群把所有数据都映射到16384个slot当中，每个key都会映射到一个固定的slot当中，只有当节点分配了slot，才能响应和这些slot关联的key命令。</p><p>因为在交互模式下，不能批量的输入slot的范围，因此使用这种非交互的方式进行添加slot </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[cachecloud@common007-dev.novalocal logs]$ redis-cli  -p 7000 CLUSTER ADDSLOTS &#123;0..16383&#125;</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h2 id="集群的从节点"><a href="#集群的从节点" class="headerlink" title="集群的从节点"></a>集群的从节点</h2><p>可以看到，和sentinel等方式不一样，节点的主从关系我们没有在配置文件当中使用slaveof进行指定，在当前状态下，每一个集群的节点都是master。</p><p>一般情况下我们会对半，一半为master，一半为slave，因此在上面分配slot时，如果节点总数为6，那么将16384个slot进行三等分，分配之后，还剩下3个节点时为空，这个时候，我们执行以下命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6380&gt; cluster replicate 集群node的id</span><br></pre></td></tr></table></figure><h2 id="redis-trib-rb方式创建"><a href="#redis-trib-rb方式创建" class="headerlink" title="redis-trib.rb方式创建"></a>redis-trib.rb方式创建</h2><p>使用这种方式首先需要解决ruby的相关问题，默认使用yum安装的版本太低，无法正确安装Redis</p><p>ruby的官方网站为：<a href="http://www.rvm.io/" target="_blank" rel="noopener">http://www.rvm.io/</a></p><p>整个的操作过程为：</p><p>第1步：解决ruby问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># gpg2 --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB</span><br><span class="line"></span><br><span class="line">下载rvm</span><br><span class="line"># curl -sSL https://get.rvm.io | bash -s stable</span><br><span class="line"></span><br><span class="line">查找配置文件</span><br><span class="line"># find / -name rvm.sh</span><br><span class="line"></span><br><span class="line">配置文件生效</span><br><span class="line"># source /etc/profile.d/rvm.sh </span><br><span class="line"></span><br><span class="line">下载rvm依赖</span><br><span class="line"># rvm requirements </span><br><span class="line"></span><br><span class="line">查看rvm库ruby版本</span><br><span class="line"># rvm list known</span><br><span class="line"></span><br><span class="line">安装ruby指定版本</span><br><span class="line"># rvm install ruby-2.4.1</span><br><span class="line"></span><br><span class="line">使用ruby版本默认</span><br><span class="line"># rvm use 2.4.1 default</span><br><span class="line"></span><br><span class="line">安装Redis</span><br><span class="line"># gem install redis</span><br></pre></td></tr></table></figure><p>可能还需要：yum install -y rubygems</p><p>第2步：启动集群节点</p><p>第3步：创建Redis集群</p><p>接下来我们创建Redis集群</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">使用 --replicas 1 创建 每个master带一个 slave 指令</span><br><span class="line"># ./redis-trib.rb create --replicas 1   192.168.11.84:7000 192.168.11.84:7001 192.168.11.84:7002 192.168.11.11:7000 192.168.11.11:7001 192.168.11.11:7002</span><br></pre></td></tr></table></figure><p>如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">[cachecloud@common007-dev.novalocal src]$ ./redis-trib.rb create --replicas 1   192.168.11.84:7000 192.168.11.84:7001 192.168.11.84:7002 192.168.11.11:7000 192.168.11.11:7001 192.168.11.11:7002</span><br><span class="line">&gt;&gt;&gt; Creating cluster</span><br><span class="line">&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...</span><br><span class="line">Using 3 masters:</span><br><span class="line">192.168.11.84:7000</span><br><span class="line">192.168.11.11:7000</span><br><span class="line">192.168.11.84:7001</span><br><span class="line">Adding replica 192.168.11.11:7001 to 192.168.11.84:7000</span><br><span class="line">Adding replica 192.168.11.84:7002 to 192.168.11.11:7000</span><br><span class="line">Adding replica 192.168.11.11:7002 to 192.168.11.84:7001</span><br><span class="line">M: 2fcb0a92c0b055e9e0c0ec7a279a1c33e400b92c 192.168.11.84:7000</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">M: 94d79d6303e6de4745ec4f1dd61d51d61f73919e 192.168.11.84:7001</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">S: 1c6db7f5c2998db943cb26bf9716d13a367034b9 192.168.11.84:7002</span><br><span class="line">   replicates 1073c42cefa1e192ff219e554c843cbdc1eabd80</span><br><span class="line">M: 1073c42cefa1e192ff219e554c843cbdc1eabd80 192.168.11.11:7000</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">S: 8c911465ef9118912ab848f6a9e5790027b0d4fa 192.168.11.11:7001</span><br><span class="line">   replicates 2fcb0a92c0b055e9e0c0ec7a279a1c33e400b92c</span><br><span class="line">S: 39f885d55462cd7fc4e975317da9db19abcc1835 192.168.11.11:7002</span><br><span class="line">   replicates 94d79d6303e6de4745ec4f1dd61d51d61f73919e</span><br><span class="line">Can I set the above configuration? (type &apos;yes&apos; to accept): yes</span><br><span class="line">&gt;&gt;&gt; Nodes configuration updated</span><br><span class="line">&gt;&gt;&gt; Assign a different config epoch to each node</span><br><span class="line">&gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster</span><br><span class="line">Waiting for the cluster to join....</span><br><span class="line">&gt;&gt;&gt; Performing Cluster Check (using node 192.168.11.84:7000)</span><br><span class="line">M: 2fcb0a92c0b055e9e0c0ec7a279a1c33e400b92c 192.168.11.84:7000</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 8c911465ef9118912ab848f6a9e5790027b0d4fa 192.168.11.11:7001</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 2fcb0a92c0b055e9e0c0ec7a279a1c33e400b92c</span><br><span class="line">M: 94d79d6303e6de4745ec4f1dd61d51d61f73919e 192.168.11.84:7001</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">M: 1073c42cefa1e192ff219e554c843cbdc1eabd80 192.168.11.11:7000</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">   1 additional replica(s)</span><br><span class="line">S: 1c6db7f5c2998db943cb26bf9716d13a367034b9 192.168.11.84:7002</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 1073c42cefa1e192ff219e554c843cbdc1eabd80</span><br><span class="line">S: 39f885d55462cd7fc4e975317da9db19abcc1835 192.168.11.11:7002</span><br><span class="line">   slots: (0 slots) slave</span><br><span class="line">   replicates 94d79d6303e6de4745ec4f1dd61d51d61f73919e</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line">&gt;&gt;&gt; Check for open slots...</span><br><span class="line">&gt;&gt;&gt; Check slots coverage...</span><br><span class="line">[OK] All 16384 slots covered.</span><br></pre></td></tr></table></figure><p>192.168.11.84:7000:2048<br>192.168.11.11:7001:2048<br>192.168.11.11:7000:2048<br>192.168.11.84:7002:2048<br>192.168.11.84:7001:2048<br>192.168.11.11:7002:2048</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./redis-trib.rb create --replicas 1  10.11.4.1:6526 10.11.4.2:6526 10.11.4.3:6526 10.11.4.4:6526 10.11.4.5:6526 10.11.4.6:6526</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> ./redis-trib.rb create --replicas 1  10.11.4.1:6527 10.11.4.2:6527 10.11.4.3:6527 10.11.4.4:6527 10.11.4.5:6527 10.11.4.6:6527</span><br><span class="line"> </span><br><span class="line">  ./redis-trib.rb create --replicas 1  10.11.4.1:6528 10.11.4.2:6528 10.11.4.3:6528 10.11.4.4:6528 10.11.4.5:6528 10.11.4.6:6528</span><br><span class="line">  </span><br><span class="line">   ./redis-trib.rb create --replicas 1  10.11.4.1:6529 10.11.4.2:6529 10.11.4.3:6529 10.11.4.4:6529 10.11.4.5:6529 10.11.4.6:6529</span><br></pre></td></tr></table></figure><p>10.11.4.1:6526:8192</p><p>10.11.4.4:6526:8192</p><p>10.11.4.2:6526:8192</p><p>10.11.4.5:6526:8192</p><p>10.11.4.3:6526:8192</p><p>10.11.4.6:6526:8192</p><p>10.11.4.1:6529:8192<br>10.11.4.4:6529:8192<br>10.11.4.2:6529:8192<br>10.11.4.5:6529:8192<br>10.11.4.3:6529:8192<br>10.11.4.6:6529:8192</p><h1 id="集群运维"><a href="#集群运维" class="headerlink" title="集群运维"></a>集群运维</h1><h2 id="集群伸缩"><a href="#集群伸缩" class="headerlink" title="集群伸缩"></a>集群伸缩</h2><p>Redis集群可以实现对节点的灵活上下线控制，其中的原理可以抽象为槽和对应数据在不同节点之间的灵活移动。</p><p>也就是：<font color="red"><strong>集群伸缩=slot槽和数据在节点之间的移动</strong></font></p><h2 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h2><p>整个集群的扩容操作可以分为以下步骤：</p><ol><li>启动新节点</li><li>加入现有集群</li><li>迁移slot和数据</li></ol><h3 id="新集群节点创建"><a href="#新集群节点创建" class="headerlink" title="新集群节点创建"></a>新集群节点创建</h3><p>和之前的配置一样，在配置文件中设置cluster-enabled为yes，然后启动即可。</p><h3 id="加入现有集群"><a href="#加入现有集群" class="headerlink" title="加入现有集群"></a>加入现有集群</h3><p>其实也就是一个meet操作</p><p>在随便一个集群节点当中执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; cluster meet ip port</span><br></pre></td></tr></table></figure><p>即可将该节点加入现有集群当中，注意，这里应该是加入了2个节点（另一个后续会作为从节点）</p><p>1. 152</p><p>multi-message-gw-service</p><p>rider-station-base-service</p><p>221</p><p>red-packet-unit-service</p><p>105</p><p>rider-elastic-probe</p><p>153</p><p>rich-unit-service</p><p>220 </p><p>order-rule-unit-service</p><p>candidate-select-service</p><p>dispatch-alg-config</p><p>dispatch-bywaydegree-provider</p><p>dispatch-config-dispatch-mode</p><p>dispatch-consistent-service</p><p>dispatch-fairy-provider</p><p>dispatch-pathplan-rider</p><p>dispatch-pathplan-service</p><p>dispatch-revise-params</p><p>dispatch-timer-task</p><p>grab-order-service</p><p>lbs-provider</p><p>lbs-rider-position-service</p><p>lbs-rider-space-service</p><p>order-diagnose-service</p><p>package-order-service</p><p>parameter-service</p><p>recommend-config-provider</p><p>rider-gateway-current-limit</p><p>rider-invert-select</p><p>system-dispatch</p><p>/usr/bin/nohup /usr/local/jdk/bin/java -Dproject.name=${name} -Dlogging.file.path=”/home/${start_user}/deploy/logs/${name}” -Dmonitor.file.path=”/home/${start_user}/deploy/logs/monitor” -Daction.file.path=”/home/${start_user}/deploy/logs/action/“ -Dbigdata.file.path=”/home/${start_user}/deploy/logs/bigdata/“ -Ddisconf.env=${disconf_env} -Ddisconf.enable.remote.conf=true -Ddisconf.conf_server_host=${disconf_url} &lt;#if zone??  &amp;&amp; zone != “”&gt; -Dspring.cloud.config.label=${region}.${zone} -Dspring.cloud.config.index=${region}.${zone} -Dzone=${zone} &lt;/#if&gt; &lt;#if region??  &amp;&amp; region != “”&gt; -Dregion=${region} &lt;/#if&gt; &lt;#if service_chain??&gt; -javaagent:/home/${start_user}/deploy/tools/service-chain-1.0-RELEASE.jar -Xbootclasspath/a:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -javaagent:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -Dservice-chain=${service_chain} &lt;/#if&gt; -Dlogging.console.level=off -server &lt;#if config_prefix == “production”&gt; -Xmx4g -Xms4g &lt;#else&gt; -Xms${xms}m -Xmx${xmx}m &lt;/#if&gt;  -XX:NewRatio=1 -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+CMSScavengeBeforeRemark -XX:+ParallelRefProcEnabled -XX:+CMSParallelInitialMarkEnabled -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+ExplicitGCInvokesConcurrent -XX:+AlwaysPreTouch -server -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=”/home/${start_user}/deploy/logs/${name}/“ -XX:-UseBiasedLocking -XX:AutoBoxCacheMax=20000 -XX:+UseCondCardMark -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -XX:+PrintJNIGCStalls -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -XX:+PrintPromotionFailure -XX:+PrintCommandLineFlags -XX:-OmitStackTraceInFastThrow -Xloggc:/dev/shm/${name}-gc.log -XX:ErrorFile=/home/${start_user}/deploy/logs/${name}/hs<em>err</em>%p.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=2 -XX:GCLogFileSize=20M -Djava.security.egd=file:/dev/./urandom -Dlog4j.shutdownHookEnabled=false -jar ${name}.jar –spring.profiles.active=${config_prefix} &gt; &lt;#if config_prefix == “production” || config_prefix == “dwd-pre”&gt; /dev/null &lt;#else&gt; /home/${start_user}/deploy/logs/${name}/${name}-start.log &lt;/#if&gt; 2&gt;&amp;1 &amp;</p><p>-server -Xmx4g -Xms4g -XX:NewRatio=1 -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -XX:+CMSScavengeBeforeRemark -XX:+ParallelRefProcEnabled -XX:+CMSParallelInitialMarkEnabled -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -XX:+ExplicitGCInvokesConcurrent -XX:+AlwaysPreTouch -server -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=”/home/appdeploy/deploy/logs/scan-order-service/“ -XX:-UseBiasedLocking -XX:AutoBoxCacheMax=20000 -XX:+UseCondCardMark -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -XX:+PrintJNIGCStalls -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -XX:+PrintPromotionFailure -XX:+PrintCommandLineFlags -XX:-OmitStackTraceInFastThrow -Xloggc:/dev/shm/scan-order-service-gc.log -XX:ErrorFile=/home/appdeploy/deploy/logs/scan-order-service/hs<em>err</em>%p.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=2 -XX:GCLogFileSize=20M -Djava.security.egd=file:/dev/./urandom -Dlog4j.shutdownHookEnabled=false -jar scan-order-service.jar –spring.profiles.active=production &gt; /dev/null 2&gt;&amp;1 &amp;</p><p>上海的多活环境，jvm内存1.5G。<br>没问题的话，下面这个模板就作为你们所有应用部署上海机房的默认启动脚本了，有问题跟我说下。</p><p>#!/bin/bash<br>mkdir -p /home/${start_user}/deploy/logs/${name}<br>cd /home/${start_user}/deploy/apps/${name}<br>/usr/bin/nohup /usr/local/jdk/bin/java -Dproject.name=${name} -verbose:gc -Xloggc:/home/${start_user}/deploy/logs/${name}/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/${start_user}/deploy/logs/${name}/java.hprof -XX:ErrorFile=/home/${start_user}/deploy/logs/${name}/java_error.log -Dlogging.file.path=”/home/${start_user}/deploy/logs/${name}” &lt;#if zone??  &amp;&amp; zone != “”&gt; -Dspring.cloud.config.label=${region}.${zone} -Dspring.application.index=${region}.${zone} -Dlogging.console.level=off -Dzone=${zone} &lt;/#if&gt; &lt;#if region??  &amp;&amp; region != “”&gt; -Dregion=${region} &lt;/#if&gt; &lt;#if service_chain??&gt; -javaagent:/home/${start_user}/deploy/tools/service-chain-1.0-RELEASE.jar -Xbootclasspath/a:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -javaagent:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -Dservice-chain=${service_chain} &lt;/#if&gt; -Dmonitor.file.path=/home/${start_user}/deploy/logs/monitor -Daction.file.path=/home/${start_user}/deploy/logs/action/ -Dbigdata.file.path=/home/${start_user}/deploy/logs/bigdata/ -Ddisconf.env=${disconf_env} -Ddisconf.enable.remote.conf=true -Ddisconf.conf_server_host=${disconf_url} -server -Xms${xms}m -Xmx${xmx}m -XX:MaxNewSize=${max_new_size}m  -XX:ThreadStackSize=${thread_stack_size} -jar ${name}.jar –spring.profiles.active=${config_prefix} &gt;/home/${start_user}/deploy/logs/${name}/${name}-start.log 2&gt;&amp;1 &amp;</p><p>#!/bin/bash<br>mkdir -p /home/${start_user}/deploy/logs/${name}<br>cd /home/${start_user}/deploy/apps/${name}<br>/usr/bin/nohup /usr/local/jdk/bin/java -Dproject.name=${name} -Dlogging.file.path=”/home/${start_user}/deploy/logs/${name}” &lt;#if zone??  &amp;&amp; zone != “”&gt; -Dspring.cloud.config.label=${region}.${zone} -Dspring.application.index=${region}.${zone} -Dspring.application.name=fortune-unit-service-primary -Dlogging.console.level=off -Dzone=${zone} &lt;/#if&gt; &lt;#if region??  &amp;&amp; region != “”&gt; -Dregion=${region} &lt;/#if&gt; &lt;#if service_chain??&gt; -javaagent:/home/${start_user}/deploy/tools/service-chain-1.0-RELEASE.jar -Xbootclasspath/a:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -javaagent:/home/${start_user}/deploy/tools/transmittable-thread-local-2.5.1.jar -Dservice-chain=${service_chain} &lt;/#if&gt; -server -Xms3000m -Xmx3000m -XX:MaxNewSize=${max_new_size}m  -XX:ThreadStackSize=${thread_stack_size} -jar ${name}.jar –spring.profiles.active=${config_prefix} &gt; &lt;#if config_prefix == “production” || config_prefix == “dwd-pre” || config_prefix == “production-sh”&gt; /dev/null &lt;#else&gt; /home/${start_user}/deploy/logs/${name}/${name}-start.log &lt;/#if&gt; 2&gt;&amp;1 &amp;</p><p>grant all on zentaopro.* to ‘dev’@’192.168.%’ identified by ‘zentao123’;</p>]]></content>
    
    <summary type="html">
    
      Redis集群相关知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="数据库" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Redis" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/"/>
    
      <category term="Redis集群" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%95%B0%E6%8D%AE%E5%BA%93/Redis/Redis%E9%9B%86%E7%BE%A4/"/>
    
    
      <category term="redis集群" scheme="http://yoursite.com/tags/redis%E9%9B%86%E7%BE%A4/"/>
    
  </entry>
  
  <entry>
    <title>语言学基础</title>
    <link href="http://yoursite.com/2019/01/26/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%8F%8A%E8%B7%AF%E7%BA%BF/%E8%AF%AD%E8%A8%80%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2019/01/26/个人知识体系/英语学习/英语学习方法及路线/语言学基础/</id>
    <published>2019-01-26T10:18:49.000Z</published>
    <updated>2019-01-26T10:18:49.000Z</updated>
    
    <summary type="html">
    
      语言学基础
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="英语学习" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="英语学习方法及路线" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E5%8F%8A%E8%B7%AF%E7%BA%BF/"/>
    
    
      <category term="语言学基础" scheme="http://yoursite.com/tags/%E8%AF%AD%E8%A8%80%E5%AD%A6%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title>rsync用法</title>
    <link href="http://yoursite.com/2019/01/24/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/rsync/rsync/"/>
    <id>http://yoursite.com/2019/01/24/IT科学技术知识体系结构-Linux运维方向/网络知识及网络服务/网络服务/rsync/rsync/</id>
    <published>2019-01-24T15:13:25.000Z</published>
    <updated>2019-01-24T15:13:25.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>rsync作为一个数据<strong>同步</strong>的工具，可通过LAN/WAN快速同步多台主机间的文件。</p><p>主要解决的核心问题是：<strong>使两端的数据保持同步</strong></p><p>可以分为2个部分：</p><ul><li>全量传输（也可以理解为全量备份）</li><li>差异化传输（只传输有变化的部分内容）</li></ul><h2 id="语法及6种命令格式"><a href="#语法及6种命令格式" class="headerlink" title="语法及6种命令格式"></a>语法及6种命令格式</h2><p>抽象后的语法表达式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync [option] src dest</span><br></pre></td></tr></table></figure><p>在实际使用中，源和目的地的组合有一下几种方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Usage: rsync [OPTION]... SRC [SRC]... DEST</span><br><span class="line">  or   rsync [OPTION]... SRC [SRC]... [USER@]HOST:DEST</span><br><span class="line">  or   rsync [OPTION]... SRC [SRC]... [USER@]HOST::DEST</span><br><span class="line">  or   rsync [OPTION]... SRC [SRC]... rsync://[USER@]HOST[:PORT]/DEST</span><br><span class="line">  or   rsync [OPTION]... [USER@]HOST:SRC [DEST]</span><br><span class="line">  or   rsync [OPTION]... [USER@]HOST::SRC [DEST]</span><br><span class="line">  or   rsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]</span><br><span class="line">The &apos;:&apos; usages connect via remote shell, while &apos;::&apos; &amp; &apos;rsync://&apos; usages connect</span><br><span class="line">to an rsync daemon, and require SRC or DEST to start with a module name.</span><br></pre></td></tr></table></figure><p>:表示连接的是远端的shell。而::或者rsync://表示连接的是远端的rsync守护进程。</p><p>以上这几种命令格式对应的是不同的工作模式和场景，我们把它提取精简出来就是：</p><ul><li>本地文件之间的传输。src dest</li><li>将本地同步到远端。src user@host:dest</li><li>将本地文件同步到远端的默认配置rsync服务端。src user@host::dest</li><li>将本地文件同步到远端的指定配置的rsync服务端。src rsync://user@host:port/dest</li><li>将远端机器上的数据同步传输到本地。user@host:src local_dest</li><li>将远端rsync服务器(默认配置)上的数据同步传输到本地。user@host::src local_dest</li><li>将远端rsync服务器(指定配置)上的数据同步传输到本地。rsync://user@host:por/src local_dest</li></ul><p>一共7种方式。</p><h2 id="6种命令格式对"><a href="#6种命令格式对" class="headerlink" title="6种命令格式对"></a>6种命令格式对</h2><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="目的或者说要解决的问题"><a href="#目的或者说要解决的问题" class="headerlink" title="目的或者说要解决的问题"></a>目的或者说要解决的问题</h2><p>rsync作为一个数据<strong>同步</strong>的工具，可通过LAN/WAN快速同步多台主机间的文件。</p><p>主要解决的核心问题是：<strong>使两端的数据保持同步</strong></p><p>可以分为2个部分：</p><ul><li>全量传输（也可以理解为全量备份）</li><li>差异化传输（只传输有变化的部分内容）</li></ul><h2 id="核心观点和内容"><a href="#核心观点和内容" class="headerlink" title="核心观点和内容"></a>核心观点和内容</h2><h2 id="目的和核心内容是怎么连接的"><a href="#目的和核心内容是怎么连接的" class="headerlink" title="目的和核心内容是怎么连接的"></a>目的和核心内容是怎么连接的</h2><h2 id="整体的实现逻辑"><a href="#整体的实现逻辑" class="headerlink" title="整体的实现逻辑"></a>整体的实现逻辑</h2><h2 id="启发点和疑问点"><a href="#启发点和疑问点" class="headerlink" title="启发点和疑问点"></a>启发点和疑问点</h2><h2 id="抽象化"><a href="#抽象化" class="headerlink" title="抽象化"></a>抽象化</h2><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>Redis数据备份这个我已经把核心的sentinel这些实现好了，cpu、内存、流量、sentinel日志这些可能会出现的报警情况都已经思考确认优化过了。</p><p>刚才11点的时候做了一次测试，没有问题，待会我把时间点换成凌晨。</p><p>cluster部分的数据备份和恢复稍微有点不一样，我先把上海机房Redis都创建之后再来做下这个。</p>]]></content>
    
    <summary type="html">
    
      rsync用法
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="网络知识及网络服务" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="网络服务" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="rsync" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1/rsync/"/>
    
    
      <category term="rsync" scheme="http://yoursite.com/tags/rsync/"/>
    
  </entry>
  
  <entry>
    <title>django-定时任务</title>
    <link href="http://yoursite.com/2019/01/13/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/django/django-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    <id>http://yoursite.com/2019/01/13/IT科学技术知识体系结构-Linux运维方向/编程开发/Python/django/django-定时任务/</id>
    <published>2019-01-13T06:19:01.000Z</published>
    <updated>2019-01-13T06:19:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>在编写django项目的时候，很多时候会有定时任务的需求。</p><h1 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h1><h2 id="步骤1：安装django-crontab库"><a href="#步骤1：安装django-crontab库" class="headerlink" title="步骤1：安装django-crontab库"></a>步骤1：安装django-crontab库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install django-crontab</span><br></pre></td></tr></table></figure><p>再在settings.py中添加app:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">INSTALLED_APPS = (</span><br><span class="line">       ...</span><br><span class="line">       &apos;django_crontab&apos;,</span><br><span class="line">   )</span><br></pre></td></tr></table></figure><h2 id="步骤2：创建定时任务"><a href="#步骤2：创建定时任务" class="headerlink" title="步骤2：创建定时任务"></a>步骤2：创建定时任务</h2><p>在app内新建py文件，文件名称随意。</p><p>例如我们在名为bind_ops的app下新建了一个bind_crontab.py文件。</p><p>文件内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">from lib.logger  import logger</span><br><span class="line">import datetime</span><br><span class="line">time = datetime.datetime.now()</span><br><span class="line">time = str(time)</span><br><span class="line">def crontab_test():</span><br><span class="line">    print (111)</span><br><span class="line">    logger.info(&quot;bind crontab&quot; +time )</span><br></pre></td></tr></table></figure><p>因为要看定时任务的效果，所以采用了直接输出和记录到文件的形式</p><p>经过测试发现：当定时任务在执行时，如果你只是输出一些语句，那么你将看不到任何内容，所以请不要怀疑这个定时任务没有执行。</p><p>然后在 settings.py中增加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 最简单配置</span><br><span class="line">CRONJOBS = [</span><br><span class="line">    # 表示每天2：01执行</span><br><span class="line">    (&apos;01 2 * * *&apos;, &apos;bind_ops.bind_crontab.crontab_test&apos;)</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">#</span><br></pre></td></tr></table></figure><p><strong>参数及字段说明：</strong></p><p>第一个参数（表示时间），前5个字段分别表示：</p><ul><li>分钟：0-59</li><li>小时：1-23</li><li>日期：1-31</li><li>月份：1-12</li><li>星期：0-6（0表示周日）</li></ul><p>一些特殊符号：</p><ul><li>*： 表示任何时刻</li><li>,：　表示分割</li><li>-：表示一个段，如在第二段里： 1-5，就表示1到5点</li><li>/n : 表示每个n的单位执行一次，如第二段里，*/1, 就表示每隔1个小时执行一次命令。也可以写成1-23/1.</li></ul><p>第二个参数（表示路径）：</p><p>格式：app名称.文件名.函数名</p><p>如果想生成日志，那就<strong>再加一个字符串类型的参数</strong>：’&gt;&gt; path/name.log’， path路径，name文件名。’&gt;&gt;’表示追加写入，’&gt;’表示覆盖写入。</p><p><strong>提示：</strong></p><ul><li>如果你有多个定时任务，以逗号隔开，都放入CORNJOBS的列表中即可。</li><li>路径必须写绝对路径，写相对路径是不识别的。</li></ul><h2 id="步骤3：启动任务"><a href="#步骤3：启动任务" class="headerlink" title="步骤3：启动任务"></a>步骤3：启动任务</h2><p>以上都完成后，需要执行以下命令将任务添加并生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py crontab add</span><br></pre></td></tr></table></figure><p>显示当前的定时任务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py crontab show</span><br></pre></td></tr></table></figure><p>删除所有定时任务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py crontab remove</span><br></pre></td></tr></table></figure><p>重启django服务执行（可能不需要，因为并没有用，也正常使用了。）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py corntab -e</span><br></pre></td></tr></table></figure><h1 id="实际案例"><a href="#实际案例" class="headerlink" title="实际案例"></a>实际案例</h1><h2 id="dname项目-bind定时获取主机名"><a href="#dname项目-bind定时获取主机名" class="headerlink" title="dname项目-bind定时获取主机名"></a>dname项目-bind定时获取主机名</h2><h3 id="需求说明"><a href="#需求说明" class="headerlink" title="需求说明"></a>需求说明</h3><p>需求：bind服务需要提供解析主机名的功能</p><p>拆分：</p><ul><li>从数据源中获取主机名的对应信息并写入zone数据文件-这里的数据源是cmdb</li><li>定期检测删除的主机</li><li>定期更新有ip变化的主机记录</li></ul><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3>]]></content>
    
    <summary type="html">
    
      django-定时任务
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="编程开发" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/"/>
    
      <category term="django" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/django/"/>
    
    
      <category term="django-定时任务" scheme="http://yoursite.com/tags/django-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>python文件处理</title>
    <link href="http://yoursite.com/2019/01/07/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/python%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/python%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/"/>
    <id>http://yoursite.com/2019/01/07/IT科学技术知识体系结构-Linux运维方向/编程开发/Python/python文件处理/python文件处理/</id>
    <published>2019-01-07T15:04:17.000Z</published>
    <updated>2019-01-07T15:04:17.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>Python open() 方法用于打开一个文件，并返回文件对象，在对文件进行处理过程都需要使用到这个函数，如果该文件无法被打开，会抛出 OSError。</p><p><strong>注意：</strong></p><p>使用 open() 方法一定要保证关闭文件对象，即调用 close() 方法。</p><p>open() 函数常用形式是接收两个参数：文件名(file)和模式(mode)。</p><h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><h3 id="open"><a href="#open" class="headerlink" title="open()"></a>open()</h3><p>Python open() 方法用于打开一个文件，并返回文件对象，在对文件进行处理过程都需要使用到这个函数，如果该文件无法被打开，会抛出 OSError。</p><p><strong>注意：</strong></p><p>使用 open() 方法一定要保证关闭文件对象，即调用 close() 方法。</p><p>open() 函数常用形式是接收两个参数：文件名(file)和模式(mode)。</p><p>语法格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open(file, mode=&apos;r&apos;)</span><br></pre></td></tr></table></figure><p>完整的语法格式为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open(file, mode=&apos;r&apos;, buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)</span><br></pre></td></tr></table></figure><p>参数说明:</p><ul><li>file: 必需，文件路径（相对或者绝对路径）。</li><li>mode: 可选，文件打开模式</li><li>buffering: 设置缓冲</li><li>encoding: 一般使用utf8</li><li>errors: 报错级别</li><li>newline: 区分换行符</li><li>closefd: 传入的file参数类型</li><li>opener:</li></ul><p>mode模式一共有一下几种：</p><table><thead><tr><th>模式</th><th>描述</th></tr></thead><tbody><tr><td>t</td><td>文本模式 (默认)。</td></tr><tr><td>x</td><td>写模式，新建一个文件，如果该文件已存在则会报错。</td></tr><tr><td>b</td><td>二进制模式。</td></tr><tr><td>+</td><td>打开一个文件进行更新(可读可写)。</td></tr><tr><td>U</td><td>通用换行模式（不推荐）。</td></tr><tr><td>r</td><td>以只读方式打开文件。文件的指针将会放在文件的开头。这是默认模式。</td></tr><tr><td>rb</td><td>以二进制格式打开一个文件用于只读。文件指针将会放在文件的开头。这是默认模式。一般用于非文本文件如图片等。</td></tr><tr><td>r+</td><td>打开一个文件用于读写。文件指针将会放在文件的开头。</td></tr><tr><td>rb+</td><td>以二进制格式打开一个文件用于读写。文件指针将会放在文件的开头。一般用于非文本文件如图片等。</td></tr><tr><td>w</td><td>打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。</td></tr><tr><td>wb</td><td>以二进制格式打开一个文件只用于写入。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。</td></tr><tr><td>w+</td><td>打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。</td></tr><tr><td>wb+</td><td>以二进制格式打开一个文件用于读写。如果该文件已存在则打开文件，并从开头开始编辑，即原有内容会被删除。如果该文件不存在，创建新文件。一般用于非文本文件如图片等。</td></tr><tr><td>a</td><td>打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</td></tr><tr><td>ab</td><td>以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。也就是说，新的内容将会被写入到已有内容之后。如果该文件不存在，创建新文件进行写入。</td></tr><tr><td>a+</td><td>打开一个文件用于读写。如果该文件已存在，文件指针将会放在文件的结尾。文件打开时会是追加模式。如果该文件不存在，创建新文件用于读写。</td></tr><tr><td>ab+</td><td>以二进制格式打开一个文件用于追加。如果该文件已存在，文件指针将会放在文件的结尾。如果该文件不存在，创建新文件用于读写。</td></tr></tbody></table><p>默认为文本模式，如果要以二进制模式打开，加上 b 。</p><h3 id="file-对象"><a href="#file-对象" class="headerlink" title="file 对象"></a>file 对象</h3><p>file 对象使用 open 函数来创建，下表列出了 file 对象常用的函数：</p><table><thead><tr><th>序号</th><th>方法及描述</th></tr></thead><tbody><tr><td>1</td><td><a href="http://www.runoob.com/python/file-close.html" target="_blank" rel="noopener">file.close()</a>关闭文件。关闭后文件不能再进行读写操作。</td></tr><tr><td>2</td><td><a href="http://www.runoob.com/python/file-flush.html" target="_blank" rel="noopener">file.flush()</a>刷新文件内部缓冲，直接把内部缓冲区的数据立刻写入文件, 而不是被动的等待输出缓冲区写入。</td></tr><tr><td>3</td><td><a href="http://www.runoob.com/python/file-fileno.html" target="_blank" rel="noopener">file.fileno()</a>返回一个整型的文件描述符(file descriptor FD 整型), 可以用在如os模块的read方法等一些底层操作上。</td></tr><tr><td>4</td><td><a href="http://www.runoob.com/python/file-isatty.html" target="_blank" rel="noopener">file.isatty()</a>如果文件连接到一个终端设备返回 True，否则返回 False。</td></tr><tr><td>5</td><td><a href="http://www.runoob.com/python/file-next.html" target="_blank" rel="noopener">file.next()</a>返回文件下一行。</td></tr><tr><td>6</td><td><a href="http://www.runoob.com/python/python-file-read.html" target="_blank" rel="noopener">file.read([size])</a>从文件读取指定的字节数，如果未给定或为负则读取所有。</td></tr><tr><td>7</td><td><a href="http://www.runoob.com/python/file-readline.html" target="_blank" rel="noopener">file.readline([size])</a>读取整行，包括 “\n” 字符。</td></tr><tr><td>8</td><td><a href="http://www.runoob.com/python/file-readlines.html" target="_blank" rel="noopener">file.readlines([sizeint])</a>读取所有行并返回列表，若给定sizeint&gt;0，则是设置一次读多少字节，这是为了减轻读取压力。</td></tr><tr><td>9</td><td><a href="http://www.runoob.com/python/file-seek.html" target="_blank" rel="noopener">file.seek(offset[, whence])</a>设置文件当前位置</td></tr><tr><td>10</td><td><a href="http://www.runoob.com/python/file-tell.html" target="_blank" rel="noopener">file.tell()</a>返回文件当前位置。</td></tr><tr><td>11</td><td><a href="http://www.runoob.com/python/file-truncate.html" target="_blank" rel="noopener">file.truncate([size])</a>截取文件，截取的字节通过size指定，默认为当前文件位置。</td></tr><tr><td>12</td><td><a href="http://www.runoob.com/python/python-file-write.html" target="_blank" rel="noopener">file.write(str)</a>将字符串写入文件，返回的是写入的字符长度。</td></tr><tr><td>13</td><td><a href="http://www.runoob.com/python/file-writelines.html" target="_blank" rel="noopener">file.writelines(sequence)</a>向文件写入一个序列字符串列表，如果需要换行则要自己加入每行的换行符。</td></tr></tbody></table><h2 id="关于-Buffering"><a href="#关于-Buffering" class="headerlink" title="关于 Buffering"></a>关于 Buffering</h2><p>官方解释如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The optional buffering argument specifies the file’s desired buffer size: 0 means unbuffered, 1 means line buffered, any other positive value means use a buffer of (approximately) that size. A negative buffering means to use the system default, which is usually line buffered for tty devices and fully buffered for other files. If omitted, the system default is used.</span><br></pre></td></tr></table></figure><p>缓冲的目的：是为了减少系统的io调用。只有当符合一定条件(比如缓冲数量)时才调用io。</p><p>缓冲分以下几种： </p><ul><li><p>全缓冲 : open函数的buffering设置大于1的整数n,n为缓冲区大小，linux默认为page的大小4096 满了n 个字节才会写入磁盘 。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=open(“demo.txt”,’w’,buffering=10)</span><br></pre></td></tr></table></figure></li><li><p>行缓冲 : open 函数的buffering设置为1, 每写一行就会将缓冲区写入磁盘。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=open(“demo.txt”,’w’,buffering=1)</span><br></pre></td></tr></table></figure></li><li><p>无缓冲 : open 函数的buffering设置为0 有输入就写入磁盘。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=open(“demo.txt”,’w,’,buffering=0)</span><br></pre></td></tr></table></figure></li><li><p>系统缓存：open 函数的buffering设置小于0，由操作系统决定何时写入磁盘</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">f=open(“demo.txt”,’w,’,buffering=-1)</span><br></pre></td></tr></table></figure></li></ul><p>如果没有设置，那么默认值就是使用系统缓存</p>]]></content>
    
    <summary type="html">
    
      python文件处理
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="编程开发" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/"/>
    
      <category term="python文件处理" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BC%96%E7%A8%8B%E5%BC%80%E5%8F%91/Python/python%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/"/>
    
    
      <category term="python文件处理" scheme="http://yoursite.com/tags/python%E6%96%87%E4%BB%B6%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>sed命令</title>
    <link href="http://yoursite.com/2019/01/07/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%91%BD%E4%BB%A4/sed%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2019/01/07/IT科学技术知识体系结构-Linux运维方向/Linux命令/sed命令/</id>
    <published>2019-01-07T01:42:29.000Z</published>
    <updated>2019-01-07T01:42:29.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>sed全称stream editor，流编辑器，用程序的方式来编辑文本，它是文本处理中常用的工具，能够完美的配合正则表达式使用。</p><p>sed处理文件的具体过程如下：</p><ol><li><p>首先sed把当前正在处理的行保存在一个临时缓存区中（也称为模式空间），然后处理临时缓冲区中的行，完成后把该行发送到屏幕上。</p></li><li><p>sed每处理完一行就将其从临时缓冲区删除，然后将下一行读入，进行处理和显示。</p></li><li><p>处理完输入文件的最后一行后，sed便结束运行。</p></li><li><p>sed把每一行都存在临时缓冲区中，对这个副本进行编辑，所以不会修改原文件。</p></li></ol><h1 id="sed语法"><a href="#sed语法" class="headerlink" title="sed语法"></a>sed语法</h1><p>sed的操作过程包括：</p><ol><li>定位。定址用于决定对哪些行进行编辑。地址的形式可以是数字、正则表达式、或二者的结合。如果没有指定地址，sed将处理输入文件的所有行。</li><li></li></ol><p>地址是一个数字，则表示行号；是“$”符号，则表示最后一行。例如： </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`sed -n &apos;3p&apos; datafile只打印第三行`</span><br></pre></td></tr></table></figure><p> 只显示指定行范围的文件内容，例如：</p><p># 只查看文件的第100行到第200行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -n &apos;100,200p&apos; mysql_slow_query.log</span><br></pre></td></tr></table></figure><p>地址是逗号分隔的，那么需要处理的地址是这两行之间的范围（包括这两行在内）。范围可以用数字、正则表达式、或二者的组合表示。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`sed &apos;2,5d&apos; datafile#删除第二到第五行sed &apos;/My/,/You/d&apos; datafile#删除包含&quot;My&quot;的行到包含&quot;You&quot;的行之间的行sed &apos;/My/,10d&apos; datafile#删除包含&quot;My&quot;的行到第十行的内容`</span><br></pre></td></tr></table></figure><h1 id="sed实际案例"><a href="#sed实际案例" class="headerlink" title="sed实际案例"></a>sed实际案例</h1><p>sed -n  ‘/;[ ]{1,5}serial/s/[0-9]{1,10}/&amp;+1/;s/;[ ]{1,5}serial[ ][0-9]{1,10}/; serial date+1/;s/[0-9]{1,10}$/no+1/p’ dianwoba.com.zone</p><p>sed -n  ‘/;[ ]{1,5}serial/s/[0-9]{1,10}$/no+1/p’ dianwoba.com.zone</p><p>sed -n  ‘/;[ ]{1,5}serial/s#[0-9]{1,10}#&amp;+1#;/;[ ]{1,5}serial/s#;[ ]{1,5}serial[ ][0-9]{1,10}#; serial date+1#;/;[ ]{1,5}serial/s#[0-9]{1,10}$#no+1#p’ dianwoba.com.zone</p><p>sed -n  ‘/;[ ]{1,5}serial/s/[0-9]{1,10}/&amp;+1/;/;[ ]{1,5}serial/s/;[ ]{1,5}serial[ ][0-9]{1,10}/; serial date+1/;/;[ ]{1,5}serial/s/[0-9]{1,10}$/no+1/p’ dianwoba.com.zone</p><p>sed -n  ‘3s/[0-9]{1,10}/&amp;+1/;3s/;[ ]{1,5}serial[ ][0-9]{1,10}/; serial date+1/;3s/[0-9]{1,10}$/no+1/p’ dianwoba.com.zone</p><p>sed -n  ‘3s/[0-9]{1,10}/&amp;+1/;3s/;[ ]{1,5}serial[ ][0-9]{1,10}/; serial date/;3s/$/no+1/p’ dianwoba.com.zone</p><h1 id="高级知识"><a href="#高级知识" class="headerlink" title="高级知识"></a>高级知识</h1>]]></content>
    
    <summary type="html">
    
      sed命令
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux命令" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="sed" scheme="http://yoursite.com/tags/sed/"/>
    
  </entry>
  
  <entry>
    <title>思维模型</title>
    <link href="http://yoursite.com/2019/01/04/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2019/01/04/个人知识体系/认知升级/学习方法/思维模型/</id>
    <published>2019-01-04T15:09:14.000Z</published>
    <updated>2019-01-04T15:09:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><h2 id="什么是思维模型"><a href="#什么是思维模型" class="headerlink" title="什么是思维模型"></a>什么是思维模型</h2><p>查理芒格曾说：每个人都需要掌握至少100个思维模型，才能解决生活中的80%、90%的问题。</p><p>那么，思维模型究竟是什么？以及思维模型究竟怎么样在生活中帮助我们解决问题？</p><p>查理芒格本身说：思维模式是重要学科的重要原理，通常是那些不证自明的基础规律</p><p>我的个人理解：思维模型是高级思维方式的底层框架抽象，是一个系统框架</p><p>学习思维模型，关键不在于具体的技巧和答案，而在于思考的过程。</p><h2 id="思维模型的分层"><a href="#思维模型的分层" class="headerlink" title="思维模型的分层"></a>思维模型的分层</h2><p>思维模型其实是分层次的</p><p>从上到下适用范围越来越基础，也就是说适用范围越来越广</p><p><strong>最上层：</strong>解决具体问题的思维模型。比如FFC、SWOT法则、冰山模型等等</p><p><strong>中间层：</strong>某一学科的原理或者规律。比如精益创业、边际效应、价值投资理念等等，解决一个学科中问题的思维模型</p><p><strong>最下层：</strong>最底层的抽象的跨学科的原理和规律。比如哲学上的递弱代偿、物理学的机械论、物理学的熵增定律，生物学的进化论等等</p><p>思维模型越往上就越有用，工具属性就越强，解决某个具体场景的问题</p><p>思维模型越往下就越无用，距离具体问题越远，解释事情的属性更强</p><h2 id="思维模型的作用"><a href="#思维模型的作用" class="headerlink" title="思维模型的作用"></a>思维模型的作用</h2><p>思维模型主要有2个作用：</p><ul><li><p>帮助我们提高做决策的质量和正确率</p><p>生活是一个又一个决定的延续，每个选择做的好与不好对于我们的影响是巨大的。可是我们很少仔细地思考，我们究竟是怎么做决策的，做决策的过程是什么样的。具体看补充知识</p></li><li><p>提升创新力</p><p>我们的创新力往往来自于那些无用的思维模型。</p><p>熊彼特：创新是生产要素的重组，关键在于我们要懂看世界的方式，我们只有掌握了更多理解理解世界的方式，更多解释世界问题的方式，才能够打破我们过去经验世界里各要素的关系，用新的视角来将各个要素进行重新组合，进而产生创新…..</p></li></ul><h2 id="如何发现和学习思维模型？"><a href="#如何发现和学习思维模型？" class="headerlink" title="如何发现和学习思维模型？"></a>如何发现和学习思维模型？</h2><p>查理芒格在《穷查理宝典》中只写了十几个思维模型，那么还有那么多的思维模型我们去哪里学习呢？</p><p>其实在我们的日常生活中，我们可以发现很多很好的思维模型，只不过我们没有方法、没有意识去发现这些思维模型。</p><p>那么，我们如何在生活中发现思维模型呢？</p><h3 id="方法1：启发、问题、思路、模型"><a href="#方法1：启发、问题、思路、模型" class="headerlink" title="方法1：启发、问题、思路、模型"></a>方法1：启发、问题、思路、模型</h3><p>在生活当中，经常会遇到一些让你觉得有启发的事情。大部分人往往不会去深究背后到底在解决什么问题？</p><p>所以，不是碰到问题，再去发现思维模型，而是碰到让你有启发的事情的时候，就可以去思考思维模型。</p><p>分析：</p><ol><li>解决了什么问题</li><li>思路是什么，为什么有效，有哪些基本的要素，本质是什么</li><li>把思路抽象提炼出模型，思考这个思路所调用的更底层的思维模型</li></ol><p>要想实现这个，需要我们做相应的改变：</p><ol><li>心态的转变。需要有好奇心，主动的去问，为什么这个现象的背后有这么一个答案，为什么这个答案起作用</li><li>重点的转变。过去在学习时，时间都主要花在：记笔记、看书、记答案。可是真正重要的地方是将时间花在思考的过程。把时间花在硬问题，打通思维的过程。</li><li>方法的转变。顺着答案不断的和我们过去已有的经验结合。重要的不是答案，重要的是知识之间的联系。</li></ol><h2 id="如何运用思维模型"><a href="#如何运用思维模型" class="headerlink" title="如何运用思维模型?"></a>如何运用思维模型?</h2><p>我们学习了思维模型之后，在我们日常生活中应该怎么去应用呢？</p><p>运用思维模型，关键点在于：多层次、多视角</p><ul><li><p>多层次：把一个问题，使用不同层次的思维模型进行分析。这里的层次可以理解为学科，不同的学科解释问题的层次</p></li><li><p>多视角：在同一个层次当中，用不同的角度来分析问题</p></li></ul><p>欧内斯特-内格尔：各学科就是一系列解释的层次。</p><h2 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h2><h3 id="我们是如何做决策的？"><a href="#我们是如何做决策的？" class="headerlink" title="我们是如何做决策的？"></a>我们是如何做决策的？</h3><p>我们在外部刺激和做出反应之间，并不是简单的刺激行为模式，而是一个ABC模式。</p><ul><li>A: Activatiing event 诱发刺激</li><li>B: beliefs 信念反应，决策依据</li><li>C: consequences 行动结果</li></ul><p>对于同一个刺激A，由于背后的信念B不同，我们会做出不同的行为决策C。我把它理解是一种流式模式，信息源输入一个系统框架（决策依据）中，然后进行运算，得出一个输出结果。</p><p>每个人由于过往的经历、经验、家庭等等因素的不同，会有不同的信念B，而信念往往是很难改变的，因为这个形成的过程往往是自己不自知的，并且容易成为潜意识。</p><p>我们经常说的认知升级，其实本质就是面对同一个问题，你有不同的处理方式，也就是你的中间信念反应，决策依据发生了改变。</p><p>所以，我们成长进步的过程实际上是用更好的决策依据来替换自己之前因为有限知识或经验得出的那些不太可靠的决策依据。</p><p>这个新的，好的决策依据就是我们所说的思维模型。也就是说，我们把这个决策的模型进行了修改，修改之后的实现顺序是：刺激–&gt;思维模型–&gt;行动结果</p><p>总结：我们要把中间的这个黑箱（决策依据）变成我们可以调控的白箱</p><h3 id="多元思维模型"><a href="#多元思维模型" class="headerlink" title="多元思维模型"></a>多元思维模型</h3><p>对于一个系统而言，结构远远大于单个要素本身，系统的性质是取决于要素的结构，而不是要素本身。</p><p>就行C原子，它可以排列成钻石，也可以是石墨，这不是取决于碳元素本身的原因，而是它相互之间关系形成的系统。</p><p>同样的，就算你把查理芒格的思维模型全都学会了，但是你不知道在应用之间它们的关系，结构，权重，先后关系，哪些互相有冲突，你也成为不了查理芒格。最终的结果是你知识知道了很多的思维模型的一个someone。</p><h3 id="如何更高效的学习思维模型"><a href="#如何更高效的学习思维模型" class="headerlink" title="如何更高效的学习思维模型"></a>如何更高效的学习思维模型</h3><p>学习思维模型，重要的不是那些思维模型本身，而不是那些知识点。而是理解我们运用思维模型的思路，它解决问题的过程，所以我们在记笔记的时候可以换一种方法。</p><p>我们记笔记的目的是：描绘出这个思维模型的一个全局框架，而不是零散的看起来非常用来但是不能建立连接的知识点，当问题进入这个框架，出去的时候就是满意的解决。</p><h4 id="七星笔记法"><a href="#七星笔记法" class="headerlink" title="七星笔记法"></a>七星笔记法</h4><p>目的：事先人为的描述整体全局框架的关键点，在过程中，填充着7个关键点，填充完了之后，这个框架也就描绘出来了。也就是说，用你的学习的思维模型去学习其他思维模型</p><p>在学习做记笔记的时候，7个星星，也就是7个问题</p><p>上课或者学习的时候就是回答这7个问题，当这7个问题回答完了，那么笔记也记完了</p><ul><li><p>这门课的目的是什么？也就是：为什么要学习它，它解决什么问题？</p></li><li><p>这门课的核心观点和内容是什么？</p></li><li>目的和这些核心观点是怎么连接的？</li><li>老师或作者讲述的逻辑是什么？</li><li>我在听课学习的过程中，有哪些疑问（说的对吗）和启发（为什么能这么思考）的地方？</li><li>上面的这些疑问和启发背后的思维模型是什么？</li><li>有哪些事情可以让我直接就可以开始找应用场景并采取行动？</li></ul><p>一些说明：</p><ul><li>在学习之前，可以通过上网查资料等方式先了解下这门课，这个领域的核心框架是什么，之后在学习的时候去进行比较。</li><li>老师或者作者的逻辑和我自己理解的有什么差别，重要的不是知识点，重要的是为什么这么组织推演思考过程，为什么这么思考？</li></ul><h4 id="做自己理解的思维导图"><a href="#做自己理解的思维导图" class="headerlink" title="做自己理解的思维导图"></a>做自己理解的思维导图</h4><p>就像上面我说的，要使用自己的框架去记忆这些知识点，如果只是单纯的这些知识点，那么将会是孤立的，没有办法建立连接。</p><h4 id="收集启发点和疑问点"><a href="#收集启发点和疑问点" class="headerlink" title="收集启发点和疑问点"></a>收集启发点和疑问点</h4><p>你在碎片时间进行学习的时候，当碰到启发点和疑问点的时候，简单记录一下，当你有整块时间的时候再去深究它。</p><h4 id="通过预想使用的场景去记忆"><a href="#通过预想使用的场景去记忆" class="headerlink" title="通过预想使用的场景去记忆"></a>通过预想使用的场景去记忆</h4><p>这一点在学习英语等学科中尤为有效，你在记忆单词的时候，最好是在记忆句子的时候顺便记忆单词，如果只是单纯的记忆单词，效果根据不好。</p><p>并且在学习一些语法知识点的时候，最好也是通过一个句子来记忆。</p><p>同样的，在学习其他学科知识的时候，通过结果去记忆这些知识点。</p><h1 id="思维模型"><a href="#思维模型" class="headerlink" title="思维模型"></a>思维模型</h1><h2 id="FFC"><a href="#FFC" class="headerlink" title="FFC"></a>FFC</h2><p>在于他们进行沟通交流的时候，可以使用FFC模型</p><p>F：feeling。描述感觉</p><p>F：fact。描述事实</p><p>C: compare。进行比较</p><p>常规赞美：你好漂亮、今天很漂亮。</p><p>优化：你的打扮让我眼前一亮，你今天的绿色衣服和围巾和项链特别搭配，简直是一股生机盎然的气息，你是今天嘉宾里面最亮眼的。</p>]]></content>
    
    <summary type="html">
    
      思维模型
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="认知升级" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/"/>
    
      <category term="学习方法" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
    
      <category term="思维模型" scheme="http://yoursite.com/tags/%E6%80%9D%E7%BB%B4%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>知识之网理论</title>
    <link href="http://yoursite.com/2019/01/03/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E7%9F%A5%E8%AF%86%E4%B9%8B%E7%BD%91%E7%90%86%E8%AE%BA/"/>
    <id>http://yoursite.com/2019/01/03/个人知识体系/认知升级/学习方法/知识之网理论/</id>
    <published>2019-01-02T16:19:16.000Z</published>
    <updated>2019-01-02T16:19:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>我把一个人的知识看成是一张知识之网（可以类比为蜘蛛网），那么中心节点就是我这个人，由我这个中心发起的每一条边（实际上射线，在这里不严谨，这么用主要是便于直观理解），就是所有基础学科的知识</p><p>这里放上一张蜘蛛网的图</p><p>这个时候这张网只有边，过于分散，是无法捕捉到猎物的，因此需要使用一定的规则将所有边组合起来，对于蜘蛛网来说，我们直观的感受是一个个的<font color="blue"><strong>同心圆</strong></font>。</p><p>同样的，对于我来说，我怎么把这些分散的知识有机的结合起来，形成为一个整体？我的方法就是使用思维模型，通过跨界思维，将所学的知识结合成为一个整体。</p><p>也就是说，我只把知识分为2类：基础学科的知识和思维模型。</p><p>这里有几个问题我需要说明下：</p><ol><li>思维模型是什么？</li><li>跨界思维是什么意思？</li><li>为什么要构建这张知识之网，有了这张网之后又什么作用？</li></ol><h1 id="第一个问题：思维模型是什么？"><a href="#第一个问题：思维模型是什么？" class="headerlink" title="第一个问题：思维模型是什么？"></a><strong>第一个问题：</strong>思维模型是什么？</h1><p>思维模型可以理解为：<strong>思维方式的抽象</strong>。</p><p>生活是由一个个的选择构成的，那么是什么在背后指导我们做选择？我们决定是否买一个东西时需要考虑各种因素（价钱，必要性，时机等等），我们在思考这些因素的时候就是调用我们过往认知产生的思维模型，只不过我们不自知而已。我们在处理问题时，在做考试题目时，解题的思路和步骤更是思维方式的直接体现。</p><p>而思维模型是思维方式的抽象，很多时候我们拥有某一种思维的方式，但是自己却不清楚是怎么运作的，所以这个时候需要站在更高的维度，把它抽象出来，让它能为更多人学习使用。</p><h1 id="第二个问题：跨界思维是什么意思？"><a href="#第二个问题：跨界思维是什么意思？" class="headerlink" title="第二个问题：跨界思维是什么意思？"></a><strong>第二个问题：</strong>跨界思维是什么意思？</h1><p>关于学习知识，我们需要拉大尺度，在大时间线上，在宏观上看待这件事。</p><p>在人类历史中，一开始根本就没有学科，早期的知识主要是为了生存（如果要分类的话可以理解为生存学科），后来解决了生存危机，有了火，有了农耕畜牧之后，慢慢的知识的总量得到的极大增长，人类开始探索自然，这一个阶段的学科其实就一个-自然科学，然后随着文明的进一步发展，才慢慢有了今天我们所看到的样子</p><p>说了这么多，其实就是想说：<strong>人类目前的所有科目其实都是后天分类出来的</strong>。这一点可能很多人往往会忽略。</p><p>每一个学科之间其实是相互影响的，一个学科的重要基础理论可能也同样适用于另一个学科，能够提高你在学习这个学科时的效率</p><p>所以，将所有的学科看成为一个整体，不要局限于某一个具体的学科，才是真正的有效学习。</p><h1 id="第三个问题：知识之网的作用？"><a href="#第三个问题：知识之网的作用？" class="headerlink" title="第三个问题：知识之网的作用？"></a><strong>第三个问题：</strong>知识之网的作用？</h1><p>当我们把思维+具体的知识编织成为一张网，这个时候我们可以把自己看做是等到猎物的蜘蛛，当有问题（蜘蛛的猎物）来的时候，只要落在这张网上面，我们就能找到方法消灭（解决）</p><p>如果有问题解决不了，这个时候我们就知道，我们需要更新我们的知识系统，加固或者扩大我们的知识之网。</p>]]></content>
    
    <summary type="html">
    
      知识之网理论
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="认知升级" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/"/>
    
      <category term="学习方法" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
    
      <category term="学习方法" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>如何输入和输出</title>
    <link href="http://yoursite.com/2019/01/02/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E5%A6%82%E4%BD%95%E8%BE%93%E5%85%A5%E5%92%8C%E8%BE%93%E5%87%BA/"/>
    <id>http://yoursite.com/2019/01/02/个人知识体系/认知升级/学习方法/如何输入和输出/</id>
    <published>2019-01-02T15:02:40.000Z</published>
    <updated>2019-01-02T15:02:40.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><p>就我个人而言，整个学习过程分为以下3个步骤（注意是有顺序的）：</p><ol><li>输入。信息来源</li><li>内化。最核心部分，将所学的知识、思维模型及专业技能存储能够被<strong>直接调用</strong>的资源池中，内化成直觉</li><li>输出。将思维模型或者专业的技能变成直觉的直接输出</li></ol><p>虽然内化是最核心的部分，但是学习是一个完整的系统，输入和输出环境也影响着内化环节。</p><p>我针对我的情况画了一张学习整体结构图，仅供参考：</p><p>下面我们来介绍这三个方面</p><h1 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h1><p>输入也就是信息（知识）的摄入，在日常生活中，我的信息输入源主要有：</p><ul><li><p>书籍</p></li><li><p>视频</p></li><li><p>音频</p></li><li><p>网上获取的知识</p></li><li><p>生活中看到的事情得到的启发</p></li><li><p>自己深度思考得出的知识（也就是说知识的来源可以是本身）</p></li><li><p>交际活动获取的知识</p><blockquote><p>这一部分包含的范围就比较广了，可以是与他人交流时获取的，也可以是参加线下或线上会议、论坛等获取的知识</p></blockquote></li></ul><p>我把通过这些输入源学到的知识主要分为以下2类：</p><ul><li>思维模型。一个思维方式的系统框架。为下面所说的专业领域知识所服务，主要作用是不断优化改善分析和处理问题的逻辑，关于这部分的内容我有专门的文章《思维模型》。</li><li>专业领域的知识。比如计算机科学、英语、数学、历史、心理学、生命科学、经济学、哲学等等学科的知识</li></ul><p>按道理来说，学到的知识应该可以分为很多个类别，为什么我只分了2类？</p><p>这就涉及到个人的知识体系结构问题了，这一点在我的另一篇文章《知识之网理论》有概述。</p><p>因此最佳阅读顺序是：《思维模型》–&gt;《知识之网理论》–&gt;《如何输入和输出》。当然不按照这个顺序来也可以</p><h1 id="内化-关于内化的一些前提知识"><a href="#内化-关于内化的一些前提知识" class="headerlink" title="内化-关于内化的一些前提知识"></a>内化-关于内化的一些前提知识</h1><p>这一章节是全文的重点和核心</p><p>整个内化的过程比较复杂和抽象，因此会花很长的篇幅来进行解释和记录。</p><p>内化是将所学到知识融会贯通的过程，这个过程根据个人的差异（主要是所采取的方法技巧（包括时间管理、一些提升效率的工具的使用等）的差异、思维方式的差异等），整个内化的时间和效果会有非常大的差异性</p><p>下面我要介绍的这些有关学习的基础知识，都是我个人实践过的或者正在实践的，在了解了这些基础知识之后，我们再来说说如何才能达到最佳的内化效果。</p><p>下面我们说一说这些有关内化的基础知识</p><h2 id="大脑结构-神经元连接"><a href="#大脑结构-神经元连接" class="headerlink" title="大脑结构-神经元连接"></a>大脑结构-神经元连接</h2><p>桑代克在《教育心理学》中说：学习就是联结，人之所以善于学习，主要是因为能够形成大量的联结。学习会使人成为异常复杂而精致的联结系统</p><p>一学习之所以有助于另一学习，是因为两种学习具有相同因素的原因</p><p>真正的高手会把模型与模型之间也建立连接，其实这一部分我主要在《知识之网理论》中说明，各个知识或者思维模型可以联结成为一个网站结构，多个网状结构可以形成知识的互联网，这一点其实也和当前宇宙的结构类似。</p><h2 id="艾宾浩斯遗忘曲线"><a href="#艾宾浩斯遗忘曲线" class="headerlink" title="艾宾浩斯遗忘曲线"></a>艾宾浩斯遗忘曲线</h2><p>遗忘曲线的背后实质原因其实还是因为神经元之间没有建立连接</p><h2 id="烧开水理论"><a href="#烧开水理论" class="headerlink" title="烧开水理论"></a>烧开水理论</h2><h2 id="为什么自学比培训好？"><a href="#为什么自学比培训好？" class="headerlink" title="为什么自学比培训好？"></a>为什么自学比培训好？</h2><p>主要的一个原因是神经元无法建立连接以及遗忘曲线的原因。</p><p>这一个部分其实在《知识之网理论》中能够找到答案，在培训班中，大量的知识输入大脑，在现有知识没有建立神经元连接的时候，学习新的知识，不断的恶性循环，就像是在沙子上盖楼，一层水泥还没有干，就开始网上买铺第二层水泥。</p><h2 id="认知升级"><a href="#认知升级" class="headerlink" title="认知升级"></a>认知升级</h2><p>在问题来的时候，原本是走这个神经元通路，经过反复的训练，让大脑走另一个神经元网络通路，新的网络通路越来越强壮，旧的就会慢慢消失。</p><p>所谓的认知升级本质上其实是：建立新的神经网络链路，替换原有的旧的神经网络。修新路，绕旧路。</p><h2 id="内化的5个阶段"><a href="#内化的5个阶段" class="headerlink" title="内化的5个阶段"></a>内化的5个阶段</h2><p>我们在学习新知识的时候，一般来说都会经历这几个阶段</p><ul><li>事前想不到</li><li>事后诸葛亮</li><li>事中有启发。在中某些事的时候，还是用以前的思维的时候，突然会提醒自己，我应该用更好的方式。</li><li>事前会想起</li><li>自然而然。内化成为我们的直觉。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在这里我们对上面的这些知识进行一个总结</p><h1 id="内化-如何达到最佳内化效果"><a href="#内化-如何达到最佳内化效果" class="headerlink" title="内化-如何达到最佳内化效果"></a>内化-如何达到最佳内化效果</h1><p>在这个部分，记录各种学习的方法和基本准则，帮助我们进行有效的内化，提升效率。</p><p>就像我在开头说的，虽然内化是最核心的部分，但是学习是一个完整的系统，输入和输出环境也影响着内化环节。</p><p>所以在这个部分，众多方法我会先讲输入和输出是怎么提升内化的</p><h2 id="通用方法"><a href="#通用方法" class="headerlink" title="通用方法"></a>通用方法</h2><p>学习知识的顺序：</p><ol><li>网上了解，了解粗略的框架</li><li>看视频，视频偏实际的应用，先实践，了解具体是怎么运作的</li><li>看书籍，通过书籍去深入</li></ol><h2 id="输入提升内化"><a href="#输入提升内化" class="headerlink" title="输入提升内化"></a>输入提升内化</h2><p>在这里我们主要以“读书”这个输入方式进行讲解。</p><p>我们在读书的时候，书和书是不一样的，书的类型不同，难度不同，因为所使用的方法也会有所不同。</p><p>下面简单介绍3个方法帮助大家提高阅读时吸收知识的效率。</p><h3 id="熔断不读书法"><a href="#熔断不读书法" class="headerlink" title="熔断不读书法"></a>熔断不读书法</h3><p>在利用碎片时间进行读书的时候，就可以使用这个方法，比如只有十几二十分钟的时候。</p><p>股市中的熔断机制：当股市下跌到某一个指标的时候，就强制不允许买卖交易了，暂停，熔断。</p><p>同样的，当你读书的时候，遇到有疑问或者有启发的地方，立马合上书，然后思考，这里为什么让我有启发，启发点在哪里，我可以把它用在生活中的哪些场景中，这个背后有什么基本原理吗。这个时候其实也就是我在《思维模型》中所说的6星学习法中的后3点。</p><p>使用这种方法，哪怕你只有20分钟的时间，你也可以在书中找到对你有帮助的启发点，我们读书并不需要全部看完，寻找到启发点远比看到毫无收益要好的多。</p><p>总结：每一个单点的知识，都可以让我们真正地去理解思考，通过很短的时间来大幅度提升效率。对于大多数的畅销书而言，使用这个方法去阅读就足够了。</p><p>这种方法的弊端：当你专注于某一个点，你就很容易看不到整个系统。而我们知道，对于一个系统而言，结构远大于单点的要素。</p><p>如果你遇到想深入阅读，理解作者思路和逻辑，看清整个系统的时候，这个时候就不能再使用这个方法。</p><h3 id="关键词读书法"><a href="#关键词读书法" class="headerlink" title="关键词读书法"></a>关键词读书法</h3><p>一本书，无论它的组织思想是什么，它一定是用一些节点串联起来的，而这些节点往往是概念或者关键词的形式。</p><p>你把这些关键词提炼出来，然后寻找它们之间的关系，再结合这本书的主题和目的，梳理出它们之间的关系网络，就找到了作者的思路。</p><p>因为，我们核心要做的就是3件事：</p><ul><li>作者在这本书中想要解决什么问题？</li><li>关于这个问题，他提出了哪些核心观点（观点通常会以关键词的方式展示出来）</li><li>目的和关键词之间的关系是什么？（也就是：要解决的问题，是怎么和观点连接起来的，它们的联系）</li></ul><p>如何获取核心观点或者说关键词，需要我们把整本书读完再去总结吗？</p><p>我们其实可以用这个方法去提炼：封序目尾（封面，序言，目录，结尾）</p><p>换一个视角来看，其实阅读不仅仅是我们去读书，也就是说，不仅仅是我们一个人的事，还有作者和出版社，阅读，其实是3个元素构成的一个系统。就像人际沟通，其实也就是双方与信息三者构成的系统。</p><ul><li>封面：出版社会想尽办法把这本书的重点、主要价值提炼出来。主要是为了更好的销售。</li><li>序言：一般情况在封面之后会有说明，提炼出在这本书中，作者最核心的观点。</li><li>目录：关键词列表，作者在写目录的时候，通常会那些关键的概念提炼出来</li><li>结尾：</li></ul><p>任何一个作者，通常都会在开篇或者结尾的时候，把自己的书的特点、最关键的思想提炼出来。</p><p>所以，我们要找到一本书的关键词，通常情况下，根据不需要读完一本书，通过这4个步骤，通常就能获取。</p><h3 id="经典书籍-里应外合读书法"><a href="#经典书籍-里应外合读书法" class="headerlink" title="经典书籍-里应外合读书法"></a>经典书籍-里应外合读书法</h3><p>里：书里写的文字，阅读书籍的内容</p><p>外：书籍里没有写的内容部分</p><p>我们知道，我们写书籍的目的是，通过书籍这种语言文字符号去表达我们头脑的思想。</p><p>斯蒂芬-平克曾说：写作的难点在于要把网状的思考用树状的结构体现在线性展开的语句里。所以，写作实际上是作者思维层层压缩维度的一个过程。</p><p>因此，黑格尔会说：每当我用语言和符号去表达我的思想，我的思想就发生质变和肤浅化。</p><p>所以说，语言符号这种方式本身会带来一些限制问题，因此我们要精读那些最经典的书籍的时候，就需要注意到这种缺陷，因此，在阅读经典书籍的时候，使用里应外合的方法。</p><p>因此，在这种情况下，我们要知人论世，就是要研究作者的成长背景，他过去的经历对他有什么影响，哪些人的思想对他有很大的影响。他所处的时代，主流思想是什么。文化背景是什么，这些都是我们额外需要去做的功夫。</p><p>我们要把这本书放在时代、人物、文化等大的背景下理解，才能真正理解经典思想。</p><h2 id="输出提升内化-输出倒逼输入"><a href="#输出提升内化-输出倒逼输入" class="headerlink" title="输出提升内化-输出倒逼输入"></a>输出提升内化-输出倒逼输入</h2><h3 id="以教为学"><a href="#以教为学" class="headerlink" title="以教为学"></a>以教为学</h3><p>把教别人当做一个学习的过程，你不懂哪个思维模型，你不会用哪一个，你就去教别人哪一个。</p><p>主要有3个点再驱动你：</p><ul><li>压力。压力转化为动力。</li><li>发现自己的知识阻塞。在准备的过程中，你会发现一些原来自己以为懂但是实际上是不懂的地方。</li><li>通过别人的提问检验反馈。</li></ul><h2 id="具象抽象再具象"><a href="#具象抽象再具象" class="headerlink" title="具象抽象再具象"></a>具象抽象再具象</h2><p>我们所学习到的思维模型，一般情况下来说是已经具象化过的。</p><p>这个时候，我们需要把它进行抽象，抽象出一个系统框架，再填充上我们自己的内容，再重新具象化。</p><p>举例来说，我们在学习查理芒格的“复利”思维模型的时候，如果从表面上学习的话，很难被我们在日常生活中所运用，因为它是已经被查理芒格具象化的，我们所看到的并不是抽象层面的。</p><p>这个时候，我们把他说的这个思维模型进行抽象，可以看到“复利”的本质是：</p><p>做A会导致B，而B反过来又会强化A。所以我们在生活中看到的，凡是符合做A产生B，B又会强化A的都是“复利”这个思维模型的具象表现。</p><p>当我们知道了这个抽象的思维模型之后，我们可以看到，生活中的很多事情都可以用复利来进行解释。</p><p>例如，亚马逊的增长飞轮模式其实就是一个方法的复利的具象应用，是一个更大的综合系统下来思考。</p><p>所以，明白了复利的核心之后，我们就知道，我们需要使用长线思维去做一些事情，而不能短视。</p><h2 id="刻意练习"><a href="#刻意练习" class="headerlink" title="刻意练习"></a>刻意练习</h2><p>先把结论放出来：刻意练习=核心算法*大量练习。最终的结果是把思维模型和专业技能这些转换成为直觉。</p><p>把思维模型和专业技能转化成为直觉是需要大量的训练的。但是应该怎样去训练呢？不断的重复，遵循一万小时定律吗？</p><p>但是我们每天要上班，各种事情，哪有那么多的时间去训练呢？</p><p>就算我有时间，我应该怎么去训练这些思维模型和知识呢？</p><p>《助推》：如果我们想要持续的产生一个行为，那么外部的环境影响是非常重要的。</p><p>也就是说：不同的环境会影响我们某个行为产生的频率。而不断的练习和反省训练思维模型和专业技能也需要这样一个助推的环节。你需要设计一个场景，能够不断的触发我们反省思考</p><p>一个非常重要的工具：《反思日记》。提高我们成长进步斜率的杠杆点</p><h3 id="核心算法1-对标练习"><a href="#核心算法1-对标练习" class="headerlink" title="核心算法1-对标练习"></a>核心算法1-对标练习</h3><p>在日常生活中，经常碰到的一个问题是，学习了一个思维模型或者一些我们觉得非常有用的知识点之后，找不到使用的场景。也就是说，我们学的这些知识和我们是脱节的。</p><p><strong>核心问题：</strong>不是学习的这个思维模型不起作用，而是我们看不到它如何起作用。</p><p>对标：把思维模型当做思考问题的标准。寻找可以用思维模型的场景。</p><h3 id="核心算法2-举一反三"><a href="#核心算法2-举一反三" class="headerlink" title="核心算法2-举一反三"></a>核心算法2-举一反三</h3><p>学习了一个思维模型之后，至少在3个以上的不同场景中练习应用。</p><p>你必须找到不同的场景去运用同一个思维模型，如果找不到，说明还是不理解这个事情。</p><h2 id="七星笔记法"><a href="#七星笔记法" class="headerlink" title="七星笔记法"></a>七星笔记法</h2><p>目的：事先人为的描述整体全局框架的关键点，在过程中，填充着7个关键点，填充完了之后，这个框架也就描绘出来了。也就是说，用你的学习的思维模型去学习其他思维模型</p><p>在学习做记笔记的时候，7个星星，也就是7个问题。上课或者学习的时候就是回答这7个问题，当这7个问题回答完了，那么笔记也记完了</p><ul><li>这门课的目的是什么？也就是：为什么要学习它，它解决什么问题？</li><li>这门课的核心观点和内容是什么？</li><li>目的和这些核心观点是怎么连接的？</li><li>老师或作者讲述的逻辑是什么？</li><li>我在听课学习的过程中，有哪些疑问（说的对吗）和启发（为什么能这么思考）的地方？</li><li>上面的这些疑问和启发背后的思维模型是什么？</li><li>有哪些事情可以让我直接就可以开始找应用场景并采取行动？</li></ul><p>一些说明：</p><ul><li>在学习之前，可以通过上网查资料等方式先了解下这门课，这个领域的核心框架是什么，之后在学习的时候去进行比较。</li><li>老师或者作者的逻辑和我自己理解的有什么差别，重要的不是知识点，重要的是为什么这么组织推演思考过程，为什么这么思考？</li></ul><h2 id="逻辑思维"><a href="#逻辑思维" class="headerlink" title="逻辑思维"></a>逻辑思维</h2><h3 id="star1-学习逻辑的目的"><a href="#star1-学习逻辑的目的" class="headerlink" title="star1:学习逻辑的目的"></a>star1:学习逻辑的目的</h3><p>通过学习逻辑思维的相关知识，提高我们在今后学习的时候，提取知识和梳理脉络的效率。最终目的是为了更好的构建思维模型。</p><h3 id="star2-逻辑思维的核心观点和内容"><a href="#star2-逻辑思维的核心观点和内容" class="headerlink" title="star2:逻辑思维的核心观点和内容"></a>star2:逻辑思维的核心观点和内容</h3><h4 id="什么是逻辑-知识和思考方法"><a href="#什么是逻辑-知识和思考方法" class="headerlink" title="什么是逻辑-知识和思考方法"></a>什么是逻辑-知识和思考方法</h4><p>知识：是问题的答案，比如人有一张嘴、2个耳朵；达尔文的进化论。</p><p>思考的方法：知识背后的。</p><p>举例来说：我们都学了达尔文的演化论，我们是要学习达尔文的演化论究竟说了什么东西吗？演化论里面，它的知识点有哪些吗？我们学习演化论其实是要琢磨这么一个事情：全人类都面对同一个大自然，但是有的人找出的是神造论，那么，为什么达尔文就偏偏能够解读出演化论这件事情，他是怎么找出这个<strong>视角</strong>、怎么从这个视角<strong>推论出道理</strong>、怎么证明这个道理。<font color="red">视角–&gt;道理–&gt;证明</font>。这个系列就是达尔文的思考方法。</p><p>逻辑就是：从找到角度进而论述道理，进而证明道理，这整条的脉络，运算机制就是逻辑。</p><p>总结一下，逻辑思维是分析思考事物的方法，帮我们找出知识的脉络。</p><h4 id="为什么要学逻辑？"><a href="#为什么要学逻辑？" class="headerlink" title="为什么要学逻辑？"></a>为什么要学逻辑？</h4><p>逻辑是每一个人先天就有的，我们常常会误认为不学习逻辑就没有逻辑。</p><p>我们身处其中却又不知自的逻辑通常有2个：</p><ul><li>逻辑1：归纳法。同一件事情，它的因果链条在不同的情况中，高频率的重复出现，我们自然而然的就会把它归纳起来，认为这就是一个道理。此蘑菇有毒。这个道理的整个过程是不需要进行推理的，只需要记忆就可以。</li><li>逻辑2：演绎推理法。例如祈祷这个事情，前提：有病是因为我冒犯了神灵。过程：向神灵沟通，就能够让他宽恕我的罪过。因此结论就是：求神能治病。这个就是演绎法（演绎推理法）的雏形。</li><li>补充：演绎推理是严格的逻辑推理，一般表现为大前提、小前提、结论的三段论模式：即从两个反映客观世界对象的联系和关系的判断中得出新的判断的推理形式。如：“自然界一切物质都是可分的，基本粒子是自然界的物质，因此，基本粒子是可分的。”演绎推理的基本要求是：一是大、小前提的判断必须是真实的；二是推理过程必须符合正确的逻辑形式和规则。演绎推理的正确与否首先取决于大前提的正确与否，如果大前提错了，结论自然不会正确。</li></ul><p>那么，既然逻辑是我们每一个人先天就有的，为什么我们还要学习逻辑呢？</p><p>2个原因：</p><ul><li>直观答案阻碍我们启动思考。只要我们对某一个疑问有了一个答案，那我们很自然的就会让我们的大脑停止思考。例如：学音乐的孩子比较乖。这个说法是不是有点因果倒置了？当我们开始进行推敲的时候，我们往往就能发现潜藏在背后的真正答案。</li><li>世界越来越复杂。很难直观的发现，我们现在的一个行为最终会造成什么样的后果。商场中，所有的决策，永远不会只有一个面的效果，所以我们需要让我们的视角更开阔，让判断更精密。</li></ul><p>头脑中拥有非常多的逻辑知识，不代表你的逻辑能力强。逻辑其实是一个能力，而不是知识</p><p>所以，学逻辑应该说是：<strong>锻炼我们先天既有的逻辑能力，让它变得更精准</strong></p><h4 id="如何启动触发逻辑"><a href="#如何启动触发逻辑" class="headerlink" title="如何启动触发逻辑"></a>如何启动触发逻辑</h4><p>也就是如何运用</p><p>人的大脑是分为两个部分的：</p><ul><li>理性思考。也就是逻辑思维。</li><li>感性直觉。人在碰到问题的时候，最直观的答案。</li></ul><p>人的大脑总是：先感性直觉，再决定要不要启动理性思考。理性思考往往滞后于感性直觉。</p><p>思考工具：为什么、凭什么？前提是方向的确定性。</p><p>4个判断：</p><ul><li>事实判断</li><li>功利判断</li><li>价值判断</li><li>审美判断。主要是感受</li></ul><p>我们在进行思考的时候，往往会有多个判断同时浮现，这个时候方向的确定就显得非常重要。</p><h4 id="提高逻辑的效率"><a href="#提高逻辑的效率" class="headerlink" title="提高逻辑的效率"></a>提高逻辑的效率</h4><h5 id="足够的信息-更多信息"><a href="#足够的信息-更多信息" class="headerlink" title="足够的信息-更多信息"></a>足够的信息-更多信息</h5><p>很多人认为，一个有逻辑的人，他找出的答案一定是正确的。这是不一定的</p><p>案例：例如四方形的面积等于长*宽。如果这个时候只是知道了长，那么是不能就算出面积的。</p><p>也就是说：逻辑思维要能给我们反馈一个准确的答案，还有一个重要的前提就是：我们注入的信息是足够丰富的。</p><p>也就是说表象要足够丰富，我们才能够进行抽象</p><h5 id="封装-更多观念"><a href="#封装-更多观念" class="headerlink" title="封装-更多观念"></a>封装-更多观念</h5><p>掌握更多封装的观念。一个就久经验证的道理，这个道理可以直接为我们所用，不用我们再去麻烦的推演的一套观念。</p><p>例如：勾股定理。供需关系。</p><h5 id="找出更多元的答案"><a href="#找出更多元的答案" class="headerlink" title="找出更多元的答案"></a>找出更多元的答案</h5><p>当我们习惯用一个方法来解决问题之后，就会不由自主的在下一次碰到同类问题的时候会重复沿用。</p><p>但是每一个问题或多或少都是不一样的。人不可能在同一条河中出现两次。</p><p>工具：类比思维。这个事情在其他领域有没有类似性质可以参考。把其他领域的解法引用进来帮助我们解决问题。</p><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>信息—&gt;逻辑—&gt;本质—&gt;逻辑—&gt;方法。</p><h3 id="star3-观点内容和目的是如何连接的？"><a href="#star3-观点内容和目的是如何连接的？" class="headerlink" title="star3:观点内容和目的是如何连接的？"></a>star3:观点内容和目的是如何连接的？</h3><p>目的-内容：</p><ul><li>了解逻辑思维。第一部分的知识和思考方法以及第二部分的为什么要学。说明了什么是逻辑思维，逻辑思维是分析思考事物的方法；以及学习逻辑思维对我们有什么影响，默认内置的2个逻辑思维不够不能满足实际的需求，因为直观答案阻碍我们并且当今世界越来越复杂。</li><li>掌握逻辑思维。首先确定思考的方向，然后使用工具：为什么？凭什么？</li><li>更高效的使用逻辑思维。信息、可以直接调用的封装框架，多元角度。</li></ul><h3 id="star4-讲述的逻辑是什么样的？"><a href="#star4-讲述的逻辑是什么样的？" class="headerlink" title="star4:讲述的逻辑是什么样的？"></a>star4:讲述的逻辑是什么样的？</h3><p><strong>讲述的顺序：</strong></p><ul><li>简介学习的目的</li><li>介绍核心观点和内容(是什么、为什么、怎么做、如何提高)</li></ul><h3 id="star5-有哪些启发点和疑问点"><a href="#star5-有哪些启发点和疑问点" class="headerlink" title="star5:有哪些启发点和疑问点"></a>star5:有哪些启发点和疑问点</h3><p>启发点：主要是在为什么要学习逻辑这一个部分。介绍了我们已经被内置的2个逻辑，也就是归纳法和演绎推理法。但是这2个先天的逻辑在没有经过训练强化的情况下不能满足我们的使用需求，所以我们要做的事情其实上是强化锻炼我们的先天逻辑，让它变得更精准。而不是所谓的创建逻辑思维，它本身就是存在的。</p><h3 id="star6-这些启发点和疑问点背后的本质和思维模型是什么？"><a href="#star6-这些启发点和疑问点背后的本质和思维模型是什么？" class="headerlink" title="star6:这些启发点和疑问点背后的本质和思维模型是什么？"></a>star6:这些启发点和疑问点背后的本质和思维模型是什么？</h3><p>我的理解：其实逻辑还是算是思维模型体系中的一个部分，并不是独立存在的。逻辑其实是我们做决策的一个依据，也就是处理一个事情的脉络，也就是抽象后的单个或多个思维模型的组合。</p><p>而逻辑能力是发现和从构建思维模型的能力。</p><h3 id="star7-有哪些我可以直接运用的应用场景？"><a href="#star7-有哪些我可以直接运用的应用场景？" class="headerlink" title="star7:有哪些我可以直接运用的应用场景？"></a>star7:有哪些我可以直接运用的应用场景？</h3><p>思维模型的抽象有一个前提，就是需要输入大量的具象的信息，有了大量的具象信息之后我们才能进行抽象，依靠唯心主义，凭空创造是不可取的。</p><p>总结：这个逻辑思维的内容部分，我学习完了之后其实是没有多少收获的，说的都是我已经知道的内容，但是在没学之前又生怕错过了什么。如果对你有启发，那就最好。</p><h1 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h1><p>当经历了输入和内化之后，就只剩下输出了。</p><p>在很多人看到，输出很简单，通过文章或者讲解把自己的要表达的这些内容说抛出来就完成了。</p><p>但是，行百里者半九十！良好的输出和输入及内化同等重要！</p><p>但是，行百里者半九十！良好的输出和输入及内化同等重要！</p><p>但是，行百里者半九十！良好的输出和输入及内化同等重要！</p><p>重要的事情说三遍！</p><p>一般人在进行输出的时候，往往是采取：是什么？、为什么？、怎么做？这么3个问题来展开。这种方式有其一定的科学道理，但并不是任何场景都试用的，这些还是在表象层面，我们要做的，是真正的发掘更本质的东西。</p><p>因此，我个人思考得出的观点是在输出的时候，有没有想过一下这些问题：</p><ul><li>说的对吗？你是否正确的把你要表达的内容输出出来了？是否达到了本次输出的目的？</li><li>听/看完了吗？信息接受者有没有真的听或看完你的内容？为什么不能坚持？是输出的方式有问题还是输出结构还是什么问题？</li><li>听/看懂了吗？信息接受者有没有理解你表达出来的内容。</li><li>是科学的吗？<ul><li>你的输出方式是不是合理科学的？有时间的控制还是任意发挥?</li><li>在阐述一些其他人没有接触过的新知识的时候，有没有更好的方法帮助他人吸收？</li><li>输出介质（文章、图片、视频等）的组织结构是否清晰易读，内容是否重点突出（最终的目的是为了更好的理解），是否可以学习下写作技巧等科学的方法进行提升</li></ul></li></ul><p>下面我们进行拆分讲解。</p>]]></content>
    
    <summary type="html">
    
      如何输出和输出
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="认知升级" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/"/>
    
      <category term="学习方法" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E8%AE%A4%E7%9F%A5%E5%8D%87%E7%BA%A7/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
    
      <category term="学习方法" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
    
  </entry>
  
</feed>
