<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Watchmen1992&#39;s Blog</title>
  
  <subtitle>锦瑟年华当与书香为度，是为不负天地人生。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-04-22T01:20:34.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>XiaoHua WANG</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>湿气的产生及预防治疗</title>
    <link href="http://yoursite.com/2018/04/22/%E6%B9%BF%E6%B0%94%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8F%8A%E9%A2%84%E9%98%B2%E6%B2%BB%E7%96%97/"/>
    <id>http://yoursite.com/2018/04/22/湿气的产生及预防治疗/</id>
    <published>2018-04-22T01:20:34.000Z</published>
    <updated>2018-04-22T01:20:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>文章结构：</p><p>google了所有<code>湿气</code>页的成果</p><ul><li>第一部分：是什么-湿气的概念  &amp;&amp; 为什么-湿气的产生原因</li><li>第二部分：怎么做-如何预防及治疗</li></ul><p>参考文献：</p><ul><li><a href="https://www.zhihu.com/question/20368808" target="_blank" rel="noopener">知乎-湿气是怎么回事，人为什么会有湿气？</a></li><li><a href="https://baike.baidu.com/item/%E6%B9%BF%E6%B0%94/2050090" target="_blank" rel="noopener">湿气（中医理论概念）</a></li></ul><h1 id="1-湿气概念及产生原因"><a href="#1-湿气概念及产生原因" class="headerlink" title=" 1. 湿气概念及产生原因 "></a><font color="red"> 1. 湿气概念及产生原因 </font></h1><h2 id="1-1-概念"><a href="#1-1-概念" class="headerlink" title="1.1 概念"></a>1.1 概念</h2><p><strong>1.1.1 湿</strong></p><blockquote><p>我们在日常生活中，感受到湿的时候一般是物体含水量超出一定范围，这个水分可以依附到很多物体上，比如湿巾、湿木头、湿衣服等等（无法正常排出的水）。</p><p>但含水量也不能超过一定限度，依附不住的水就不叫做湿，而是自由的水，比如湿衣服滴下来的水，这就不称为湿。</p></blockquote><p><strong>1.1.2 湿气</strong></p><blockquote><p>湿气是一种中医理论中的概念。通俗的来说，就是人体内有多余的水份无法正常代谢排出，堆积在身体之内，从而影响身体健康。（具体原因可能是个人体质、疾病或生活习惯不良，造成体内水分调控系统失衡）</p><p>就像我们日常生活中所看见的：食物放在潮湿的地方相比干燥的地方，很快就会发霉，类比到人上，当人的湿气较重之后，会产生一系列疾病。</p><p>一般也把湿气称之为：<strong><code>湿邪</code></strong></p></blockquote><p><strong>在致病的风、寒、暑、湿、燥、火这“六淫邪气” 中，中医最怕湿邪。</strong></p><p>湿是最容易渗透的。湿邪从来不孤军奋战，总是要与别的邪气狼狈为奸。</p><p>湿气遇寒则成为寒湿，这就好比冬天的时候，如果气候干燥，不管怎么冷，人都还是能接受的，但如果湿气重，人就很难受了。南方的冬天比北方的冬天更令人难受，就是因为南方湿气比较重，寒湿袭人。</p><p>湿气遇热则成为湿热，这就好比夏天的桑拿天，又热又湿，让人喘不过气来，明显不如烈日当空、气候干燥的时候来得痛快。</p><p>湿气遇风则成为风湿，驱风很容易，但一旦成了风湿，就往往是慢性疾病，一时半会儿治不好了。</p><p>湿气在皮下，就形成肥胖，也是不好处理的健康问题……</p><p>为什么现代人的病那么复杂，那么难治？因为他们体内有湿，体外的邪气总是和体内的湿气里应外合，纠缠不清！以前仅仅盛行于我国西南的川菜，风行全国，就是因为川味是辛辣的，以前只有生活在湿邪比较重的西南一带人需要用它来化解体内的湿气；全国人体内都有湿气了，这就需要辛辣来化解。</p><font color="blue"> <strong>主导湿气的人体器官是：<code>脾</code></strong> </font>。<br><br>因此，湿气问题的根本原因是各种原因导致的脾功能下降（也有可能是其他器官导致，因为脾在工作时要需要借助胃肝肾等器官），具体见下文。<br><br><br><br>## 1.2 产生原因-那么湿气是怎么来的呢？<br><br><strong>1.2.1 外在原因</strong><br><br>&gt; 一个是因为外在的环境，也就是湿邪进入到了身体。<br>&gt;<br>&gt; 比如长期居住在湿气重的地方，比如淋了雨还不及时擦干，比如晚上洗头没吹干就睡觉，让外界的湿气进入到体内。<br><br>&gt; 湿气进入身体后常常奔着脾胃去，导致脾的运化能力下降，而这又会容易导致体内生湿。<br><br><strong>1.2.2 内因</strong><br><br>&gt; 另外一个就是饮食习惯差，导致脾运化能力下降而生湿。【饮食不当，伤害脾胃，这是产生湿气的罪归祸首】<br><br>&gt; 此外夏天的时候狂开空调，狂吃冷饮，硬生生的把要出来的水份给逼回去了。还有缺乏运动，没有及时的增强脾的工作能力。<br><br>&gt; 脾主运化，吃进来的食物通过它来运化出精微物质，剩下的糟粕排出体外。当因为各种原因导致脾虚、运化能力下降的时候，精微物质就没法完全提炼出来。<br><br><br><strong>1.2.3 原因解析</strong><br><br><br>&gt; 从微观的角度讲，物质没有完全被消化时，就成了携带营养物质的“垃圾”，成分复杂且分子比较大，没法被人体吸收，但又不像糟粕那么大块头好分辨，那么容易把它们驱逐。<br>&gt;<br>&gt; 它们的分子量和体积远大于水分子，潜伏着，聚集起来，极其容易把周围的水分子吸附住、束缚住，使含水量超出正常的生理水平，于是形成了湿。<br><br>&gt; <font color="blue"> 脾被湿气困住，更加影响它的运化工作，导致湿气加重。湿一直凝聚不化，时间长了就成为痰，身体出于自保自救，把其中一部分水、二氧化碳和营养垃圾打包成了脂肪。所以中医常说胖人多痰湿，就是这个道理。【So，减肥先去湿气】</font><h2 id="1-3-湿气的特点"><a href="#1-3-湿气的特点" class="headerlink" title="1.3 湿气的特点"></a>1.3 湿气的特点</h2><p><strong>1.3.1 笨重并且混浊</strong></p><blockquote><p>湿气依附在身体某些地方，和身边的物体紧紧结合，难舍难离。物体湿的状态时会比干燥的时候重很多,所以体内有湿气的时候，我们往往觉得身体或头部沉重；湿气浊会导致身体气血流通不畅，长期聚集身体又没法整治它,导致有湿气的地方脏乱差，滋生各种毒害。</p></blockquote><p><strong>1.3.2 难缠粘人</strong></p><blockquote><p>什么东西被湿邪盯上，就好像被缠上了粘液，各种不爽，比如小便不畅，大便黏腻不爽等。此外它还很难去除，经常和你缠缠绵绵，病程较长，比如风湿病、温湿病。</p></blockquote><p><strong>1.3.3 阻遏气机、损伤阳气</strong></p><blockquote><p>湿气本质上属于阴邪，靠着它黏腻难缠的劲头，赖在脏腑经络上不走，导致气机升降无能，于是阳气就没法正常生发了。所以一般被湿邪困住的人，阳气都不太旺，会有脸色淡白，精力不济的现象。</p></blockquote><h2 id="1-4-湿气重的表现"><a href="#1-4-湿气重的表现" class="headerlink" title="1.4 湿气重的表现"></a>1.4 湿气重的表现</h2><ul><li><p>头发爱出油、面部油亮, 小肚子大(常有胀气)，身体浮肿。</p></li><li><p>身体发沉、发重，浑身无力。</p></li><li><p>皮肤上会有湿疹，胃口不好，嘴里发黏。</p></li><li><p>常感到疲倦，精力不集中睡觉打呼噜，痰多，咳嗽,睡觉留口水、口臭、身体有异味，耳内湿（耳禅湿）毛发粗糙，易脱落。</p></li><li><p>舌质很胖，颜色偏淡。症状严重的，舌头边上会有齿痕，这叫“裙边舌”。</p></li><li><p>眼袋下垂，黑圆圈严重，肥胖，减肥后反弹，机能衰退，对房事不感兴趣质量不高等。</p></li><li><p>大便溏稀不成型，正常的大便是光滑的呈圆柱体，每次大便之后，不会粘在光滑的马桶壁上，如果你每次上完厕所，大便冲不干净，那么一定是体内湿气在作怪。而且，湿气会让便秘如影随形。下一次，当你大便的时候，很可能就会出现便秘。</p></li><li><p>等等等等</p></li></ul><p>当湿气演变成为顽固性湿气的时候，身体会出现数十种不适：</p><p><img src="http://picture.watchmen.xin/湿气/1.jpg" alt="湿气"></p><p>以上症状，如果你占了2种以上，要引起注意了，这说明体内有湿气。湿气不除，是引发及恶化疾病的关键。</p><p>并且现代人由于工作强度、压力等都更大，因此运动量也原来越小，体内阴盛阳虚从而湿邪内郁。这也是当前越来越多的年轻人有湿气相关疾病的原因。</p><h1 id="2-如何预防及治疗"><a href="#2-如何预防及治疗" class="headerlink" title="2. 如何预防及治疗 "></a><font color="red">2. 如何预防及治疗 </font></h1><p>在这里，我们将预防和治疗两者结合在一起说明，因为光靠预防不能完全杜绝，或多或少肯定都还是会产生湿气。</p><p>湿气很重，不要只会傻傻拔罐。</p><h2 id="药物"><a href="#药物" class="headerlink" title="药物"></a>药物</h2><p>目前没有什么比较好的药物，一般采用饮食结合运动的方式来预防和治疗湿气。</p><h2 id="饮食"><a href="#饮食" class="headerlink" title="饮食"></a>饮食</h2><p>这里只说该吃什么，至于不该吃什么，请看<code>日常生活</code>章节</p><ul><li>薏米赤小豆桂圆粥<ul><li>薏米：性寒。因此要用赤小豆来中和，并且每次的量不宜太多</li><li>赤小豆：性，。注意赤小豆是扁的，红豆是圆的</li><li>桂圆/枣：桂圆甘温。有的人体质偏寒，里面可以加一点温补的食物，像桂圆、大枣都可以</li></ul></li></ul><p>如果着凉感冒了，或是体内有寒，胃中寒痛，食欲不佳，可在薏米赤小豆汤中加几片生姜。生姜性温，能温中祛寒，健脾和胃。</p><p>肾虚的人，可在薏米赤小豆汤中加一些黑豆。因为黑色入肾，豆的形状也跟肾十分相似，以形补形，是补肾的佳品。</p><p>人们常说的脚气病，是典型的湿热下注。可在薏米赤小豆汤中加点碎黄豆，用熬出来的汤泡脚，这是治脚气的一个小秘方。</p><p>学会薏米赤小豆汤的加减变化，使用得当可以对生活中大部分常见病起到很好的治疗效果。</p><p><strong>如下图所示：</strong></p><p><img src="http://picture.watchmen.xin/湿气/2.png" alt="加减法"></p><h2 id="运动"><a href="#运动" class="headerlink" title="运动"></a>运动</h2><p>现代人动脑多、体力消耗少，加上长期待在密闭空调内，很少流汗，身体调控湿度的能力变差。因此这也为产生湿气创造了条件。</p><p>运动出汗是很好的去湿气方式</p><h2 id="日常生活"><a href="#日常生活" class="headerlink" title="日常生活"></a>日常生活</h2><p><strong>不宜</strong></p><ul><li>不过食生冷肥甘厚腻甜辛辣，</li><li>避开生冷食物。这里说的生冷食物指的是冷饮、凉拌菜等，而不是水果。【这一点在夏天的时候最为明显，一些人在夏天时喝冷饮、和冰镇啤酒、吃冰镇西瓜、吃凉菜等毫无节制】</li><li>夏天尽量不吹空调</li><li>睡前务必吹干头发</li><li>饮食口味重，日常饮食口味经常过重的话，由于细胞渗透压的作用，浓度低的会向浓度高的一方渗透，力求平衡，从而会使身体处于不正常状态</li><li>不宜久坐，一小时不动两小时不动三小时不动，身体以为你不会动了，它的运行也会慢下来慢下来</li><li>不宜大量吃水果。</li></ul><p><strong>宜</strong></p><ul><li>晚上用热水泡脚。<ul><li>每天晚上坚持用热水泡脚半小时（<strong>注意：时间是半小时</strong>），泡到微微出汗。</li><li>泡脚的同时敲打肘窝、腘和腋窝各5分钟。这三个地方是排湿气的重要部位。腋窝都知道，肘窝就是手肘后面弯曲部位，腘就是膝盖后面弯曲部位。</li></ul></li></ul><ul><li><p>天气好的日子，勤晒衣物和被子，减少病菌，降低生病的可能。</p></li><li><p>夏天时家中易闷热潮湿，每天要适度开窗换气，新鲜的空气可以减少细菌病毒的滋生，以傍晚最适宜。</p></li><li><p>清淡饮食</p></li><li>保持衣物干爽,不要穿潮湿未干的衣服、盖潮湿的被子，被子(垫絮)要经常晒。</li><li>夏天不要贪凉睡地板</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>食疗、运动最多只能暂时缓解症状，找到自身湿气产生的原因，才能从根上断绝它。</p><p>我们不能怪罪脾胃太虚弱，吃那么多它累死也消化不完啊；不要怪它懒罢工不干活，湿气困着它，它也很无奈；别说它工作不到位，身体消耗少，营养物质只能不断堆积。</p><p>不形成良好的生活习惯，喝再多薏米粥、吃再多健脾祛湿的方药都是白搭！所以与其总是寻医问药寻找除湿气的方法，不如老老实实先好好吃饭、合理饮食、不贪凉不贪酒、加强体育锻炼.多动少吃清淡平衡饮食,这才是正确的姿势。</p>]]></content>
    
    <summary type="html">
    
      湿气是我们日常生活中经常听到的一个概念，在医院看病的时候，医生可能会来上一句：&quot;湿气有点重&quot;，那么到底什么事湿气呢，我们在日常生活中又该如何预防及治疗呢？
    
    </summary>
    
      <category term="个人知识体系" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"/>
    
      <category term="及简身体之道" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E5%8F%8A%E7%AE%80%E8%BA%AB%E4%BD%93%E4%B9%8B%E9%81%93/"/>
    
      <category term="湿气" scheme="http://yoursite.com/categories/%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E5%8F%8A%E7%AE%80%E8%BA%AB%E4%BD%93%E4%B9%8B%E9%81%93/%E6%B9%BF%E6%B0%94/"/>
    
    
      <category term="湿气" scheme="http://yoursite.com/tags/%E6%B9%BF%E6%B0%94/"/>
    
  </entry>
  
  <entry>
    <title>keepass常用操作</title>
    <link href="http://yoursite.com/2018/04/20/keepass%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2018/04/20/keepass常用操作/</id>
    <published>2018-04-20T02:27:55.000Z</published>
    <updated>2018-04-20T02:27:55.000Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="tag1" scheme="http://yoursite.com/tags/tag1/"/>
    
  </entry>
  
  <entry>
    <title>X-Pack</title>
    <link href="http://yoursite.com/2018/04/19/X-Pack/"/>
    <id>http://yoursite.com/2018/04/19/X-Pack/</id>
    <published>2018-04-19T03:35:55.000Z</published>
    <updated>2018-04-19T03:35:55.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考资料：</p><p><a href="https://www.elastic.co/guide/en/x-pack/current/index.html" target="_blank" rel="noopener">官网</a></p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>x-pack是Elastic Stack的扩展包，实现了如下的一系列功能：</p><ul><li>Security</li><li>Monitoring</li><li>Alerting and Notification</li><li>Reporting</li><li>Graph</li><li>Machine Learning</li></ul><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1>]]></content>
    
    <summary type="html">
    
      X-Pack从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="X-Pack" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/X-Pack/"/>
    
    
      <category term="X-Pack" scheme="http://yoursite.com/tags/X-Pack/"/>
    
  </entry>
  
  <entry>
    <title>su: cannot set user id: Resource temporarily unavailable</title>
    <link href="http://yoursite.com/2018/04/18/su-cannot-set-user-id-Resource-temporarily-unavailable/"/>
    <id>http://yoursite.com/2018/04/18/su-cannot-set-user-id-Resource-temporarily-unavailable/</id>
    <published>2018-04-18T03:47:17.000Z</published>
    <updated>2018-04-18T03:47:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>切换用户时出现如下提示符：</p><pre><code>[root@qa3-app018 ~]# su - appqasu: cannot set user id: Resource temporarily unavailable</code></pre><p>常见的能够控制用户资源的文件一般有两个，一是/etc/profile,二是/etc/security/limits.conf。</p><p>除此之外，在Centos6.x版本后，还有一个配置文件对ulimit设置生效，就是<code>/etc/security/limits.d/90-nproc.conf</code></p><h3 id="etc-security-limits-conf文件"><a href="#etc-security-limits-conf文件" class="headerlink" title="/etc/security/limits.conf文件"></a>/etc/security/limits.conf文件</h3><p>如下图所示：</p><p><img src="http://picture.watchmen.xin/problems/1.png" alt="图片"></p><p>domain: </p><p>是指限制的对象，可以是个人，也可以是组，组前面要加@符号，也可以设置为除root用户外的 任何人，用*号表示；</p><p>type:</p><p>是指类型，soft是当前系统生效的值，hard是系统可以设置的最大值；</p><p>item:</p><p>项目，是可以对什么项目做限制，如最大进程数，文件最大值；</p><p>value:</p><p>值，所设置的值的大小。</p><p><strong>这里我的设置是：</strong></p><pre><code>root soft nofile 65535root hard nofile 65535* soft nofile 65535* hard nofile 65535</code></pre><p>可以看到是没有问题的</p><h3 id="etc-security-limits-d-90-nproc-conf"><a href="#etc-security-limits-d-90-nproc-conf" class="headerlink" title="/etc/security/limits.d/90-nproc.conf"></a>/etc/security/limits.d/90-nproc.conf</h3><pre><code>[appqa@qa3-app018 ~]$ cat /etc/security/limits.d/90-nproc.conf# Default limit for number of user&apos;s processes to prevent# accidental fork bombs.# See rhbz #432903 for reasoning.*          soft    nproc     1024root       soft    nproc     unlimited</code></pre><p>这这里发现默认最大进程数只有1024</p><p>将1024修改为10240之后，再次执行su即可恢复正常，问题得到解决。</p>]]></content>
    
    <summary type="html">
    
      切换用户时提示资源不可用问题解决
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维工作日常问题" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98/"/>
    
    
      <category term="运维工作日常问题" scheme="http://yoursite.com/tags/%E8%BF%90%E7%BB%B4%E5%B7%A5%E4%BD%9C%E6%97%A5%E5%B8%B8%E9%97%AE%E9%A2%98/"/>
    
  </entry>
  
  <entry>
    <title>服务器硬件知识</title>
    <link href="http://yoursite.com/2018/04/18/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2018/04/18/服务器硬件知识/</id>
    <published>2018-04-18T03:38:29.000Z</published>
    <updated>2018-04-18T03:38:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>##</p>]]></content>
    
    <summary type="html">
    
      服务器硬件知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="服务器硬件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6/"/>
    
      <category term="服务器硬件知识" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="服务器硬件" scheme="http://yoursite.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A1%AC%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>进程管理-进程性能分析</title>
    <link href="http://yoursite.com/2018/04/18/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86-%E8%BF%9B%E7%A8%8B%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2018/04/18/进程管理-进程性能分析/</id>
    <published>2018-04-18T02:49:51.000Z</published>
    <updated>2018-04-18T02:49:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>分为两部分</p><ul><li><p>服务器即时数据查看</p></li><li><p>监控趋势数据查看</p></li></ul><p>主要分为以下4个部分</p><pre><code>- CPU        系统整体CPU情况，具体进程占用CPU情况，需要精确进程或者线程调用的系统调用- 内存        系统整体占用情况，具体进程占用内存情况，需要精确进程或者线程调用的系统调用- 磁盘        整体磁盘IO情况，具体进程占用磁盘IO情况，需要精确进程或者线程调用的系统调用- 网络        系统整体网络IO情况，带宽使用情况；具体进程占用的网络IO情况，需要精确进程或者线程调用的系统调用- 系统负载    系统整体占用情况</code></pre><p>本文主要讲述在服务器端的即时数据查看。</p><p>#CPU性能分析#</p><h2 id="即时数据查看"><a href="#即时数据查看" class="headerlink" title="即时数据查看"></a>即时数据查看</h2>]]></content>
    
    <summary type="html">
    
      进程管理之进程性能分析
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="进程管理" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    
      <category term="进程性能分析" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/%E8%BF%9B%E7%A8%8B%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    
    
      <category term="进程管理" scheme="http://yoursite.com/tags/%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>LVS从入门到精通</title>
    <link href="http://yoursite.com/2018/04/18/LVS%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A/"/>
    <id>http://yoursite.com/2018/04/18/LVS从入门到精通/</id>
    <published>2018-04-18T01:07:47.000Z</published>
    <updated>2018-04-18T01:07:47.000Z</updated>
    
    <summary type="html">
    
      本文讲述4层负载均衡-LVS的相关知识
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="负载均衡" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"/>
    
      <category term="LVS" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/LVS/"/>
    
    
      <category term="LVS" scheme="http://yoursite.com/tags/LVS/"/>
    
  </entry>
  
  <entry>
    <title>Python-django项目</title>
    <link href="http://yoursite.com/2018/04/17/Python-django%E9%A1%B9%E7%9B%AE/"/>
    <id>http://yoursite.com/2018/04/17/Python-django项目/</id>
    <published>2018-04-17T12:07:03.000Z</published>
    <updated>2018-04-17T12:07:03.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>基础环境：</strong></p><ul><li>Python3系列（针对环境变量做好软链接，将python3链接为python）<ul><li>sudo apt-get -y install python3</li><li>ln -s /usr/bin/python3 /usr/bin/python</li></ul></li></ul><ul><li>pip3(pip2不支持Python3.x，因此我们要安装pip来支持python3)<ul><li>sudo apt-get install python3-pip</li><li>ln -s /usr/bin/pip3 /usr/bin/pip</li></ul></li></ul><ul><li>依赖关系（python3-venv）<ul><li>sudo apt-get -y install python3-venv</li></ul></li></ul><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><h2 id="创建激活虚拟环境"><a href="#创建激活虚拟环境" class="headerlink" title="创建激活虚拟环境"></a>创建激活虚拟环境</h2><p>要使用django，首先需要建立一个虚拟工作环境。虚拟环境是系统的一个位置，你可以在其中安装包，并将其与其他python包隔离。将项目的库与其他项目分离是有益的。</p><pre><code>创建虚拟环境：wxh@wxh-virtual-machine:/opt$ python -m venv ll_env激活虚拟环境(ll_env) wxh@wxh-virtual-machine:/opt$ source ll_env/bin/activate停止虚拟环境(ll_env) wxh@wxh-virtual-machine:/opt$ deactivate </code></pre><h2 id="安装django"><a href="#安装django" class="headerlink" title="安装django"></a>安装django</h2><p>安装django(python3之后对应的django版本为1.8.1，因此在安装的时候需要额外注意)：</p><pre><code>(ll_env) wxh@wxh-virtual-machine:/opt$ pip install Django</code></pre><h2 id="配置django"><a href="#配置django" class="headerlink" title="配置django"></a>配置django</h2><h3 id="创建项目："><a href="#创建项目：" class="headerlink" title="创建项目："></a>创建项目：</h3><pre><code>(ll_env) wxh@wxh-virtual-machine:/opt$ sudo django-admin.py  startproject learning_log .</code></pre><p>创建完毕之后的目录结构如下所示：</p><p><img src="http://picture.watchmen.xin/python-django/project.png" alt="目录"></p><p>注意事项：</p><ul><li>命令末尾有有一个句点的存在，如果遗忘，可能出现一些问题。</li></ul><ul><li><code>manage.py文件</code>是一个简单的程序，它接受命令并将其交给django的相关部分去运行，我们将会使用这些命令来管理诸如使用数据库和运行服务器等任务</li></ul><ul><li>目录learning_log有4个文件，其中最重要的的是setting.py、urls.py、wsgi.py。</li></ul><ul><li>setting.py指定django如何与系统交互以及如何管理项目。在开发项目的过程中，我们将修改其中的一些设置，并添加一些设置。</li></ul><ul><li>urls.py告诉django应该创建哪些网页来响应浏览器请求。</li></ul><ul><li><p>wsgi.py帮助django提供它创建的文件。（web server gateway interface）web服务器网关接口的缩写</p></li><li><p><strong><font color="red">在一个目录下，只能创建一个django项目，因为一个目录下不允许存在2个manage.py</font></strong></p></li></ul><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><p>django将大部分与项目有关的信息都存储在数据库中，因此我们需要创建一个供django使用的数据库。为给项目“学习笔记”创建数据库，在处于活动虚拟环境中的情况下执行下面的命令：</p><pre><code>(ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py migrate</code></pre><h3 id="启动-停止项目"><a href="#启动-停止项目" class="headerlink" title="启动/停止项目"></a>启动/停止项目</h3><p>核实django项目是否正确的创建，执行下面的命令启动：</p>]]></content>
    
    <summary type="html">
    
      《Python编程从入门到实践》-Django入门
    
    </summary>
    
      <category term="编程语言" scheme="http://yoursite.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"/>
    
      <category term="Python" scheme="http://yoursite.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Python/"/>
    
    
      <category term="django" scheme="http://yoursite.com/tags/django/"/>
    
  </entry>
  
  <entry>
    <title>VPC+专线+IDC网络</title>
    <link href="http://yoursite.com/2018/04/17/VPC-%E4%B8%93%E7%BA%BF-IDC%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2018/04/17/VPC-专线-IDC网络/</id>
    <published>2018-04-17T05:57:23.000Z</published>
    <updated>2018-04-17T05:57:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>#<font color="red">VPC</font></p><p>专有网络VPC（Virtual Private Cloud）是基于阿里云构建的一个隔离的网络环境。</p><p>每个专有网络（也就是每个VPC）之间逻辑上彻底隔离。</p><p>专有网络是独有的的云上私有网络。用户可以完全掌控自己的专有网络，例如选择IP地址范围、配置路由表和网关等，可以在自己定义的专有网络中使用阿里云资源如ECS、RDS、SLB等。</p><p>可以将专有网络连接到其他专有网络，或本地网络（这里的本地网络包括IDC和公司内部机房），形成一个按需定制的网络环境，实现应用的平滑迁移上云和对数据中心的扩展。</p><h2 id="VPC中的路由器和交换机"><a href="#VPC中的路由器和交换机" class="headerlink" title="VPC中的路由器和交换机"></a>VPC中的路由器和交换机</h2><p>一个专有网络是一个大网段，例如：192.168.0.0/16<br>每一个可用区是其中的子网，例如可用区A的网段：192.168.1.0/24</p><ul><li>在当前的环境下，可以划分出来2^8=256个可用区（可用的为256个，0-255，剔除了256）</li></ul><ul><li>每一个可用区的可用主机数量为：2^8=256个（可用的为254个，1-255，剔除了0和256)</li></ul><p>一个交换机连接的是一个可用区（也就是一个子网），路由器连接的是每个可用区，对外的网段是VPC的网段。</p><p>如下图所示：</p><p><img src="http://picture.watchmen.xin/vpc/VswitchandVrouter.png" alt="路由器和交换机"></p><p>路由器（VRouter）是专有网络的枢纽。<br>作为专有网络中重要的功能组件，它可以连接VPC内的各个交换机，同时也是连接VPC和其他网络的网关设备。<br><strong>每个专有网络创建成功后，系统会自动创建一个路由器。每个路由器关联一张路由表。</strong></p><p>交换机（VSwitch）是组成专有网络的基础网络设备，用来连接不同的云产品实例。<br>创建专有网络之后，您可以通过创建交换机为专有网络划分一个或多个子网。<br>同一专有网络内的不同交换机之间内网互通。您可以将应用部署在不同可用区的交换机内，提高应用的可用性。</p><p><strong>VPC可以使用的私网地址范围：</strong></p><table><thead><tr><th style="text-align:center">网段</th><th style="text-align:center">可用私网IP数量 （不包括系统保留）</th></tr></thead><tbody><tr><td style="text-align:center">192.168.0.0/16</td><td style="text-align:center">65532</td></tr><tr><td style="text-align:center">172.16.0.0/12</td><td style="text-align:center">1048572</td></tr><tr><td style="text-align:center">10.0.0.0/8</td><td style="text-align:center">16777212</td></tr></tbody></table><p>交换机的网段不能和所属的专有网络的网段重叠，可以是其子集或者相同，<code>网段大小在16位网络掩码与29位网络掩码之间</code>。</p><p>注意：VPC的私网地址范围和我们实际认知的有所差异</p><p>在创建VPC时，系统会自动添加一条目标网段为100.64.0.0/10的<code>系统路由</code>用于VPC内的云产品通信。</p><p><strong>问题：不同可用区之间通信是直接到达还是需要路由？</strong></p><p>我们也可以通过抓包来进行分析</p><font color="red">总结：</font><ul><li>一个VPC有且只会分配一个路由器</li><li>该路由器会关联一张路由表（其中包括不可更改的系统路由，用于VPC内部通信）</li></ul><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>每个VPC都有一个独立的隧道号，一个隧道号对应着一个虚拟化网络。</p><p>一个VPC内的ECS（Elastic Compute Service）实例之间的传输数据包都会加上隧道封装，带有唯一的隧道ID标识，然后送到物理网络上进行传输。</p><p>不同VPC内的ECS实例因为所在的隧道ID不同，本身处于两个不同的路由平面，所以不同VPC内的ECS实例无法进行通信，天然地进行了隔离。</p><p>基于隧道技术和软件定义网络（Software Defined Network，简称SDN）技术，阿里云的研发在硬件网关和自研交换机设备的基础上实现了VPC产品。</p><p>以下是VPC实现的逻辑架构：</p><p>VPC包含<strong>交换机、网关和控制器</strong>三个重要的组件。</p><p><img src="http://picture.watchmen.xin/vpc/架构图.png" alt="实现原理"></p><h2 id="VPC通信"><a href="#VPC通信" class="headerlink" title="VPC通信"></a>VPC通信</h2><ul><li><p>VPC与VPC通信</p></li><li><p>VPC与经典网络通信</p></li><li><p>VPC与Internet通信</p></li><li><p>VPC与本地IDC通信</p></li></ul>]]></content>
    
    <summary type="html">
    
      VPC+专线+IDC网络相关知识记录
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="网络" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C/"/>
    
      <category term="VPC+专线+IDC网络" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E7%BD%91%E7%BB%9C/VPC-%E4%B8%93%E7%BA%BF-IDC%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="VPC" scheme="http://yoursite.com/tags/VPC/"/>
    
      <category term="专线" scheme="http://yoursite.com/tags/%E4%B8%93%E7%BA%BF/"/>
    
      <category term="IDC网络" scheme="http://yoursite.com/tags/IDC%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>Zookeeper</title>
    <link href="http://yoursite.com/2018/04/17/Zookeeper/"/>
    <id>http://yoursite.com/2018/04/17/Zookeeper/</id>
    <published>2018-04-17T05:21:24.000Z</published>
    <updated>2018-04-17T05:21:24.000Z</updated>
    
    <summary type="html">
    
      Zookeeper从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Zookeeper" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Zookeeper/"/>
    
    
      <category term="Zookeeper" scheme="http://yoursite.com/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Logstash</title>
    <link href="http://yoursite.com/2018/04/17/Logstash/"/>
    <id>http://yoursite.com/2018/04/17/Logstash/</id>
    <published>2018-04-17T05:21:00.000Z</published>
    <updated>2018-04-17T05:21:00.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>logstash由以下几个部分组成</p><ul><li>input</li><li>filter</li><li>output</li></ul><h1 id="How-Logstash-Works"><a href="#How-Logstash-Works" class="headerlink" title="How Logstash Works"></a>How Logstash Works</h1><p>每个input都拥有一个线程</p><p>input生成的event存储在<code>内存或者磁盘</code>中</p>]]></content>
    
    <summary type="html">
    
      Logstash从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Logstash" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Logstash/"/>
    
    
      <category term="Logstash" scheme="http://yoursite.com/tags/Logstash/"/>
    
  </entry>
  
  <entry>
    <title>Kibana</title>
    <link href="http://yoursite.com/2018/04/17/Kibana/"/>
    <id>http://yoursite.com/2018/04/17/Kibana/</id>
    <published>2018-04-17T05:20:54.000Z</published>
    <updated>2018-04-17T05:20:54.000Z</updated>
    
    <summary type="html">
    
      Kibana从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Kibana" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Kibana/"/>
    
    
      <category term="Kibana" scheme="http://yoursite.com/tags/Kibana/"/>
    
  </entry>
  
  <entry>
    <title>Filebeat</title>
    <link href="http://yoursite.com/2018/04/17/Filebeat/"/>
    <id>http://yoursite.com/2018/04/17/Filebeat/</id>
    <published>2018-04-17T05:20:23.000Z</published>
    <updated>2018-04-17T05:20:23.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>本文基于Filebeat 6.2.3版本</strong></p><p>参考文献： <a href="https://www.elastic.co/guide/en/beats/filebeat/current/index.html" target="_blank" rel="noopener">官网</a></p><h2 id="1-Filebeat基础知识"><a href="#1-Filebeat基础知识" class="headerlink" title="1. Filebeat基础知识"></a>1. Filebeat基础知识</h2><blockquote><p>Filebeat consists of two main components: <code>prospectors and harvesters.</code></p><p>These components work together to <code>tail files</code> and send event data to the output that you specify.</p></blockquote><ul><li><p>prospectors:勘探者；探矿者【也就是数据变化的探测者，也就是入向配置】</p></li><li><p>harvesters：收割机；收获者【也就是数据的下游接收端，也就是出向配置】</p></li><li><p>spooler：处理程序；【处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。】</p></li></ul><p>Filebeat工作流程：</p><blockquote><p>当你开启filebeat程序的时候，它会启动一个或多个探测器（prospectors）去检测你指定的日志目录或文件，对于探测器找出的每一个日志文件，filebeat启动收割进程（harvester），每一个收割进程读取一个日志文件的新内容，并发送这些新的日志数据到处理程序（spooler），处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。</p></blockquote><p>流程图如下：</p><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-2.png" alt="流程图"></p><h3 id="1-1-What-is-harvester"><a href="#1-1-What-is-harvester" class="headerlink" title="1.1 What is harvester?"></a>1.1 What is harvester?</h3><blockquote><p>A harvester is responsible for reading the content of a single file. The harvester reads each file, line by line, and sends the content to the output. One harvester is started for each file. T<code>he harvester is responsible for opening and closing the file</code>, which means that the file descriptor remains open while the harvester is running. If a file is removed or renamed while it’s being harvested, Filebeat continues to read the file. This has the side effect that the space on your disk is reserved until the harvester closes. By default, Filebeat keeps the file open until close_inactive is reached.</p><p>Closing a harvester has the following consequences:【关闭时按以下顺序依`次执行，也就是关闭顺序】</p></blockquote><ul><li><p>The file handler is closed, freeing up the underlying resources if the file was deleted while the harvester was still reading the file.<br>The</p></li><li><p>harvesting of the file will only be started again after scan_frequency has elapsed.</p></li></ul><ul><li>If the file is moved or removed while the harvester is closed, harvesting of the file will not continue.</li></ul><p>To control when a harvester is closed, use the close_* configuration options.</p><p>harvester负责打开和关闭文件</p><p>当harvester捕获到一个文件之后，这个文件被删除或者重命名，它将继续读取这个文件。【副作用是占用磁盘空间直到harvester进程关闭】</p><h3 id="1-2-What-is-prospector"><a href="#1-2-What-is-prospector" class="headerlink" title="1.2 What is prospector?"></a>1.2 What is prospector?</h3><blockquote><p>A prospector is responsible for managing the harvesters and finding all sources to read from.</p><p>If the input type is log, the prospector finds all files on the drive that match the defined glob paths and starts a harvester for each file. Each prospector runs in its own Go routine.</p><p>The following example configures Filebeat to harvest lines from all log files that match the specified glob patterns:</p></blockquote><pre><code>filebeat.prospectors:- type: log  paths:    - /var/log/*.log    - /var/path2/*.log</code></pre><p>prospector负责管理harvesters进程以及寻找需要去读取的资源（input设置）</p><p>Filebeat的input type当前有两种设置：<code>log和stdin</code></p><blockquote><p>The log prospector checks each file to see whether a harvester needs to be started, whether one is already running, or whether the file can be ignored (see ignore_older).<br><code>New lines are only picked up if the size of the file has changed since the harvester was closed.</code></p></blockquote><p>注意，Filebeat只能读取本地的文件，也就是需要在每个日志产生端都安装：<br><strong>Filebeat prospectors can only read <code>local files</code>. There is no functionality to connect to remote hosts to read stored files or logs.</strong></p><h3 id="1-3-How-does-Filebeat-keep-the-state-of-files"><a href="#1-3-How-does-Filebeat-keep-the-state-of-files" class="headerlink" title="1.3 How does Filebeat keep the state of files"></a>1.3 How does Filebeat keep the state of files</h3><p>filebeat通过定期去刷新，将状态落地到磁盘的注册文件中，以这种形式来保持文件检测状态</p><blockquote><p>Filebeat keeps the state of each file and frequently flushes the state to disk in the registry file</p><p>The state is used to remember the last offset a harvester was reading from and to ensure all log lines are sent</p></blockquote><p>filebeat的状态信息记录的是最新的读取偏移量，如果下游的接受者（ES、kafka、logstash等不可达），filebeat将会保持这种状态，当检测后可达之后将会重新发送</p><p>当filebeat重启时，将会重新构建这个注册文件</p><p>每个prospector针对每个文件都会保持一个状态，也就是一个注册文件，因为文件可能会被删除或者重命名</p><p>针对每个文件，filebeat存储一个唯一的标识符去发现该文件之前是否有被收集过</p><blockquote><p>For each file, Filebeat stores unique identifiers to detect whether a file was harvested previously.</p></blockquote><h3 id="1-4-how-does-Filebeat-ensure-at-least-once-delivery"><a href="#1-4-how-does-Filebeat-ensure-at-least-once-delivery" class="headerlink" title="1.4 how does Filebeat ensure at-least-once delivery?"></a>1.4 how does Filebeat ensure at-least-once delivery?</h3><p>Filebeat保证一个事件的完整及正确性，它将发送最少一次给设置的下游输出，以保证没有数据丢失。</p><blockquote><p>Filebeat guarantees that events will be delivered to the configured output at least once and with no data loss.</p><p>Filebeat is able to achieve this behavior because it stores the delivery state of each event in the registry file.</p></blockquote><p>Filebeat能够保证这种特性的原因是因为它将分发状态也存储在这个注册文件中。</p><p>当下游因为阻塞或者其他原因，没有对某一个事件进行确认的时候，filebeat将一直尝试去发送这个事件，直到收到ACK</p><blockquote><p>If Filebeat shuts down while it’s in the process of sending events, it does not wait for the output to acknowledge all events before shutting down. Any events that are sent to the output, but not acknowledged before Filebeat shuts down, are sent again when Filebeat is restarted. This ensures that each event is sent at least once, but you can end up with duplicate events being sent to the output. You can configure Filebeat to wait a specific amount of time before shutting down by setting the<code>shutdown_timeout</code> option.</p></blockquote><p>当Filebeat异常关闭，再次启动的时候，它将会重新发送没有接受到ACk的事件。通过这种机制来保证每个事件至少发送一次。</p><p>因此，为了减少重新发送event事件的次数，可以通过设置shutdown_timeout参数来设置当filebeat关闭时，等待多少时间之后再关闭进程，以保证收到尽量多的ACK</p><p>注意：虽然拥有这种机制来保证数据的不丢失，但还是存在一些可能的情况导致数据的丢失（日志轮转和删除文件时）</p><p>例如：</p><ul><li><p>If log files are written to disk and rotated faster than they can be processed by Filebeat 【当日志刚好触发到日志轮转条件时，并且此时filebeat还没有来得及收集的时候，原因是inode节点发生变化】</p></li><li><p>if files are deleted while the output is unavailable 【当该文件被删除时，并且输出不可用时】</p></li></ul><p><strong>总结：filebeat会维护一个注册文件【是落地到磁盘中的】，该注册文件中包含2个信息</strong></p><ul><li>所发送事件的偏移量，精确记录当前的发送情况。        下游断开时，将保持直到连接后再发送</li><li>发送事件的ACk，记录发送事件的接受情况。            没有收到，将一直持续发送。</li></ul><h2 id="2-Filebeat安装部署配置启动"><a href="#2-Filebeat安装部署配置启动" class="headerlink" title="2. Filebeat安装部署配置启动"></a>2. Filebeat安装部署配置启动</h2><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><pre><code>curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.3-x86_64.rpmrpm -vih filebeat-6.2.3-x86_64.rpm</code></pre><h3 id="2-2-启动"><a href="#2-2-启动" class="headerlink" title="2.2 启动"></a>2.2 启动</h3><pre><code>service filebeat start./filebeat -e -c ./bigdata.yml</code></pre><h3 id="2-3-命令"><a href="#2-3-命令" class="headerlink" title="2.3 命令"></a>2.3 命令</h3><p>主要提供了8个命令API</p><pre><code>[root@master ~]# filebeat --helpUsage:  filebeat [flags]  filebeat [command]Available Commands:  export      Export current config or index template        #导出ES的索引模板  help        Help about any command  keystore    Manage secrets keystore  modules     Manage configured modules                        #Filebeat的模块相关  run         Run filebeat  setup       Setup index template, dashboards and ML jobs    #设置初始化环境，包括索引模板，kibana的仪表盘等  test        Test config  version     Show current version infoFlags:  -E, --E setting=value      Configuration overwrite  -M, --M setting=value      Module configuration overwrite  -N, --N                    Disable actual publishing for testing  -c, --c string             Configuration file, relative to path.config (default &quot;filebeat.yml&quot;)      --cpuprofile string    Write cpu profile to file  -d, --d string             Enable certain debug selectors  -e, --e                    Log to stderr and disable syslog/file output  -h, --help                 help for filebeat      --httpprof string      Start pprof http server      --memprofile string    Write memory profile to this file      --modules string       List of enabled modules (comma separated)      --once                 Run filebeat only once until all harvesters reach EOF      --path.config string   Configuration path (default &quot;&quot;)      --path.data string     Data path (default &quot;&quot;)      --path.home string     Home path (default &quot;&quot;)      --path.logs string     Logs path (default &quot;&quot;)      --plugin pluginList    Load additional plugins      --setup                Load the sample Kibana dashboards      --strict.perms         Strict permission checking on config files (default true)  -v, --v                    Log at INFO levelUse &quot;filebeat [command] --help&quot; for more information about a command.</code></pre><p>注意： filebeat有：<code>Config File Ownership and Permissions</code></p><blockquote><p>On systems with POSIX file permissions, all Beats configuration files are subject to ownership and file permission checks. The purpose of these checks is to prevent unauthorized users from providing or modifying configurations that are run by the Beat. The owner of the configuration files must be either root or the user who is executing the Beat process. The permissions on each file must disallow writes by anyone other than the owner.</p></blockquote><p>也就是说只有root用户或者文件的属主才有权限执行命令</p><h3 id="2-4-编辑配置文件"><a href="#2-4-编辑配置文件" class="headerlink" title="2.4 编辑配置文件"></a>2.4 编辑配置文件</h3><p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/directory-layout.html#_docker" target="_blank" rel="noopener">配置文件生成规则</a></p><p>安装完毕之后，配置文件路径：/etc/filebeat/filebeat.yml<br>参考配置文件为：filebeat.reference.yml</p><p>这里采用的是rpm包方式安装，因此生成规则如下：</p><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-1.png" alt="生成规则"></p><p>filebeat.yml整个配置文件分为几个部分，分别是：</p><pre><code>- Modules configuration- Filebeat prospectors        【上游输入设置。这部分包含内容为：type设置|path路径设置，】- Filebeat autodiscover- Filebeat global options- General- Elastic Cloud- Outputs                    【下游输出设置。这部分内容为：ES|kafka|logstash|】- Paths- Dashboards- Template                    【ES模板配置】- Kibana- Logging- X- - -  Monitoring            【x-  -  -  监控】- HTTP Endpoint</code></pre><p>让我们来配置filebeat：</p><h4 id="modules模块设置"><a href="#modules模块设置" class="headerlink" title="modules模块设置"></a>modules模块设置</h4><p>filebeat的模块实现了快速部署的方式。该部分的设置是可选的，你可以选择在后面自己定义prospectors设置相关设置。<br>可以通过以下3种方式开启modules</p><ul><li>Enable module configs in the modules.d directoryedit</li></ul><ul><li>Enable modules when you run Filebeatedit</li></ul><ul><li>Enable module configs in the filebeat.yml file</li></ul><p>使用了模块之后，仍然可以指定变量设置来覆盖模块中的定义【最小局部生效】。并且，可以使用高级设置来覆盖prospector中的相关设置</p><p>模块命令：</p><p><strong>第一种方式：</strong></p><pre><code>./filebeat modules enable apache2 mysql    开启modules.d下的指定模块./filebeat modules list        查看启动的模块情况</code></pre><p><strong>第二种方式：</strong></p><pre><code>./filebeat -e --modules nginx,mysql,system    在启动filebeat的时候启动模块</code></pre><p><strong>第三种方式：</strong></p><pre><code>filebeat.modules:- module: nginx- module: mysql- module: system</code></pre><p><strong>模块的高级设置：</strong></p><p>能够覆盖prospector中的设置</p><p>Behind the scenes, each module starts a Filebeat prospector. Advanced users can add or override any prospector settings. For example, you can set close_eof to true in the module configuration:</p><pre><code>- module: nginx  access:    prospector:      close_eof: true</code></pre><p>Or at the command line like this:</p><pre><code>./filebeat -M &quot;nginx.access.prospector.close_eof=true&quot;</code></pre><p>Here you see how to use the -M flag along with the –modules flag:</p><pre><code>./filebeat --modules nginx -M &quot;nginx.access.prospector.close_eof=true&quot;</code></pre><p>You can use wildcards to change variables or settings for multiple modules/filesets at once. For example, the following command enables close_eof for all the filesets in the nginx module:</p><pre><code>./filebeat -M &quot;nginx.*.prospector.close_eof=true&quot;</code></pre><p>The following command enables close_eof for all prospectors created by any of the modules:</p><pre><code>./filebeat -M &quot;*.*.prospector.close_eof=true&quot;</code></pre><h4 id="Filebeat-global-options-设置"><a href="#Filebeat-global-options-设置" class="headerlink" title="Filebeat global options 设置"></a>Filebeat global options 设置</h4><p>这部分可以设置filebeat自动去探测检测文件</p><pre><code>filebeat.config.prospectors:  enabled: true  path: configs/*.yml  reload.enabled: true  reload.period: 10s</code></pre><h4 id="prospectors设置"><a href="#prospectors设置" class="headerlink" title="prospectors设置"></a>prospectors设置</h4><p>对于大多数的基本filebeat配置，你可以定义一个单一探测器针对一个单一的路径，例如：</p><pre><code>filebeat.prospectors:- input_type: log  paths:    - /var/log/*.log</code></pre><p>在这个例子中，探测器会收集/var/log/*.log的所有匹配文件，这意味这filebeat会手机所有的/var/log下以.log结尾的文件，此处还支持Golang Glob支持的所有模式。</p><p>在预定义级别的子目录中获取所有文件，可以使用这个配置：/var/log/<em>/</em>.log，这会找到/var/log下所有子目录中所有的以.log结尾的文件。但它并不会找到/var/log文件夹下的以.log结尾的文件。现在它还不能递归的在所有子目录中获取所有的日志文件。</p><h4 id="Outputs设置"><a href="#Outputs设置" class="headerlink" title="Outputs设置"></a>Outputs设置</h4><p>如果你设置输出到elasticsearch中，那么你需要在filebeat的配置文件中设置elasticsearch的IP地址与端口。</p><pre><code>output.elasticsearch:  hosts: [&quot;192.168.1.42:9200&quot;]</code></pre><p>如果要使用Logstash对Filebeat收集的数据执行附加处理，则需要将Filebeat配置为使用Logstash。</p><pre><code>＃----------------------------- Logstash输出------------------ --------------output.logstash：  hosts：[“127.0.0.1:5044”]</code></pre><p>如果您打算使用随Filebeat提供的示例Kibana仪表板，需要配置Kibana，这段是属于kibana设置，不输出output设置</p><pre><code>#============================== Kibana =====================================setup.kibana：  host：“localhost：5601”</code></pre><p>如果设置ES和kibana的安全性设置，使用以下的配置</p><pre><code>output.elasticsearch:  hosts: [&quot;myEShost:9200&quot;]  username: &quot;elastic&quot;  password: &quot;elastic&quot;setup.kibana:  host: &quot;mykibanahost:5601&quot;  username: &quot;elastic&quot;   password: &quot;elastic&quot;</code></pre><h4 id="Template设置"><a href="#Template设置" class="headerlink" title="Template设置"></a>Template设置</h4><p><strong>这一部分主要设置ES的模板</strong></p><p>在Elasticsearch中，索引模板用于定义设置和映射，以确定如何分析字段。<br>通过使用ES模板，可以有效的减轻存储压力<br>ES模板：通过对索引中的每个字段做事先的预定义数据类型（例如ID，name等分别使用存储空间最小的数据类型）</p><p>在安装完毕Filebeat之后，会生成fields.yml这个ES模板文件<br>下游如果是ES的话，Filebeat在启动的时候会自动的加载这个模板文件<br>如果要关闭自动加载功能，则将以下参数设置为false</p><pre><code>setup.template.enabled: false</code></pre><p>注意：如果该模板已经存在，则不会覆盖它，除非您配置Filebeat来指定执行此操作。</p><p>如果下游连接的不是ES而是logstash，那么需要手动导入模板</p><pre><code>filebeat setup --template -E output.logstash.enabled=false -E &apos;output.elasticsearch.hosts=[&quot;localhost:9200&quot;]&apos;</code></pre><p><strong>强制Kibana使用最新的Filebeat索引信息</strong></p><p>如果当前ES中已经有了filebeat的索引信息，那么修改模板之后，因此模板不会被覆盖，因此需要强制刷新生效。</p><pre><code>curl -XDELETE &apos;http://localhost:9200/filebeat-*&apos;</code></pre><p><strong>中转方式导入ES模板</strong></p><p>如果Filebeat没有直接连接到ES，那么可以将模板文件先导出到可以连接到ES的主机上，再通过这台去导入</p><pre><code>filebeat export template &gt; filebeat.template.jsoncurl -XPUT -H &apos;Content-Type: application/json&apos; http://localhost:9200/_template/filebeat-6.2.3 -d@filebeat.template.json</code></pre><p><strong>相关命令</strong></p><pre><code>./filebeat setup -e    导入ES的索引末班./filebeat -e --modules system 导入模块的命令，这里是导入system模块./filebeat -e --modules system,nginx,mysql  一次运行多个模块</code></pre><h4 id="Kibana设置"><a href="#Kibana设置" class="headerlink" title="Kibana设置"></a>Kibana设置</h4><p>再kibana上显示filebeat的索引信息之前，you need to create the index pattern, <code>filebeat-*</code>， and load the dashboards into Kibana.<br>不过在filebeat的6.0.0版本之后，这部分操作通过配置文件中的kibana配置部署来实现<br>也就是上面说到的这一段的配置：</p><pre><code>#============================== Kibana =====================================setup.kibana：  host：“localhost：5601”</code></pre><p>在配置之前请确保kibana已经处于运行状态，然后执行如下命令</p><pre><code>filebeat setup --dashboards</code></pre><h4 id="多行日志处理"><a href="#多行日志处理" class="headerlink" title="多行日志处理"></a>多行日志处理</h4><p><strong>处理多行日志，主要包括JAVA的堆栈内存，程序语言的类似\换行功能，时间戳引导的一段日志，应用指定的start–end等日志段</strong></p><p>默认情况下JAVA堆栈日志是有多行组成的，例如：</p><pre><code>Exception in thread &quot;main&quot; java.lang.NullPointerException    at com.example.myproject.Book.getTitle(Book.java:16)    at com.example.myproject.Author.getBookTitles(Author.java:25)    at com.example.myproject.Bootstrap.main(Bootstrap.java:14)</code></pre><p>因此在filebeat中要把这些多行的日志组合成为一个event。这就需要以下的配置：</p><pre><code>multiline.pattern: &apos;^[[:space:]]&apos;multiline.negate: falsemultiline.match: after</code></pre><p><strong>This configuration merges any line that begins with whitespace up to the previous line.</strong></p><p>如果还涉及到更复杂的JAVA堆栈日志格式，例如：</p><pre><code>Exception in thread &quot;main&quot; java.lang.IllegalStateException: A book has a null property       at com.example.myproject.Author.getBookIds(Author.java:38)       at com.example.myproject.Bootstrap.main(Bootstrap.java:14)Caused by: java.lang.NullPointerException       at com.example.myproject.Book.getId(Book.java:22)       at com.example.myproject.Author.getBookIds(Author.java:35)       ... 1 more</code></pre><p>那么需要如下的配置：</p><pre><code>multiline.pattern: &apos;^[[:space:]]+(at|\.{3})\b|^Caused by:&apos;multiline.negate: falsemultiline.match: after</code></pre><p>In this example, the pattern matches the following lines:</p><ul><li>a line that begins with spaces followed by the word at or …</li></ul><ul><li>a line that begins with the words Caused by:</li></ul>]]></content>
    
    <summary type="html">
    
      Filebeat从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linu" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linu/"/>
    
      <category term="x运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linu/x%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linu/x%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linu/x%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Filebeat" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linu/x%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Filebeat/"/>
    
    
      <category term="Filebeat" scheme="http://yoursite.com/tags/Filebeat/"/>
    
  </entry>
  
  <entry>
    <title>Kafka</title>
    <link href="http://yoursite.com/2018/04/17/Kafka/"/>
    <id>http://yoursite.com/2018/04/17/Kafka/</id>
    <published>2018-04-17T05:20:18.000Z</published>
    <updated>2018-04-17T05:20:18.000Z</updated>
    
    <summary type="html">
    
      Kafka从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Kafka" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://yoursite.com/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Flume</title>
    <link href="http://yoursite.com/2018/04/17/Flume/"/>
    <id>http://yoursite.com/2018/04/17/Flume/</id>
    <published>2018-04-17T05:20:12.000Z</published>
    <updated>2018-04-17T05:20:12.000Z</updated>
    
    <summary type="html">
    
      Flume从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Flume" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Flume/"/>
    
    
      <category term="Flume" scheme="http://yoursite.com/tags/Flume/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch</title>
    <link href="http://yoursite.com/2018/04/17/Elasticsearch/"/>
    <id>http://yoursite.com/2018/04/17/Elasticsearch/</id>
    <published>2018-04-17T05:16:22.000Z</published>
    <updated>2018-04-17T05:16:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>更多内容请看：<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html" target="_blank" rel="noopener">官方文档</a></p><h1 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h1><p>ES在整个ELk架构中提供的功能：</p><ul><li>数据存储</li><li>数据搜索</li><li>数据分析</li></ul><h3 id="索引模板"><a href="#索引模板" class="headerlink" title="索引模板"></a>索引模板</h3><p>在Elasticsearch中，索引模板用于定义设置和映射，以确定如何分析字段。（例如ID，name等分别使用存储空间最小的数据类型）</p><p>索引模板允许您<code>定义创建新索引</code>时将<code>自动应用</code>的模板。</p><p>模板仅适用于索引创建时。更改模板将不会影响现有的索引。在使用创建索引的API时，如果设置了数据类型，那么将会覆盖模板的设置，也就是最小局部生效</p>]]></content>
    
    <summary type="html">
    
      Elasticsearch从入门到精通
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="大数据相关组件" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/"/>
    
      <category term="Elasticsearch" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="http://yoursite.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>ELK架构之Filebeat+kafka+logstash+Elasticsearch</title>
    <link href="http://yoursite.com/2018/04/17/ELK%E6%9E%B6%E6%9E%84%E4%B9%8BFilebeat-kafka-logstash-Elasticsearch/"/>
    <id>http://yoursite.com/2018/04/17/ELK架构之Filebeat-kafka-logstash-Elasticsearch/</id>
    <published>2018-04-17T02:06:21.000Z</published>
    <updated>2018-04-17T02:06:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h1><p><img src="http://picture.watchmen.xin/elk-filebeat/filebeat-3.png" alt="流程图"></p><p><strong>组件关系说明：</strong></p><p>logstash 和filebeat都具有日志收集功能，filebeat更轻量，占用资源更少，但logstash 具有filter功能，能过滤分析日志。一般结构都是filebeat采集日志，然后发送到消息队列，redis，kafaka。然后logstash去获取，利用filter功能过滤分析，然后存储到elasticsearch中</p><p>filebeat–&gt;kafka集群–&gt;logstash–&gt;(file server文件系统|kafka集群|ES集群)</p><ul><li>Filebeat    日志收集</li><li>kafka        日志接受消息队列</li><li>logstash    将日志进行过滤分析后存储到ES</li><li>ES        存储，检索，分析</li></ul><h1 id="Filebeat"><a href="#Filebeat" class="headerlink" title="Filebeat"></a><font color="red">Filebeat</font></h1><p><strong>Filebeat配置文件：</strong></p><pre><code>filebeat.prospectors:- input_type: log  paths:    - /home/appdeploy/deploy/logs/pinpoint/*-pinpoint.log  document_type: tools.pinpoint.data  scan_frequency: 5s  tail_files: trueoutput.kafka:   hosts: [&quot;10.10.10.92:9092&quot;, &quot;10.10.10.93:9092&quot;, &quot;10.10.10.94:9092&quot;]   topic: &apos;%{[type]}&apos;   partition.round_robin:     reachable_only: false   required_acks: 1   compression: gzip   max_message_bytes: 1000000   codec.format:        string: &apos;%{[message]}&apos;</code></pre><p><strong>说明</strong></p><pre><code>filebeat.prospectors:- input_type: log            #类型选择log|stdin中的log，在filebeat最新版本中input_type写成type  paths:    - /home/appdeploy/deploy/logs/pinpoint/*-pinpoint.log        #指定探测的文件  document_type: tools.pinpoint.data              scan_frequency: 5s            #prospector每隔5秒去检测日志的生成情况  tail_files: true                #设置之后，filebeat读取新文件时从文件末尾开始读取，而不是开头，如果设置了日志轮转，那么新文件的第一行将会被忽略output.kafka:                    #输出策略采用kafka   hosts: [&quot;10.10.10.92:9092&quot;, &quot;10.10.10.93:9092&quot;, &quot;10.10.10.94:9092&quot;]        #kafka集群的配置信息   topic: &apos;%{[type]}&apos;            #设置topic使用文件类型   partition.round_robin:        #Topic的分区算法     reachable_only: false        # 如果设置为true，那么event将只会推送到leader上，默认设置就是false   required_acks: 1                #ACk可靠性级别，0表示不响应，1表示本地commit，-1表示所有的副本commit。默认为1   compression: gzip            # 设置输出压缩编解码器，可选snappy and gzip。默认就是gzip   max_message_bytes: 1000000    # JSON格式的信息一个传输允许的最大大小上限   codec.format:        string: &apos;%{[message]}&apos;</code></pre><h1 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a><font color="red">Kafka</font></h1><p>在这里，kafka的作用是将日志接受到消息队列中，以备后续的logstash收取</p><p><strong>kafka的配置【每台的配置除了id不同之外，其他均类似】</strong></p><p>[root@qa-bigdata002 config]# egrep  -v ‘^#|^$’ <strong>server.properties</strong></p><pre><code>broker.id=0port=9092host.name=172.24.80.87num.network.threads=3num.io.threads=8socket.send.buffer.bytes=102400socket.receive.buffer.bytes=102400socket.request.max.bytes=104857600log.dirs=/home/kafka/kafka-logsnum.partitions=2num.recovery.threads.per.data.dir=1log.retention.hours=168log.segment.bytes=1073741824log.retention.check.interval.ms=300000log.cleaner.enable=falsezookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181zookeeper.connection.timeout.ms=600000</code></pre><p><strong>说明</strong></p><pre><code>broker.id=0                # The id of the broker. This must be set to a unique integer for each broker，在一个kafka集群中，每个broker的ID必须不同port=9092host.name=172.24.80.87num.network.threads=3                    #The number of threads handling network requestsnum.io.threads=8                        # The number of threads doing disk I/O，将数据落地到磁盘的线程数量，一般为CPU核数的倍数socket.send.buffer.bytes=102400            #发送缓冲区的大小，单位是字节，这里是1Msocket.receive.buffer.bytes=102400        #接受缓冲区大小，这里是1Msocket.request.max.bytes=104857600        #最大接受的请求数量，防止OOM的出现，out of memory,这里设置为104Mlog.dirs=/home/kafka/kafka-logs            # 落地到磁盘的文件的存储路径num.partitions=2                        # 每个Topic的分区数量num.recovery.threads.per.data.dir=1        #在日志数据恢复时，log.retention.hours=168                    #日志保留小时数，这里的168小时，也就是保留7天。log.segment.bytes=1073741824            #单个日志的文件的最大大小，现在配置为1Glog.retention.check.interval.ms=300000    #每隔5分钟检测日志文件是否可以被删除log.cleaner.enable=false                #设置flase之后，日志保留策略将会采用上面的分段及超时设置，如果为true，zookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181    #ZK的配置zookeeper.connection.timeout.ms=600000            #连接ZK的超时时间</code></pre><p><strong>consumer.properties</strong></p><pre><code># Zookeeper connection string# comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;zookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181# timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000#consumer group idgroup.id=test-consumer-group</code></pre><p><strong>producer.properties</strong></p><pre><code># list of brokers used for bootstrapping knowledge about the rest of the cluster# format: host1:port1,host2:port2 ...metadata.broker.list=172.24.80.87:9092,172.24.80.88:9092,172.24.80.89:9092</code></pre><p><strong>zookeeper.properties</strong></p><pre><code># the directory where the snapshot is stored.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# disable the per-ip limit on the number of connections since this is a non-production configmaxClientCnxns=0</code></pre><h1 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a><font color="red">Logstash</font></h1><h1 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a><font color="red">Elasticsearch</font></h1><h4 id="ES模板设置"><a href="#ES模板设置" class="headerlink" title="ES模板设置"></a>ES模板设置</h4><p>通过使用ES模板，可以有效的减轻存储压力<br>ES模板：通过对索引中的每个字段做事先的预定义数据类型（例如ID，name等分别使用存储空间最小的数据类型）</p>]]></content>
    
    <summary type="html">
    
      ELk日志处理平台架构之Filebeat+kafka+logstash+Elasticsearch
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="大数据" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="ELk日志处理平台" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELk%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0/"/>
    
      <category term="Filebeat+kafka+logstash+Elasticsearch" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/ELk%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0/Filebeat-kafka-logstash-Elasticsearch/"/>
    
    
      <category term="ELK架构" scheme="http://yoursite.com/tags/ELK%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>异地多活机房建设</title>
    <link href="http://yoursite.com/2018/04/17/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9C%BA%E6%88%BF%E5%BB%BA%E8%AE%BE/"/>
    <id>http://yoursite.com/2018/04/17/异地多活机房建设/</id>
    <published>2018-04-17T01:30:16.000Z</published>
    <updated>2018-04-17T01:30:16.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-前言概述"><a href="#1-前言概述" class="headerlink" title="1. 前言概述"></a>1. 前言概述</h1><p>当前公司的核心应用都是运行在阿里云上，这种方式存在以下几个缺点：</p><ul><li>星型拓扑结构，所有压力都集中在一套系统之上，整体系统的高可用性还不够充分。新增IDC机房之后，可以将一部分流量引入到就近的云下机房。为核心系统减负，也就是说，同一个应用对应有多个生产环境。</li><li>的</li></ul><h1 id="1-1-思路"><a href="#1-1-思路" class="headerlink" title="1.1 思路"></a>1.1 思路</h1><p>整体思路：</p><ul><li>为什么？</li><li>是什么？</li><li>怎么做？</li></ul><h2 id="1-2-为什么？为什么需要异地机房？"><a href="#1-2-为什么？为什么需要异地机房？" class="headerlink" title="1.2 为什么？为什么需要异地机房？"></a>1.2 为什么？为什么需要异地机房？</h2><h2 id="1-3-是什么？-异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？"><a href="#1-3-是什么？-异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？" class="headerlink" title="1.3 是什么？ 异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？"></a>1.3 是什么？ 异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？</h2><h2 id="1-4-怎么做？-如何实现？"><a href="#1-4-怎么做？-如何实现？" class="headerlink" title="1.4 怎么做？ 如何实现？"></a>1.4 怎么做？ 如何实现？</h2><p>这部分内容将会在下面的章节进行具体的阐述。</p><h1 id="2-具体实施"><a href="#2-具体实施" class="headerlink" title="2. 具体实施"></a>2. 具体实施</h1>]]></content>
    
    <summary type="html">
    
      近期公司在进行异地机房的建设，在不涉及公司机密数据的前提下，在这里记录下整个过程，一方面是便于自己检索，另一方面是给有同样需求的网友一定参考。
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="运维架构" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/"/>
    
      <category term="异地多活" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB/"/>
    
    
      <category term="异地多活机房建设" scheme="http://yoursite.com/tags/%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9C%BA%E6%88%BF%E5%BB%BA%E8%AE%BE/"/>
    
  </entry>
  
  <entry>
    <title>常用软件激活密钥</title>
    <link href="http://yoursite.com/2018/04/16/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    <id>http://yoursite.com/2018/04/16/常用软件激活密钥/</id>
    <published>2018-04-16T12:06:56.000Z</published>
    <updated>2018-04-16T12:06:56.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>vmware workstations 14 pro</strong></p><ul><li>CG54H-D8D0H-H8DHY-C6X7X-N2KG6 【亲测可用】</li></ul><ul><li>ZC3WK-AFXEK-488JP-A7MQX-XL8YF</li></ul><ul><li>AC5XK-0ZD4H-088HP-9NQZV-ZG2R4</li></ul><ul><li>ZC5XK-A6E0M-080XQ-04ZZG-YF08D</li></ul><ul><li>ZY5H0-D3Y8K-M89EZ-AYPEG-MYUA8</li></ul><p><strong>sublime Text 3</strong></p><pre><code>—– BEGIN LICENSE —–TwitterInc200 User LicenseEA7E-8900071D77F72E 390CDD93 4DCBA022 FAF6079061AA12C0 A37081C5 D0316412 4584D13694D7F7D4 95BC8C1C 527DA828 560BB037D1EDDD8C AE7B379F 50C9D69D B35179EF2FE898C4 8E4277A8 555CE714 E1FB0E43D5D52613 C3D12E98 BC49967F 7652EED29D2D2E61 67610860 6D338B72 5CF95C69E36B85CC 84991F19 7575D828 470A92AB—— END LICENSE ——</code></pre><p>使用：</p><p>软件主界面——右下角help——Enter License</p><p>将上面的代码进去即可激活。</p>]]></content>
    
    <summary type="html">
    
      常用软件激活密钥/序列号
    
    </summary>
    
      <category term="常用软件工具" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/"/>
    
      <category term="常用软件激活密钥" scheme="http://yoursite.com/categories/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    
    
      <category term="软件激活密钥" scheme="http://yoursite.com/tags/%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5/"/>
    
  </entry>
  
  <entry>
    <title>Linux常用命令之curl命令</title>
    <link href="http://yoursite.com/2018/04/16/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2018/04/16/Linux常用命令/</id>
    <published>2018-04-16T02:57:34.000Z</published>
    <updated>2018-04-16T02:57:34.000Z</updated>
    
    <summary type="html">
    
      Linux常用命令之curl命令
    
    </summary>
    
      <category term="IT科学技术知识体系结构-Linux运维方向" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/"/>
    
      <category term="Linux基础知识" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    
      <category term="Linux常用命令" scheme="http://yoursite.com/categories/IT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91/Linux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    
    
      <category term="curl命令" scheme="http://yoursite.com/tags/curl%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
</feed>
