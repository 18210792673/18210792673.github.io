<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[如何自学计算机科学]]></title>
    <url>%2F2018%2F12%2F31%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FIT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%2F%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[引言]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>IT基础知识</category>
        <category>如何自学计算机科学</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT技术学习网站及学习资料汇总]]></title>
    <url>%2F2018%2F12%2F31%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FIT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F%E5%A6%82%E4%BD%95%E8%87%AA%E5%AD%A6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%2FIT%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99%E5%8F%8A%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[说明本文有2个目的： 记录同级目录下的另一篇文章：《如何自学计算机科学》中所提及的资料，便于检索查找。 记录在学习及工作中所涉及到的相关网站或者书籍资料等。同样的，也是为了便于检索查找。 学习网站汇总学习资料汇总]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>IT基础知识</category>
        <category>如何自学计算机科学</category>
      </categories>
      <tags>
        <tag>计算机科学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python可变参数args]]></title>
    <url>%2F2018%2F12%2F20%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B%2FPython%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fpython%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0args%2F</url>
    <content type="text"><![CDATA[基础概念如果我们在函数被调用前并不知道也不限制将来函数可以接收的参数数量。在这种情况下我们可以使用*args和**kwargs来进行定义函数 *args和**kwargs这两个是python中的可变参数。 args表示任何多个无名参数，它是一个tuple kwargs表示关键字参数，它是一个dict 特别注意： 同时使用*args和**kwargs时，*args参数要列在**kwargs前。 因此像foo(a=1, b=’2’, c=3, a’, 1, None, )这样调用的话，会提示语法错误“SyntaxError: non-keyword arg after keyword arg”。 当两者同时存在时，正确的调用方式应该像是：foo(‘a’,1,a=1,b=2) 实际上真正的Python参数传递语法是*和**。*args和**kwargs只是一种约定俗成的编程实践。我们也可以写成*vars和**kvars。 实际案例代码如下： 1234567def test(*args,**kwargs): print (&quot;args = &quot;,args) print (&quot;kwargs = &quot;,kwargs) passtest(1,2,3,4)test(&quot;11&quot;,&quot;2&quot;,a=1,b=2) 执行后输出如下： 1234args = (1, 2, 3, 4)kwargs = &#123;&#125;args = (&apos;11&apos;, &apos;2&apos;)kwargs = &#123;&apos;a&apos;: 1, &apos;b&apos;: 2&#125;]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>程序编程</category>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python可变参数args</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[harbor镜像仓库实战]]></title>
    <url>%2F2018%2F12%2F18%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E8%99%9A%E6%8B%9F%E5%8C%96%2FDocker%2Bk8s%2Fharbor%2F</url>
    <content type="text"><![CDATA[参考文献 github主页 Harbor基础知识Features-功能特性 Role based access control: Users and repositories are organized via ‘projects’ and a user can have different permission for images under a project. 用户和镜像仓库是通过项目关联起来的，不同用户在该项目下拥有不同的权限 Policy based image replication: Images can be replicated (synchronized) between multiple registry instances, with auto-retry on errors. Great for load balancing, high availability, multi-datacenter, hybrid and multi-cloud scenarios. 镜像将在多个注册实例中复制，实现高可用、负载均衡、多路选择等功能 Vulnerability Scanning: Harbor scans images regularly and warns users of vulnerabilities. 高危扫描：harbor将会在规律的扫描镜像并且提醒用户相关的危险 LDAP/AD support: Harbor integrates with existing enterprise LDAP/AD for user authentication and management. harbor可以聚合企业现在的LDAP/AD等实现用户认证和管理 Image deletion &amp; garbage collection: Images can be deleted and their space can be recycled. 镜像删除和垃圾收集 Notary: Image authenticity can be ensured. 可以保证镜像的可靠性 Graphical user portal: User can easily browse, search repositories and manage projects. 图形化的用户入口：可以浏览，检索，管理项目 Auditing: All the operations to the repositories are tracked. 审计：所有的操作都可以被追踪 RESTful API: RESTful APIs for most administrative operations, easy to integrate with external systems. 提供api Easy deployment: Provide both an online and offline installer. 部署简单，提供在线和离线两种安装方式 Architecture-体系结构 As depicted in the above diagram, Harbor comprises 6 components: Proxy: Components of Harbor, such as registry, UI and token services, are all behind a reversed proxy. The proxy forwards requests from browsers and Docker clients to various backend services. harbor使用代理结构，外部的客户端（浏览器或者docker client）访问调用是通过代理层去实现的 Registry: Responsible for storing Docker images and processing Docker push/pull commands. As Harbor needs to enforce access control to images, the Registry will direct clients to a token service to obtain a valid token for each pull or push request. 注册部分：响应操作docker镜像的请求 harbor为了确保安全性，客户端在调用的时候，需要取得valid token才可以进行操作 Core services: Harbor’s core functions, which mainly provides the following services: UI: a graphical user interface to help users manage images on the Registry Webhook: Webhook is a mechanism configured in the Registry so that image status changes in the Registry can be populated to the Webhook endpoint of Harbor. Harbor uses webhook to update logs, initiate replications, and some other functions. Token service: Responsible for issuing a token for every docker push/pull command according to a user’s role of a project. If there is no token in a request sent from a Docker client, the Registry will redirect the request to the token service. Database: Database stores the meta data of projects, users, roles, replication policies and images. 提供一个图形的用户入口，方便用户在注册钩子系统（registry webhook）中管理镜像。 Job services: used for image replication, local images can be replicated(synchronized) to other Harbor instances. Log collector: Responsible for collecting logs of other modules in a single place. 安装部署参考文献 官方安装手册 环境要求Harbor is deployed as several Docker containers, and, therefore, can be deployed on any Linux distribution that supports Docker. The target host requires Python, Docker, and Docker Compose to be installed. harbor是使用docker的方式部署的，整个harbor包含几个容器，因此能够部署在任何只要支持docker的Linux发行版本上。 目标主机只需要包含：python、docker、docker compose这3个东西即可 Hardware Resource Capacity Description CPU minimal 2 CPU 4 CPU is prefered Mem minimal 4GB 8GB is prefered Disk minimal 40GB 160GB is prefered Software Software Version Description Python version 2.7 or higher Note that you may have to install Python on Linux distributions (Gentoo, Arch) that do not come with a Python interpreter installed by default Docker engine version 1.10 or higher For installation instructions, please refer to: https://docs.docker.com/engine/installation/ Docker Compose version 1.6.0 or higher For installation instructions, please refer to: https://docs.docker.com/compose/install/ Openssl latest is prefered Generate certificate and keys for Harbor Network ports Port Protocol Description 443 HTTPS Harbor UI and API will accept requests on this port for https protocol 4443 HTTPS Connections to the Docker Content Trust service for Harbor, only needed when Notary is enabled 80 HTTP Harbor UI and API will accept requests on this port for http protocol 官方的安装步骤（The installation steps boil down to the following）： Download the installer; Configure harbor.cfg; Run install.sh to install and start Harbor; 下面我们开始实际操作 下载安装下载并解压所有软件包的下载地址 1# tar -xvf harbor-online-installer-&lt;version&gt;.tgz 当前节点我使用的是harbor.v1.4.0.tar.gz 安装docker-ce12345# sudo yum install -y yum-utils device-mapper-persistent-data lvm2# sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo# sudo yum install docker-ce 启动docker12# systemctl start docker# systemctl enable docker 安装Docker Compose12345# sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose# sudo chmod +x /usr/local/bin/docker-compose# docker-compose --version 配置配置概述Configuration parameters are located in the file harbor.cfg There are two categories of parameters in harbor.cfg, required parameters and optional parameters. required parameters: These parameters are required to be set in the configuration file. They will take effect if a user updates them in harbor.cfg and run the install.sh script to reinstall Harbor. optional parameters: These parameters are optional for updating, i.e. user can leave them as default and update them on Web UI after Harbor is started. If they are set in harbor.cfg, they only take effect in the first launch of Harbor. Subsequent update to these parameters in harbor.cfg will be ignored. Note: If you choose to set these parameters via the UI, be sure to do so right after Harbor is started. In particular, you must set the desired auth_mode before registering or creating any new users in Harbor. When there are users in the system (besides the default admin user), auth_mode cannot be changed. 配置文件中有2种配置内容，一种是必须配置的参数，一种是可选参数 必须参数：这是是在配置文件当中必须要存在的参数，当用户修改之后并且重新安装harbor之后生效 可选参数：这些参数是可以动态更新的，你能够在harbor启动之后，在web界面中进行更新。但是如果你把这些参数直接配置在harbor.cfg配置文件中（默认的配置不算人为配置了），它们只能在你第一次启动harbor的时候加载生效，之后再更新参数将不会生效。这一点需要尤为注意 注意1：你使用动态的可选参数方式的时候，首先要确认harbor已经启动 注意2：有一个特别需要注意的参数，当有用户（除了默认的管理员用户）已经存在于harbor中的时候，auth_mode这个参数是不能被修改的。所以你需要在有新的用户注册进harbor之前，设置好认证模式（auth_mode） 配置文件参数详解Required parameters-必需参数 hostname: The target host’s hostname, which is used to access the UI and the registry service. It should be the IP address or the fully qualified domain name (FQDN) of your target machine, e.g., 192.168.1.10 or reg.yourdomain.com. Do NOT use localhost or 127.0.0.1 for the hostname - the registry service needs to be accessible by external clients! hostname一般配置为域名,也就是整个harbor的入口 ui_url_protocol: (http or https. Default is http) The protocol used to access the UI and the token/notification service. If Notary is enabled, this parameter has to be https. By default, this is http. To set up the https protocol, refer to Configuring Harbor with HTTPS Access. 走HTT还是HTTPS db_password: The root password for the MySQL database used for db_auth. Change this password for any production use! max_job_workers: (default value is 3) The maximum number of replication workers in job service. For each image replication job, a worker synchronizes all tags of a repository to the remote destination. Increasing this number allows more concurrent replication jobs in the system. However, since each worker consumes a certain amount of network/CPU/IO resources, please carefully pick the value of this attribute based on the hardware resource of the host. 做复制工作的进程数量，默认3个，这些进程，将这些镜像同步到远端的存储中 每个进程都需要消耗系统的资源，因此合理设置数量 customize_crt: (on or off. Default is on) When this attribute is on, the prepare script creates private key and root certificate for the generation/verification of the registry’s token. Set this attribute to off when the key and root certificate are supplied by external sources. Refer to Customize Key and Certificate of Harbor Token Service for more info. ssl_cert: The path of SSL certificate, it’s applied only when the protocol is set to https ssl_cert_key: The path of SSL key, it’s applied only when the protocol is set to https secretkey_path: The path of key for encrypt or decrypt the password of a remote registry in a replication policy. log_rotate_count: Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated. log_rotate_size: Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes. If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G are all valid. optional parameters-动态可选参数harbor启动修改完毕之后的配置如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@app028-dev harbor]# less harbor.cfg | egrep -v &apos;^$|^#&apos;hostname = dhub-dev.dwbops.comui_url_protocol = httpsmax_job_workers = 3customize_crt = onssl_cert = /data/cert/server.cerssl_cert_key = /data/cert/server.keysecretkey_path = /dataadmiral_url = NAlog_rotate_count = 50log_rotate_size = 200Memail_identity =email_server = smtp.mydomain.comemail_server_port = 25email_username = sample_admin@mydomain.comemail_password = abcemail_from = admin &lt;sample_admin@mydomain.com&gt;email_ssl = falseemail_insecure = falseharbor_admin_password = dHarbor12345auth_mode = db_authldap_url = ldaps://ldap.mydomain.comldap_basedn = ou=people,dc=mydomain,dc=comldap_uid = uidldap_scope = 2ldap_timeout = 5ldap_verify_cert = trueself_registration = ontoken_expiration = 30project_creation_restriction = everyonedb_host = mysqldb_password = root123db_port = 3306db_user = rootredis_url =clair_db_host = postgresclair_db_password = passwordclair_db_port = 5432clair_db_username = postgresclair_db = postgresuaa_endpoint = uaa.mydomain.orguaa_clientid = iduaa_clientsecret = secretuaa_verify_cert = trueuaa_ca_cert = /path/to/ca.pemregistry_storage_provider_name = filesystemregistry_storage_provider_config = 自己做测试时，将url类型设置成为http，并且将域名设置成为了：harbor.wxh.com 修改完配置之后： 1$ sudo ./install.sh 整个的安装过程如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119[root@localhost harbor]# ./install.sh[Step 0]: checking installation environment ...Note: docker version: 18.06.1Note: docker-compose version: 1.22.0[Step 1]: loading Harbor images ...651f69aef02c: Loading layer [==================================================&gt;] 135.8MB/135.8MB40a1aad64343: Loading layer [==================================================&gt;] 23.24MB/23.24MB3fe2713e4072: Loading layer [==================================================&gt;] 12.16MB/12.16MBba3a1eb0e375: Loading layer [==================================================&gt;] 17.3MB/17.3MB447427ec5e1a: Loading layer [==================================================&gt;] 15.87kB/15.87kB4ccb4026663c: Loading layer [==================================================&gt;] 3.072kB/3.072kB16faa95946a1: Loading layer [==================================================&gt;] 29.46MB/29.46MBLoaded image: vmware/notary-server-photon:v0.5.1-v1.4.0fa7ba9fd42c9: Loading layer [==================================================&gt;] 10.95MB/10.95MB4e400f9ae23e: Loading layer [==================================================&gt;] 17.3MB/17.3MB2802fb27c88b: Loading layer [==================================================&gt;] 15.87kB/15.87kBe6367a4e1e1e: Loading layer [==================================================&gt;] 3.072kB/3.072kB8ece8dfcdd98: Loading layer [==================================================&gt;] 28.24MB/28.24MBLoaded image: vmware/notary-signer-photon:v0.5.1-v1.4.0a7dd1a8afcaf: Loading layer [==================================================&gt;] 396.7MB/396.7MB05adebbe496f: Loading layer [==================================================&gt;] 9.216kB/9.216kB86eb534949fa: Loading layer [==================================================&gt;] 9.216kB/9.216kBd7f127c69380: Loading layer [==================================================&gt;] 7.68kB/7.68kB5ac1c4dc5ee9: Loading layer [==================================================&gt;] 1.536kB/1.536kBd0bec56b5b1a: Loading layer [==================================================&gt;] 9.728kB/9.728kB4bbe83860556: Loading layer [==================================================&gt;] 2.56kB/2.56kBe526f9e6769f: Loading layer [==================================================&gt;] 3.072kB/3.072kBLoaded image: vmware/harbor-db:v1.4.01cff102bbda2: Loading layer [==================================================&gt;] 154.1MB/154.1MB04c9f3e07de1: Loading layer [==================================================&gt;] 10.75MB/10.75MB7b6c7bf54f5c: Loading layer [==================================================&gt;] 2.048kB/2.048kB42f8acdb7fe3: Loading layer [==================================================&gt;] 48.13kB/48.13kB5b6299d0a1df: Loading layer [==================================================&gt;] 10.8MB/10.8MBLoaded image: vmware/clair-photon:v2.0.1-v1.4.06534131f457c: Loading layer [==================================================&gt;] 94.76MB/94.76MB73f582101e4b: Loading layer [==================================================&gt;] 6.656kB/6.656kB86d847823c48: Loading layer [==================================================&gt;] 6.656kB/6.656kBLoaded image: vmware/postgresql-photon:v1.4.05cd250d5a352: Loading layer [==================================================&gt;] 23.24MB/23.24MBad3fd52b54f3: Loading layer [==================================================&gt;] 14.99MB/14.99MB13b1e24cc368: Loading layer [==================================================&gt;] 14.99MB/14.99MBLoaded image: vmware/harbor-adminserver:v1.4.0c26c69706710: Loading layer [==================================================&gt;] 23.24MB/23.24MB223f6fe02cc8: Loading layer [==================================================&gt;] 23.45MB/23.45MB1fc843c8698a: Loading layer [==================================================&gt;] 7.168kB/7.168kBe09293610ee7: Loading layer [==================================================&gt;] 10.39MB/10.39MBd59f9780b1d8: Loading layer [==================================================&gt;] 23.44MB/23.44MBLoaded image: vmware/harbor-ui:v1.4.0dd4753242e59: Loading layer [==================================================&gt;] 73.07MB/73.07MB95aed61ca251: Loading layer [==================================================&gt;] 3.584kB/3.584kB1864f9818562: Loading layer [==================================================&gt;] 3.072kB/3.072kBda2a19f80b81: Loading layer [==================================================&gt;] 4.096kB/4.096kB058531639e75: Loading layer [==================================================&gt;] 3.584kB/3.584kBa84e69fb619b: Loading layer [==================================================&gt;] 10.24kB/10.24kBLoaded image: vmware/harbor-log:v1.4.0b1056051f246: Loading layer [==================================================&gt;] 23.24MB/23.24MB07678065e08b: Loading layer [==================================================&gt;] 19.19MB/19.19MBa2d9bdb8f5fb: Loading layer [==================================================&gt;] 19.19MB/19.19MBLoaded image: vmware/harbor-jobservice:v1.4.07f58ce57cd5e: Loading layer [==================================================&gt;] 4.805MB/4.805MBLoaded image: vmware/nginx-photon:v1.4.04c8965978b77: Loading layer [==================================================&gt;] 23.24MB/23.24MB1466c942edde: Loading layer [==================================================&gt;] 2.048kB/2.048kBac5c17331735: Loading layer [==================================================&gt;] 2.048kB/2.048kB86824c7c466a: Loading layer [==================================================&gt;] 2.048kB/2.048kBfd3bd0e70d67: Loading layer [==================================================&gt;] 22.8MB/22.8MBb02195d77636: Loading layer [==================================================&gt;] 22.8MB/22.8MBLoaded image: vmware/registry-photon:v2.6.2-v1.4.0Loaded image: vmware/photon:1.0Loaded image: vmware/mariadb-photon:v1.4.0454c81edbd3b: Loading layer [==================================================&gt;] 135.2MB/135.2MBe99db1275091: Loading layer [==================================================&gt;] 395.4MB/395.4MB051e4ee23882: Loading layer [==================================================&gt;] 9.216kB/9.216kB6cca4437b6f6: Loading layer [==================================================&gt;] 9.216kB/9.216kB1d48fc08c8bc: Loading layer [==================================================&gt;] 7.68kB/7.68kB0419724fd942: Loading layer [==================================================&gt;] 1.536kB/1.536kB526b2156bd7a: Loading layer [==================================================&gt;] 637.8MB/637.8MB9ebf6900ecbd: Loading layer [==================================================&gt;] 78.34kB/78.34kBLoaded image: vmware/harbor-db-migrator:1.4[Step 2]: preparing environment ...Generated and saved secret to file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/ui/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/jobservice/app.confGenerated configuration file: ./common/config/ui/app.confGenerated certificate, key file: ./common/config/ui/private_key.pem, cert file: ./common/config/registry/root.crtThe configuration files are ready, please use docker-compose to start the service.[Step 3]: checking existing instance of Harbor ...[Step 4]: starting Harbor ...Creating network &quot;harbor_harbor&quot; with the default driverCreating harbor-log ... doneCreating harbor-db ... doneCreating registry ... doneCreating harbor-adminserver ... doneCreating harbor-ui ... doneCreating nginx ... doneCreating harbor-jobservice ... done✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at http://harbor.wxh.com.For more details, please visit https://github.com/vmware/harbor .[root@localhost harbor]# 镜像操作上传镜像push的格式为： 1# docker push reg.yourdomain.com/myproject/myrepo:mytag 注意首先需要登录： docker login domain_name 步骤1：登录 1docker login domain_name 步骤2：将要上传的镜像打上标志 123# docker tag hello-world harbor.wxh.com/apps/hello-world# docker push harbor.wxh.com/apps/hello-world 这种上传的话，默认是打上latest的标志 打上指定的标签使用： 12docker tag hello-world harbor.wxh.com/apps/hello-world:v1docker push harbor.wxh.com/apps/hello-world:v1 harbor镜像删除在web页面上删除镜像实际上只是执行的软删除，因为镜像存在很强的文件系统依赖关系 Harbor的UI界面上先删除镜像，但这个操作并没有删除磁盘上存放的镜像文件，只是镜像文件manifest的映射关系，还需要通过GC来删除。 CAUTION: If both tag A and tag B refer to the same image, after deleting tag A, B will also get deleted. if you enabled content trust, you need to use notary command line tool to delete the tag’s signature before you delete an image. 注意，如果标签A和B都指向都一个镜像（比如hello-world的2个镜像），那么删除一个之后，另外一个也会消失 步骤1：删除镜像tag 在web页面删除镜像或者使用api接口进行删除 步骤2：停止Harbor 1docker-compose stop 步骤3：执行gc回收空间 通过带有–dry-run选项，可以查看到将要删除的镜像文件： 1docker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect --dry-run /etc/registry/config.yml1 不带–dry-run选项，直接执行删除： 1docker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect /etc/registry/config.yml1 步骤4：启动Harbor 1docker-compose start 镜像清理策略需求： 暂时不做删除 repo 的处理【这部分手动处理】 保留 60 天内创建的所有 tag ，在 60 天之前创建的 tag ，额外保留 10 个； 标签数只有 1的镜像，不清理 保留最后一次更新的tag，有些image比较稳定，有可能超过60天都没有修改，但是却一直在用 针对一些特殊的（比如每天5个tag的镜像，那么60天就有300个），这个单独特殊处理 最终： 针对 tag ：保留 60 天内创建的所有 tag ，在 60 天之前创建的 tag ，额外保留 10 个； 针对 repo ：暂时不做删除 repo 的处理（不太好确定 repo 是否还在使用，理论上讲每个 repo 下至少应该有一个 tag 是被需要的；若打算删除，则建议 repo 负责人自行进行删除操作）； 私有仓库暂时不做处理； 具体实现： harbor 主要概念的关系：1 个 project -&gt; 每个 project 下具有 N 种不同的 repos &gt; 每个 repo 下具有 M 个 tags project 有创建时间，但这个对我们的处理策略来说没有用处； repo 有创建时间和 pull 时间，该 pull 时间对应 repo 下任意一个 tag ，最新一次，被拉取的那个时间 tag 有创建时间，但没有针对 tag 的 pull 时间（harbor 中定义的数据结构中不支持）； 因此 保留 60 天内的 tag”，这个根据 tag 的创建时间 “60 天之外的看 pull 的数量，关注 60 天之外是不是被 pull 过”，由于 pull 数量是针对 repo 整体的，无法对应到具体的 tag ，即在 API 层面无法方便的知道哪些 tag 最近被 pull 过（当然如果一定要做，就只能沟通分析 log 来搞，性价比不高），所以，只能根据 tag 创建时间的先后，“武断”的认为，后创建的 tag 应该是用户最想保留的； “如果没有被 pull 过，则只保留最新 5 个 tag”，根据上一条的说明，某个 tag 是否被 pull 过是无法知道的，但目前可以做到根据 tag 的创建时间进行保留（满足保留最新 N 个需求）； Harborclient-harbor客户端命令参考文献： 主页说明 实际案例实战案例harbor镜像复制参考文献 官网文档 镜像复制概述镜像复制有一些基本的概念需要知晓： 该功能是面向项目的，系统管理员设置之后，匹配了过滤规则的项目，在触发了事先定义好的触发条件之后，这些项目就会被复制到远程的另一个仓库中。 如果在远程镜像仓库中，该项目不存在，那么就会自动创建这个项目 如果在远程仓库中，这个项目已经存在，并且配置的用户对这个项目没有写的权限，那么这个操作将会失败 因为网络的原因，在复制传输的过程中，可能会出现一些延迟。如果复制job是因为网络原因而导致失败的，那么这个任务将会在几分钟之后再次尝试，一直尝试，知道网络恢复正常。 注意： 因为api等原因，不同版本的镜像复制可能会失败，所以尽量使用同一个版本。 用户信息不会被复制 创建复制规则注意，在创建endpoint的时候，直接test connection是会报错：“harbor Failed to ping endpoint” 这是因为网络问题导致，在内网访问的时候，还需要额外的添加hosts文件，详见注意事项 注意：在创建完毕之后，默认不会执行同步，需要手动点击一下replication 删除replication规则删除规则的时候有几个注意事项： Only rules which have no pending/running/retrying jobs can be deleted. 也就是说，只有当改规则下面没有正在运行或者等待运行或者正在重传的jobs时，才可以删除 注意事项在创建endpoint的时候，如果事先没有在容器内存配置对端的地址，那么会报连接错误 官方的issues：https://github.com/goharbor/harbor/issues/2221 harbor迁移节点完全迁移存储迁移常见问题证书问题证书生成： 1openssl req -sha256 -x509 -days 365 -nodes -newkey rsa:4096 -keyout harbor.wxh.com.key -out harbor.wxh.com.crt 注意，一些name的字段要配置成为配置文件中配置的域名，例如：harbor.wxh.com 生成之后，将证书存放到指定位置，然后修改配置文件指向这些证书文件 123less harbor.cfg | egrep -v &quot;^$|^#&quot;ssl_cert = /data/cert/harbor.wxh.com.crtssl_cert_key = /data/cert/harbor.wxh.com.key 然后需要对docker进行一些配置 1mkdir -p /etc/docker/certs.d/harbor.wxh.com 然后将上面的2个证书文件复制到这个目录之下，并将/data/cert/harbor.wxh.com.crt重命名为/data/cert/harbor.wxh.com.cert 12345# pwd;ls/etc/docker/certs.d/harbor.wxh.comharbor.wxh.com.crt harbor.wxh.com.key# mv harbor.wxh.com.crt harbor.wxh.com.cert 文件创建为目录问题/data1/harbor/data/secretkey 在harbor安装之后以及运行过程中，secretkey为文件，而不是目录。 在一些异常情况可能会出现这个文件变成目录这种问题，当出现这种问题的时候，将该目录清空，然后重新安装即可]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>虚拟化</category>
        <category>Docker+k8s</category>
      </categories>
      <tags>
        <tag>harbor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python操作MySQL]]></title>
    <url>%2F2018%2F12%2F13%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B%2FPython%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fpython%E6%93%8D%E4%BD%9CMySQL%2F</url>
    <content type="text"><![CDATA[参考文献 菜鸟教程 实例案例在py3中，我们一般使用pymysql这个客户端去连接mysql数据库 读取数据修改数据写入数据]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>程序编程</category>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python操作MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异地多活-多机房bind部署]]></title>
    <url>%2F2018%2F12%2F12%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2F%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2FDNS%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0-bind%2F%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB-%E5%A4%9A%E6%9C%BA%E6%88%BFbind%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[参考文献有关bind的一些部署，请查看我在该目录下的其他文章 背景在实现多机房异地多活时，将服务分散到多个机房之后，一个核心的问题就是自建DNS，实现根据不同来源的ip段，返回相对应zone中的nginx服务端ip地址，只有这样才能 需求概述需要实现的功能如下： DNS服务端采取主从结构，阿里云端为master，IDC机房端为slave，数据保持一致 阿里云VPC内网IP地址作为dns客户端访问时，返回VPC内机房的nginx服务器IP地址 IDC机房内网IP地址作为dns客户端访问时，返回IDC机房的nginx服务器IP地址 杭州的公网IP地址访问SLB的公网地址，上海的公网IP地址访问IDC机房的IP地址 总结：dns客户端请求到的永远是最距离最近服务器 bind部署需要明确的几个问题 主从关系 暂定：阿里云为主，其他为从 服务器配置 阿里云端需要重新购置机器吗？是的话可用区及配置？ IDC机房端的机器规划，挑一台common机器 匹配ip转发规则 根据阿里云网段、机房网段等不同网段进行匹配转发 dns客户端请求域名之后，分别返回阿里云nginx服务的地址，机房的nginx服务器对应的vip 因此，阿里云端的请求的域名就有2条记录，机房端就一条记录 服务器端dns服务器配置 服务端预计配置 123# cat /etc/resolv.confnameserver 机房1dns服务器ip nameserver 机房2dns服务器ip 所有的dns客户端，在请求dns服务的时候 ，可能会连接到距离较远的服务器，但是获取记录之后将不会有影响。这里的第一次开销就保持这样吗？还是说这个也需要做优化，暂时没想到太好的方法 域名记录同步实现方式【这个目前是主要矛盾】 数据源为dnspod 如何同步dnspod上的记录到自建dns（我的想法：每隔3/5分钟去调用dnspod的api获取结果，根据对应的公网ip，去判断是阿里云还是机房的记录，然后追加进对应的zone数据文件，并且增大复制偏移量的值） 那么这个时候就存在一个问题：当一个域名只存在一个地方的时候，其他地域的主机将无法访问，因为没有记录到对应的zone数据文件中。所以需要每个地域都配置并且注册到dnspod上 主服务器有数据更新之后，触发通知的实现方式 我这边看下是否有更好的方式，没有的话暂时使用reload的方式 移动端配置？ 移动端需要考虑吗？ 总结： 阿里云走内网的slb 并不是所有的域名都需要配置成为多机房，只有一些特定的域名需要配置成为多记录的方式 当只有一条记录的时候，我们所有的配置文件中都配置成为这一个记录 当有3条记录的时候，我们将数据分发到3个配置文件当中 当只有一条记录的时候，每个数据文件都记录这个内容，保证解析成功 架构规划这里是拓扑图讲解 主从结构 Bind 视图和zone功能，实现根据来源ip进行判断 现在的所有域名导入 部署实施目录分层并不是所有的域名都需要根据地域不同返回不同的ip 我们根据不不同的地域创建了不同的zone目录，目录下有相同名称的zone数据文件 所以这个时候我们就可以进行匹配，当匹配到一个域名只有一个解析ip的时候，我们就把这条记录写入到3个不同的目录下的相同域名zone文件中 当匹配到有3个解析ip的时候，我们就对这个信息做处理，把对应的ip写入到对应的目录下的zone文件当中。 zone配置common123[named@host1 common]$ pwd;ls/home/named/bind/chroot/var/named/zone/commondwb.dgt.zone dwd.gds-sh.zone ecs.east1-b.zone ecs.east1-e.zone ecs.east1-g.zone zone文件配置模板： 123456789101112131415161718[named@host1 common]$ cat dwd.gds-sh.zone$TTL 86400@ IN SOA dwd.gds-sh. admin.dwd.gds-sh. ( 1 ; serial 3H ; refresh 15M ; retry 1W ; expiry 1D ) ; minimum IN NS dns.dwd.gds-sh.dns IN A 10.11.4.11dns IN A 10.11.4.12dns IN A 10.10.10.72dns IN A 10.10.10.73dns IN A 172.24.139.193dns IN A 172.24.139.194lvs001 IN A 10.11.0.11lvs002 IN A 11.11.0.12 说明： 为了便于后期分析及拍错等操作，我们在每个zone配置文件中都添加上6条ns记录 数据写入因为dnspod上的数据都是公网地址 所以要进行匹配，匹配公网之后，替换为对应的内网负载均衡的ip地址 优化进阶最终实现目标是编写一个平台去管理，在当前时间节点下，先只能做到通过web框架去编写api实现下面这些操作 主节点zone数据信息变更写入在master节点上启动django服务，提供api，当数据源有变化时，对端发送POST请求，参数为： 收到请求之后进行处理 注意：因为这个很重要，所以事先定义用户名和密码，生成token，然后才运行更新数据 写完之后，序列号更新为当天的时间，例如：2007041501 如果发现当天已经存在，那么在当前的序列号上+1 修改和写入一样，在master节点上启动django服务，提供api，当数据源有变化时，对端发送POST请求 删除和写入一样，在master节点上启动django服务，提供api，当数据源有变化时，对端发送delete请求 针对主机名的配置，我们不使用提供接口的方式，对主机名的配置，我们编写程序作为客户端，定时的去扫描数据源（阿里云或者jumpserver端） 主从数据同步主从数据同步主要分为2种 一种是主节点数据变化之后，主动的触发通知机制，发送通知消息给所以slave节点。 另一种是从节点定期去连接主节点，获取序列号信息，与当前的值进行比较，如果获取的更大则发起数据同步 结合实际情况，我们选择第一种方式 那么，当数据变更之后，如何不适用rndc reload的方式 序列号增长问题因为序列号最多为10位数，所以使用传统的日期表示法 dns服务稳定性问题注意事项主从节点两边的acl列表需要保持一致，这部分数据是不会同步的 会同步的只是zone数据 因此在启动之前，一定要确保主配置文件、acl列表、view配置等都保持一致 因为主的多个view会共用一些zone（主机名），所以这些zone，view配置中的路径可以一致 但是从上，每一个view之间不能存在这种通用文件。 slave的ip地址不止应该在named.conf主配置文件当中定义 在acl列表中也应该写明，不然会被refused 在master上：所有的acl列表需要包含slave节点ip 在salve节点上，所有的acl列表需要包含master节点的ip 不然： 主从同步开始时，slave向master发送soa时会被拒绝 主修改之后发送notify，slave将会拒绝这个消息，因此来源ip不在acl中 同时存在3个view，在主上修改了view3或view2，但是slave上收到的信息始终是view1的notify 在这里，只有shidc这个view能收到信息 主节点 acl配置阿里云acl： vpc的网段 【必须有】 阿里云2台dns的ip 杭州acl： 杭州机房网段 【必须有】 杭州机房2台dns服务器的ip 允许这2台主机发送soa请求并给予响应 上海机房acl 上海机房网段 【必须有】 上海机房2台dns服务器 从节点acl配置 vpc的网段 【必须有】 上海主节点的ip地址。为了主节点发送notify发送消息时不拒绝 杭州acl： 杭州机房网段 【必须有】 上海主节点的ip地址。为了主节点发送notify发送消息时不拒绝 上海机房acl 上海机房网段 【必须有】 上海主节点的ip地址。为了主节点发送notify发送消息时不拒绝 因为从节点需要做备份，所以从节点上需要维护3个view，而不只是所在地域的这一个网段 测试：有变化的只是杭州idc和阿里云 测试客户端 hzidc: common008-dev 192.168.11.88 Aliyun: common010-dev 192.168.11.76 shIDC：common007-dev 192.168.11.84 notify配置注意，notify的配置需要写在每一个zone里面，不能写在主配置文件当中 master发送的notify信息中不能携带view信息，slave接收的时候，根据本身的view的配置进行匹配 如果一个网段存在于多个view当中，那么只有第一个生效，也就是说，如果主节点更新的是view3的数据，如果view1收到之后，那么将会更新view1中的zone信息 又因为master的ip必须存在于acl中（需要允许master发送的notify，不设置的话主节点发送的消息会被拒绝）， 但是因为acl是从上到下匹配的 因此slave只能有一个view，也就是说除了主上维护的是全量的数据，其他从节点维护的只是一个view的数据 也就是说，如果存在同一个ip，那么不管配置几个view，同时生效的只会有一个view 从节点直接显示文本多view主从同步问题多个view的主备同步主要是是主备之间每个view都使用共享key进行消息的签名。master的配置和之前的稍微有点小的改动 大家经常使用bind的时候是划分不同的view的，因为每个view的zone需要单独修改，所以人肉修改是比较麻烦的。这个时候可以使用nsupdate进行批量的操作。只要注意每个view使用正确的记录就行。 每个view指定一个对应key进行能更新 最终的实现目的：主从上的数据完全一致，也就是 参考文献： bind多个view的主备同步 #!/bin/bashcd /home/appdeploy/deploy/apps/fortune-unit-service/usr/bin/nohup /usr/local/jdk/bin/java -Dproject.name=fortune-unit-service -verbose:gc -Xloggc:/home/appdeploy/deploy/logs/fortune-unit-service/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/appdeploy/deploy/logs/fortune-unit-service/java.hprof -XX:ErrorFile=/home/appdeploy/deploy/logs/fortune-unit-service/java_error.log -Dlogging.file.path=”/home/appdeploy/deploy/logs/fortune-unit-service” -Dspring.cloud.config.label=aliyun.hz.unit1 -Dspring.cloud.config.index=aliyun.hz.unit1 -Dlogging.console.level=off -Dzone=unit1 -Dregion=aliyun.hz -server -Xms3000m -Xmx3000m -XX:MaxNewSize=512m -XX:PermSize=512M -XX:MaxPermSize=512m -XX:ThreadStackSize=512 -XX:-OmitStackTraceInFastThrow -jar fortune-unit-service.jar –spring.profiles.active=production &gt;&gt; /dev/null 2&gt;&amp;1 &amp; select h.name as hostname,SUM(tre.value_min) as mem_availfrom hosts h,items i,trends_uint trewhereh.name like ‘redis%’and h.status = ‘0’and h.hostid= i.hostidand i.itemid= tre.itemidand i.name = “Available memory”and tre.clock BETWEEN 1545809182 and 1545812782group by hostname,total]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>网络知识及网络服务</category>
        <category>网络服务</category>
        <category>DNS服务实现-bind</category>
      </categories>
      <tags>
        <tag>bind</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python异常处理]]></title>
    <url>%2F2018%2F12%2F09%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B%2FPython%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fpython%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[参考文献 菜鸟教程-Python异常处理 异常处理基础知识异常处理在任何一门编程语言里都是值得关注的一个话题，良好的异常处理可以让你的程序更加健壮，清晰的错误信息更能帮助你快速修复问题。 默认情况下，出现异常之后，整个程序就会直接终止，因此我们需要定义异常处理，保证程序按照我们的意愿输出便于我们分析问题的信息或者继续运行 两种实现方式python提供了两个非常重要的功能来处理python程序在运行中出现的异常和错误。你可以使用它们来调试python程序。 异常处理 断言(Assertions) 本文会将这两种方式都进行介绍及梳理 方式/功能1-异常处理使用python自带异常进行处理python标准异常我们先了解下python定义了哪些标准异常 异常名称 描述 BaseException 所有异常的基类 SystemExit 解释器请求退出 KeyboardInterrupt 用户中断执行(通常是输入^C) Exception 常规错误的基类 StopIteration 迭代器没有更多的值 GeneratorExit 生成器(generator)发生异常来通知退出 StandardError 所有的内建标准异常的基类 ArithmeticError 所有数值计算错误的基类 FloatingPointError 浮点计算错误 OverflowError 数值运算超出最大限制 ZeroDivisionError 除(或取模)零 (所有数据类型) AssertionError 断言语句失败 AttributeError 对象没有这个属性 EOFError 没有内建输入,到达EOF 标记 EnvironmentError 操作系统错误的基类 IOError 输入/输出操作失败 OSError 操作系统错误 WindowsError 系统调用失败 ImportError 导入模块/对象失败 LookupError 无效数据查询的基类 IndexError 序列中没有此索引(index) KeyError 映射中没有这个键 MemoryError 内存溢出错误(对于Python 解释器不是致命的) NameError 未声明/初始化对象 (没有属性) UnboundLocalError 访问未初始化的本地变量 ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象 RuntimeError 一般的运行时错误 NotImplementedError 尚未实现的方法 SyntaxError Python 语法错误 IndentationError 缩进错误 TabError Tab 和空格混用 SystemError 一般的解释器系统错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 UnicodeError Unicode 相关的错误 UnicodeDecodeError Unicode 解码时的错误 UnicodeEncodeError Unicode 编码时错误 UnicodeTranslateError Unicode 转换时错误 Warning 警告的基类 DeprecationWarning 关于被弃用的特征的警告 FutureWarning 关于构造将来语义会有改变的警告 OverflowWarning 旧的关于自动提升为长整型(long)的警告 PendingDeprecationWarning 关于特性将会被废弃的警告 RuntimeWarning 可疑的运行时行为(runtime behavior)的警告 SyntaxWarning 可疑的语法的警告 UserWarning 用户代码生成的警告 try/except/else/finally语法首先说明下语法 try: 需要检测异常的代码块放在try中 except &lt;异常名称&gt;：匹配之后，指定该段中的代码。可以定义多个抓取异常的语句 except Exception：用户捕获我们没有发现的异常，这段需要放在except语句块的最后 else: 语句执行正常时执行的代码 finally：语句无论是否发生异常都将执行最后的代码 实际组合： 123456789101112try:&lt;语句&gt; #运行代码except &lt;名字1&gt;：&lt;语句&gt; #如果在try部份引发了&apos;name1&apos;异常，则执行这段代码except &lt;名字2&gt;:&lt;语句&gt; #如果在try部份引发了&apos;name2&apos;异常，则执行这段代码except Exception：&lt;语句&gt; # 匹配到未知异常时执行，也就是没有被&quot;except &lt;名字&gt;&quot;定义的异常else:&lt;语句&gt; #如果没有异常发生执行这段代码finally:&lt;语句&gt; # 无论异常与否都执行 光说没案例是理解不了的，下面我们看一个案例 实例案例我们先看一段会导致异常的代码 1234def test(par1,par2): print (par1,par2)test(1) 运行之后的结果是： 1234567/usr/local/bin/python3 /Users/wangxiaohua/PycharmProjects/private_project/test/test.pyTraceback (most recent call last): File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 6, in &lt;module&gt; test(1)TypeError: test() missing 1 required positional argument: &apos;par2&apos;Process finished with exit code 1 可以很明显的看到，因为我们少输入的一个参数，这里产生了TypeError这个异常，并且还给出了异常的相关信息 —— 分割线 —— 接下来我们对这段代码进行一下改造，添加上异常处理功能 修改之后的代码如下： 123456789101112def test(par1,par2): print (par1,par2)try: test(1)except TypeError as e: print (&quot;位置参数错误，详细信息为：&quot;,e)except Exception as e: print (&quot;未知错误：&quot;,e)else: print (&quot;执行正常时输出这段话&quot;)finally: print (&quot;不管成功与否，都会执行的代码段，可以不定义&quot;) 我们开始运行程序 第一次（错误案例，调用方式为：test(1)），结果如下 12345/usr/local/bin/python3 /Users/wangxiaohua/PycharmProjects/private_project/test/test.py位置参数错误，详细信息为： test() missing 1 required positional argument: &apos;par2&apos;不管成功与否，都会执行的代码段，可以不定义Process finished with exit code 0 第二次（成功案例，调用方式为：test(1,2)），结果如下 123456/usr/local/bin/python3 /Users/wangxiaohua/PycharmProjects/private_project/test/test.py1 2执行正常时输出这段话不管成功与否，都会执行的代码段，可以不定义Process finished with exit code 0 注意： 如果代码本身有错误，都没办法执行的话，是抓不到错误异常的，因为上面抓取错误异常指的是在代码执行时出现的异常 工作流try的工作原理是，当开始一个try语句后，python就在当前程序的上下文中作标记，这样当异常出现时就可以回到这里，try子句先执行，接下来会发生什么依赖于执行时是否出现异常。 如果当try后的语句执行时发生异常，python就跳回到try并执行第一个匹配该异常的except子句，异常处理完毕，控制流就通过整个try语句（除非在处理异常时又引发新的异常）。 如果在try后的语句里发生了异常，却没有匹配的except子句，异常将被递交到上层的try，或者到程序的最上层（这样将结束程序，并打印缺省的出错信息）。 如果在try子句执行时没有发生异常，python将执行else语句后的语句（如果有else的话），然后控制流通过整个try语句。 自定义触发异常在我们定义一些代码逻辑的时候，可能程序并不是产生异常，但是已经不符合我们定义的逻辑，这个时候，我们需要使用raise语句来强制引发抛出异常 语法raise语法格式如下： 1raise Exception(&quot;message&quot;, args) 语句中 Exception 是异常的类型（例如，NameError、IOError）参数，标准异常中任一种，args 是自已提供的参数。两个参数都可以省略 实例案例代码： 1234567891011def test (num): if num &lt; 10: raise ValueError(&quot;Invaild num:&quot;,num)try: test(8)except ValueError as e: print (e)except Exception as e: print (&quot;异常错误&quot;,e)else: print (&quot;ok&quot;) 执行后输出如下： 1(&apos;Invaild num:&apos;, 8) 自定义异常类有些时候，我们需要使用我们自己定义的异常类去做一些处理 123456789101112131415class wxherror(Exception): passdef test (num): if num &lt; 10: raise wxherror(num)try: test(8)except wxherror as e: print (&quot;错误,参数为：&#123;e&#125;&quot;.format(e=e))except Exception as e: print (&quot;异常错误&quot;,e)else: print (&quot;ok&quot;) 执行后输出如下： 1错误,参数为：8 总结通过上面的案例，我们可以总结一下使用方式 和python自带的异常处理不同，在使用自定义异常的时候，我们在具体的实现代码块中就要事先定义好，当出现某种情况时，需要抛出指定的异常（需要人为定义异常的内容） 其实自带异常处理，也是在实现代码中定义了这些异常，只不过已经内部集成，不为外部所见 自己写的异常，系统不知道它的存在，也就是说系统不知道走到哪一步应该触发它，因为所有的逻辑都是我们认为的去判断的，因此自己写的异常需要我们自己去触发，否则它不会自动触发，会自动触发的异常只有标准异常 方式/功能2-断言(Assertions)语法assert断言语句用来声明某个条件是真的，其作用是判断一个条件(condition)是否成立，如果不成立，则抛出异常。 assert一般用法： 1assert condition 如果condition为false，就raise一个AssertionError出来。逻辑上等同于： 12if not condition: raise AssertionError() 另一种使用方法： 1assert condition，expression 如果condition为false，就raise一个描述为 expression 的AssertionError出来。逻辑上等同于： 12if not condition: raise AssertionError(expression) 案例assert使用示例： 案例1 1assert isinstance(11,str) 执行后输出为： 1234Traceback (most recent call last): File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 26, in &lt;module&gt; assert isinstance(11,str)AssertionError 知道会抛出AssertionError之后，我们就可以做一些判断处理 案例2 12345678910def test (num): if not (num &lt; 10): raise AssertionError(&quot;&#123;num&#125; &gt;= 10&quot;.format(num=num))try: test(11)except AssertionError as e: print (&quot;输入数字错误&quot;,e)except Exception as e: print (&quot;异常错误&quot;,e) 执行后输出为： 1输入数字错误 11 &gt;= 10 案例3 1assert (1&gt;2),&quot;异常信息：1&gt;2&quot; 执行后输出为： 1234Traceback (most recent call last): File &quot;/Users/wangxiaohua/PycharmProjects/private_project/test/test.py&quot;, line 18, in &lt;module&gt; assert (1&gt;2),&quot;异常信息：1&gt;2&quot;AssertionError: 异常信息：1&gt;2 断言跟异常的区别断言是用来检查非法情况而不是错误情况的，用来帮开发者快速定位问题的位置。异常处理用于对程序发生异常情况的处理，增强程序的健壮性和容错性。 对一个函数而言，一般情况下，断言用于检查函数输入的合法性，要求输入满足一定的条件才能继续执行; 在函数执行过程中出现的异常情况使用异常来捕获。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>程序编程</category>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python异常处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python日志处理]]></title>
    <url>%2F2018%2F12%2F05%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B%2FPython%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fpython%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[参考文献 Python之日志处理（logging模块） 官方文档 日志相关概念日志是一种可以追踪某些软件运行时所发生事件的方法。软件开发人员可以向他们的代码中调用日志记录相关的方法来表明发生了某些事情。一个事件可以用一个可包含可选变量数据的消息来描述。此外，事件也有重要性的概念，这个重要性也可以被称为严重性级别（level）。 总结重点： 追踪记录程序运行时发生的事件 实现：在代码中调用日志处理方法 事件有严重性级别 日志作用通过对log进行分析，可以 方便用户了解系统或软件、应用的运行情况； 如果你的应用log足够丰富，也可以分析以往用户的操作行为、类型喜好、地域分布或其他更多信息； 如果一个应用的log同时也分了多个级别，那么可以很轻易地分析得到该应用的健康状况，及时发现问题并快速定位、解决问题，补救损失。 简单来讲就是：我们通过记录和分析日志可以了解一个系统或软件程序运行情况是否正常，也可以在应用程序出现故障时快速定位问题。 比如，做运维的同学，在接收到报警或各种问题反馈后，进行问题排查时通常都会先去看各种日志，大部分问题都可以在日志中找到答案。 再比如，做开发的同学，可以通过IDE控制台上输出的各种日志进行程序调试。 对于运维老司机或者有经验的开发人员，可以快速的通过日志定位到问题的根源。可见，日志的重要性不可小觑。 如果应用的日志信息足够详细和丰富，还可以用来做用户行为分析，如：分析用户的操作行为、类型洗好、地域分布以及其它更多的信息，由此可以实现改进业务、提高商业利益。 日志作用简单总结： 程序调试 了解软件程序运行状况是否正常 软件程序运行故障时定位问题及分析问题 用户行为分析，并以此改进业务等 日志等级在软件开发阶段或部署开发环境时，为了尽可能详细的查看应用程序的运行状态来保证上线后的稳定性，我们需要把该应用程序所有的运行日志全部记录下来进行分析，这是非常耗费机器性能的。当应用程序在生产环境正式部署时，我们通常只记录应用程序的异常信息、错误信息等，这样既可以减小服务器的I/O压力，也可以避免我们在排查故障时被淹没在日志的海洋里。 那么，怎样才能在不改动应用程序代码的情况下实现在不同的环境记录不同详细程度的日志呢？这就是日志等级的作用了，我们通过配置文件指定我们需要的日志等级就可以了。 不同的应用程序所定义的日志等级可能会有所差别，分的详细点的会包含以下几个等级： DEBUG INFO NOTICE WARNING ERROR CRITICAL ALERT EMERGENCY 日志字段信息与日志格式一条日志信息对应的是一个需要关注的事件的发生，因此通常需要包括以下几个内容： 事件的严重程度（日志级别） 事件发生时间 事件发生位置 事件内容 上面这些都是一条日志记录中可能包含的字段信息，当然还可以包括一些其他信息，如进程ID、进程名称、线程ID、线程名称等。 日志格式就是用来定义一条日志记录中包含哪些字段及其组合顺序及方式，且日志格式通常都是可以自定义的。 注意：输出一条日志时，日志内容和日志级别是需要开发人员明确指定的。对于而其它字段信息，只需要是否显示在日志中就可以了。 日志功能实现几乎所有开发语言都会内置日志相关功能，或者会有比较优秀的第三方库来提供日志操作功能，比如：log4j，log4php等。它们功能强大、使用简单。Python自身也提供了一个用于记录日志的标准库模块-logging。 python日志处理我们在Python中一般使用logging模块实现日志功能，因此我们在这里说的python日志处理实际上是logging模块相关内容。 logging模块是Python的一个标准库模块，由标准库模块提供日志记录API的关键好处是所有Python模块都可以使用这个日志记录功能。所以，你的应用日志可以将你自己的日志信息与来自第三方模块的信息整合起来。 logging模块支持日志级别logging模块并不支持我们上面说的所有级别，它默认定义了以下几个日志等级 日志等级（level） 描述 DEBUG 最详细的日志信息，典型应用场景是 问题诊断 INFO 信息详细程度仅次于DEBUG，通常只记录关键节点信息，用于确认一切都是按照我们预期的那样进行工作 WARNING 当某些不期望的事情发生时记录的信息（如，磁盘可用空间较低），但是此时应用程序还是正常运行的 ERROR 由于一个更严重的问题导致某些功能不能正常运行时记录的信息 CRITICAL 当发生严重错误，导致应用程序不能继续运行时记录的信息 开发应用程序或部署开发环境时，可以使用DEBUG或INFO级别的日志获取尽可能详细的日志信息来进行开发或部署调试； 应用上线或部署生产环境时，应该使用WARNING或ERROR或CRITICAL级别的日志来降低机器的I/O压力和提高获取错误日志信息的效率。日志级别的指定通常都是在应用程序的配置文件中进行指定的。 说明： 上面列表中的日志等级是从上到下依次升高的，即：DEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; CRITICAL，而日志的信息量是依次减少的； 当为某个应用程序指定一个日志级别后，应用程序会记录所有日志级别大于或等于指定日志级别的日志信息，而不是仅仅记录指定级别的日志信息，nginx、php等应用程序以及这里python的logging模块都是这样的。同样，logging模块也可以指定日志记录器的日志级别，只有级别大于或等于该指定日志级别的日志记录才会被输出，小于该等级的日志记录将会被丢弃。 logging模块的两种实现方式logging模块提供了两种记录日志的方式： 第一种方式是使用logging提供的模块级别的函数 第二种方式是使用Logging日志系统的四大组件 logging模块定义的模块级别常用函数 函数 说明 logging.debug(msg, args, *kwargs) 创建一条严重级别为DEBUG的日志记录 logging.info(msg, args, *kwargs) 创建一条严重级别为INFO的日志记录 logging.warning(msg, args, *kwargs) 创建一条严重级别为WARNING的日志记录 logging.error(msg, args, *kwargs) 创建一条严重级别为ERROR的日志记录 logging.critical(msg, args, *kwargs) 创建一条严重级别为CRITICAL的日志记录 logging.log(level, args, *kwargs) 创建一条严重级别为level的日志记录 logging.basicConfig(**kwargs) 对root logger进行一次性配置 其中logging.basicConfig(**kwargs)函数用于指定“要记录的日志级别”、“日志格式”、“日志输出位置”、“日志文件的打开模式”等信息，其他几个都是用于记录各个级别日志的函数。 logging模块日志系统的四大组件 组件 说明 loggers 提供应用程序代码直接使用的接口 handlers 用于将日志记录发送到指定的目的位置进行输出 filters 提供更细粒度的日志过滤功能，用于决定哪些日志记录将会被输出（其它的日志记录将会被忽略） formatters 用于控制日志信息的最终输出格式 说明： logging模块提供的模块级别的那些函数实际上也是通过这几个组件的相关实现类来记录日志的，只是在创建这些类的实例时设置了一些默认值。 实现方式1-使用logging提供的模块级别函数记录日志代码： 12345logging.debug(&quot;debug log&quot;)logging.info(&quot;info log&quot;)logging.warning(&quot;warning log&quot;)logging.error(&quot;error log&quot;)logging.critical(&quot;critical log&quot;) 执行后输出如下： 123WARNING:root:warning logERROR:root:error logCRITICAL:root:critical log 这里需要注意的是：logging模块提供的日志记录函数所使用的日志器设置的日志级别是WARNING，因此只有WARNING级别的日志记录以及大于它的ERROR和CRITICAL级别的日志记录被输出了，而小于它的DEBUG和INFO级别的日志记录被丢弃了。 几个注意事项： 默认的输出格式为：日志级别:日志器名称:日志内容 之所以会这样输出，是因为logging模块提供的日志记录函数所使用的日志器设置的日志格式默认是BASIC_FORMAT，其值为： 1&quot;%(levelname)s:%(name)s:%(message)s&quot; 日志记录函数所使用的日志器设置的处理器所指定的日志输出位置默认为:sys.stderr 日志器（Logger）是有层级关系的，上面调用的logging模块级别的函数所使用的日志器是RootLogger类的实例，其名称为’root’，它是处于日志器层级关系最顶层的日志器，且该实例是以单例模式存在的。 源码实现： 查看这些日志记录函数的实现代码，可以发现：当我们没有提供任何配置信息的时候，这些函数都会去调用logging.basicConfig(**kwargs)方法，且不会向该方法传递任何参数。继续查看basicConfig()方法的代码就可以找到上面这些问题的答案了。 如何修改默认配置 在我们调用上面这些日志记录函数之前，手动调用一下basicConfig()方法，把我们想设置的内容以参数的形式传递进去就可以了 在我们需要将日志内容从控制台输出重定向到文件时需要修改配置 logging.basicConfig()函数该方法用于为logging日志系统做一些基本配置，方法定义如下： 1logging.basicConfig(**kwargs) 该函数可接收的关键字参数如下： 参数名称 描述 filename 指定日志输出目标文件的文件名，指定该设置项后日志就不会被输出到控制台了 filemode 指定日志文件的打开模式，默认为’a’。需要注意的是，该选项要在filename指定时才有效 format 指定日志格式字符串，即指定日志输出时所包含的字段信息以及它们的顺序。logging模块定义的格式字段下面会列出。 datefmt 指定日期/时间格式。需要注意的是，该选项要在format中包含时间字段%(asctime)s时才有效 level 指定日志器的日志级别 stream 指定日志输出目标stream，如sys.stdout、sys.stderr以及网络stream。需要说明的是，stream和filename不能同时提供，否则会引发 ValueError异常 style Python 3.2中新添加的配置项。指定format格式字符串的风格，可取值为’%’、’{‘和’$’，默认为’%’ handlers Python 3.3中新添加的配置项。该选项如果被指定，它应该是一个创建了多个Handler的可迭代对象，这些handler将会被添加到root logger。需要说明的是：filename、stream和handlers这三个配置项只能有一个存在，不能同时出现2个或3个，否则会引发ValueError异常。 logging模块中定义好的可以用于format格式字符串中的字段： 字段/属性名称 使用格式 描述 asctime %(asctime)s 日志事件发生的时间–人类可读时间，如：2003-07-08 16:49:45,896 created %(created)f 日志事件发生的时间–时间戳，就是当时调用time.time()函数返回的值 relativeCreated %(relativeCreated)d 日志事件发生的时间相对于logging模块加载时间的相对毫秒数（目前还不知道干嘛用的） msecs %(msecs)d 日志事件发生事件的毫秒部分 levelname %(levelname)s 该日志记录的文字形式的日志级别（’DEBUG’, ‘INFO’, ‘WARNING’, ‘ERROR’, ‘CRITICAL’） levelno %(levelno)s 该日志记录的数字形式的日志级别（10, 20, 30, 40, 50） name %(name)s 所使用的日志器名称，默认是’root’，因为默认使用的是 rootLogger message %(message)s 日志记录的文本内容，通过 msg % args计算得到的 pathname %(pathname)s 调用日志记录函数的源码文件的全路径 filename %(filename)s pathname的文件名部分，包含文件后缀 module %(module)s filename的名称部分，不包含后缀 lineno %(lineno)d 调用日志记录函数的源代码所在的行号 funcName %(funcName)s 调用日志记录函数的函数名 process %(process)d 进程ID processName %(processName)s 进程名称，Python 3.1新增 thread %(thread)d 线程ID threadName %(thread)s 线程名称 实际配置案例代码如下： 12345678910111213141516171819import loggingimport timefrom os import path# 定义日志文件名称格式base_log_name = path.abspath(path.dirname(path.dirname(__file__))) + &apos;/logs/&apos; + &quot;dcache.log&quot; + &quot;-&quot;info_log_filename = base_log_name + time.strftime(&apos;%Y-%m-%d-%H&apos;) + &quot;-&quot; + time.strftime(&apos;%H&apos;)error_log_filename = base_log_name + &quot;error.log&quot;warn_log_filename = base_log_name + &quot;warn.log&quot;# 定义日志的输出格式log_format = &quot;%(asctime)s - %(levelname)s - %(pathname)s[line:%(lineno)d] - %(message)s&quot;logging.basicConfig(filename=info_log_filename,level=logging.DEBUG,format=log_format)# 日志记录，第一种方式来源方式2，下面会将log = logging.getLogger(&apos;root&apos;)log.info(&quot;info log&quot;)或者logging.info(&quot;info log&quot;) 在这里使用了以下字段： asctime 事件发生的时间 levelname 事件的等级 pathname 产生事件的文件的绝对路径 lineno 调用日志记录函数的源代码所在的行号 message 日志记录的文本内容 日志的输出格式为： 12018-12-07 11:10:33,546 - INFO - /Users/wangxiaohua/PycharmProjects/dcache/lib/logger.py[line:35] - info log 实现方式2-使用四大组件记录日志logging模块的四大组件 组件名称 对应类名 功能描述 日志器 Logger 提供了应用程序可一直使用的接口 处理器 Handler 将logger创建的日志记录发送到合适的目的输出 过滤器 Filter 提供了更细粒度的控制工具来决定输出哪条日志记录，丢弃哪条日志记录 格式器 Formatter 决定日志记录的最终输出格式 logging模块就是通过这些组件来完成日志处理的，上面所使用的logging模块级别的函数也是通过这些组件对应的类来实现的。 这些组件之间的关系描述： 日志器/记录器（logger）需要通过处理器（handler）将日志信息输出到目标位置，如：文件、sys.stdout、网络等； 不同的处理器（handler）可以将日志输出到不同的位置； 日志器（logger）可以设置多个处理器（handler）将同一条日志记录输出到不同的位置； 每个处理器（handler）都可以设置自己的过滤器（filter）实现日志过滤，从而只保留感兴趣的日志； 每个处理器（handler）都可以设置自己的格式器（formatter）实现同一条日志以不同的格式输出到不同的地方。 简单点说就是：日志器（logger）是入口，真正干活儿的是处理器（handler），处理器（handler）还可以通过过滤器（filter）和格式器（formatter）对要输出的日志内容做过滤和格式化等处理操作。 四大组件相关类及其常用方法下面介绍下与logging四大组件相关的类：Logger, Handler, Filter, Formatter。 logger类Logger对象，也就是日志器有3个任务要做： 向应用程序代码暴露几个方法，使应用程序可以在运行时记录日志消息； 基于日志严重等级（默认的过滤设施）或filter对象来决定要对哪些日志进行后续处理； 也就是说logger日志器这一层就会对日志做初步的过滤 将日志消息传送给所有感兴趣的日志handlers。 Logger对象最常用的方法分为两类：配置方法 和 消息发送方法 常用配置方法： 方法 描述 Logger.setLevel() 设置日志器将会处理的日志消息的最低严重级别 Logger.addHandler() 和 Logger.removeHandler() 为该logger对象添加 和 移除一个handler对象 Logger.addFilter() 和 Logger.removeFilter() 为该logger对象添加 和 移除一个filter对象 关于Logger.setLevel()方法的说明： 内建等级中，级别最低的是DEBUG，级别最高的是CRITICAL。例如setLevel(logging.INFO)，此时函数参数为INFO，那么该logger将只会处理INFO、WARNING、ERROR和CRITICAL级别的日志，而DEBUG级别的消息将会被忽略/丢弃。 logger对象配置完成后，可以使用下面的方法来创建日志记录： 常用消息发送方法 方法 描述 Logger.debug(), Logger.info(), Logger.warning(), Logger.error(), Logger.critical() 创建一个与它们的方法名对应等级的日志记录 Logger.exception() 创建一个类似于Logger.error()的日志消息 Logger.log() 需要获取一个明确的日志level参数来创建一个日志记录 说明： Logger.exception()与Logger.error()的区别在于：Logger.exception()将会输出堆栈追踪信息，另外通常只是在一个exception handler中调用该方法。 Logger.log()的用法为：logging.log(logging.ERROR,”log message”) Logger.log()与Logger.debug()、Logger.info()等方法相比，虽然需要多传一个level参数，显得不是那么方便，但是当需要记录自定义level的日志时还是需要该方法来完成。 如何得到一个Logger对象呢？一种方式是通过Logger类的实例化方法创建一个Logger类的实例，但是我们通常都是用第二种方式–logging.getLogger()方法。 logging.getLogger()方法有一个可选参数name，该参数表示将要返回的日志器的名称标识，如果不提供该参数，则其值为’root’。若以相同的name参数值多次调用getLogger()方法，将会返回指向同一个logger对象的引用。 关于logger的层级结构与有效等级的说明 logger的名称是一个以’.’分割的层级结构，每个’.’后面的logger都是’.’前面的logger的children，例如，有一个名称为 foo 的logger，其它名称分别为 foo.bar, foo.bar.baz 和 foo.bam都是 foo 的后代。 logger有一个”有效等级（effective level）”的概念。如果一个logger上没有被明确设置一个level，那么该logger就是使用它parent的level;如果它的parent也没有明确设置level则继续向上查找parent的parent的有效level，依次类推，直到找到个一个明确设置了level的祖先为止。需要说明的是，root logger总是会有一个明确的level设置（默认为 WARNING）。当决定是否去处理一个已发生的事件时，logger的有效等级将会被用来决定是否将该事件传递给该logger的handlers进行处理。 child loggers在完成对日志消息的处理后，默认会将日志消息传递给与它们的祖先loggers相关的handlers。因此，我们不必为一个应用程序中所使用的所有loggers定义和配置handlers，只需要为一个顶层的logger配置handlers，然后按照需要创建child loggers就可足够了。我们也可以通过将一个logger的propagate属性设置为False来关闭这种传递机制。 也就是说：四大组件是一种分层的架构，不管是父logger还是子logger，只要是logger，都是在handler层级之上的，所以child logger处理之后，会把消息传递给父logger的handler Handler类Handler对象的作用是（基于日志消息的level）将消息分发到handler指定的位置（文件、网络、邮件等）。Logger对象可以通过addHandler()方法为自己添加0个或者更多个handler对象。比如，一个应用程序可能想要实现以下几个日志需求： 1）把所有日志都发送到一个日志文件中； 2）把所有严重级别大于等于error的日志发送到stdout（标准输出）； 3）把所有严重级别为critical的日志发送到一个email邮件地址。这种场景就需要3个不同的handlers，每个handler负责发送一个特定严重级别的日志到一个特定的位置。 一个handler中只有非常少数的方法是需要应用开发人员去关心的。对于使用内建handler对象的应用开发人员来说，似乎唯一相关的handler方法就是下面这几个配置方法： 方法 描述 Handler.setLevel() 设置handler将会处理的日志消息的最低严重级别 Handler.setFormatter() 为handler设置一个格式器对象 Handler.addFilter() 和 Handler.removeFilter() 为handler添加 和 删除一个过滤器对象 需要说明的是，应用程序代码不应该直接实例化和使用Handler实例。因为Handler是一个基类，它只定义了所有handlers都应该有的接口，同时提供了一些子类可以直接使用或覆盖的默认行为。下面是一些常用的Handler： Handler 描述 logging.StreamHandler 将日志消息发送到输出到Stream，如std.out, std.err或任何file-like对象。 logging.FileHandler 将日志消息发送到磁盘文件，默认情况下文件大小会无限增长 logging.handlers.RotatingFileHandler 将日志消息发送到磁盘文件，并支持日志文件按大小切割 logging.hanlders.TimedRotatingFileHandler 将日志消息发送到磁盘文件，并支持日志文件按时间切割 logging.handlers.HTTPHandler 将日志消息以GET或POST的方式发送给一个HTTP服务器 logging.handlers.SMTPHandler 将日志消息发送给一个指定的email地址 logging.NullHandler 该Handler实例会忽略error messages，通常被想使用logging的library开发者使用来避免’No handlers could be found for logger XXX’信息的出现。 Formater类Formater对象用于配置日志信息的顺序、结构和内容。 与logging.Handler基类不同的是，应用代码可以直接实例化Formatter类。另外，如果你的应用程序需要一些特殊的处理行为，也可以实现一个Formatter的子类来完成。 Formatter类的构造方法定义如下： 1logging.Formatter.__init__(fmt=None, datefmt=None, style=&apos;%&apos;) 可见，该构造方法接收3个可选参数： fmt：指定消息格式化字符串，如果不指定该参数则默认使用message的原始值 datefmt：指定日期格式字符串，如果不指定该参数则默认使用”%Y-%m-%d %H:%M:%S” style：Python 3.2新增的参数，可取值为 ‘%’, ‘{‘和 ‘$’，如果不指定该参数则默认使用’%’ Filter类Filter可以被Handler和Logger用来做比level更细粒度的、更复杂的过滤功能。Filter是一个过滤器基类，它只允许某个logger层级下的日志事件通过过滤。该类定义如下： 12class logging.Filter(name=&apos;&apos;) filter(record) 比如，一个filter实例化时传递的name参数值为’A.B’，那么该filter实例将只允许名称为类似如下规则的loggers产生的日志记录通过过滤：’A.B’，’A.B,C’，’A.B.C.D’，’A.B.D’，而名称为’A.BB’, ‘B.A.B’的loggers产生的日志则会被过滤掉。如果name的值为空字符串，则允许所有的日志事件通过过滤。 filter方法用于具体控制传递的record记录是否能通过过滤，如果该方法返回值为0表示不能通过过滤，返回值为非0表示可以通过过滤。 说明： 如果有需要，也可以在filter(record)方法内部改变该record，比如添加、删除或修改一些属性。 我们还可以通过filter做一些统计工作，比如可以计算下被一个特殊的logger或handler所处理的record数量等。 案例演示需求： 生成2个日志文件 普通日志文件： 日志级别：INFO及以上级别 格式：dcache.log | 之前文件：dcache.log.2018-12-09 日志轮询：所有级别的日志相对来说会比较大，因此按天分割，每天输出一个日志文件，保留30天 error日志： 日志级别：Error及CRITICAL级别 格式：dcache-error.log | 之前文件：dcache-error.log.2018-12-09 日志轮询：error日志不会太大，因此每7天生成一个新的文件，保留4个文件 分析： 要记录INFO级别机器以上的日志，因此日志器的有效level需要设置为最低级别–INFO; 日志需要被发送到2个不同的目的地，因此需要为日志器设置2个handler，并且这3个目的地都是磁盘文件，因此这3个handler都是与FileHandler相关的 这里使用统一的内容格式，因此handler分别格式器设置一致，不需要额外区分 日志按照时间进行分割，因此需要用logging.handlers.TimedRotatingFileHandler; 而不是使用FileHandler; 代码实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import loggingimport logging.handlersfrom os import pathimport datetime&quot;&quot;&quot;生成2个日志文件1. 普通日志文件： - 日志级别：INFO及以上级别 - 格式：dcache.log | 之前文件：dcache.log.2018-12-09 - 日志轮询：按天分割，每天输出一个日志文件，保留30天2. error日志： - 日志级别：Error及CRITICAL级别 - 格式：dcache-error.log | 之前文件：dcache-error.log.2018-12-09 - 日志轮询：为防止文件过大，每7天生成一个新的文件，保留7个文件 &quot;&quot;&quot;## 定义日志文件名称格式base_log_name = path.abspath(path.dirname(path.dirname(__file__))) + &apos;/logs/&apos; + &quot;dcache&quot;info_log_filename = base_log_name + &quot;.log&quot;error_log_filename = base_log_name + &quot;-error.log&quot;# 定义日志内容的输出格式log_format = &quot;%(asctime)s - %(levelname)s - %(pathname)s[line:%(lineno)d] - %(message)s&quot;# 定义日志处理器(实例化一个日志处理器对象)logger = logging.getLogger(&apos;root&apos;)logger.setLevel(logging.INFO)# 定义handlersinfo_handler = logging.handlers.TimedRotatingFileHandler(info_log_filename, when=&apos;midnight&apos;, interval=1,backupCount=30, atTime=datetime.time(0, 0, 0, 0))info_handler.suffix = &quot;%Y-%m-%d&quot;info_handler.setLevel(logging.INFO)info_handler.setFormatter(logging.Formatter(log_format))error_handler = logging.handlers.TimedRotatingFileHandler(error_log_filename, when=&apos;midnight&apos;, interval=7,backupCount=4, atTime=datetime.time(0, 0, 0, 0))error_handler.suffix = &quot;%Y-%m-%d&quot;error_handler.setLevel(logging.ERROR)error_handler.setFormatter(logging.Formatter(log_format))# 日志器添加handlerslogger.addHandler(info_handler)logger.addHandler(error_handler)# testlogger.debug(&apos;debug message&apos;)logger.info(&apos;info message&apos;)logger.warning(&apos;warning message&apos;)logger.error(&apos;error message&apos;)logger.critical(&apos;critical message&apos;) 注意： interval表示的是：多少个指定时间内，当前的日志文件没有新的内容被写入进来，再去创建新文件，而不是时间一到就去创建新文件。每次每隔一小时输出一个文件的功能使用TimedRotatingFileHandler的方式实现不了。 因此要每小时一个文件的这种功能，需要我们想其他办法去实现]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>程序编程</category>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python日志处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维思想]]></title>
    <url>%2F2018%2F12%2F04%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E8%BF%90%E7%BB%B4%E6%80%9D%E6%83%B3%2F%E8%BF%90%E7%BB%B4%E6%80%9D%E6%83%B3%2F</url>
    <content type="text"><![CDATA[产品思维指导工作产品 站在远处、高处分析这件事对不对 所负责的工作产出是一个产品，自己本身也是一个产品 如何确定目标：主谓宾方法论，未来十年，什么是不变的 目标 不关注合理性，只讨论必要性 目标–&gt;路径–&gt;资源（目标管理本质其实是资源管理） 运营 把目标分解成没人每天每件事 成本效率（每天的工作） 流程 规范 框架 用户体验]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>运维思想</category>
      </categories>
      <tags>
        <tag>运维思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day14-前端技术]]></title>
    <url>%2F2018%2F11%2F28%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday14-%E5%89%8D%E7%AB%AF%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day09-进程线程协程]]></title>
    <url>%2F2018%2F11%2F28%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday09-%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day08-socket编程]]></title>
    <url>%2F2018%2F11%2F28%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday08-socket%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[day08目录 08-03 通过socket实现减半的ssh 08-04 通过socket结束大数据 08-06 通过socket接收大数据 08-06 通过socket实现文件发送 08-07 socket粘包问题解决 08-09 socketservr使用 08-10 socketservr使用2]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bind部署]]></title>
    <url>%2F2018%2F11%2F20%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2F%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2FDNS%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0-bind%2Fbind%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[参考文献 bind官方网站 bind9官方PDF文档 鸟哥的bind文章 BIND配置文件详解（一） 《TCP/IP详解》DNS部分 google了无数网页 基本概念记录在bind中的一些基本概念 DNS服务器：向客户端提供域名解析服务的服务器· DNS服务器的类型； 主DNS服务器：维护所负责解析的域内解析库服务器；解析库由管理维护；读写操作均可进行； 从DNS服务器：从主DNS服务器或从其他的从DNS服务器那里区域传递(类似“复制”)一份解析库，只能进行读操作 缓存DNS服务器：负责代理客户机的递归查询工作，并且采用迭代查询的服务器 转发器：如果目标域名在本DNS服务器辖区内，直接转发 BIND (Berkeley Internet Name Domain) 是Domain Name System (DNS) 协议的一个实现，提供了DNS主要功能的开放实现 资源记录 resource records (RRs) | 表示 domain 域，树状结构上的每一个节点叫做domain Each node of the tree, called a domain, is given a label. Domain name 存储在dns分布式数据库中的每一个具体的数据被称之为域名 The data stored in the DNS is identified by domain names that are organized as a tree according to organizational or administrative boundaries zone zone是dns树状结构中某个节点的代表 a zone is a point of delegation in the DNS tree zone被用于管理界限的划分，一个域名空间被划分为各个区域，也就是zone zone本身就是一个节点（domain），一个zone包含了那些相邻并且是往下的节点 It contains all domain names from a certain point downward in thedomain tree except those which are delegated to other zones 这个zone(节点)被它的上级zone标记为NS记录，而它的上级zone将会被根标记为NS记录 A delegation point is marked by one or more NS records in the parent zone, which should be matched by equivalent NS records at the root of the delegated zone 例如，有一个 domain 叫 example.com ，它可以包含test1.aaa.example.com 和test2.bbb.example.com 这些名字，但是它的 zone 文件中却只有 2 个 zone 的记录aaa.example.com 和 bbb.example.com。 权威DNS服务器（Authoritative name server） 权威服务器用于响应dns客户端的请求，上面有完整的zone数据，下面要说的主和从服务器都是属于权威服务器 在响应数据库报中，我们可以看到authoritative answer标志位的出现 设置权威服务器可以帮助我们排查问题，例如使用dig的时候可以输出重要信息 Responses from authoritative servers have the “authoritative answer” (AA) bit set in the responsepackets. This makes them easy to identify when debugging DNS configurations usingtools like dig The Primary Master 主域名服务器 在权威服务器中，起主要重要的我们称之为主域名服务器 数据文件一般是zone file或者master file This file is called the zone file or master file. Slave Servers 从域名服务器 权威服务器的一种 slave提供必要的冗余服务，所有的slave服务器都应该记录在这个域名的ns记录中 一般来说，slave上的数据一般是通过zone transfer进程从master上同步的，但是它也能从其他slave节点上同步数据 slave节点会周期性的发送请求到master节点，检测和同步数据（sending a query for the zone’s SOA record and checking whether the SERIAL field has been updated） bind-chroot bind-chroot是bind的一个功能，使bind可以在一个chroot的模式下运行。也就是说，bind运行时的/(根)目录，并不是系统真正的/(根)目录，只是系统中的一个子目录而已。这样做的目的是为了提高安全性。因为在chroot的模式下，bind可以访问的范围仅限于这个子目录的范围里，无法进一步提升，进入到系统的其他目录中。 dns服务器工作流程 设置forward转发。如果设置了转发，则将请求转发到forward服务器 没有设置forward转发 1). 本地cache 2). 本地zone配置 2). 若本地cache和zone都没有数据，则前往root(.)进行查询 具体部署部署方式在做测试或者只是提供基本功能的时候，我们可以使用软件源，只需用yum(redhat、centos系列)等方式安装即可。 如果需要更深层次的使用配置，我们建议使用源码包的安装方式 创建用户12groupadd nameduseradd -g named named 依赖关系依赖关系需要使用管理员用户安装 具体安装哪些需要根据实际的服务器情况决定，例如gcc、openssl等都是需要的，这里不再赘述。 下载bind为了便于后续的维护及配置，这里采用源码包的安装方式 123[named@host1 ~]$ pwd/home/named[named@host1 ~]$ wget https://www.isc.org/downloads/file/bind-9-12-3/?version=tar-gz -O bind-9.12.3.tar.gz 这里我们选择9.12.3版本（当前时间节点为：2018年11月20日） 安装在编译的时候可以添加以下功能参数 --enable-threads | 在多cpu环境下，开启多线程支持，提高性能 --with-tuning=large | 在内存充裕（12G以上）的情况下，开启以提高性能，否则不建议开启 --prefix=&lt;PREFIX&gt; | 自定义安装路径，源码安装时必须指定。 --with-openssl=&lt;PREFIX&gt; | 如果使用自定义的openssl，需要进行指定。使用系统自带的就不需要额外指定 1234tar -zxvf bind-9.12.3.tar.gz./configure --prefix=/home/named/bindmakemake install 安装完成之后在目录下会提供一些调试工具 123[named@host1 bin]$ pwd;ls/home/named/bind/bin arpaname bind9-config delv dig host isc-config.sh mdig named-rrchecker nslookup nsupdate 然后我们把必要的系统管理命令的目录路径添加到系统路径： 12345[named@host1 ~]$ vim .bash_profile # 在文件末尾添加一下2行内容PATH=/home/named/bind/sbin/:$PATHexport PATHalias rndc=&apos;rndc -c /home/named/bind/chroot/etc/rndc.conf&apos;[named@host1 ~]$ source .bash_profile 配置通用配置1. 创建chroot目录123[named@host1 bind]$ mkdir -p /home/named/bind/chroot/&#123;etc,var,log&#125;[named@host1 bind]$ mkdir -p /home/named/bind/chroot/var/&#123;run,named&#125;[named@host1 bind]$ mkdir -p /home/named/bind/chroot/var/named/&#123;zone,data&#125; 2. 生成配置文件1234[named@host1 etc]$ pwd/home/named/bind/chroot/etc[named@host1 etc]$ /home/named/bind/sbin/rndc-confgen &gt; rndc.conf[named@host1 etc]$ sed -n &apos;15,23s/#\ //p&apos; rndc.conf &gt; named.conf 两个配置文件简要说明： named.conf 这个是我们的主配置文件，关于域名的配置都记录在这里 rndc.conf 这个是rndc的安全配置文件。 rndc 是 BIND 9 之后提供一个管理工具，包括重加载zone数据而不需要重新启动整个 DNS 、检查 DNS 的状态与统计数据等等 因为 rndc 可以很深入的管理DNS 服务器，所以要进行一些管控。控管的方式是通过rndc 的设置创建一个密钥 (rndc key)，并将这个密钥相关信息写入 named.conf 配置文件当中。启动 DNS 后，你的 DNS 就能够藉由 rndc 这个命令管理！ 3. 下载name.root文件（13个根服务器的配置）1[named@host1 etc]$ wget ftp://ftp.rs.internic.net/domain/named.root -P /home/named/bind/chroot/var/named/ 4. 创建localhost.zone文件该文件一般情况下不使用，因为服务器上的本地hosts文件中都会添加这个信息 在实际部署时，不会使用。这里也进行说明，如有特殊需求可以使用。 12345678910111213[named@host1 named]$ pwd/home/named/bind/chroot/var/named[named@host1 named]$ cat localhost.zone$TTL 86400@ IN SOA @ root ( 1 ; serial (d. adams) 3H ; refresh 15M ; retry 1W ; expiry 1D ) ; minimum IN NS @ IN A 127.0.0.1 IN AAAA ::1 5. 创建文件localhost.rev该文件一般情况下不使用，因为服务器上的本地hosts文件中都会添加这个信息 在实际部署时，不会使用。这里也进行说明，如有特殊需求可以使用。 123456789101112[named@host1 named]$ pwd/home/named/bind/chroot/var/named[named@host1 named]$ cat localhost.rev$TTL 86400@ IN SOA localhost. root.localhost. ( 1 ; Serial 3H ; Refresh 15M ; Retry 1W ; Expire 1D ) ; Minimum IN NS localhost.1 IN PTR localhost. 6. 修改named.conf配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116[named@host1 etc]$ pwd/home/named/bind/chroot/etc[named@host1 etc]$ cat named.confkey &quot;rndc-key&quot; &#123; algorithm hmac-sha256; secret &quot;vqOF9VUn75lvtpCYvYffOVNT8LkLK0z78UCPVkX1ofk=&quot;;&#125;;controls &#123; inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;options&#123; listen-on port 53&#123; 192.168.103.99; &#125;; listen-on-v6 port 53&#123; fe80::20c:29ff:fefe:d1f4; &#125;; version &quot;bind 9.12.3&quot;; directory &quot;/home/named/bind/chroot/var/named&quot;; pid-file &quot;/home/named/bind/chroot/var/run/named.pid&quot;; session-keyfile &quot;/home/named/bind/chroot/var/run/session.key&quot;; dump-file &quot;/home/named/bind/chroot/var/named/data/cache_dump.db&quot;; statistics-file &quot;/home/named/bind/chroot/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/home/named/bind/chroot/var/named/data/named_mem_stats.txt&quot;; recursion yes; allow-query&#123; any; &#125;; allow-query-cache&#123; any; &#125;; allow-transfer&#123; 192.168.101.172; &#125;; notify yes; also-notify&#123; 192.168.101.172; &#125;;&#125;;logging &#123; channel default_debug &#123; file &quot;/home/named/bind/chroot/log/named.run&quot; versions 10 size 128m; severity dynamic; print-category yes; print-severity yes; print-time yes; &#125;; channel queries_info &#123; file &quot;/home/named/bind/chroot/log/query.log&quot; versions 10 size 128m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category queries &#123; queries_info; default_debug; &#125;; channel notify_info &#123; file &quot;/home/named/bind/chroot/log/notify.log&quot; versions 10 size 128m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category notify &#123; notify_info; default_debug; &#125;; channel xfer_in_log &#123; file &quot;/home/named/bind/chroot/log/xfer_in.log&quot; versions 10 size 128m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; channel xfer_out_log &#123; file &quot;/home/named/bind/chroot/log/xfer_out.log&quot; versions 10 size 128m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category xfer-in &#123; xfer_in_log; &#125;; category xfer-out &#123; xfer_out_log; &#125;;&#125;;zone &quot;.&quot; in&#123; type hint; file &quot;named.root&quot;;&#125;;zone &quot;localhost&quot; in&#123; type master; file &quot;localhost.zone&quot;;&#125;;zone &quot;0.0.127.in-addr.arpa&quot; in&#123; type master; file &quot;localhost.rev&quot;; allow-update &#123; none; &#125;;&#125;;zone &quot;test.com&quot; IN &#123; type master; file &quot;zone/test.com.zone&quot;;&#125;; 注意：localhost和0.0.127.in-addr.arpa这2个zone，我们在实际部署的时候不会添加，当有特殊需求时使用 上面是为了测试把zone信息写了出来，在实际部署中，主配置文件中zone相关部分替换成下面这种形式： 1234567include &quot;/home/named/bind/chroot/etc/acls/shidc&quot;;include &quot;/home/named/bind/chroot/etc/acls/hzidc&quot;;include &quot;/home/named/bind/chroot/etc/acls/aliyun-east1&quot;;include &quot;/home/named/bind/chroot/etc/views/shidc&quot;;include &quot;/home/named/bind/chroot/etc/views/hzidc&quot;;include &quot;/home/named/bind/chroot/etc/views/aliyun-east1&quot;; 有关acl以及view的部分，请查看本文的bind总结部分的named.conf配置文件详解 7. 创建zone相关文件123456789101112131415[named@host1 zone]$ pwd/home/named/bind/chroot/var/named/zone[named@host1 zone]$ cat test.com.zone$TTL 86400@ IN SOA test.com. admin.test.com. ( 57 ; serial (d. adams) 3H ; refresh 15M ; retry 1W ; expiry 1D ) ; minimum IN NS dns.test.com. IN MX 5 maildns IN A 192.168.11.91mail IN A 192.168.11.102www IN A 192.168.11.8 8. 检查配置文件1[named@host1 etc]$ /home/named/bind/sbin/named-checkconf /home/named/bind/chroot/etc/named.conf 9. 检查正向和反向zone配置文件1234567[named@host1 etc]$ /home/named/bind/sbin/named-checkzone localhost /home/named/bind/chroot/var/named/localhost.zonezone localhost/IN: loaded serial 42OK[named@host1 etc]$ /home/named/bind/sbin/named-checkzone 127.0.0.1 /home/named/bind/chroot/var/named/localhost.revzone 127.0.0.1/IN: loaded serial 1997022700OK 10. 检查自定义zone配置文件123[named@host1 etc]$ /home/named/bind/sbin/named-checkzone 127.0.0.1 /home/named/bind/chroot/var/named/zone/test.com.zonezone 127.0.0.1/IN: loaded serial 57OK 主从/主辅同步配置bind的主从，也称之为主辅，其实都是一样的。 master/主配置修改named.conf配置文件在option配置段中增加如下配置： 1234567allow-transfer&#123; 192.168.11.89;&#125;; notify yes;also-notify&#123; 192.168.11.89;&#125;; 上面是全局配置，如果是配置到具体的zone，只需要将以上3个参数配置zone里面即可（从服务器无需变化），如下： 1234567891011zone &quot;test.com&quot; IN &#123; type master; file &quot;zone/test.com.zone&quot;; allow-transfer&#123; 192.168.11.89; &#125;; notify yes; also-notify&#123; 192.168.11.89; &#125;;&#125;; 增加参数为： allow-transfer notify also-notify 有关这些参数的含义，请查看本文的bind总结部分的named.conf配置文件详解 注意：bind的主辅同步可以针对具体的每一个zone，也就是说每个zone都可以配置自己的从服务器。当域名的数据量很庞大时，为提高解析效率，实现读写分离，使用一台主服务器写，并将域名均分到多台从服务器上，以提高读的效率。 slave/辅配置修改named.conf配置文件在zone配置段中增加如下配置： 123[named@host1 etc]$ pwd/home/named/bind/chroot/etc[named@host1 etc]$ vim named.conf 1234567zone &quot;test.com&quot; IN &#123; type slave; file &quot;zone/test.com.zone&quot;; masters&#123; 192.168.11.91; &#125;;&#125;; 主要增加参数： masters 配置主服务器 type slave指定为从服务器 注意：slave端的zone配置文件可以事先不存在，但是对应的存储目录一定要存在 子域授权配置除了 Master/Slave 这种需要多个DNS 服务器共同提供服务之外，DNS 之间如果有上层、下属的关系时，该如何设置？ 也就是说，假设我的管理范围很大，我只想要负责上层的 DNS ，下层希望直接交给各单位的负责人来负责，要怎么设置呢？ 所以，bind可以将各个 subdomain (子域) 的管理权交给指定的的主机管理员去管理，如此一来， 域名设置会比较灵活，而且上层 DNS 服务器管理员也不用太麻烦！ 子域授权在我们当前的这种架构中不会部署，但是也提及一下 子域授权的配置相当简单，分为两个步骤 步骤1. master端配置我们只需要在master端的zone配置文件（注意是zone配置文件而不是named.conf）添加对应的NS记录和A记录即可 12sub.test.com.com. IN NS dns.sub.test.com.com.dns.sub.test.com.com. IN A 192.168.100.200 在这里，我们把sub.test.com.com.这个子域的解析交给dns.sub.test.com.com.这个域名对应的主机 因此，在这之后，例如www.sub.test.com.com.、aaa.sub.test.com.com.等域名都将由200这个主机提供解析服务 步骤2. 下层dns服务器上层 DNS 的设置非常简单！只要修改 zone file 即可 下层的dns服务器配置没有什么特殊的，按照正常的配置，只不过named.conf和zone配置文件中域名要设置成“sub.test.com.com” 1234zone &quot;sub.test.com.com&quot; IN &#123; type master; file &quot;zone/sub.test.com.com.zone&quot;;&#125;; view-视图解析配置根据客户端的ip地址，返回不同的zone解析记录，因此，我们就需要对同一个zone准备几个不同的配置 我们根据这个原则，进行如下的测试 当来源是192.168.11.0/24网段时，返回www.test.com的解析记录是192.168.11.80 当来源是非上述之外的所有网段时，返回www.test.com的解析记录是8.8.8.8 对不同的来源创建不同的zone文件 下面我们开始正式的配置 在named.conf配置文件中添加一下内容 view的配置分为2个步骤，一个是设置客户端的来源，这部分通过acl列表设置；另一个是编辑view块 acl列表12acl internal &#123;192.168.11.0/24;&#125;; acl external &#123;!192.168.11.0/24;any;&#125;; !表示反向选择的意思，也就是取反 第二行其实也可以写成如下的形式 1acl external &#123;!&quot;internal&quot;;any;&#125;; 当ip地址和网段过多时，可以采取导入外部文件的形式 文件内容如下： 123456789# cat CHINANET.aclacl &quot;CHINANET&quot; &#123;1.0.1.0/24;1.0.2.0/23;1.0.8.0/21;1.0.32.0/19;1.1.0.0/24;1.1.2.0/23;&#125; named.conf配置方式如下 导入 1include &quot;/home/named/bind/etc/CHINANET.acl&quot;; 调用 12view &quot;view_CHINANET&quot; &#123;match-clients &#123;CHINANET; &#125;; view区块配置1234567891011121314151617181920212223242526272829303132333435363738394041view &quot;internal&quot; &#123; match-clients &#123;&quot;internal&quot;;&#125;; zone &quot;.&quot; in&#123; type hint; file &quot;named.root&quot;; &#125;; zone &quot;localhost&quot; in&#123; type master; file &quot;localhost.zone&quot;; &#125;; zone &quot;0.0.127.in-addr.arpa&quot; in&#123; type master; file &quot;localhost.rev&quot;; allow-update &#123; none; &#125;; &#125;; zone &quot;test.com&quot; IN &#123; type master; file &quot;zone/test.com.zone.int&quot;; &#125;;&#125;;view &quot;external&quot; &#123; match-clients &#123;&quot;external&quot;;&#125;; zone &quot;.&quot; in&#123; type hint; file &quot;named.root&quot;; &#125;; zone &quot;localhost&quot; in&#123; type master; file &quot;localhost.zone&quot;; &#125;; zone &quot;0.0.127.in-addr.arpa&quot; in&#123; type master; file &quot;localhost.rev&quot;; allow-update &#123; none; &#125;; &#125;; zone &quot;test.com&quot; IN &#123; type master; file &quot;zone/test.com.zone.ext&quot;; &#125;;&#125;; 测试192.168.11.0/24网段主机 123456789101112131415161718192021[root@wxh-func-test-3 ~]# dig @192.168.11.91 -p 53 www.test.com; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.68.rc1.el6_10.1 &lt;&lt;&gt;&gt; @192.168.11.91 -p 53 www.test.com; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43365;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;www.test.com. IN A;; ANSWER SECTION:www.test.com. 86400 IN A 192.168.11.80;; Query time: 1 msec;; SERVER: 192.168.11.91#53(192.168.11.91);; WHEN: Tue Nov 27 14:14:26 2018;; MSG SIZE rcvd: 46[root@wxh-func-test-3 ~]# 其他网段主机 123456789101112131415161718192021➜ ~ dig @192.168.11.91 -p 53 www.test.com; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; @192.168.11.91 -p 53 www.test.com; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 25915;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;www.test.com. IN A;; ANSWER SECTION:www.test.com. 86400 IN A 8.8.8.8;; Query time: 10 msec;; SERVER: 192.168.11.91#53(192.168.11.91);; WHEN: Tue Nov 27 14:13:07 CST 2018;; MSG SIZE rcvd: 57 dns服务器端的访问日志 123[root@Zabbix server log]# tailf query.log27-Nov-2018 14:13:12.955 queries: info: client @0x7fcf840be8e0 192.168.11.64#47324 (www.test.com): view internal: query: www.test.com IN A + (192.168.11.91)27-Nov-2018 14:13:18.323 queries: info: client @0x7fcf840be8e0 192.168.101.35#50891 (www.test.com): view extenal: query: www.test.com IN A +E(0) (192.168.11.91) 启动命令行启动通过查看源码包中提供的named.8，我们在启动的时候添加以下参数： -L logfile Log to the file logfile by default instead of the system log. -u user Setuid to user after completing privileged operations, such as creating sockets that listen on privileged ports. 启动命令： 1[root@Zabbix server chroot]# /home/named/bind/sbin/named -gc /home/named/bind/chroot/etc/named.conf 注意： 此处是在前台启动并且启动了调试模式，有问题会打印出出错信息。当调试正常后启动需要去掉g这个参数。 启动脚本内容如下： 1/home/named/bind/sbin/named -c /home/named/bind/chroot/etc/named.conf 启动脚本因为我们监听的是小于1024的知名端口，named用户默认没有权限，因此我们的启动脚本为系统用户执行，在启动命令中使用-u参数指定named用户 在后续使用过程中，有关bind服务都是管理员用户去执行（改操作很少会涉及，因为后续配置重载等操作使用rndc即完成） 启动脚本内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495[named@host1 etc]$ cat /etc/init.d/named#!/bin/sh# chkconfig: - 86 14# Source function library.. /etc/rc.d/init.d/functionsuser=&quot;named&quot;exec=&quot;/home/named/bind/sbin/named&quot;prog=&quot;named&quot;config=&quot;/home/named/bind/chroot/etc/named.conf&quot;#[ -e /usr/local/named/etc/sysconfig/$prog ] &amp;&amp; . /usr/local/named/etc/sysconfig/$proglockfile=/var/lock/subsys/namedstart() &#123; #[ -x $exec ] || exit 5 [ -e $config ] || exit 6 echo -n $&quot;Starting $prog: &quot; daemon $exec -c $config -u $user retval=$? echo [ $retval -eq 0 ] &amp;&amp; touch $lockfile return $retval&#125;stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $prog retval=$? echo [ $retval -eq 0 ] &amp;&amp; rm -f $lockfile return $retval&#125;restart() &#123; stop start&#125;reload() &#123; echo -n $&quot;Reloading $prog: &quot; killproc $prog -1 retval=$? echo return $retval&#125;force_reload() &#123; restart&#125;rh_status() &#123; status $prog&#125;rh_status_q() &#123; rh_status &amp;&gt;/dev/null&#125;case &quot;$1&quot; in start) rh_status_q &amp;&amp; exit 0 $1 ;; stop) rh_status_q || exit 0 $1 ;; restart) $1 ;; reload) rh_status_q || exit 7 $1 ;; force-reload) force_reload ;; status) rh_status ;; condrestart|try-restart) rh_status_q || exit 0 restart ;; *) echo $&quot;Usage: $0 &#123;start|stop|status|restart|condrestart|try-restart|reload|force-reload&#125;&quot; exit 2esacexit $? 功能测试我们使用dig命令进行测试 1# dig @192.168.11.91 -p 53 www.test.com 监控bind的监控从几个方面 端口号（53和953） 解析功能是否正常 主从同步是否正常 在这里使用zabbix去实现监控，那么这个监控模板的内容就如下所示： bind总结rndc命令rndc命令作为我们管理bind的一大利器，我们有必要对它进行掌握，这一部分就记录下常用的操作 我们首先看一下它的help输出： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118[named@host1 ~]$ rndc -hUsage: rndc [-b address] [-c config] [-s server] [-p port] [-k key-file ] [-y key] [-r] [-V] [-4 | -6] commandcommand is one of the following: addzone zone [class [view]] &#123; zone-options &#125; Add zone to given view. Requires allow-new-zones option. delzone [-clean] zone [class [view]] Removes zone from given view. dnstap -reopen Close, truncate and re-open the DNSTAP output file. dnstap -roll count Close, rename and re-open the DNSTAP output file(s). dumpdb [-all|-cache|-zones|-adb|-bad|-fail] [view ...] Dump cache(s) to the dump file (named_dump.db). flush Flushes all of the server&apos;s caches. flush [view] Flushes the server&apos;s cache for a view. flushname name [view] Flush the given name from the server&apos;s cache(s) flushtree name [view] Flush all names under the given name from the server&apos;s cache(s) freeze Suspend updates to all dynamic zones. freeze zone [class [view]] Suspend updates to a dynamic zone. halt Stop the server without saving pending updates. halt -p Stop the server without saving pending updates reporting process id. loadkeys zone [class [view]] Update keys without signing immediately. managed-keys refresh [class [view]] Check trust anchor for RFC 5011 key changes managed-keys status [class [view]] Display RFC 5011 managed keys information managed-keys sync [class [view]] Write RFC 5011 managed keys to disk modzone zone [class [view]] &#123; zone-options &#125; Modify a zone&apos;s configuration. Requires allow-new-zones option. notify zone [class [view]] Resend NOTIFY messages for the zone. notrace Set debugging level to 0. nta -dump List all negative trust anchors. nta [-lifetime duration] [-force] domain [view] Set a negative trust anchor, disabling DNSSEC validation for the given domain. Using -lifetime specifies the duration of the NTA, up to one week. Using -force prevents the NTA from expiring before its full lifetime, even if the domain can validate sooner. nta -remove domain [view] Remove a negative trust anchor, re-enabling validation for the given domain. querylog [ on | off ] Enable / disable query logging. reconfig Reload configuration file and new zones only. recursing Dump the queries that are currently recursing (named.recursing) refresh zone [class [view]] Schedule immediate maintenance for a zone. reload Reload configuration file and zones. reload zone [class [view]] Reload a single zone. retransfer zone [class [view]] Retransfer a single zone without checking serial number. scan Scan available network interfaces for changes. secroots [view ...] Write security roots to the secroots file. serve-stale [ yes | no | reset | status ] [class [view]] Control whether stale answers are returned showzone zone [class [view]] Print a zone&apos;s configuration. sign zone [class [view]] Update zone keys, and sign as needed. signing -clear all zone [class [view]] Remove the private records for all keys that have finished signing the given zone. signing -clear &lt;keyid&gt;/&lt;algorithm&gt; zone [class [view]] Remove the private record that indicating the given key has finished signing the given zone. signing -list zone [class [view]] List the private records showing the state of DNSSEC signing in the given zone. signing -nsec3param hash flags iterations salt zone [class [view]] Add NSEC3 chain to zone if already signed. Prime zone with NSEC3 chain if not yet signed. signing -nsec3param none zone [class [view]] Remove NSEC3 chains from zone. signing -serial &lt;value&gt; zone [class [view]] Set the zones&apos;s serial to &lt;value&gt;. stats Write server statistics to the statistics file. status Display status of the server. stop Save pending updates to master files and stop the server. stop -p Save pending updates to master files and stop the server reporting process id. sync [-clean] Dump changes to all dynamic zones to disk, and optionally remove their journal files. sync [-clean] zone [class [view]] Dump a single zone&apos;s changes to disk, and optionally remove its journal file. tcp-timeouts Display the tcp-*-timeout option values tcp-timeouts initial idle keepalive advertised Update the tcp-*-timeout option values thaw Enable updates to all dynamic zones and reload them. thaw zone [class [view]] Enable updates to a frozen dynamic zone and reload it. trace Increment debugging level by one. trace level Change the debugging level. tsig-delete keyname [view] Delete a TKEY-negotiated TSIG key. tsig-list List all currently active TSIG keys, including both statically configured and TKEY-negotiated keys. validation [ yes | no | status ] [view] Enable / disable DNSSEC validation. zonestatus zone [class [view]] Display the current status of a zone.Version: 9.12.3 现在开始讲解 概述rndc（Remote Name Domain Controllerr）是一个远程管理bind的工具，通过这个工具可以在本地或者远程了解当前服务器的运行状况，也可以对服务器进行关闭、重载、刷新缓存、增加删除zone等操作。 使用rndc可以在不停止DNS服务器工作的情况进行数据的更新，使修改后的配置文件生效。 在实际情况下，DNS服务器是非常繁忙的，任何短时间的停顿都会给用户的使用带来影响。因此，使用rndc工具可以使DNS服务器更好地为用户提供服务。在使用rndc管理bind前需要使用rndc生成一对密钥文件，一半保存于rndc的配置文件中，另一半保存于bind主配置文件中。rndc的配置文件默认路径为/etc/rndc.conf，在CentOS或者RHEL中，rndc的密钥保存在/etc/rndc.key文件中。rndc默认监听在953号端口（TCP），其实在bind9中rndc默认就是可以使用，不需要配置密钥文件。 rndc与DNS服务器实行连接时，需要通过数字证书进行认证，而不是传统的用户名/密码方式。在当前版本的rndc 和 named中，唯一支持的认证算法是HMAC-MD5，在连接的两端使用共享密钥。它为命令请求和名字服务器的响应提供 TSIG类型的认证。所有经由通道发送的命令都必须被一个服务器所知道的 key_id 签名。为了生成双方都认可的密钥，可以使用rndc-confgen命令产生密钥和相应的配置，再把这些配置分别放入named.conf和rndc的配置文件rndc.conf中。 常用命令rndc常用命令： status # Display status of the server 显示bind的相关信息 reload # Reload configuration file and zones. 重新加载所有配置文件和zone数据文件 reload zone [class [view]] #Reload a single zone reconfig # Reload configuration file and new zones only。重新加载配置文件以及zone文件(只涉及新的zone文件) flush [view] # 刷新服务器的所有高速缓存 stats # 将服务器统计信息写入统计文件中（统计文件的路径定义在namd.conf配置文件当中） dumpdb # 将cache高速缓存转储到转储文件 (文件的路径定义在named.conf配置文件当中) zonestatus zone [class [view]] # Display the current status of a zone 显示指定的zone的状态信息 notify zone [class [view]] # Resend NOTIFY messages for the zone 针对指定的zone发送通知消息 实际案例 status 显示bind运行状态 123456789101112131415161718[named@host1 etc]$ rndc statusversion: BIND 9.12.3 &lt;id:6c8e92c&gt; (bind 9.12.3)running on host1: Linux x86_64 2.6.32-642.el6.x86_64 #1 SMP Tue May 10 17:27:01 UTC 2016boot time: Fri, 14 Dec 2018 07:40:25 GMTlast configured: Mon, 17 Dec 2018 05:52:49 GMTconfiguration file: /home/named/bind/chroot/etc/named.confCPUs found: 4worker threads: 4UDP listeners per interface: 3number of zones: 336 (297 automatic)debug level: 0xfers running: 0xfers deferred: 0soa queries in progress: 0query logging is ONrecursive clients: 0/900/1000tcp clients: 0/150server is up and running reload单个zone的数据内容 12345[named@host1 etc]$ rndc reload dwd.gds-sh IN shidczone reload up-to-date注意：reload zone [class [view]]对应的实际执行格式是zone IN view这个执行之后就有通知从域复制的作用 单纯通知某个zone的信息 1234[named@host1 common]$ rndc notify dwd.gds-sh IN shidczone notify queued注意：经过实际的测试，使用该命名不能实现通知从节点复制域的功能 刷新某个view的缓存数据 1[named@host1 common]$ rndc flush shidc named.conf配置文件详解配置文件框架 常规配置配置 1234567891011121314151617181920include &quot;/path/file&quot;; # 加载外部文件key &quot;rndc-key&quot; &#123; # rndc相关配置&#125;;controls &#123; # rndc相关配置&#125;;options&#123; # 全局配置&#125;logging&#123; # 日志配置&#125;zone &quot;zone name&quot; IN &#123; # 区域（域名）配置&#125; view（视图）模式配置文件 1234567891011121314151617181920212223242526272829303132333435acl acl_name1 &#123;192.168.11.0/24;&#125;; # acl列表，用于后面调用，这部分通常置于最上方acl acl_name2 &#123;!192.168.11.0/24;any;&#125;; include &quot;/path/file&quot;; # 加载外部文件key &quot;rndc-key&quot; &#123; # rndc相关配置&#125;;controls &#123; # rndc相关配置&#125;;options&#123; # 全局配置&#125;logging&#123; # 日志配置&#125;view &quot;view_name1&quot; &#123; match-clients &#123;&quot;acl_name1&quot;;&#125;; # 定义该view匹配的网段 zone &quot;zone name&quot; IN &#123; # 区域（域名）配置 &#125;&#125;view &quot;view_name2&quot; &#123; match-clients &#123;&quot;acl_name2&quot;;&#125;; # 定义该view匹配的网络 zone &quot;zone name&quot; IN &#123; # 区域（域名）配置 &#125;&#125; # 注意：使用view之后，所有的zone都需要包含在view块中 我们拿下面这个配置文件进行案例说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109[named@host1 etc]$ cat named.confkey &quot;rndc-key&quot; &#123; algorithm hmac-sha256; secret &quot;vqOF9VUn75lvtpCYvYffOVNT8LkLK0z78UCPVkX1ofk=&quot;;&#125;;controls &#123; inet 127.0.0.1 port 953 allow &#123; 127.0.0.1; &#125; keys &#123; &quot;rndc-key&quot;; &#125;;&#125;;options&#123; listen-on port 53&#123; 192.168.103.99; &#125;; listen-on-v6 port 53&#123; fe80::20c:29ff:fefe:d1f4; &#125;; version &quot;bind 9.12.3&quot;; directory &quot;/home/named/bind/chroot/var/named&quot;; pid-file &quot;/home/named/bind/chroot/var/run/named.pid&quot;; session-keyfile &quot;/home/named/bind/chroot/var/run/session.key&quot;; dump-file &quot;/home/named/bind/chroot/var/named/data/cache_dump.db&quot;; statistics-file &quot;/home/named/bind/chroot/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/home/named/bind/chroot/var/named/data/named_mem_stats.txt&quot;; recursion yes; allow-query&#123; any; &#125;; allow-query-cache&#123; any; &#125;; allow-transfer&#123; 192.168.11.89; &#125;; notify yes; also-notify&#123; 192.168.11.89; &#125;; /* Path to ISC DLV key */ bindkeys-file &quot;/home/named/bind/chroot/etc/named.iscdlv.key&quot;; managed-keys-directory &quot;/home/named/bind/chroot/var/named/dynamic&quot;;&#125;;logging &#123; channel default_debug &#123; file &quot;/home/named/bind/chroot/log/named.run&quot; versions 10 size 128m; severity dynamic; print-category yes; print-severity yes; print-time yes; &#125;; channel queries_info &#123; file &quot;/home/named/bind/chroot/log/query.log&quot; versions 10 size 128m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category queries &#123; queries_info; default_debug; &#125;; channel notify_info &#123; file &quot;/home/named/bind/chroot/log/notify.log&quot; versions 10 size 128m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category notify &#123; notify_info; default_debug; &#125;; channel xfer_in_log &#123; file &quot;/home/named/bind/chroot/log/xfer_in.log&quot; versions 10 size 128m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; channel xfer_out_log &#123; file &quot;/home/named/bind/chroot/log/xfer_out.log&quot; versions 10 size 128m; severity info; print-category yes; print-severity yes; print-time yes; &#125;; category xfer-in &#123; xfer_in_log; &#125;; category xfer-out &#123; xfer_out_log; &#125;;&#125;;include &quot;/home/named/bind/chroot/etc/acls/shidc&quot;;include &quot;/home/named/bind/chroot/etc/acls/hzidc&quot;;include &quot;/home/named/bind/chroot/etc/acls/aliyun-east1&quot;;include &quot;/home/named/bind/chroot/etc/views/shidc&quot;;include &quot;/home/named/bind/chroot/etc/views/hzidc&quot;;include &quot;/home/named/bind/chroot/etc/views/aliyun-east1&quot;; 某一段acl的配置 12345[named@host1 etc]$ cat /home/named/bind/chroot/etc/acls/shidcacl shidc &#123; 10.11.0.0/16; # 省略剩余网段，格式一致&#125;; 某一段view的配置 12345678910111213[named@host1 etc]$ cat /home/named/bind/chroot/etc/views/shidcview &quot;shidc&quot; &#123; match-clients &#123;&quot;shidc&quot;;&#125;; zone &quot;.&quot; in&#123; type hint; file &quot;named.root&quot;; &#125;; zone &quot;dianwoda.com&quot; IN &#123; type master; file &quot;zone/shidc/dianwoda.com.zone&quot;; &#125;; # 这里省略很多zone配置段&#125;; 注意：配置文件中每一行必须以;结尾，{} 里面两侧必须有空格 acl访问控制列表只有定义后才能使用，通常acl要定义在named.conf的最上方 除了我们自己定义的acl，在bind中有4个内置的acl any：任何主机 none：无一主机 local：本机 localnet：本机所在的网络 include include “/path/file”; 导入相关文件，为了保持主配置文件的简介，我们通常会把大段的配置文件使用include的方式进行加载，acl、view、zone等都可以使用include方式进行加载 key+controls定义rndc管理命令的相关配置 我们在文章的最开始配置章节就看到，使用了rndc-confgen命令来生成rndc文件。生成之后，需要把其中的密码信息等完整的复制进主配置文件当中 algorithm hmac-sha256; 密钥算法 secret “vqOF9VUn75lvtpCYvYffOVNT8LkLK0z78UCPVkX1ofk=”; 密钥内容 inet 127.0.0.1 port 953 rndc服务监听在本机的953端口 allow { 127.0.0.1; } keys { “rndc-key”; }; 只允许本机访问，使用的认证密码信息为前面定义的：rndc-key 有关rndc，请看下面的有关rndc章节 options这一部分主要定义全局的核心信息 listen-on port 53 {}; IPv4网络：指定提供dns服务的端口以及ip地址（很多服务器上可能会有多块网卡） listen-on-v6 port 53 {}; IPv6网络：指定提供dns服务的端口以及ip地址（很多服务器上可能会有多块网卡） version “version”; bind版本信息 directory “file_path”; zone区域文件存储目录 pid-file “file_path”; pid文件所在路径 session-keyfile “file_path”; dns安全方面的配置 dump-file “file_path”; 当执行rndc dumpdb命令时，服务器存放数据库文件的路径名。 statistics-file 当使用rndc stats命令的时候，服务器会将统计信息追加到的文件路径名。如果没有指定，默认为named.stats在服务器程序的当前目录中。 memstatistics-file “file_path”; 当服务退出的时候，会把内存使用情况统计写入到这个文件中 forwarders {}; 当设置为转发服务器时需要设置，在{}内设置上游服务器ip recursion yes; 开启递归功能，当接收到请求的域名不是自身所负责解析的域名（也就是没有对应的zone配置），这个时候，将自己变成dns客户端，向根服务器发送请求，获取解析记录之后再返回客户端 allow-recursion {}; 允许递归的白名单，配合上面的recursion yes使用 allow-query {}; 允许谁可以查询，也就是定义接收请求的来源，当设置为any之后表示可以接收所有人的域名请求 allow-query-cache {}; 允许谁可以查询域名记录的缓存数据，和上面一样，当设置为any之后表示可以接收所有人的域名请求 allow-transfer {}; 设定哪台主机允许和本地服务器进行域传输。allow-transfer也可以设置在zone语句中，这样全局options中的allow-transfer选项在这里就不起作用了。如果没有设定，默认值是允许和所有主机进行域传输 一般我们定义成从节点的网段 allow-update {}; 允许动态更新数据文件的主机白名单，一般设置为none notify yes; 如果是yes（默认），当一个授权的服务器修改了一个域后，DNS NOTIFY信息被发送出去。此信息将会发给列在域NS记录上的服务器（除了由SOA MNAME标示的主域名服务器）和任何列在also-notify选项中的服务器。 如果是explicit，则notify将只发给列在also-notify中的服务器。 如果是no，就不会发出任何报文。 注意：notify选项也可能设定在zone语句中，这样它就替代了options中的notify 语句。 also-notify {}; 定义一个用于全局的域名服务器IP地址列表。无论何时，当一个新的域文件被调入系统，域名服务器都会向这些地址，还有这些域中的NS记录发送NOTIFY信息。这有助于更新的域文件尽快在相关的域名服务器上收敛同步。 also-notify列表也可以配置在一个zone语句中，那么全局options中的also-notify语句就会在这里失效。 当一个zone-notify语句被设定为no，系统就不会向在全局中also-notify列表中的IP地址发送NOTIFY消息。缺省状态为空表(没有全局通知列表)。 logginglogging语句为域名服务器设定了一个多样性的logging选项。它的channel短语对应于输出方式、格式选项和分类级别，它的名称可以与category短语一起定义多样的日志信息。 只用一个logging语句就可以用来定义多个channel和category。 在BIND9中，logging的配置只有在整个配置文件被读取后才被执行。而在BIND8中，logging部分被读取后就开始执行了。当服务器启动时，所有在配置文件中关于语法错误的logging信息都转到缺省通道（channel）中，或者使用”-g”选项，指定转成标准错误。 channel所有日志会输出到一个或多个channel中；你可以定义所有你想要的通道。每个通道的定义必须包括一个目的字句，用来确定所选的相关通道的信息，将会被输出到一个文件，或者到一个特殊的syslog工具，或者到一个标准错误流，或者被忽略。它也可以随意的限制通道能接受的信息级别（默认值info），定义是否包含一个由named产生的时间标记，或者是否包含分类的名称、级别等（默认是不包含任何内容）。 目的子句为null时，会使所有发送给通道的信息被丢弃；那样的话，其他通道选项就没有意义了。 目的子句为file 时，会使通道的内容输出到一个磁盘文件。它可以包含这个文件的大小和该文件可以保存多少个版本。 如果使用versions日志文件选项，named就会自动保留多个版本的日志文件。例如，如果选择保存文件lamers.log的三个老版本，那么在它被打开的时候lamers.log.1被更名为lamers.log.2，lamers.log.0 被更名为lamers.log.1 ，lamers.log 被更名为lamers.log.0。也可以设置version unlimited，这样就没有备份版本的限制了。 如果对日志文件设置了size选项，那么仅当此文件超过了设定的大小时，系统就会进行更名。默认情况下不储存备份文件；所有存在的日志文件被简单进行追加。文件的size 选项用来限制日志的增长。如果文件超过了限制，又没有versions选项，则named 就会停止写入文件。如果保留了备份版本，则备份文件如上所述进行滚动命名，然后开始创建一个新的文件。如果没有versions选项，也没有其它的机制来删除或减小日志文件，则系统就不会有数据继续写入日志中。默认状态是不限制文件的大小的。 syslog 目的子句是把通道指向系统日志。它的参数是一个syslog的前缀，如syslog帮助中所述。syslog是怎样处理带有这些前缀的信息，可以参考syslog.conf 的帮助信息。 severity子句象syslog中的”priorites”一样工作，唯一区别的是用户可以直接写入一个文件，而不是使用syslog写入一个文件。不到严重级的信息将不会被通道选择；高严重级的信息将会被接受。 如果用户正在使用syslog，那么syslog.conf 的优先级也会决定什么会最终通过。例如，将channel facility和severity定义成daemon和debug，就不会只记录通过syslog.conf的daemon.warning信息，后者会使severity是info和notice的信息被丢弃。如果情况相反，named就会只记录warning或更高级别的信息，而syslogd则会记录来自于通道的所有信息。 stderr目的子句将通道输出到服务器的标准错误流。它用于服务器在前台运行的情况下，例如，当处于debug模式的时候，服务器能提供丰富的调试信息。如果服务器的全局debug级别（globe debug level）大于0，debug 模式将被激活。全局debug级别可以通过在启动named时设置“-d”参数加一个正数，或运行rndc trace来设置。如果要关闭debug模式，则将全局debug 级别设置成0，或运行rndc notrace。服务器中所有的debug信息有一个debug级别，高调试级给出更详细的输出。 如果使用了print-time参数，则日期和时间也将会记录下来。print-time也可以针对syslog的通道进行设置，但因为syslog也打印日期和时间，所以一般来讲，这没有什么意义。如果设置了print-category 参数，则信息的分类也会记录下来。如果设置了print-severity参数，则信息的严重级别也会记录下来。print-xxx 选项可以进行多重组合，单输出格式都是这个顺序：时间、分类、严重级别。 default_debug 通道有特殊的性质：只有当服务器的debug级别非0的时候，它才产生输出。一般来说，它会在服务器的工作目录中写入named.run文件。因为安全原因，当在命令行选项中使用了“-u”参数后，只有当named使用了新的UID后，named.run文件才会产生，以root身份启动和运行的named所产生的debug信息将会被丢弃。如果用户需要得到这些输出，则必须使用“-g”参数运行服务器，并重新将标准错误定向到一个文件中去。 一旦定义好一个通道，它就不能被重新定义。这样就不能修改内置的通道，但是可以通过把分类指向你已经定义的通道，来修改默认的日志记录。 category这里存在许多分类，用户可根据需要定义想看到或不想看到的日志。如果你不将某个分类指定到某些通道的话，那么在这个分类的日志信息就会被发送到default分类通道中。如果用户没有设定缺省的分类，下列”default”则会被系统使用： 1category &quot;default&quot; &#123; &quot;default_syslog&quot;; &quot;default_debug&quot;; &#125;; 作为一个例子，假定你要在文件中记录安全事件，但您也要保留缺省的日志文件。最好按照下面配置： 123456789101112channel &quot;my_security_channel&quot; &#123;file &quot;my_security_file&quot;;severity info;&#125;;category &quot;security&quot; &#123;&quot;my_security_channel&quot;;&quot;default_debug&quot;;&#125;;# 为了丢弃一个分类中的所有信息，可以设定null 通道：category &quot;xfer-out&quot; &#123; &quot;null&quot;; &#125;;category &quot;notify&quot; &#123; &quot;null&quot;; &#125;; 下面是简单写这里用到的分类和相关的简明描述，更多内容可以查看官网提供的bind9管理员手册 default 没有配置的分类会使用default的分类日志配置 notify notify协议相关日志 queries dns解析请求日志 xfer-in 主从域传输相关日志（入方向） xfer-out 主从域传输相关日志（出方向） viewview试图段的配置相对来说比较简单，主要分为2个部分，通过上面的案例我们就可以很直观看出来： 使用match-clients匹配来源ip 将要解析的zone都放置在view区块内，匹配来源之后，将使用对应的zone文件数据去响应请求 zonezone可以单独存在或者包含在view当中，不管哪种方式配置格式都是一样的。 type master; type字段说明了当前服务器所承担的任务职责，type可为： hint。根角色 master 主角色。可以响应该域名的解析请求。数据源为本地的zone文件 slave 从角色。可以响应该域名的解析请求。不使用自身的数据，数据源为从master端同步的zone数据 forward 转发角色。不直接响应域名解析请求，接受到请求之后，将请求直接转发给配置的上游服务器 zone配置文件详解123456789101112$TTL 86400@ IN SOA test.com. admin.test.com. ( 2018121401 ; serial (d. adams) 3H ; refresh 15M ; retry 1W ; expiry 1D ) ; minimum IN NS dns.test.com. IN MX 5 maildns IN A 192.168.11.49mail IN A 192.168.11.100www IN A 192.168.11.80 $TTL 86400资源记录的缓存超时时间，为了简化 RR 记录的设置，因此我们可以将 TTL 挪到最前面统一设定，在这里相当于是一个默认值，针对所有记录生效 单位是s，例如这里是86400秒，也就是一天 @第一列的这个符号代表 zone 对应域名，例如写在 test.com.zone 中，@ 代表 test.com.（注意不是根据名称决定的，而是根据named.conf中的配置） 在下面的配置中，第一列可以不写，那么将会继承这个配置 SOA如果你有多个 DNS 服务器管理同一个领域名时，那么最好使用 master/slave 的方式来进行管理。 既然要这样管理， 那就得要宣告被管理的 zone file 是如何进行传输的，此时就得要 SOA (Start Of Authority) 的标志了。 SOA 主要是与zone有关，SOA 后面共会接七个参数，这七个参数的意义依序是： 负责解析的域名 管理员的 email：发生问题可以联络这个管理员。要注意的是， 由于 @ 有特殊意义的，因此这里就将 admin@test.com 改写成 admin.test.com 序号 (Serial)：这个序号代表的是这个数据库档案的新旧，序号越大代表越新。 当 slave 要判断是否主动下载新的数据库时，就以序号是否比 slave 上的还要新来判断，若是则下载，若不是则不下载。 所以当你修订了数据库内容时，记得要将这个数值放大才行！ 为了方便用户记忆，通常序号都会使用日期格式『YYYYMMDDNU』来记忆，例如 2010080369 序号代表 2010/08/03 当天的第 69 次更新的感觉。不过，序号不可大于 2 的 32 次方，亦即必须小于 4294967296 一共10位数才行。 也就是说一天最多能更新99次，当到达99次之后，就不得不使用明天的日期，所以当场景的变更次数很频繁的时候，需要思考使用其他方式来定义序列号 更新频率 (Refresh)：那么什么时候 slave 会去向 master 要求数据更新的判断？ 就是这个数值定义的。 这里设置为每 10800 秒（3小时）进行一次 slave 向 master 要求数据更新。每次 slave 去更新时， 如果发现序号没有比较自身的大，那就不会下载数据库档案。 失败重新尝试时间 (Retry)：如果因为某些因素，导致 slave 无法正常访问 master， 那么在多久的时间内，slave 会尝试重新联机到 master。在这里设置为900 秒（15分钟）会重新尝试一次。意思是说，每 3小时slave 会主动向 master 联机，但如果该次联机没有成功，那接下来尝试联机的时间会变成 15分钟。若后来有成功，则又会恢复到3小时再一次联机。 失效时间 (Expire)：如果一直尝试失败，持续到到达这个时间， 那么 slave 将不再继续尝试联机，并且尝试删除这份下载的 zone file 信息。这里设置为 604800 秒（1周）。意思是说，当联机失败，每 15分钟进行一次尝试，直到到达1周后，slave 将不再更新，只能等待系统管理员的处理。 Minimum部分，这个部分定义了DNS对否定回答(NXDOMAIN即访问的记录在权威DNS上不存在)的缓存时间。 除了 Serial 不可以超过 2^32 次方之外，还有一些其他的限制： Refresh &gt;= Retry *2 Refresh + Retry &lt; Expire Expire &gt;= Rrtry * 10 Expire &gt;= 7Days 一般来说，如果 DNS RR 记录变更情况频繁，那么上述的相关数值可以设置的小一些，如果 DNS RR 是很稳定的， 为了节省带宽，则可以将 Refresh 设置的较大一些。 注意事项 再次强调，一个正向解析的RR数据库中，至少应该要有 $TTL, SOA, NS 如果是写完全的域名，RR记录中在最后一定要带上”.”。不写完整的，则系统会进行自动补全 在zone配置文件中，master和slave都需要添加NS记录，并对对应主机还需要添加A记录 有关rndc在服务启动之后，我们可以看到服务器的监听端口情况： 123456[root@Zabbix server etc]# netstat -unptl | grep namedtcp 0 0 192.168.11.91:53 0.0.0.0:* LISTEN 14861/namedtcp 0 0 127.0.0.1:953 0.0.0.0:* LISTEN 14861/namedtcp 0 0 :::53 :::* LISTEN 14861/namedudp 0 0 192.168.11.91:53 0.0.0.0:* 14861/namedudp 0 0 :::53 :::* 14861/named 那么为什么会开启953端口呢？ 其实这就是所谓的 rndc 了。rndc 是 BIND version 9 以后所提供的功能，他可以让你很轻松的管理你自己的 DNS 服务器。包括检查已经存在 DNS 当中的资料、更新某个 zone 而不需要重新启动整个 DNS ， 以及检查 DNS 的状态与统计数据。 不过，因为 rndc 可以很深入的管理你的 DNS 服务器，所以当然要进行一些管控。控管的方式是通过rndc 的设置创建一个密钥 (rndc key)，并将这个密钥相关信息写入 named.conf 配置文件当中。重新启动 DNS 后，你的 DNS 就能够藉由 rndc 这个命令管理！ 事实上，新版的 distributions 通常已经帮你主动的建立好 rndc key了。 关于rndc的更多内容可以看鸟哥的文章：http://cn.linux.vbird.org/linux_server/0350dns.php 启动用户在测试的时候，我们可以使用root用户启动，实际在生产环境中运行的时候，我们需要使用named这个普通用户去启动服务，这里一定要注意 递归查询一般客户机和服务器之间属递归查询，当客户机向DNS服务器发出请求后,若DNS服务器本身不能解析,DNS服务器则会向另外的DNS服务器发出查询请求，得到结果后转交给客户机。 当客户端的请求域名不在本地named.conf中配置的zone区块中，并且缓存中也没有的话，那么就会开启递归查询，为这个客户端去请求这个域名对应的ip。 如果请求的域名在zone配置中，但是zone的数据文件中没有这条记录，那么解析失败，server将不会再为这条记录去进行递归查询 因此： 如果是完全作为一个真正的权威服务器，那么不建议开启递归查询功能（默认为开启） 如果是既要作为权威服务器又要作为第一级的dns服务器，提供递归功能，那么可以开启 相关问题主从数据同步 Master和Slave 的数据库，都会有一个代表该数据库新旧的序列号，这个序号数值的大小，会影响是否要更新的动作， 至于更新的方式主要有两种： Master 主动告知：例如在 Master 在修改了数据库内容，并且加大数据库序号后， 重新启动 DNS 服务或者reload文件之后， master 会主动告知在配置文件中定义好的notify列表来更新数据库，此时就能够达成数据同步； 由 Slave 主动提出要求：Slave 会定时的向 Master发起请求，查看数据库的序号， 当发现Master的序号比 Slave 自己的序号还要大 (代表比较新)，那么 Slave 就会开始更新。如果序号不变， 那么就判断数据库没有更动，因此不会进行同步更新。 由上面的说明来看，其实设计数据库的序列号最重要的目的就是让 master/slave 数据的同步化。那我们也知道slave 会向 master 提出数据库更新的需求，问题是，多久提出一次更新，如果该次更新时由于网络问题，所以没有查询到 master 的序号 (亦即更新失败)，那隔多久会重新更新一次？这个可以查看上面的 SOA 的标志。 Name Servers in Multiple Roles导致不能实现域名穿透DNS服务器的类型； 主DNS服务器：维护所负责解析的域内解析库服务器；解析库由管理维护；读写操作均可进行； 从DNS服务器：从主DNS服务器或从其他的从DNS服务器那里区域传递(类似“复制”)一份解析库，只能进行读操作 缓存DNS服务器：负责代理客户机的递归查询工作，并且采用迭代查询的服务器 转发器：如果目标域名在本DNS服务器辖区内，直接转发 希望实现： 当自主dns的配置中没有请求的域名时，本地dns服务器进行迭代查询，查找dnspod或者其他上的相关记录，然后将对应信息返回给dns客户端 例如：本机可以解析test.com这个域，但是不包含www这条A记录，当有请求来的时候，希望实现dns服务器可以作为客户端，从internet上找寻对应记录信息。 存在问题： The BIND name server 能同时拥有多种角色，可以是作为权威服务器（主或者从服务器）专门负责解析，缓存服务器（递归服务器，也就是本地dns服务器）负责处理dns客户端的请求 但是，权威服务器和本地服务器的功能是冲突的，因为建议将这2个分开部署 原因是处于安全性和可靠性，权威服务器不能实现递归功能，也就是说本地没有记录的话，不会再作为客户端帮助末端去请求 只要当本地dns配置中存在某个域名的时候，就算配置数据库中不包含dns客户端请求的记录，也不会进行迭代查询，因此，最终会导致解析失败 问题解决： 因为本身的协议限制，无法实现，所以在实例应用到公司时，需要维护全量的域名资源记录。 注意事项 修改zone数据文件在每次存盘时要注意增加Serial值，主要用来让辅助服务器同步主服务器的区域数据文件。 使用绝对域名时千万别忘了后面要带”.”。 主配置文件named.conf的”;”不能少。 通常 DNS 查询的时候，是以 udp 协议来查询的， 但是万一没有办法查询到完整的信息时，就会再次的以 tcp 来重新查询的！所以启动 DNS 的 daemon (就是 named ) 时，会同时启动 tcp 及 udp 的 port 53 ,所以如果涉及到一些防火墙配置的时候，记得需要同时放行 tcp, udp port 53]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>网络知识及网络服务</category>
        <category>网络服务</category>
        <category>DNS服务实现-bind</category>
      </categories>
      <tags>
        <tag>bind</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day07-面向对象编程进阶及异常处理]]></title>
    <url>%2F2018%2F08%2F31%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday07-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%E8%BF%9B%E9%98%B6%E5%8F%8A%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节讲解内容： 面向对象高级语法部分 静态方法、类方法、属性方法 类的特殊方法 反射 异常处理 socket开发基础 静态方法通过@staticmethod装饰器即可把其装饰的方法变为一个静态方法。 什么是静态方法呢？其实不难理解，普通的方法，可以在实例化后直接调用，并且在方法里可以通过self.调用实例变量或类变量，但静态方法是不可以访问实例变量或类变量的，一个不能访问实例变量和类变量的方法，其实相当于跟类本身已经没什么关系了，它与类唯一的关联就是需要通过类名来调用这个方法 总结： 使用了静态方法之后，这个方法不能访问变量，只能被直接调用 把这个方法和类关联取消，因此self参数不再有效（默认会自动传self） 被静态化之后的方法的作用就只是相当于是一个单纯的函数，调用不了类的变量，调用不了实例的变量 因为，在这种情况下，如果还是需要使用参数，进行调用相关的方法，那么需要把实例或者属性传递进去 一般情况下，我们传递进去都会是一个实例，而不是一个属性 12345678910111213141516171819202122232425262728293031323334传递单个属性：class Dog(object): def __init__(self,name): self.name = name @staticmethod def eat(self): # print (&quot;&#123;name&#125; is eating &#123;food&#125;...&quot;.format(name=self.name,food=food)) print (&quot;&#123;name&#125; is eating ...&quot;.format(name=self))d1 = Dog(&quot;wxh&quot;)d1.eat(&quot;wxh&quot;)传递实例对象：class Dog(object): def __init__(self,name): self.name = name @staticmethod def eat(self): # print (&quot;&#123;name&#125; is eating &#123;food&#125;...&quot;.format(name=self.name,food=food)) print (&quot;&#123;name&#125; is eating ...&quot;.format(name=self.name))d1 = Dog(&quot;wxh&quot;)d1.eat(d1)执行后输出如下所示：sdd is eating ... 类方法：类方法中，只能访问类变量 12345678910111213141516171819class Dog(object): name = &quot;gegege&quot; def __init__(self,name): self.name = name # @staticmethod @classmethod def eat(self): # print (&quot;&#123;name&#125; is eating &#123;food&#125;...&quot;.format(name=self.name,food=food)) print (&quot;&#123;name&#125; is eating ...&quot;.format(name=self.name))d1 = Dog(&quot;wxh&quot;)d1.eat()执行后输出如下：gegege is eating ... 属性方法属性方法详解把一个方法变成静态的属性 ，因此，在调用的时候，不能再通过()调用 这个时候就涉及到2个操作 将方法变成属性 对这个属性赋值 对属性赋值，不能直接像传参数一样操作了，需要使用eat.setter 12345678910111213141516171819202122232425class Dog(object): name = &quot;gegege&quot; def __init__(self,name): self.name = name @property def eat(self): # print (&quot;&#123;name&#125; is eating &#123;food&#125;...&quot;.format(name=self.name,food=food)) print (&quot;&#123;name&#125; is eating ...&quot;.format(name=self.name)) @eat.setter def eat(self,food): print (&quot;set to food: &#123;food&#125;&quot;.format(food=food))d1 = Dog(&quot;wxh&quot;) d1.eatd1.eat = &quot;arg&quot;d1.eat执行后输出如下：wxh is eating ...set to food: argwxh is eating ... 通过上面我们可以看到，这个值并没有真正赋值进去，因此在再次调用的时候，输出的还是原来的值（赋值之前的值）。 因此@eat.setter下面这个方法只是执行了一系列的动作，根本没有存到某个地方 修改之后的代码如下所示： 1234567891011121314151617181920212223242526272829class Dog(object): name = &quot;gegege&quot; def __init__(self,name): self.name = name self.__food = None # @staticmethod # @classmethod @property def eat(self): # print (&quot;&#123;name&#125; is eating &#123;food&#125;...&quot;.format(name=self.name,food=food)) print (&quot;&#123;name&#125; is eating &#123;food&#125;...&quot;.format(name=self.name,food=self.__food)) @eat.setter def eat(self,food): print (&quot;set to food: &#123;food&#125;&quot;.format(food=food)) self.__food = foodd1 = Dog(&quot;wxh&quot;)d1.eatd1.eat = &quot;arg&quot;d1.eat执行后输出如下：wxh is eating None...set to food: argwxh is eating arg... 要删除的话，添加删除方法 1234@eat.deleterdef eat(self): del self.__food print (&quot;删除完毕&quot;) 删除这个属性 1del d1.eat 属性方法的使用场景了解了属性方法的编写规则之后，需要知道它的应用场景。 我们在定义这个属性方法的时候，不需要传入参数等就能获取一个明确的输出，因此适用于比如我们想知道一个事物的当前状态，但是这个状态可能会牵涉到很多其他的操作，但是对于我们用户而言，我只需要知道一个结果就可以了，因此在这种情况下就可以使用属性方法。 比如 ，你想知道一个航班当前的状态，是到达了、延迟了、取消了、还是已经飞走了， 想知道这种状态你必须经历以下几步: \1. 连接航空公司API查询 \2. 对查询结果进行解析 （可能是json、xml等等） \3. 返回结果给你的用户 因此这个status属性的值是一系列动作后才得到的结果，所以你每次调用时，其实它都要经过一系列的动作才返回你结果，但这些动作过程不需要用户关心， 用户只需要调用这个属性就可以。背后的连接api，对结果解析等操作全部被隐藏了。 类的特殊成员方法__doc__-类的描述信息12345678class Foo: &quot;&quot;&quot; 描述类信息，这是用于看片的神奇 &quot;&quot;&quot; def func(self): pass print Foo.__doc__#输出：类的描述信息 __module__ 和 __class____module__ 表示当前操作的对象在那个模块 __class__ 表示当前操作的对象的类是什么 1234class C: def __init__(self): self.name = &apos;wupeiqi&apos; 12345from lib.aa import Cobj = C()print obj.__module__ # 输出 lib.aa，即：输出模块print obj.__class__ # 输出 lib.aa.C，即：输出类 __init__ -构造方法构造方法，通过类创建对象时，自动触发执行。 __del__-析构方法析构方法，当对象在内存中被释放时，自动触发执行。 注：此方法一般无须定义，因为Python是一门高级语言，程序员在使用时无需关心内存的分配和释放，因为此工作都是交给Python解释器来执行，所以，析构函数的调用是由解释器在进行垃圾回收时自动触发执行的 __call__ -对象后面加括号，触发执行。 注：构造方法的执行是由创建对象触发的，即：对象 = 类名() ；而对于 call 方法的执行是由对象后加括号触发的，即：对象() 或者 类()() 123456789101112class Foo: def __init__(self): pass def __call__(self, *args, **kwargs): print &apos;__call__&apos; obj = Foo() # 执行 __init__obj() # 执行 __call__ __dict__ -查看类或对象中的所有成员 123456789101112131415161718192021222324class Province: country = &apos;China&apos; def __init__(self, name, count): self.name = name self.count = count def func(self, *args, **kwargs): print &apos;func&apos; # 获取类的成员，即：静态字段、方法、print Province.__dict__# 输出：&#123;&apos;country&apos;: &apos;China&apos;, &apos;__module__&apos;: &apos;__main__&apos;, &apos;func&apos;: &lt;function func at 0x10be30f50&gt;, &apos;__init__&apos;: &lt;function __init__ at 0x10be30ed8&gt;, &apos;__doc__&apos;: None&#125; obj1 = Province(&apos;HeBei&apos;,10000)print obj1.__dict__# 获取 对象obj1 的成员# 输出：&#123;&apos;count&apos;: 10000, &apos;name&apos;: &apos;HeBei&apos;&#125; obj2 = Province(&apos;HeNan&apos;, 3888)print obj2.__dict__# 获取 对象obj1 的成员# 输出：&#123;&apos;count&apos;: 3888, &apos;name&apos;: &apos;HeNan&apos;&#125; __str__-输出方法返回值如果一个类中定义了str方法，那么在打印 对象 时，默认输出该方法的返回值。 123456789class Foo: def __str__(self): return &apos;alex li&apos; obj = Foo()print obj# 输出：alex li __new__ \ __metaclass__12345678class Foo(object): def __init__(self,name): self.name = name f = Foo(&quot;alex&quot;) 上述代码中，obj 是通过 Foo 类实例化的对象，其实，不仅 obj 是一个对象，Foo类本身也是一个对象，因为在Python中一切事物都是对象。 如果按照一切事物都是对象的理论：obj对象是通过执行Foo类的构造方法创建，那么Foo类对象应该也是通过执行某个类的 构造方法 创建。 12print type(f) # 输出：&lt;class &apos;__main__.Foo&apos;&gt; 表示，obj 对象由Foo类创建print type(Foo) # 输出：&lt;type &apos;type&apos;&gt; 表示，Foo类对象由 type 类创建 所以，f对象是Foo类的一个实例，Foo类对象是 type 类的一个实例，即：Foo类对象 是通过type类的构造方法创建。 那么，创建类就可以有两种方式： 普通方式 1234class Foo(object): def func(self): print &apos;hello alex&apos; 特殊方式 1234567def func(self): print &apos;hello wupeiqi&apos; Foo = type(&apos;Foo&apos;,(object,), &#123;&apos;func&apos;: func&#125;)#type第一个参数：类名#type第二个参数：当前类的基类#type第三个参数：类的成员 以及 12345678910def func(self): print(&quot;hello %s&quot;%self.name)def __init__(self,name,age): self.name = name self.age = ageFoo = type(&apos;Foo&apos;,(object,),&#123;&apos;func&apos;:func,&apos;__init__&apos;:__init__&#125;)f = Foo(&quot;jack&quot;,22)f.func() 那么问题来了，类默认是由 type 类实例化产生，type类中如何实现的创建类？类又是如何创建对象？ 答：类中有一个属性 metaclass，其用来表示该类由 谁 来实例化创建，所以，我们可以为 metaclass 设置一个type类的派生类，从而查看 类 创建的过程 类的生成 调用 顺序依次是 new –&gt; init –&gt; call metaclass 详解文章：http://stackoverflow.com/questions/100003/what-is-a-metaclass-in-python 得票最高那个答案写的非常好 类的一些额外操作isinstance(obj, cls)- 检查是否是某个类的对象检查是否obj是否是类 cls 的对象 123456class Foo(object): pass obj = Foo() isinstance(obj, Foo) issubclass(sub, super)-检查是否是某个类的子类检查sub类是否是 super 类的派生类/子类 1234567class Foo(object): pass class Bar(Foo): pass issubclass(Bar, Foo) 反射通过反射，传入字符，获取相对应的对象的内存地址，获取了之后就可以直接调用。 通过hasattr去判断是否存在在类中，如果存在则通过getattr去获取它并调用 因此，最简单的书写格式应该是： 12345d = xxx() # 实例化出一个对象choice = input(&quot;&gt;&gt;:&quot;).strip()if hasattr(d,choice): func = getattr(d,choice) func(这里输入参数调用) 总结如下： 12345678910111213141516171819202122232425class Foo(object): def __init__(self): self.name = &apos;wupeiqi&apos; def func(self): return &apos;func&apos; obj = Foo() # #### 检查是否含有成员 ####hasattr(obj, &apos;name&apos;)hasattr(obj, &apos;func&apos;) # #### 获取成员 ####getattr(obj, &apos;name&apos;)getattr(obj, &apos;func&apos;) # #### 设置成员 ####setattr(obj, &apos;age&apos;, 18)setattr(obj, &apos;show&apos;, lambda num: num + 1) # #### 删除成员 ####delattr(obj, &apos;name&apos;)delattr(obj, &apos;func&apos;) 反射： hasattr(obj,name_str)：判断一个对象里面是否有对应的字符串的方法或属性 getattr(obj,name_str)：根据字符串去获取obj对象里的对应的方法的内存地址 setattr(obj,’y’,z)：setattr(x, ‘y’, v) is equivalent to ``x.y = v’’。通过字符串去设置一个新的属性 delattr(obj,name_str)： 删除属性 异常处理做异常处理的原因：虽然程序出错了，但是我不想让用户看到这个错误信息。我已经预料到，程序可能会出这种错，出了这种错误，代表什么意思。这个时候，我就可以做一些预处理，提前做好预防，说如果出现指定的错误，我就输出我认为自定义的输出信息 默认情况下，出现异常之后，整个程序就会奔溃 下面我们写一段测试代码 一次抓一个错误异常异常处理之前： 123456789class Man(object): def __init__(self,name,age): self.name = name self.age = age def old(self): print (&quot;&#123;name&#125; is &#123;age&#125; years old...&quot;.format(name=self.name,age=self.age))man1 = Man(&quot;wxh&quot;,26,&quot;df&quot;) 执行之后的输出如下所示： 1234Traceback (most recent call last): File &quot;/Users/wangxiaohua/PycharmProjects/python14/day07/exce.py&quot;, line 11, in &lt;module&gt; man1 = Man(&quot;wxh&quot;,26,&quot;df&quot;)TypeError: __init__() takes 3 positional arguments but 4 were given 异常处理之后： 123456789101112131415class Man(object): def __init__(self,name,age): self.name = name self.age = age def old(self): print (&quot;&#123;name&#125; is &#123;age&#125; years old...&quot;.format(name=self.name,age=self.age))try: man1 = Man(&quot;wxh&quot;,26,&quot;df&quot;)except TypeError as e: print (&quot;参数数量输入错误： &quot;,e)except Exception as e: print (&quot;未知错误&quot;,e) 执行之后的输出如下： 1参数数量输入错误： __init__() takes 3 positional arguments but 4 were given 一次抓所有错误异常12345man1 = Man(&quot;wxh&quot;,26)try: man1.old(&quot;df&quot;)except Exception as e: print (&quot;出错了&quot;,e) 需要注意的是，这种操作一般不用 else和finally用法12345678910try: man1.old(&quot;df&quot;)except TypeError as e: print (&quot;位置参数错误：&quot;,e)except Exception as e: print (&quot;未知错误&quot;,e)else: print (&quot;一切正常时执行&quot;)finally: print (&quot;不管有错没错都执行&quot;) 注意，如果代码本身有错误，都没办法执行的话，是抓不到错误异常的，因为上面抓取错误异常指的是在代码执行时出现的异常 自定义异常例如在MySQL中，它就是自己定义的异常，例如在连接超时的时候就会报错：MySQLConnectionFailed。 那么，我们也是可以自己定义这些异常的。 格式： raise 异常名称(‘异常描述’) 代码如下： 12345678910class WxhException(Exception): def __init__(self,message): super(LengthError,self).__init__() self.message = message def __str__(self): return self.messagetry: raise WxhException(&quot;数据库连接失败&quot;)except WxhException as e: print (e) 自己写的异常需要我们自己去触发，它不会自动触发。 会自动触发的异常只有标准异常。 自己写的异常，系统不知道它的存在，也就是说系统不知道走到哪一步应该触发它，因为所有的逻辑都是我们认为的去判断的。 自定义触发 使用raise的语法去触发 raise WxhException(“数据库连接失败”)。括号中的输入是异常描述，同时也是参数，传入到这个类的构造方法当中 接下来，通过下面的内容去打印 12except WxhException as e: print (e) 注意，这里就相当于是直接打印这个类，而不是对象，所以需要使用到__str__方法。 注意，在这里，下面的这2行代码可以不用写，但是不能写成别的 12def __str__(self): return self.message 因此，自定义的这个异常类继承了Exception这个基类的异常，这个基类的异常在里面已经定义好了，只要你打印，它就会自动的把这个值给它打印出来，传什么就打印什么。 在这里，print(e)就相当于直接打印这个实例，因此需要def __str__方法的存在 逻辑顺序： 在try中定义代码，如果符合条件，则使用raise手动的产生异常，异常的内容就是括号中的内容 接下来，使用exception去抓取这个异常 在exception的处理模块中，一般直接使用print（）语法将事先定义好的描述信息输出 python的单例模式作者：geekpy 链接：https://www.jianshu.com/p/ec6589e02e2f 來源：简书 简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。 单例模式是设计模式中逻辑最简单，最容易理解的一个模式，简单到只需要一句话就可以理解，即“保证只有一个对象实例的模式”。问题的关键在于实现起来并没有想象的那么简单。不过我们还是先来讨论下为什么需要这个模式吧。 我们首先来看看单例模式的使用场景，然后再来分析为什么需要单例模式。 Python的logger就是一个单例模式，用以日志记录 Windows的资源管理器是一个单例模式 线程池，数据库连接池等资源池一般也用单例模式 网站计数器 从这些使用场景我们可以总结下什么情况下需要单例模式： 当每个实例都会占用资源，而且实例初始化会影响性能，这个时候就可以考虑使用单例模式，它给我们带来的好处是只有一个实例占用资源，并且只需初始化一次； 当有同步需要的时候，可以通过一个实例来进行同步控制，比如对某个共享文件（如日志文件）的控制，对计数器的同步控制等，这种情况下由于只有一个实例，所以不用担心同步问题。 当然所有使用单例模式的前提是我们的确用一个实例就可以搞定要解决的问题，而不需要多个实例，如果每个实例都需要维护自己的状态，这种情况下单例模式肯定是不适用的。 接下来看看如何使用Python来实现一个单例模式。 最开始的想法很简单，实现如下： 1234567891011class Singleton(object): __instance = None def __new__(cls, *args, **kwargs): # 这里不能使用__init__，因为__init__是在instance已经生成以后才去调用的 if cls.__instance is None: cls.__instance = super(Singleton, cls).__new__(cls, *args, **kwargs) return cls.__instances1 = Singleton()s2 = Singleton()print (s1)print (s2) 执行后输出如下： 12&lt;__main__.Singleton object at 0x109cd39e8&gt;&lt;__main__.Singleton object at 0x109cd39e8&gt; 可以看出两次创建对象，结果返回的是同一个对象实例，我们再让我们的例子更接近真实的使用场景来看看 12345678910111213141516class Singleton(object): __instance = None def __new__(cls, *args, **kwargs): if cls.__instance is None: cls.__instance = super(Singleton, cls).__new__(cls) return cls.__instance def __int__(self, status_number): self.status_number = status_numbers1 = Singleton(2)s2 = Singleton(5)print (s1)print (s2) 执行后输出如下： 12&lt;__main__.Singleton object at 0x10af2d1d0&gt;&lt;__main__.Singleton object at 0x10af2d1d0&gt; 不过这个例子中有一个问题我们没有解决，那就是多线程的问题，当有多个线程同时去初始化对象时，就很可能同时判断__instance is None，从而进入初始化instance的代码中。所以为了解决这个问题，我们必须通过同步锁来解决这个问题。以下例子来自xiaorui 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import threadingtry: from synchronize import make_synchronizedexcept ImportError: def make_synchronized(func): import threading func.__lock__ = threading.Lock() def synced_func(*args, **kws): with func.__lock__: return func(*args, **kws) return synced_funcclass Singleton(object): instance = None @make_synchronized def __new__(cls, *args, **kwargs): if cls.instance is None: cls.instance = object.__new__(cls, *args, **kwargs) return cls.instance def __init__(self): self.blog = &quot;xiaorui.cc&quot; def go(self): passdef worker(): e = Singleton() print id(e) e.go()def test(): e1 = Singleton() e2 = Singleton() e1.blog = 123 print e1.blog print e2.blog print id(e1) print id(e2)if __name__ == &quot;__main__&quot;: test() task = [] for one in range(30): t = threading.Thread(target=worker) task.append(t) for one in task: one.start() for one in task: one.join() 至此我们的单例模式实现代码已经接近完美了，不过我们是否可以更简单地使用单例模式呢？答案是有的，接下来就看看如何更简单地使用单例模式。 在Python的官方网站给了两个例子是用装饰符来修饰类，从而使得类变成了单例模式，使得我们可以通过更加简单的方式去实现单例模式 例子：（这里只给出一个例子，因为更简单，另外一个大家可以看官网Singleton 12345678910111213141516171819def singleton(cls): instance = cls() instance.__call__ = lambda: instance return instance## Sample use#@singletonclass Highlander: x = 100 # Of course you can have any attributes or methods you like.Highlander() is Highlander() is Highlander #=&gt; Trueid(Highlander()) == id(Highlander) #=&gt; TrueHighlander().x == Highlander.x == 100 #=&gt; TrueHighlander.x = 50Highlander().x == Highlander.x == 50 #=&gt; True 这里简单解释下： 在定义class Highlander的时候已经执行完所有singleton装饰器中的代码，得到了一个instance，所以这之后所有对Highlander的调用实际上是在调用instance的call 方法。 我们通过lambda函数定义了call方法让它始终返回instance，因此Highlander()和Highlander都返回instance 同时由于在类定义代码执行时就已经创建了instance，所以后续不论是多线程还是单线程，在调用Highlander时都是在调用instance的call方法，也就无需同步了。 最后我想说的是这种方法简直碉堡了～～～ 日志处理几个重要的概念在介绍logging模块的日志流处理流程之前，我们先来介绍下logging模块的四大组件： 组件名称 对应类名 功能描述 日志器 Logger 提供了应用程序可一直使用的接口 处理器 Handler 将logger创建的日志记录发送到合适的目的输出 过滤器 Filter 提供了更细粒度的控制工具来决定输出哪条日志记录，丢弃哪条日志记录 格式器 Formatter 决定日志记录的最终输出格式 logging模块就是通过这些组件来完成日志处理的，上面所使用的logging模块级别的函数也是通过这些组件对应的类来实现的。 这些组件之间的关系描述： 日志器/记录器（logger）需要通过处理器（handler）将日志信息输出到目标位置，如：文件、sys.stdout、网络等； 不同的处理器（handler）可以将日志输出到不同的位置； 日志器（logger）可以设置多个处理器（handler）将同一条日志记录输出到不同的位置； 每个处理器（handler）都可以设置自己的过滤器（filter）实现日志过滤，从而只保留感兴趣的日志； 每个处理器（handler）都可以设置自己的格式器（formatter）实现同一条日志以不同的格式输出到不同的地方。 简单点说就是：日志器（logger）是入口，真正干活儿的是处理器（handler），处理器（handler）还可以通过过滤器（filter）和格式器（formatter）对要输出的日志内容做过滤和格式化等处理操作。 接口调用socket网络编程socket是将tcp的操作封装起来了，隐藏了tcp底层的很多复杂的实现过程 socket是对上层协议的封装 socket不光支持tcp/ip，还支持udp socket只干两件事【收发数据】 send Receive socket会把三次握手这些东西都封装好 下面是伪代码 注意：先要有接收端，相当于服务端 发送端： 123456import socket socket.TCP/IP # 定义操作的协议类型connect(a.ip，a.port)socket.send(hello)socket.recv()socket.close() 接收端/服务端： 12345678import socketsocket.TCP/IP #声明类型listen(0.0.0.0,6969) #一台机器上可能存在多个网卡，因此要指定ip地址和端口，同时也是唯一定位一个节点waiting()recv()send()服务器端不需要close 客户端的流程 导入socket 定义socket类型 连接远程机器 开始发送数据 接收数据 关闭socket client端代码 1234567891011# 声明socket类型，同时生成socket连接对象client = socket.socket()client.connect((&apos;localhost&apos;,6969))client.send(b&quot;hello,world&quot;)data = client.recv(1024)print (&quot;recv: &quot;,data )client.close() server端代码 1234567891011121314151617import socketserver = socket.socket()server.bind((&apos;localhost&apos;,6969))server.listen()print (&quot;dd&quot;)conn,addr = server.accept()print (conn)print (addr)print (&quot;dd&quot;)data = conn.recv(1024)print (&quot;recv:&quot;,data)conn.send(data.upper())server.close() bytes类型 只能接受ascii里面的数据类型 上面的是不能传输中文的，我们需要传输中文的时候，就需要encode成为一个byte（encode将其转成ascii里面支持的格式） 解析使用decode 在socket中，所有的数据传输都需要使用这个bytes格式]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu更改apt源]]></title>
    <url>%2F2018%2F08%2F28%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FLinux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2Fubuntu%E6%9B%B4%E6%94%B9apt%E6%BA%90%2F</url>
    <content type="text"><![CDATA[在安装完ubuntu之后，我们一般都需要将apt源替换为阿里云等国内软件源站点，以便提高响应速度。 这里使用的是Ubuntu18.04发行版本 基础知识其实Ubuntu18.04版之前的任一版更改apt源为国内源方法早就有了，内容大同小异，我们应当掌握其规律了，其实每一版内容不同的地方就是版本号（或者官方一点的说：系统代号），所以我们先了解下新版本的系统代号： 使用如下命令查看： 1lsb_release -c 执行后输出如下： 12wxh@wxh-ThinkPad-E570:/etc/apt$ lsb_release -cCodename: bionic 我们可以看到新版本的Ubuntu系统代号为bionic 同样的我们也可以得到之前任意版本的系统代号： Ubuntu 12.04 (LTS)代号为precise。 Ubuntu 14.04 (LTS)代号为trusty。 Ubuntu 15.04 代号为vivid。 Ubuntu 15.10 代号为wily。 Ubuntu 16.04 (LTS)代号为xenial。 所以这也就解释了为什么我们百度出来的那么多方案里面内容不尽相同的原因，因为他们更改apt安装源时用的系统不一样。 下面开始实际操作 备份源文件我们要修改的文件是sources.list，它在目录/etc/apt/下，sources.list是包管理工具apt所用的记录软件包仓库位置的配置文件，同样类型的还有位于 同目录下sources.list.d文件下的各种.list后缀的各文件。 命令如下： 1sudo cp /etc/apt/sources.list /etc/apt/sources.list.bak 编辑源文件内容1sudo vim /etc/apt/sources.list 将原有的内容注释或删除掉，添加以下内容 12345678910111213141516171819deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse 配置格式说明： 我们可以看到sources.list文件的条目都是有格式的（通过上面的内容大家也看的出来），一般有如下形式 12deb http://site.example.com/debian distribution component1 component2 component3deb-src http://site.example.com/debian distribution component1 component2 component3 后面几个参数是对软件包的分类（Ubuntu下是main， restricted，universe ，multiverse这四个） 补充-/etc/apt/sources.list 详解/etc/apt/sources.list 是包管理工具 apt 所用的记录软件包仓库位置的配置文件，同样的还有位于 /etc/apt/sources.list.d/*.list 的各文件。 sources.list 文件中的条目一般都有如下所示的形式： 12deb http://site.example.com/debian distribution component1 component2 component3deb-src http://site.example.com/debian distribution component1 component2 component3 档案类型 (Archive type)条目的第一个词 deb 或是 deb-src 表明了所获取的软件包档案类型。 其中： deb 档案类型为二进制预编译软件包，一般我们所用的档案类型。 deb-src 档案类型为用于编译二进制软件包的源代码。 仓库地址 (Repository URL)条目的第二个词则是软件包所在仓库的地址。我们可以更换仓库地址为其他地理位置更靠近自己的镜像来提高下载速度。 常用镜像地址列表： Debian https://www.debian.org/mirror/list Ubuntu http://wiki.ubuntu.org.cn/源列表 发行版 (Distribution)跟在仓库地址后的是发行版。发行版有两种分类方法，一类是发行版的具体代号，如 xenial,trusty, precise 等；还有一类则是发行版的发行类型，如oldstable, stable, testing 和 unstable。 另外，在发行版后还可能有进一步的指定，如 xenial-updates, trusty-security, stable-backports 等。 软件包分类 (Component)跟在发行版之后的就是软件包的具体分类了，可以有一个或多个。 不同的 Linux 发行版对软件有着不同的分类，如： Debian main 包含符合 DFSG 指导原则的自由软件包，而且这些软件包不依赖不符合该指导原则的软件包。这些软件包被视为 Debian 发型版的一部分。 contrib 包含符合 DFSG 指导原则的自由软件包，不过这些软件包依赖不在 main 分类中的软件包。 non-free 包含不符合 DFSG 指导原则的非自由软件包。 Ubuntu main 官方支持的自由软件。 restricted 官方支持的非完全自由的软件。 universe 社区维护的自由软件。 multiverse 非自由软件。 Ubuntu 对软件包的分类可以用下表来表示（参考自 Wikipedia）： 自由软件 非自由软件 官方支持的 Main Restricted 非官方支持的 Universe Multiverse 补充-update和upgrade每个LINUX的发行版，比如ubuntu、centos等，都会维护一个自己的软件仓库，我们常用的几乎所有软件都在这里面。这里面的软件绝对安全，而且绝对的能正常安装。 在UBUNTU下，我们维护一个源列表，源列表里面都是一些网址信息，这每一条网址就是一个源，这个地址指向的数据标识着这台源服务器上有哪些软件可以安装使用。 编辑源命令： 1sudo vim /etc/apt/sources.list 在这个文件里加入或者注释（加#）掉一些源后，保存。这时候，我们的源列表里指向的软件就会增加或减少一部分。 获得最近的软件包的列表:(列表中包含一些包的信息，比如这个包是否更新过) 1sudo apt-get update 这个命令，会访问源列表里的每个网址，并读取软件列表，然后保存在本地电脑。软件包管理器里看到的软件列表，都是通过update命令更新的。 update后，可能需要upgrade一下。 1sudo apt-get upgrade 这个命令，会把本地已安装的软件，与刚下载的软件列表里对应软件进行对比，如果发现已安装的软件版本太低，就会提示你更新。如果你的软件都是最新版本，会提示： 1升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 0 个软件包未被升级。 总而言之，update是更新软件列表，upgrade是更新软件。 注意：一般在执行 sudo apt-get upgrade 命令之前需要先执行一下 sudo apt-get update；这其实和windows下的软件检测更新是一样的，需要更新的会帮你自动更新并安装好 apt-get update 命令会同步使用者端和APT服务器的RPM 索引清单（package list），APT 服务器的RPM 索引清单置于base 资料夹内，使用者端电脑取得base 资料夹内的bz2 RPM 索引清单压缩档后，会将其解压置放于/var/state/apt/lists/，而使用者使用apt-get install 或apt-get dist-upgrade 指令的时候，就会将这个资料夹内的资料和使用者端电脑内的RPM 资料库比对，如此一来就可以知道那些RPM 已安装、未安装、或是可以升级的。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>Linux系统管理</category>
      </categories>
      <tags>
        <tag>ubuntu更改apt源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS记录类型简介]]></title>
    <url>%2F2018%2F08%2F28%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%2FDNS%2FDNS%E8%AE%B0%E5%BD%95%E7%B1%BB%E5%9E%8B%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[基础知识DNS：（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。使用端口号53。 DNS服务器：用于对域名进行解析的域名解析服务器。 DNS代理：用于代理域名服务器，对客户端的查询请求进行响应（一般是本地查找，查找不到再向代理的服务器转发客户端的查询请求） dns记录类型介绍A记录说明：WEB服务器的IP指向 A （Address）记录是用来指定主机名（或域名）对应的IP地址记录。用户可以将该域名下的网站服务器指向到自己的web server上。同时也可以设置域名的子域名。通俗来说A记录就是服务器的IP,域名绑定A记录就是告诉DNS,当你输入域名的时候给你引导向设置在DNS的A记录所对应的服务器。 简单的说，A记录是指定域名对应的IP地址。 AAAA记录作用同A记录，只不过该记录是将域名解析到一个指定的IPV6的IP上 CNAME记录通常称别名解析。可以将注册的不同域名都转到一个域名记录上，由这个域名记录统一解析管理 这种记录允许您将多个名字映射到同一台计算机。 通常用于同时提供WWW和MAIL服务的计算机。例如，有一台计算机名为“host.mydomain.com”（A记录）。 它同时提供WWW和MAIL服务，为了便于用户访问服务。可以为该计算机设置两个别名（CNAME）：WWW和MAIL。 这两个别名的全称就是“www.mydomain.com”和“mail.mydomain.com”。实际上他们都指向“host.mydomain.com”。 同样的方法可以用于当您拥有多个域名需要指向同一服务器IP，此时您就可以将一个域名做A记录指向服务器IP然后将其他的域名做别名到之前做A记录的域名上，那么当您的服务器IP地址变更时您就可以不必麻烦的一个一个域名更改指向了 只需要更改做A记录的那个域名其他做别名的那些域名的指向也将自动更改到新的IP地址上了。 NS记录解析服务器记录，用来表明由哪台服务器对该域名进行解析。 这里的NS记录只对子域名生效。 例如用户希望由12.34.56.78这台服务器解析news.mydomain.com，则需要设置news.mydomain.com的NS记录。 说明： “优先级”中的数字越小表示级别越高； “IP地址/主机名”中既可以填写IP地址，也可以填写像ns.mydomain.com这样的主机地址，但必须保证该主机地址有效。如，将 news.mydomain.com的NS记录指向到ns.mydomain.com，在设置NS记录的同时还需要设置ns.mydomain.com的 指向，否则NS记录将无法正常解析； NS记录优先于A记录。即，如果一个主机地址同时存在NS记录和A记录，则A记录不生效。这里的NS记录只对子域名生效。 MX记录MX（Mail Exchanger）记录是邮件交换记录，它指向一个邮件服务器，用于电子邮件系统发邮件时根据收信人的地址后缀来定位邮件服务器。例如，当Internet上的某用户要发一封信给 user@mydomain.com 时，该用户的邮件系统通过DNS查找mydomain.com这个域名的MX记录，如果MX记录存在， 用户计算机就将邮件发送到MX记录所指定的邮件服务器上。 其他的记录类型涉及到的时候再详细补充]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>网络知识及网络服务</category>
        <category>网络知识</category>
        <category>DNS</category>
      </categories>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu设置ssh服务]]></title>
    <url>%2F2018%2F08%2F26%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FLinux%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86%2Fubuntu%E8%AE%BE%E7%BD%AEssh%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[默认情况下，安装完ubuntu之后，操作系统不会像centos一样会自动把openssh-server给安装上，也就是说，在系统安装完毕之后，我们还需要进行额外的操作，才能通过ssh的方式远程访问我们的ubuntu系统。 基础知识SSH分客户端openssh-client和openssh-server 如果你只是想登陆别的机器，那么只需要安装openssh-client（ubuntu有默认安装，如果没有则sudoapt-get install openssh-client），如果要使本机开放SSH服务就需要安装openssh-server。 安装配置在命令行中使用如下命令进行安装 安装1sudo apt-get install openssh-server 配置ssh-server配置文件位于/etc/ssh/sshd_config，在这里可以定义SSH的服务端口，默认端口是22，你可以自己定义成其他端口号。 通过修改配置文件/etc/ssh/sshd_config，可以进行修改ssh登录端口、禁止root登录等一系列操作，修改端口可以防止被端口扫描。 启动默认情况下，安装完毕之后将会自动启动，我们可用用过ps来查看 1ps -elf | grep sshd 如果没有启动的话，我们执行以下命令启动 1sudo /etc/init.d/ssh start]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>Linux系统管理</category>
      </categories>
      <tags>
        <tag>ubuntu设置ssh服务</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F08%2F23%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E8%99%9A%E6%8B%9F%E5%8C%96%2FDocker%2Bk8s%2FDocker%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[参考文献： 书籍：《Docker技术入门与实战 第2版》 第1章 基础知识Docker介绍有关虚拟化虚拟化技术是一个通用的概念，在不同领域有不同的理解，在计算领域，一般指的是计算虚拟化（computing Virtualization），或通常说的服务器虚拟化。 维基百科定义如下：“虚拟化是一种资源管理技术”，是将计算机的各种实体资源，例如服务器、网络、内存及存储等，予以抽象，转换后呈现出来的，打破实体结构间的不可切割的障碍，使用户可以比原来的组态更好的方式来应用这些资源 传统来看，虚拟化既可以通过硬件模拟来实现（xen、esxi等），也可以通过操作系统软件来实现（KVM等）。而容器技术则更为优雅，它充分利用了操作系统本身已有的机制和特性，可以实现远超传统虚拟机的轻量级虚拟化。因此，有人甚至把它称为“新一代的虚拟化”技术，并将基于容器打造的云平台亲切地称之为“容器云” 什么dockerDocker的构想是要实现“build,ship and run any app,anywhere”,即通过对应用程序的封装、分发、部署、运行生命周期。达到应用组件，“一次封装，到处运行”的目的。这里的应用组件，既可以是一个web应用、一个编译环境、也可以是一套数据库平台服务，甚至是一个操作系统或者集群 可以说，Docker首次为应用的开发、运行和部署提供了“一站式”的实用解决方案 IBM DeveloperWorks网站关于容器技术的描述十分准确：“容器技术有效地将由单个操作系统管理的资源划分到孤立的组中，以更好的在孤立的组之间平衡有冲突的资源使用需求” 总结：Docker是一项容器技术，是一个开源项目 从LXC从到DockerDocker技术的主要实现参考的是Linux容器技术（Linux Containers LXC） 在LXC的基础之上，Docker进一步优化了容器的使用体验，让它进入了寻常百姓家。 优化项目： 首先，Docker提供了各种容器管理工具（如分发、版本、移植等），让用户无需关注底层的操作，可以简单明了地管理和使用容器。 其次，docker引入了分层文件系统构建和高效的镜像机制，降低了迁移难度极大地提升了用户体验。用户操作docker就像操作应用自身一样简单。 使用Docker的好处在云时代，开发者创建的应用需要要很方便的在网络上传播，也就是说，应用必须要脱离底层物理硬件的限制，同时必须是“任何时间，任何地点”都可获取的。因此，开发者需要一种新型的创建分布式应用程序的方式，快速分发和部署，这正是docker所能够提供的最大优势。 举例来说，如果要部署LAMP平台，需要分别部署mysql，apache，php等，然后再进行一系列的配置，这样的配置非常繁琐并且容易出错。并且如果需要服务器迁移，往往需要重新部署。 docker提供了一种更为聪明的方式，通过容器来打包应用。解耦应用和运行平台。这意味着在进行应用迁移的时候，只需要再新的机器上面再启动容器就可以了，不需要再进行重新部署等操作。无论服务器是否是同一类型的平台架构。这节约了大量的时间，并降低了部署过程出现问题的风险。 Docker在开发和运维中的优势具体来说，Docker在开发和运维过程中，具有如下几个方面的优势： 更快速的交付和部署 使用镜像来快速构建一套标准环境， 更高效的资源利用 docker容器不需要额外的虚拟化管理程序支持，它是内核级别的虚拟化，可以实现更高的性能 更轻松的迁移和扩展 docker容器几乎可以在任何的平台上运行，包括物理机，虚拟机，公有云，私有云，个人电脑，服务器等。 更简单的更新管理 使用dockerfile，只需要小小的配置修改，就可以替代以往大量的更新工作，并且所有的修改都是以增量的方式被分发和更新，从而实现自动化并且高效的容器管理。 Docker与虚拟机的比较 docker容器很快，启动和停止可以在秒级实现，而传统的虚拟机方式需要数分钟 docker容器对系统资源的需求很少，一台主机可以同时运行数千个docker容器 docker通过类似git设计理念的操作来方便用户获取，分发和应用镜像，存储复用，增量更新。 docker通过dockerfile支持灵活的自动化创建和部署机制，提高工作效率，使流程标准化。 Docker和核心价值docker的核心价值在于，他很有可能改变传统的软件“交付”方式和运行方式。传统的交付源码或者交付软件的方式的最大问题在于，软件运行期间所“依赖的环境”是无法控制的、不能标准化的，IT人员常常需要耗费很多精力来解决因为“依赖的环境”而导致软件运行出现的各种问题。 而docker将软件与其“依赖的环境”打包在一起，以镜像的方式交付，让软件运行在“标准的环境中”，这非常符合云计算的要求。这种变革一旦被IT人员接受，可能会对产业链带来很大的冲击，我们熟悉的apt-get、yum是否会逐渐被docker pull取代？ 从这一点可以毫不夸张的说，docker是革命性的，它重新定义了软件开发、测试、交付和部署的流程。我们交付的不再是代码、配置文件、数据库定义等。而是整个应用程序运行环境：“OS+各种中间件、类库+应用程序代码” 有了标准化的运行环境，再加上对CPU、内存、磁盘、网络等动态资源的限制，docker构造了一个“轻量级虚拟环境”，传统虚拟机的绝大多数使用场景可以被docker取代，这将给IT基础设施带来一次更大的冲击；传统虚拟化（KVM、XEN、VMWare）将会何去何从？此外，docker秒级创建/删除虚拟机以及动态调整资源的能力，也非常契合云计算的“实例水平扩展”、“资源动态调整”的需求，docker很有可能成为云计算的基石。 Docker的应用场景通过上面的介绍，可以总结出以下几个使用docker的场景 业务高峰期通过启动大量容器进行横向扩展 应用需要经常迁移或者多环境运行 核心概念/名词解释只有理解了这三个核心概念，才能顺利的理解Docker容器的整个生命周期。 docker的大部分操作都围绕着它的三个核心概念：镜像、容器和仓库展开。因此准确把握这三大核心概念对于掌握docker技术尤为重要。 三剑客之镜像-ImageDocker镜像类似虚拟机镜像，可以将它理解为一个只读的模板。例如，一个镜像可以包含一个基本的操作系统环境，里面仅安装了apache应用程序（或者其他需要的程序），这个时候，可以把它称之为一个apache镜像。 镜像是创建Docker容器的基础。通过版本管理和增量的文件系统，Docker提供了一套十分简单的机制来创建和更新删除现有的镜像，用户甚至可以从网上下载一个已经做好的应用镜像，并且直接使用 功能总结 只读的模板（包含OS+应用） 版本管理和增量文件系统的机制在其之上 操作：自行创建或网上下载、更新、删除 三剑客之容器-Container我们可以将Docker的容器理解为一种轻量级的沙盒（sanbox）。 Docker利用容器来运行和隔离应用（镜像）。 容器是从镜像创建的应用运行实例，可以将指定的镜像启动、开始、停止、删除。而这些容器都是彼此相互隔离的，互不可见的。【容器是镜像的隔离运行单元】 每个容器内运行着一个应用，不同的容器相互隔离，容器之间也可以通过网络互相通信。容器的创建和停止都十分快速，几乎跟创建和终止原生应用一致；另外，容器自身对系统资源的额外需求也十分有限，远远低于传统虚拟机。 每个容器都是一个操作系统实例 容器的功能 通过容器打包运行应用 解耦应用和运行平台。这意味着在进行应用迁移的时候，只需要再新的机器上面再启动容器就可以了，不需要再进行重新部署等操作。无论服务器是否是同一类型的平台架构。 隔离应用 容器的组成结构 上层：实际应用 下层：操作系统环境（主要是内核+函数库） 三剑客之仓库-Repositorydocker仓库类似于代码仓库，它是docker集中存放镜像文件的场所 需要注意docker仓库和仓库注册服务器（Registry）的区别。 仓库注册服务器是存放仓库的地方，其中往往存放着多个仓库。 每个仓库集中存放某一类镜像，往往包括多个镜像文件，通过不同的tag（标签）来进行区分。 根据所存储的镜像公开与否，Docker仓库可以分为两种形式。目前，最大公开仓库是官方提供的docker Hub，其中存放了数量庞大的镜像供用户下载。国内不少云服务提供商（时速云，阿里云等）也提供了仓库的本地源，可以提供稳定的国内访问 docker也支持用户在本地网络内创建一个只能自己访问的私有仓库。当用户创建了自己的镜像之后就可以使用push命令将它上传到指定的公有或者私有仓库有。这样用户下次在另外一台机器上使用该镜像时，只需要将其从仓库上pull下来就可以。 Docker-EE和Docker-CEDocker Engine改为Docker CE（社区版）, Docker Community Edition Docker Data Center改为Docker EE（企业版）, Docker Enterprise Edition 在Docker三个定价层增加了额外的支付产品和支持 Docker社区版（CE）是为了开发人员或小团队创建基于容器的应用,与团队成员分享和自动化的开发管道。docker-ce提供了简单的安装和快速的安装，以便可以立即开始开发。docker-ce集成和优化，基础设施。 Docker企业版（EE）是专为企业的发展和IT团队建立谁。docker-ee为企业提供最安全的容器平台，以应用为中心的平台。 第2章 安装配置安装Docker系统要求docker目前只能运行在64为平台上，并且要求内核版本不低于3.10，实际上内核越新越好，过低的内核版本容易造成功能不稳定。 centos环境下安装docker安装依赖包 1$ sudo yum install -y yum-utils \ device-mapper-persistent-data \lvm2 添加yum源 12$ yum-config-manager \ --add-repo \https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo 安装docker 12$ sudo yum makecache fast$ sudo yum -y install docker-ce ubuntu环境安装docker卸载老旧版本的docker Older versions of Docker were called docker or docker-engine. If these are installed, uninstall them: 1$ sudo apt-get remove docker docker-engine docker.io 安装软件源 Update the apt package index: 1$ sudo apt-get update Install packages to allow apt to use a repository over HTTPS: 12345$ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common Add Docker’s official GPG key: 1$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - Verify that you now have the key with the fingerprint 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88, by searching for the last 8 characters of the fingerprint. 123456$ sudo apt-key fingerprint 0EBFCD88pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &lt;docker@docker.com&gt;sub 4096R/F273FCD8 2017-02-22 Use the following command to set up the stable repository. You always need the stable repository, even if you want to install builds from the edge or test repositories as well. To add the edge or test repository, add the word edge or test (or both) after the word stable in the commands below. Note: The lsb_release -cs sub-command below returns the name of your Ubuntu distribution, such as xenial. Sometimes, in a distribution like Linux Mint, you might have to change $(lsb_release -cs) to your parent Ubuntu distribution. For example, if you are using Linux Mint Rafaela, you could use trusty. x86_64 / amd64 armhf IBM Power (ppc64le) IBM Z (s390x) 1234$ sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 安装docker-ce Install the latest version of Docker CE, or go to the next step to install a specific version. Any existing installation of Docker is replaced. 1$ sudo apt-get install docker-ce On production systems, you should install a specific version of Docker CE instead of always using the latest. This output is truncated. List the available versions. 123$ apt-cache madison docker-cedocker-ce | 17.09.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages 我这里的输出为： 1234$ apt-cache madison docker-ce docker-ce | 18.06.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages docker-ce | 18.06.0~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages docker-ce | 18.03.1~ce~3-0~ubuntu | https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages The contents of the list depend upon which repositories are enabled. Choose a specific version to install. The second column is the version string. The third column is the repository name, which indicates which repository the package is from and by extension its stability level. To install a specific version, append the version string to the package name and separate them by an equals sign (=): 1$ sudo apt-get install docker-ce=&lt;VERSION&gt; The Docker daemon starts automatically. Verify that Docker CE is installed correctly by running the hello-world image. 1$ sudo docker run hello-world 配置开机自启动 1$ sudo systemctl enable docker 卸载docker Uninstall the Docker CE package: 1$ sudo apt-get purge docker-ce Images, containers, volumes, or customized configuration files on your host are not automatically removed. To delete all images, containers, and volumes: 1$ sudo rm -rf /var/lib/docker You must delete any edited configuration files manually. 配置Docker服务权限配置为了避免每次使用docker命令都需要sudo使用特权身份，可以将当前用户加入安装中自动创建的docker用户组中。 1$ sudo usermod -aG docker [username] 关于这部分的内容-查看：Post-installation steps for Linux 后续需要单独写一篇文章写docker的启动权限问题 配置文件不存在问题docker服务的默认配置文件为： 12ubuntu中：/etc/default/dockercentos中：/etc/sysconfig/docker 在该配置文件中，我们可以通过修改其中的DOCKER_OPTS来修改服务启动的参数 但是实际情况，安装完docker之后，是没有改配置文件的 因此在docker的高版本之后，配置文件变成了：/etc/docker/key.json 官方参考配置文档：https://docs.docker.com/engine/reference/commandline/dockerd//#daemon-configuration-file cd 启动Docker服务 在Centos 7 中，我们可以使用如下命令启动docker 12345systemctl start docker# systemctl enable dockersystemctl daemon-reload #加载配置 第3章 使用Docker镜像镜像（image）是Docker三大核心概念中最为重要的，自Docker诞生之日起，“镜像”就是相关社区最为热门的关键词。 docker运行容器前需要本地存在对应的镜像，如果镜像没有保存在本地，docker会尝试先从默认镜像仓库下载（默认使用docker Hub公共注册服务器中的仓库），用户也可以通过配置，使用自定义的镜像仓库。 获取镜像镜像是运行容器的前提，官方的docker Hub网站已经提供了数十万个镜像供大家开放下载。 可以使用docker pull命令直接从docker Hub 镜像源来下载镜像。该命令的格式为docker pull NAME[:TAG]。其中，NAME是镜像仓库的名称（用来区分镜像），TAG是镜像的标签（往往用来表示版本信息）。例如：ubuntu系统是NAME，14.04是TAG 1docker pull ubuntu:14.04 注意： 如果不显性的制定TAG，该命令会自动选择latest标签，这会下载仓库中最新版本的镜像。 镜像的latest标签意味着该镜像的内容会跟踪最新的非稳定版本而发布，内部是不稳定的。 在生产环境中禁止忽略镜像的标签信息或者使用默认的latest标签 镜像的分层特性镜像文件一般由若干层（layer）构成，每一层都有一个唯一的id（完整的id有256比特，由64个十六进制字符组成）。 使用docker pull命令下载时会获取并输出镜像的各层信息。当不同的镜像包括相同的层时，本地仅存储该层的一份内容，减少了需要的存储空间。 镜像的重名问题在使用不同的镜像仓库时，可能会出现镜像重名的情况？ 严格来讲，镜像的仓库名称中还应该添加仓库地址（即仓库注册服务器（Registry））的地址作为前缀，默认我们使用的是docker Hub的服务，该前缀可以忽略不写。 例如：docker pull ubuntu:14.04 命令相当于docker pull registry.hub.docker.com/ubuntu:14.04命令。 运行镜像下载镜像到本地之后，即可随时使用该镜像，例如利用该镜像创建一个容器，在其中运行bash应用，执行ping localhost命令 1[root@master yum.repos.d]# docker run -it ubuntu:14.04 bash 查看镜像信息使用images命令列出镜像使用docker images命令可以列出本地主机上已有镜像的基本信息。、 1# docker images ​ 在列出的信息中，可以看到以下几个字段信息： 来自于哪个仓库 REPOSITORY 镜像的TAG（标签）信息，标签知识标记，并不能识别镜像内容 镜像的ID（唯一标识镜像）。IMAGE ID 创建时间 CREATED 镜像大小 SIZE 其中镜像的ID信息十分重要，它唯一标识了镜像。在使用镜像ID的时候，一般可以使用该ID的前若干个字符组成的可区分串来替代完整的ID。 镜像大小信息只是标识该镜像的逻辑体积的大小，实际上由于相同的镜像层本地只会存储一份，物理上占用的存储空间会小于各镜像的逻辑体积之和。 images支持的的选项参数： -a –all=true|false 列出所有的镜像文件（包括临时文件），默认为否 –digests=true|false 列出镜像的数字摘要值，默认为否 -f –filter=[] 过滤列出的镜像 ….. 具体可以通过man docker-images 进行查看。 使用tag命令添加镜像标签为了方便在后续的工作中使用特定镜像，还可以使用docker tag命令来为本地镜像任意添加新的标签 1[root@master ~]# docker tag ubuntu:14.04 ubuntu:my14.04 注意：docker tag命令添加的标签实际上起到了类似链接的作用 使用inspect命令查看详细信息使用docker inspect命令可以获取该镜像的详细信息，包括制作者，使用架构，各层的数字摘要等。 1[root@master ~]# docker inspect ubuntu:14.04 返回的是一个JSON格式的消息，如果我们只要其中一项内容时，可以使用参数-f来指定，例如，获取镜像的Architecture参数。 12[root@master ~]# docker inspect ubuntu:14.04 -f &#123;&#123;&quot;.Architecture&quot;&#125;&#125;amd64 使用history命令查看镜像历史既然镜像由多个层组成，那么怎么知道各个层的内容具体是什么呢？这时候可以使用history子命令，该命令将列出各层的创建信息。 123456789101112131415[root@master ~]# docker history ubuntu:14.04IMAGE CREATED CREATED BY SIZE COMMENTa35e70164dfb 12 days ago /bin/sh -c #(nop) CMD [&quot;/bin/bash&quot;] 0B &lt;missing&gt; 12 days ago /bin/sh -c mkdir -p /run/systemd &amp;&amp; echo &apos;do… 7B &lt;missing&gt; 12 days ago /bin/sh -c sed -i &apos;s/^#\s(deb.universe)$… 2.76kB &lt;missing&gt; 12 days ago /bin/sh -c rm -rf /var/lib/apt/lists/* 0B &lt;missing&gt; 12 days ago /bin/sh -c set -xe &amp;&amp; echo &apos;#!/bin/sh&apos; &gt; /… 195kB &lt;missing&gt; 12 days ago /bin/sh -c #(nop) ADD file:3900b83a46e97708a… 222MB 搜寻镜像使用docker search命令来搜索源端仓库中共享的镜像，默认搜索官方仓库中的镜像。 用法为： 1$ docker search TERM 支持的主要参数为： –automated=true|false：仅显示自动创建的镜像，默认为否。 –no-trubc=true|false：输出信息不截断显示，默认为否 -s –starts=X：指定仅显示评价为指定星级以上的镜像，默认为0，即输出所有的镜像。 删除镜像使用标签删除镜像使用docker rmi命令可以删除镜像，命令格式为： 123docker rmi IMAGE [IMAGE…]其中IMAGE可以为标签或ID,例如：ubuntu:my14.04 ​ 注意：当同一个镜像拥有多个标签的时候，docker rmi命令只是删除该镜像多个标签中的制定标签而已，并不影响镜像文件。因此上述操作相当于只是删除了镜像a35e70164dfb的一个标签而已。 但是，当镜像只是剩下一个标签的时候，此时再使用docker rmi 命令会彻底删除镜像。 使用镜像ID删除镜像当使用docker rmi（remove image）命令，并且后面跟上镜像的ID（也可以是能进行区分的部分ID串前缀）时，会先尝试删除所有指向该镜像，然后再删除该镜像文件本身 命令格式： 1docker rmi xxxx(ID) 注意：使用该命令可以彻底将该镜像删除，而不是只是删除对应的标签，请务必注意。 注意： 当有该镜像创建的容器存在时，镜像文件默认是无法被删除的 试图删除该镜像，docker会提示有容器正在运行，无法删除 如果要强行删除镜像，可以使用-f参数 创建镜像创建镜像的方法主要有三种： 基于已有镜像的容器创建 基于本地模板导入 基于dockerfile创建 基于已有镜像的容器创建当运行一个容器后，内部发生了变化，我们可以把这个发生了变化的容器做成一个新的镜像。 该方法主要是通过docker commit命令。 命令格式为： 1docker commit [options] container [repository[:tag]] 主要选项包括： -a –author=””：作者信息 -c –change=[]：提交的时候之心dockerfile指令， -m –message=””：提交消息 -p –pause=true 提交时暂停容器运行 123456789101112[root@master ~]# docker run -it ubuntu:14.04 /bin/bashroot@fdbe2f28b1d6:/# touch testroot@fdbe2f28b1d6:/# exitexit[root@master ~]# docker commit -m &quot;add a new file&quot; -a &quot;wxh&quot; fdbe2f28b1d6 test:0.1sha256:cd9c21826184f9e65e11644f826fb97918d40d469aa5e3fd8827cbcac19351ed[root@master ~]# docker images 查看 I’m just ​ 基于本地模板导入这部分不常用，详见书籍《docker技术入门与实践》-p32 基于dockerfile创建官方案例下面是docker官方案例，有一定的代表性 链接地址：https://docs.docker.com/v17.09/get-started/part2/#dockerfile Dockerfile will define what goes on in the environment inside your container. Access to resources like networking interfaces and disk drives is virtualized inside this environment, which is isolated from the rest of your system, so you have to map ports to the outside world, and be specific about what files you want to “copy in” to that environment. However, after doing that, you can expect that the build of your app defined in this Dockerfile will behave exactly the same wherever it runs. Dockerfile Create an empty directory. Change directories (cd) into the new directory, create a file called Dockerfile, copy-and-paste the following content into that file, and save it. Take note of the comments that explain each statement in your new Dockerfile. 1234567891011121314151617181920# Use an official Python runtime as a parent imageFROM python:2.7-slim# Set the working directory to /appWORKDIR /app# Copy the current directory contents into the container at /appADD . /app# Install any needed packages specified in requirements.txtRUN pip install --trusted-host pypi.python.org -r requirements.txt# Make port 80 available to the world outside this containerEXPOSE 80# Define environment variableENV NAME World# Run app.py when the container launchesCMD [&quot;python&quot;, &quot;app.py&quot;] Are you behind a proxy server? Proxy servers can block connections to your web app once it’s up and running. If you are behind a proxy server, add the following lines to your Dockerfile, using the ENV command to specify the host and port for your proxy servers: 1234&gt; # Set proxy server, replace host:port with values for your servers&gt; ENV http_proxy host:port&gt; ENV https_proxy host:port&gt; &gt; Add these lines before the call to pip so that the installation succeeds. This Dockerfile refers to a couple of files we haven’t created yet, namely app.py and requirements.txt. Let’s create those next. The app itself Create two more files, requirements.txt and app.py, and put them in the same folder with the Dockerfile. This completes our app, which as you can see is quite simple. When the above Dockerfile is built into an image, app.py and requirements.txt will be present because of that Dockerfile’s ADD command, and the output from app.py will be accessible over HTTP thanks to the EXPOSEcommand. requirements.txt 12FlaskRedis app.py 123456789101112131415161718192021222324from flask import Flaskfrom redis import Redis, RedisErrorimport osimport socket# Connect to Redisredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello(): try: visits = redis.incr(&quot;counter&quot;) except RedisError: visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot; html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \ &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \ &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot; return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;: app.run(host=&apos;0.0.0.0&apos;, port=80) Now we see that pip install -r requirements.txt installs the Flask and Redis libraries for Python, and the app prints the environment variable NAME, as well as the output of a call to socket.gethostname(). Finally, because Redis isn’t running (as we’ve only installed the Python library, and not Redis itself), we should expect that the attempt to use it here will fail and produce the error message. Note: Accessing the name of the host when inside a container retrieves the container ID, which is like the process ID for a running executable. That’s it! You don’t need Python or anything in requirements.txt on your system, nor will building or running this image install them on your system. It doesn’t seem like you’ve really set up an environment with Python and Flask, but you have. Build the app We are ready to build the app. Make sure you are still at the top level of your new directory. Here’s what ls should show: 12$ lsDockerfile app.py requirements.txt Now run the build command. This creates a Docker image, which we’re going to tag using -t so it has a friendly name. 1docker build -t friendlyhello . Where is your built image? It’s in your machine’s local Docker image registry: 1234$ docker imagesREPOSITORY TAG IMAGE IDfriendlyhello latest 326387cea398 Run the app Run the app, mapping your machine’s port 4000 to the container’s published port 80 using -p: 1docker run -p 4000:80 friendlyhello You should see a message that Python is serving your app at http://0.0.0.0:80. But that message is coming from inside the container, which doesn’t know you mapped port 80 of that container to 4000, making the correct URL http://localhost:4000. Go to that URL in a web browser to see the display content served up on a web page. Now let’s run the app in the background, in detached mode: 1docker run -d -p 4000:80 friendlyhello You get the long container ID for your app and then are kicked back to your terminal. Your container is running in the background. You can also see the abbreviated container ID with docker container ls (and both work interchangeably when running commands): 123$ docker container lsCONTAINER ID IMAGE COMMAND CREATED1fa4ab2cf395 friendlyhello &quot;python app.py&quot; 28 seconds ago You’ll see that CONTAINER ID matches what’s on http://localhost:4000. Now use docker container stop to end the process, using the CONTAINER ID, like so: 1docker container stop 1fa4ab2cf395 载入和导出镜像用户可以使用docker save和docker load命令来存出和载入镜像 导出镜像如果要导出镜像到本地文件，可以使用docker save命令。例如导出本地的ubunt:14.04镜像为ubuntu_14.04.tar。如下图所示： 1[root@master ~]# docker save -o ubuntu:14.04.tar ubuntu:14.04 载入镜像可以使用docker load将导出的tar文件再导入到本地的镜像库，例如从上述文件导入镜像到本地镜像列表。 12345[root@master ~]# docker load --input ubuntu\:14.04.taror[root@master ~]# docker load &lt; ubuntu\:14.04.tar 该命令将导入镜像及其相关的元数据信息（包括标签等）。导入成功之后，可以使用docker images命令进行查看。 上传和下载镜像登录首先在docker hub网站完成注册 可以通过执行 docker login 命令交互式的输入用户名及密码来完成在命令行界面登录 Docker Hub。 你可以通过 docker logout 退出登录。 1234567891011wxh@wxh-ThinkPad-E570:~$ sudo docker login[sudo] password for wxh:Login with your Docker ID to push and pull images from Docker Hub. If you don&apos;t have a Docker ID, head over to https://hub.docker.com to create one.Username: watchmen1992Password:WARNING! Your password will be stored unencrypted in /home/wxh/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeededwxh@wxh-ThinkPad-E570:~$ 上传镜像可以使用docker push命令上传镜像到仓库，默认上传到docker Hub官方仓库（需要在前面进行登录） 在进行上传之前，我们需要将指定的image镜像打上tag标签 命令格式为： 12docker tag image username/repository:tagdocker push NAME[:TAG] | [REGISTRY_HOST[:REGISTRY_PORT]/]NAME[:TAG] 例如这里是： 12345wxh@wxh-ThinkPad-E570:~/.docker$ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEfriendlyhello latest 028a0a8d1a73 18 hours ago 132MBpython 2.7-slim 40792d8a2d6d 4 weeks ago 120MBhello-world latest 2cb0d9787c4d 7 weeks ago 1.85kB 1$ sudo docker tag friendlyhello watchmen1992/get_started:part1 然后push上传 12345678910wxh@wxh-ThinkPad-E570:~/.docker$ sudo docker push watchmen1992/get_started:part1The push refers to repository [docker.io/watchmen1992/get_started]88d851af045c: Pushedaa5497e6a355: Pushedd4f7cf378376: Pushed1ea4f6a807ba: Mounted from library/pythonfda4dc055a55: Mounted from library/pythone8fc09a140cf: Mounted from library/pythoncdb3f9544e4c: Mounted from library/pythonpart1: digest: sha256:ded675c46615053ef0a655b163228e50a0e58172003f78f319dad46ee09dac9a size: 1788 上传之后，我们在docker hub的页面就可以看到新增内容 1docker run -p 4000:80 username/repository:tag 例如： 1234567891011wxh@wxh-ThinkPad-E570:~/.docker$ sudo docker run -p 4000:80 watchmen1992/get_started:part1[sudo] password for wxh: * Serving Flask app &quot;app&quot; (lazy loading) * Environment: production WARNING: Do not use the development server in a production environment. Use a production WSGI server instead. * Debug mode: off * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)192.168.101.72 - - [30/Aug/2018 03:32:34] &quot;GET / HTTP/1.1&quot; 200 - 在上传之后，我们就能直接调用仓库的镜像去启动容器 下载镜像第4章 使用Docker容器容器是docker的另一个和细腻概念。简单来说，容器是镜像的一个运行实例。所不同的是，镜像是静态的只读文件，而容器带有运行时需要的可写文件层。 创建启动容器新建容器使用docker create命令新建一个容器 1格式：docker create -it ubuntu:latest 注意：使用该命令新建的容器处于停止状态，可以使用docker start命令来启动它。 启动容器使用docker start 命令来启动一个已经创建的容器，例如启动刚创建的ubuntu容器： 1$ docker start af 新建并启动容器除了创建容器后通过start命令来启动，也可以直接新建并启动容器。 所需要的命令主要为:docker run。等价于先执行docker create命令，再执行docker start命令 例如，下面的命令输出一个“hello world”之后容器终止 12[root@master ~]# docker run ubuntu:14.04 /bin/echo &quot;hello,world&quot;hello,world ​ 当利用docker run命令来创建并启动容器时，docker在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库中下载 利用镜像创建一个容器，并启动该容器 分配一个文件系统给容器，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口道容器中 从网桥的地址池配置一个IP地址给容器 执行用户执行的应用程序 执行完毕后容器被自动终止 下面命令启动一个bash终端，允许用户进行交互 1[root@master ~]# docker run -it ubuntu:14.04 /bin/bash -t选项让docker分配一个伪终端，并绑定到容器的标准输入上，一则让容器的标准输入保持打开。更多的命令可以通过 man docker-run进行查看。 注意： 对于所创建的bash容器，当使用exit命令退出之后，容器就自动处于退出状态了，这是因为对于docker容器来说，当运行的应用退出之后，容器也就没有继续运行的必要了 守护态运行更多的时候，需要让docker容器在后台以守护态（daemonized）形式运行。此时可以添加-d参数来实现 1[root@master ~]# docker run -d ubuntu:14.04 /bin/bash -c &quot;while true;do echo hello,world;sleep 1;done&quot; 此时，要获取容器的输出信息，可以使用如下的docker logs命令 1[root@master ~]# docker logs 9e7 退出错误代码 125 docker daemon执行出错，例如指定了不支持的docker命令参数 126 所指定命令无法执行，例如权限出错 127 容器内命令无法找到 当命令执行出错时，会默认返回错误码 容器参数详见书籍《docker技术从入门到实践》p35-37 –rm 容器在终止后会立刻删除 -d 守护态启动，注意—rm和-d不能同时使用 终止容器可以使用docker stop来终止一个运行中的容器。 1命令格式为：docker stop -t|--time[=10] 该命令首先向容器发送SIGTERM信号，等待一段超时时间（默认为10秒）后，再发送SIGKILL信号来终止容器 ​ 当容器中指定的应用终结时，容器也会自动终止。 处于终止状态的容器，可以通过start命令来重新启动 此外，docker restart 命令会将一个运行态的容器先终止，然后再重新启动它 进入容器attach这种方法，同一时间只能有一个活动窗口。不建议 exec命令通过exec命令对容器执行操作是最为推荐的方式。 12345[root@master ~]# docker start 9e708d44e39a9e708d44e39a[root@master ~]# docker exec -it 9e7 /bin/bashroot@9e708d44e39a:/# 比较常用的参数有： -i –interactive=true|false 打开标准输入接受用户输入命令，默认为false。 –privileged=true|false 是否给执行命令以最高权限，默认为false。 -t –tty=true|false 分配伪终端，默认为false -u –user=”” 执行命令的用户名或者ID nsenter工具查看容器 docker ps 查看运行中的容器 docker ps -a 查看所有容器，包括运行的与停止的 docker ps -qa 查看所有容器ID 删除容器可以使用docker rm命令来删除处于终止或者退出状态的容器 命令格式为： 1docker rm -f|--force [-v|--volumes] container [container…] 主要支持的选项包括： -f –force=false 是否强行终止并删除一个运行中的容器 -l –link=false 删除容器的连接，但是保留容器 -v –volumes=false 删除容器挂载的数据卷 默认情况下，docker rm命令只能删除处于终止或者退出状态的容器，并不能删除还是处于运行状态的容器。 如果要删除一个运行中的容器，可以添加-f参数。该命令首先向容器发送SIGKILL信号给容器，终止其中的应用，之后强行删除。 导入和导出容器导出容器12345docker export -o test_for_run.tar ce5或者docker export e81 &gt; test_for_stop.tar 导入容器导出的文件可以使用docker import命令导入变成镜像 1docker import test_for_run.tar – test/ubuntu:v1.0 实际上，既可以使用docker load命令来导入镜像存储文件到本地镜像库，也可以用docker import命令来导入一个容器快照到本地镜像库。这两者的区别在于容器快照文件将丢弃所有的历史记录和元数据信息（即仅保存容器当时的快照状态），而镜像存储文件将保存完整记录，体积也更大。此外，从容器快照文件导入时可以重新制定标签等元数据信息 第5章 访问docker仓库仓库（repositroy）是集中存放镜像的地方，分为公共仓库和私有仓库。 注意：注册服务器是存放仓库的服务器 docker hub公共镜像市场默认使用的镜像来源都是docker hub中的 1docker search lnmp 时速云镜像市场搭建本地私有仓库使用registry镜像创建私有仓库安装docker之后，可以通过官方提供的registry镜像来简单搭建一套本地私有仓库环境: 1docker run -d -p 5000:5000 registry 它将自动下载并且启动一个registry容器，创建本地的私有仓库服务 在默认情况下，会将仓库创建在容器的/tmp/registry目录下。可以通过-v参数来将镜像文件存放在本地的指定路径。 1docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 管理私有仓库-上传镜像因为docker images中的字段，REPOSITORY表示仓库信息，因此，我们在创建了私有仓库之后，要使用镜像，需要对镜像进行tag标签的操作 1[root@master ~]# docker tag ubuntu:14.04 47.93.54.101:5000/test 上述命令解释： 使用tag命令将ubuntu镜像标记为47.93.54.101:5000/test【也就是这个仓库下的】 47.93.54.101:5000是仓库注册服务器，test是仓库名称，test:[name]后面接的是tag信息，没有写的话，默认是latest 接下来使用docker push上传标记的镜像： 1[root@master ~]# docker push 47.93.54.101:5000/test 注意： 客户端采用https，docker registry未采用https服务，由于服务端没有采用https方式，因此客户端无法使用默认的https形式pull镜像，因此我们要做一些操作 服务端： 在/etc/docker/目录下，创建daemon.json文件。在文件中写入： 123[root@master docker]# cat daemon.json&#123;&quot;insecure-registries&quot;:[&quot;47.93.54.101:5000&quot;]&#125; 客户端 在/etc/docker/目录下，创建daemon.json文件。在文件中写入： 123[root@master docker]# cat daemon.json&#123;&quot;insecure-registries&quot;:[&quot;47.93.54.101:5000&quot;]&#125; 注意：不光服务端要配置，客户端也需要配置 配置完毕之后，我们就可以看到客户端能够正常的拉取我们私有仓库中的镜像 第6章 Docker数据管理生产环境中使用docker的过程中，往往需要对数据进行持久化，或者需要在多个容器之间进行数据共享，这必然涉及容器的数据管理操作。 容器中管理数据主要有2种方式 数据卷（data volumes）：容器内数据直接映射到本地主机环境 数据卷容器（data volumes containers）：使用特定容器维护数据卷。 数据卷数据卷是一个可以供容器使用的特殊目录，它将主机操作系统目录直接映射进容器，类似于linux的mount挂载操作。 数据卷可以提供很多有用的特性： 数据卷可以在容器之间共享和重用，容器键传递数据将变得高效方便。 对数据卷内数据的修改会立马生效，无论是容器内操作还是本地操作。 对数据卷的更新不会影响镜像，解耦了应用和数据 卷会一直存在，直到没有容器使用，可以安全的卸载它。 在容器内创建一个数据卷在用docker run命令的时候，使用-v标记可以在容器内创建一个数据卷。多次重复使用-v标记可以创建多个数据卷。 下面使用 training/webapp镜像创建一个web容器，并创建一个数据卷挂载到容器的/webapp目录。 1[root@master ~]# docker run -d -P --name web -v /webapp training/webapp python app.py ​ 注意：这里是在容器内部创建一个目录，而不是宿主机上创建 -P是将容器服务暴露的端口，是自动映射到本地主机的临时端口 挂载宿主机目录作为数据卷使用-v标记也可以指定挂载一个本地的已有目录到容器中去作为数据卷【推荐方式】 [root@master ~]# docker run -d -P –name web -v /src/webapp:/opt/webapp training/webapp python app.py 上述命令加载主机的/src/webapp目录到容器的/opt/webapp目录 本地目录的路径必须是绝对路径，如果目录不存在，docker会自动创建 注意：docker挂载数据卷的默认权限是读写（rw）,用户也可以通过ro指定为只读 1# docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py 设置为ro之后，容器内对所挂载数据卷内的数据就无法修改了。 ​ 使用这个功能，在进行一些测试的时候十分方便，比如用户可以将一些程序或者数据放到本地目录中，然后再容器内运行和使用 挂载一个本地主机文件作为数据卷-v标记也可以从主机挂载单个文件到容器中作为数据卷（对应容器中的某一个文件） 1docker run –rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash 注意：如果直接挂载一个文件到容器中，使用文件编辑工具，包括vi或者sed等，可能会造成文件inode的概念，从docker 1.1.0版本起，这会导致报错，所以推荐的方式是直接挂载目录。 数据卷容器如果用户需要再多个容器之间共享一些持续更新的数据，最简单的方式是使用数据卷容器。数据卷容器也是一个容器，但是它的目的是专门用来提供数据卷供其他容器挂载。 首先，创建一个数据卷容器dbdata，并在其中创建一个数据卷挂载到/dbdata： 1docker run -it -v /dbdata --name dbdata ubuntu 【这个dbdata是在容器内部的一个目录，请注意】 作用是：定义一个数据卷 然后，可以在其他容器中使用–volumes-from来挂载dbdata容器中的数据卷 1docker run -it --volumes-from dbdata --name db1 ubuntu 在容器dbdata中查看，数据已经同步过来 可以多次使用 –volume-from参数来从多个容器挂载多个数据卷。还可以从其他已经挂载了容器卷的容器来挂载数据卷。 注意：如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时，显式使用docker rm -v命令来指定同时删除关联的容器。 使用数据卷容器可以让用户在容器之间自由地升级和移动数据卷。 利用数据卷容器来迁移可以利用数据卷容器对其中的数据卷进行备份、恢复、以实现数据的迁移。 备份使用下面的命令来备份dbdata数据卷容器内的数据卷 123456[root@master ~]# docker run --volumes-from dbdata -v $(pwd):/backup --name worker ubuntu tar cvf /backup/backup.tar /dbdatatar: Removing leading `/&apos; from member names/dbdata//dbdata/a/dbdata/db1 命令解析： 首先利用ubuntu镜像创建了一个容器worker，使用–volumes-from dbdata参数来让worker容器挂载dbdata容器的数据卷。 然后使用-v参数，挂载本地的当前目录到worker容器内部的/backup目录。 worker容器启动之后，使用tar命令，将/dbdata目录备份到容器内的/backup目录下，也就是宿主机的当前目录下。即可完成整个备份过程。 恢复数据操作都需要借助容器来完成，需要借助容器来打通一个通道。 恢复数据的思路（这里指的是恢复数据到另一个没有数据的数据卷容器中）： 创建一个新的数据卷容器 创建一个新的容器，挂载该容器（–volumes-from参数） 挂载本地的目录到/backup下（这时该目录下就会有本地的数据），然后解压其中的数据 命令如下： 123[root@master ~]# docker run -v /dbdata --name dbdata2 ubuntu /bin/bash[root@master ~]# docker run --volumes-from dbdata2 -v $(pwd):/backup busybox tar xvf /backup/backup.tar 第7章 端口映射与容器互联在实际情况中，是需要多个服务组件容器共同协作的情况，因此往往需要多个容器之间能够互相访问到对方的服务。 除了通过网络来进行访问，docker还提供了两个功能满足服务访问的基本需求： 一个是允许映射容器内应用的服务端口到本地宿主主机 另一个是互联机制实现多个容器键通过容器名称来来快速访问 在启动容器的时候，如果不指定对应的参数，在容器外部是无法通过网络来访问容器内的网络应用和服务的。 端口映射实现访问容器所有接口的随机端口可以通过-P或者-p参数来指定端口映射。 当使用-P时，映射一个49000-49900的端口 1[root@master ~]# docker run -d -P training/webapp python app.py ​ 可以通过docker logs -f [id]来查看应用信息 1[root@master ~]# docker logs -f 4336a2dbe777 所有接口的指定端口命令格式：hostport:containerport 1[root@master ~]# docker run -d -p 5000:5000 training/webapp python app.py 使用该命令映射所有接口地址 此时绑定所有接口上的所有地址，将本地的5000端口映射搭配容器的5000端口 指定地址的指定端口命令格式：IP:hostport:containerport 1[root@master ~]# docker run -d -p 127.0.0.1:5000:5000 training/webapp python app.py 指定使用本机的哪一个地址进行端口映射 指定地址的任意端口命令格式：IP::containerport 1[root@master ~]# docker run -d -p 127.0.0.1::5000 training/webapp python app.py 还可以使用udp标记来指定udp端口 1[root@master ~]# docker run -d -p 127.0.0.1::5000/udp training/webapp python app.py 查看映射端口配置命令语法：docker port 容id [port] 1234567[root@master ~]# docker port 4336a2dbe7775000/tcp -&gt; 0.0.0.0:32773[root@master ~]# docker port 4336a2dbe777 50000.0.0.0:32773 互联机制实现便捷互访容器的互联（link）是一种让多个容器中应用进行快速交互的方式。他会在源和接受容器之间创建连接关系，接受容器可以通过容器名称快速访问到源容器，而不用指定具体的IP地址。 自定义容器名称例如： 1[root@master ~]# docker run -v /dbdata --name dbdata2 ubuntu /bin/bash 连接系统通过容器名称来执行，因此需要给每个容器都定义一个名称。 容器互联使用—link参数可以让容器之间安全地进行交互 link参数格式为：–link name:alias docker通过两种方式为容器公开连接信息。 更新环境变量 更新/etc/hosts文件。 以下为参考案例： 首先创建一个新的数据库容器 1[root@master registry]# docker run -d --name db training/postgres 创建一个新的web容器，并将它连接到db容器 1[root@master registry]# docker run -d -P --name web --link db:db training/webapp python app.py ​ 查看容器之间的连接信息： 1[root@master registry]# docker run --rm --name web2 --link db:db training/webapp env 查看hosts信息(cat /etc/hosts) 可以看到，hosts文件中包含db的信息和自身的配置信息。 以上都是单机中多容器之间的互联，后续还会涉及跨主机之间的容器通信。 第8章 使用dockerfile创建镜像第9章 docker网络镜像仓库之-Harborgithub主页：https://github.com/goharbor/harbor Features Role based access control: Users and repositories are organized via ‘projects’ and a user can have different permission for images under a project. 用户和镜像仓库是通过项目关联起来的，不同用户在该项目下拥有不同的权限 Policy based image replication: Images can be replicated (synchronized) between multiple registry instances, with auto-retry on errors. Great for load balancing, high availability, multi-datacenter, hybrid and multi-cloud scenarios. 镜像将在多个注册实例中复制，实现高可用、负载均衡、多路选择等功能 Vulnerability Scanning: Harbor scans images regularly and warns users of vulnerabilities. 高危扫描：harbor将会在规律的扫描镜像并且提醒用户相关的危险 LDAP/AD support: Harbor integrates with existing enterprise LDAP/AD for user authentication and management. harbor可以聚合企业现在的LDAP/AD等实现用户认证和管理 Image deletion &amp; garbage collection: Images can be deleted and their space can be recycled. 镜像删除和垃圾收集 Notary: Image authenticity can be ensured. 可以保证镜像的可靠性 Graphical user portal: User can easily browse, search repositories and manage projects. 图形化的用户入口：可以浏览，检索，管理项目 Auditing: All the operations to the repositories are tracked. 审计：所有的操作都可以被追踪 RESTful API: RESTful APIs for most administrative operations, easy to integrate with external systems. 提供api Easy deployment: Provide both an online and offline installer. 部署简单，提供在线和离线两种安装方式 ### Architecture-体系结构 As depicted in the above diagram, Harbor comprises 6 components: Proxy: Components of Harbor, such as registry, UI and token services, are all behind a reversed proxy. The proxy forwards requests from browsers and Docker clients to various backend services. harbor使用代理结构，外部的客户端（浏览器或者docker client）访问调用是通过代理层去实现的 Registry: Responsible for storing Docker images and processing Docker push/pull commands. As Harbor needs to enforce access control to images, the Registry will direct clients to a token service to obtain a valid token for each pull or push request. 注册部分：响应操作docker镜像的请求 harbor为了确保安全性，客户端在调用的时候，需要取得valid token才可以进行操作 Core services: Harbor’s core functions, which mainly provides the following services: UI: a graphical user interface to help users manage images on the Registry Webhook: Webhook is a mechanism configured in the Registry so that image status changes in the Registry can be populated to the Webhook endpoint of Harbor. Harbor uses webhook to update logs, initiate replications, and some other functions. Token service: Responsible for issuing a token for every docker push/pull command according to a user’s role of a project. If there is no token in a request sent from a Docker client, the Registry will redirect the request to the token service. Database: Database stores the meta data of projects, users, roles, replication policies and images. 提供一个图形的用户入口，方便用户在注册钩子系统（registry webhook）中管理镜像。 Job services: used for image replication, local images can be replicated(synchronized) to other Harbor instances. Log collector: Responsible for collecting logs of other modules in a single place. 安装配置harbor参考文献：https://github.com/goharbor/harbor/blob/master/docs/installation_guide.md 环境要求：Harbor is deployed as several Docker containers, and, therefore, can be deployed on any Linux distribution that supports Docker. The target host requires Python, Docker, and Docker Compose to be installed. Hardware Resource Capacity Description CPU minimal 2 CPU 4 CPU is prefered Mem minimal 4GB 8GB is prefered Disk minimal 40GB 160GB is prefered Software Software Version Description Python version 2.7 or higher Note that you may have to install Python on Linux distributions (Gentoo, Arch) that do not come with a Python interpreter installed by default Docker engine version 1.10 or higher For installation instructions, please refer to: https://docs.docker.com/engine/installation/ Docker Compose version 1.6.0 or higher For installation instructions, please refer to: https://docs.docker.com/compose/install/ Openssl latest is prefered Generate certificate and keys for Harbor Network ports Port Protocol Description 443 HTTPS Harbor UI and API will accept requests on this port for https protocol 4443 HTTPS Connections to the Docker Content Trust service for Harbor, only needed when Notary is enabled 80 HTTP Harbor UI and API will accept requests on this port for http protocol Installation Steps** The installation steps boil down to the following Download the installer; Configure harbor.cfg; Run install.sh to install and start Harbor; 实际操作： 下载1$ tar xvf harbor-online-installer-&lt;version&gt;.tgz 安装docker-ce 12345sudo yum install -y yum-utils device-mapper-persistent-data lvm2sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.reposudo yum install docker-ce 启动docker 12[root@localhost tools]# systemctl start docker[root@localhost tools]# systemctl enable docker 安装Docker Compose 12345sudo curl -L &quot;https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-composedocker-compose --version 配置Configuration parameters are located in the file harbor.cfg There are two categories of parameters in harbor.cfg, required parameters and optional parameters. required parameters: These parameters are required to be set in the configuration file. They will take effect if a user updates them in harbor.cfg and run the install.sh script to reinstall Harbor. optional parameters: These parameters are optional for updating, i.e. user can leave them as default and update them on Web UI after Harbor is started. If they are set in harbor.cfg, they only take effect in the first launch of Harbor. Subsequent update to these parameters in harbor.cfg will be ignored. Note: If you choose to set these parameters via the UI, be sure to do so right after Harbor is started. In particular, you must set the desired auth_mode before registering or creating any new users in Harbor. When there are users in the system (besides the default admin user), auth_mode cannot be changed. 配置文件中有2种配置内容，一种是必须配置的参数，一种是可选参数 可选参数：如果你将可选参数设置在配置文件里面，也可以在安装完毕只有在web UI上进行设置，如果在启动之前配置在配置文件里面，那么当启动之后再在web上修改，那么修改将会是无效的，不会被刷新到配置文件当中。 可选参数：可以再harbor启动之后，在web界面进行更新，如果这些参数是在在配置文件中的，那么不会即时生效。配置文件中的只会在启动之后生效 修改完毕之后的配置如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@app028-dev harbor]# less harbor.cfg | egrep -v &apos;^$|^#&apos;hostname = dhub-dev.dwbops.comui_url_protocol = httpsmax_job_workers = 3customize_crt = onssl_cert = /data/cert/server.cerssl_cert_key = /data/cert/server.keysecretkey_path = /dataadmiral_url = NAlog_rotate_count = 50log_rotate_size = 200Memail_identity =email_server = smtp.mydomain.comemail_server_port = 25email_username = sample_admin@mydomain.comemail_password = abcemail_from = admin &lt;sample_admin@mydomain.com&gt;email_ssl = falseemail_insecure = falseharbor_admin_password = dHarbor12345auth_mode = db_authldap_url = ldaps://ldap.mydomain.comldap_basedn = ou=people,dc=mydomain,dc=comldap_uid = uidldap_scope = 2ldap_timeout = 5ldap_verify_cert = trueself_registration = ontoken_expiration = 30project_creation_restriction = everyonedb_host = mysqldb_password = root123db_port = 3306db_user = rootredis_url =clair_db_host = postgresclair_db_password = passwordclair_db_port = 5432clair_db_username = postgresclair_db = postgresuaa_endpoint = uaa.mydomain.orguaa_clientid = iduaa_clientsecret = secretuaa_verify_cert = trueuaa_ca_cert = /path/to/ca.pemregistry_storage_provider_name = filesystemregistry_storage_provider_config = 自己做测试时，将url类型设置成为http，并且将域名设置成为：harbar.wxh.com 修改完配置之后： 1$ sudo ./install.sh 整个的安装过程如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119[root@localhost harbor]# ./install.sh[Step 0]: checking installation environment ...Note: docker version: 18.06.1Note: docker-compose version: 1.22.0[Step 1]: loading Harbor images ...651f69aef02c: Loading layer [==================================================&gt;] 135.8MB/135.8MB40a1aad64343: Loading layer [==================================================&gt;] 23.24MB/23.24MB3fe2713e4072: Loading layer [==================================================&gt;] 12.16MB/12.16MBba3a1eb0e375: Loading layer [==================================================&gt;] 17.3MB/17.3MB447427ec5e1a: Loading layer [==================================================&gt;] 15.87kB/15.87kB4ccb4026663c: Loading layer [==================================================&gt;] 3.072kB/3.072kB16faa95946a1: Loading layer [==================================================&gt;] 29.46MB/29.46MBLoaded image: vmware/notary-server-photon:v0.5.1-v1.4.0fa7ba9fd42c9: Loading layer [==================================================&gt;] 10.95MB/10.95MB4e400f9ae23e: Loading layer [==================================================&gt;] 17.3MB/17.3MB2802fb27c88b: Loading layer [==================================================&gt;] 15.87kB/15.87kBe6367a4e1e1e: Loading layer [==================================================&gt;] 3.072kB/3.072kB8ece8dfcdd98: Loading layer [==================================================&gt;] 28.24MB/28.24MBLoaded image: vmware/notary-signer-photon:v0.5.1-v1.4.0a7dd1a8afcaf: Loading layer [==================================================&gt;] 396.7MB/396.7MB05adebbe496f: Loading layer [==================================================&gt;] 9.216kB/9.216kB86eb534949fa: Loading layer [==================================================&gt;] 9.216kB/9.216kBd7f127c69380: Loading layer [==================================================&gt;] 7.68kB/7.68kB5ac1c4dc5ee9: Loading layer [==================================================&gt;] 1.536kB/1.536kBd0bec56b5b1a: Loading layer [==================================================&gt;] 9.728kB/9.728kB4bbe83860556: Loading layer [==================================================&gt;] 2.56kB/2.56kBe526f9e6769f: Loading layer [==================================================&gt;] 3.072kB/3.072kBLoaded image: vmware/harbor-db:v1.4.01cff102bbda2: Loading layer [==================================================&gt;] 154.1MB/154.1MB04c9f3e07de1: Loading layer [==================================================&gt;] 10.75MB/10.75MB7b6c7bf54f5c: Loading layer [==================================================&gt;] 2.048kB/2.048kB42f8acdb7fe3: Loading layer [==================================================&gt;] 48.13kB/48.13kB5b6299d0a1df: Loading layer [==================================================&gt;] 10.8MB/10.8MBLoaded image: vmware/clair-photon:v2.0.1-v1.4.06534131f457c: Loading layer [==================================================&gt;] 94.76MB/94.76MB73f582101e4b: Loading layer [==================================================&gt;] 6.656kB/6.656kB86d847823c48: Loading layer [==================================================&gt;] 6.656kB/6.656kBLoaded image: vmware/postgresql-photon:v1.4.05cd250d5a352: Loading layer [==================================================&gt;] 23.24MB/23.24MBad3fd52b54f3: Loading layer [==================================================&gt;] 14.99MB/14.99MB13b1e24cc368: Loading layer [==================================================&gt;] 14.99MB/14.99MBLoaded image: vmware/harbor-adminserver:v1.4.0c26c69706710: Loading layer [==================================================&gt;] 23.24MB/23.24MB223f6fe02cc8: Loading layer [==================================================&gt;] 23.45MB/23.45MB1fc843c8698a: Loading layer [==================================================&gt;] 7.168kB/7.168kBe09293610ee7: Loading layer [==================================================&gt;] 10.39MB/10.39MBd59f9780b1d8: Loading layer [==================================================&gt;] 23.44MB/23.44MBLoaded image: vmware/harbor-ui:v1.4.0dd4753242e59: Loading layer [==================================================&gt;] 73.07MB/73.07MB95aed61ca251: Loading layer [==================================================&gt;] 3.584kB/3.584kB1864f9818562: Loading layer [==================================================&gt;] 3.072kB/3.072kBda2a19f80b81: Loading layer [==================================================&gt;] 4.096kB/4.096kB058531639e75: Loading layer [==================================================&gt;] 3.584kB/3.584kBa84e69fb619b: Loading layer [==================================================&gt;] 10.24kB/10.24kBLoaded image: vmware/harbor-log:v1.4.0b1056051f246: Loading layer [==================================================&gt;] 23.24MB/23.24MB07678065e08b: Loading layer [==================================================&gt;] 19.19MB/19.19MBa2d9bdb8f5fb: Loading layer [==================================================&gt;] 19.19MB/19.19MBLoaded image: vmware/harbor-jobservice:v1.4.07f58ce57cd5e: Loading layer [==================================================&gt;] 4.805MB/4.805MBLoaded image: vmware/nginx-photon:v1.4.04c8965978b77: Loading layer [==================================================&gt;] 23.24MB/23.24MB1466c942edde: Loading layer [==================================================&gt;] 2.048kB/2.048kBac5c17331735: Loading layer [==================================================&gt;] 2.048kB/2.048kB86824c7c466a: Loading layer [==================================================&gt;] 2.048kB/2.048kBfd3bd0e70d67: Loading layer [==================================================&gt;] 22.8MB/22.8MBb02195d77636: Loading layer [==================================================&gt;] 22.8MB/22.8MBLoaded image: vmware/registry-photon:v2.6.2-v1.4.0Loaded image: vmware/photon:1.0Loaded image: vmware/mariadb-photon:v1.4.0454c81edbd3b: Loading layer [==================================================&gt;] 135.2MB/135.2MBe99db1275091: Loading layer [==================================================&gt;] 395.4MB/395.4MB051e4ee23882: Loading layer [==================================================&gt;] 9.216kB/9.216kB6cca4437b6f6: Loading layer [==================================================&gt;] 9.216kB/9.216kB1d48fc08c8bc: Loading layer [==================================================&gt;] 7.68kB/7.68kB0419724fd942: Loading layer [==================================================&gt;] 1.536kB/1.536kB526b2156bd7a: Loading layer [==================================================&gt;] 637.8MB/637.8MB9ebf6900ecbd: Loading layer [==================================================&gt;] 78.34kB/78.34kBLoaded image: vmware/harbor-db-migrator:1.4[Step 2]: preparing environment ...Generated and saved secret to file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/ui/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/jobservice/app.confGenerated configuration file: ./common/config/ui/app.confGenerated certificate, key file: ./common/config/ui/private_key.pem, cert file: ./common/config/registry/root.crtThe configuration files are ready, please use docker-compose to start the service.[Step 3]: checking existing instance of Harbor ...[Step 4]: starting Harbor ...Creating network &quot;harbor_harbor&quot; with the default driverCreating harbor-log ... doneCreating harbor-db ... doneCreating registry ... doneCreating harbor-adminserver ... doneCreating harbor-ui ... doneCreating nginx ... doneCreating harbor-jobservice ... done✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at http://harbar.wxh.com.For more details, please visit https://github.com/vmware/harbor .[root@localhost harbor]# 配置文件Required parameters: hostname: The target host’s hostname, which is used to access the UI and the registry service. It should be the IP address or the fully qualified domain name (FQDN) of your target machine, e.g., 192.168.1.10 or reg.yourdomain.com. Do NOT use localhost or 127.0.0.1 for the hostname - the registry service needs to be accessible by external clients! hostname一般配置为域名,也就是整个harbor的入口 ui_url_protocol: (http or https. Default is http) The protocol used to access the UI and the token/notification service. If Notary is enabled, this parameter has to be https. By default, this is http. To set up the https protocol, refer to Configuring Harbor with HTTPS Access. 走HTT还是HTTPS db_password: The root password for the MySQL database used for db_auth. Change this password for any production use! max_job_workers: (default value is 3) The maximum number of replication workers in job service. For each image replication job, a worker synchronizes all tags of a repository to the remote destination. Increasing this number allows more concurrent replication jobs in the system. However, since each worker consumes a certain amount of network/CPU/IO resources, please carefully pick the value of this attribute based on the hardware resource of the host. 做复制工作的进程数量，默认3个，这些进程，将这些镜像同步到远端的存储中 每个进程都需要消耗系统的资源，因此合理设置数量 customize_crt: (on or off. Default is on) When this attribute is on, the prepare script creates private key and root certificate for the generation/verification of the registry’s token. Set this attribute to off when the key and root certificate are supplied by external sources. Refer to Customize Key and Certificate of Harbor Token Service for more info. ssl_cert: The path of SSL certificate, it’s applied only when the protocol is set to https ssl_cert_key: The path of SSL key, it’s applied only when the protocol is set to https secretkey_path: The path of key for encrypt or decrypt the password of a remote registry in a replication policy. log_rotate_count: Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated. log_rotate_size: Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes. If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G are all valid. http_proxy: Config http proxy for Clair, e.g. http://my.proxy.com:3128. https_proxy: Config https proxy for Clair, e.g. http://my.proxy.com:3128. no_proxy: Config no proxy for Clair, e.g. 127.0.0.1,localhost,core,registry. 镜像操作上传镜像push的格式为：docker push reg.yourdomain.com/myproject/myrepo:mytag 注意首先需要登录 将要上传的镜像打上标志 123docker tag hello-world harbar.wxh.com/apps/hello-worlddocker push harbar.wxh.com/apps/hello-world 这种上传的话，默认是打上latest的标志 打上指定的标签： 12docker tag hello-world harbar.wxh.com/apps/hello-world:v1docker push harbar.wxh.com/apps/hello-world:v1 harbor镜像删除在web页面上删除镜像实际上只是执行的软删除，因为镜像存在很强的文件系统依赖关系 Harbor的UI界面上先删除镜像，但这个操作并没有删除磁盘上存放的镜像文件，只是镜像文件manifest的映射关系，还需要通过GC来删除。 CAUTION: If both tag A and tag B refer to the same image, after deleting tag A, B will also get deleted. if you enabled content trust, you need to use notary command line tool to delete the tag’s signature before you delete an image. 注意，如果标签A和B都指向都一个镜像（比如hello-world的2个镜像），那么删除一个之后，另外一个也会消失 先停止Harbor： 1docker-compose stop 通过带有–dry-run选项，可以查看到将要删除的镜像文件： 1docker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect --dry-run /etc/registry/config.yml1 不带–dry-run选项，直接执行删除： 1docker run -it --name gc --rm --volumes-from registry vmware/registry:2.6.2-photon garbage-collect /etc/registry/config.yml1 再启动Harbor： 1docker-compose start 使用harbor-go-client项目地址：https://github.com/moooofly/harbor-go-client 操作步骤： 下载 1go get -u github.com/moooofly/harbor-go-client 安装 1make 在执行make的时候，可能会存在很多的依赖关系 有以下依赖关系需要解决： 1go get -u github.com/alecthomas/gometalinter 镜像清理策略需求： 暂时不做删除 repo 的处理【这部分手动处理】 保留 60 天内创建的所有 tag ，在 60 天之前创建的 tag ，额外保留 10 个； 标签数只有 1的镜像，不清理 保留最后一次更新的tag，有些image比较稳定，有可能超过60天都没有修改，但是却一直在用 针对一些特殊的（比如每天5个tag的镜像，那么60天就有300个），这个单独特殊处理 最终： 针对 tag ：保留 60 天内创建的所有 tag ，在 60 天之前创建的 tag ，额外保留 10 个； 针对 repo ：暂时不做删除 repo 的处理（不太好确定 repo 是否还在使用，理论上讲每个 repo 下至少应该有一个 tag 是被需要的；若打算删除，则建议 repo 负责人自行进行删除操作）； 私有仓库暂时不做处理； 具体实现： harbor 主要概念的关系：1 个 project -&gt; 每个 project 下具有 N 种不同的 repos &gt; 每个 repo 下具有 M 个 tags project 有创建时间，但这个对我们的处理策略来说没有用处； repo 有创建时间和 pull 时间，该 pull 时间对应 repo 下任意一个 tag ，最新一次，被拉取的那个时间 tag 有创建时间，但没有针对 tag 的 pull 时间（harbor 中定义的数据结构中不支持）； 因此 保留 60 天内的 tag”，这个根据 tag 的创建时间 “60 天之外的看 pull 的数量，关注 60 天之外是不是被 pull 过”，由于 pull 数量是针对 repo 整体的，无法对应到具体的 tag ，即在 API 层面无法方便的知道哪些 tag 最近被 pull 过（当然如果一定要做，就只能沟通分析 log 来搞，性价比不高），所以，只能根据 tag 创建时间的先后，“武断”的认为，后创建的 tag 应该是用户最想保留的； “如果没有被 pull 过，则只保留最新 5 个 tag”，根据上一条的说明，某个 tag 是否被 pull 过是无法知道的，但目前可以做到根据 tag 的创建时间进行保留（满足保留最新 N 个需求）； harbor镜像复制参考链接：https://github.com/goharbor/harbor/blob/master/docs/user_guide.md 该功能是面向项目的，系统管理员设置之后，匹配了过滤规则的项目，在触发了事先定义好的触发条件之后，这些项目就会被复制到远程的另一个仓库中。 如果在远程镜像仓库中，改项目不存在，那么就会自动创建这个项目 如果在远程仓库中，这个项目已经存在，并且配置的用户对这个项目没有写的权限，那么这个操作将会失败 注意：用户信息不会被复制 因为网络的原因，在复制传输的过程中，可能会出现一些延迟。如果复制job是因为网络原因而导致失败的，那么这个任务将会在几分钟之后再次尝试，一直尝试，知道网络恢复正常。 注意：因为api等原因，不同版本的镜像复制可能会失败，所以尽量使用同一个版本。 创建复制规则Click NEW REPLICATION RULE under Administration-&gt;Replications 注意，在创建endpoint的时候，直接test connection是会报错：“harbor Failed to ping endpoint” 这是因为网络问题导致，在内网访问的时候，还需要额外的添加hosts文件，详见注意事项 注意：在创建完毕之后，默认不会执行同步，需要手动点击一下replication 删除replication规则Only rules which have no pending/running/retrying jobs can be deleted. 只有当改规则下面没有正在运行或者等待运行或者正在重传的jobs时，才可以删除 注意事项在创建endpoint的时候，如果事先没有再容器内存配置对端的地址，那么会报连接错误 官方的issues：https://github.com/goharbor/harbor/issues/2221 Harborclient详见页面：https://github.com/int32bit/python-harborclient/blob/master/README.zh.md 常见问题1&gt; Why can not push image 192.168.0.1/hello-world:latest to Harbor? [A] At least two namespaces are needed for repository name in Harbor, so tag the image as 192.168.0.1/project_name/hello-world:latest should fix this. (Create the project on the web page first) 也就是说，在上传镜像的时候，应该是下面这种格式： 1docker push 192.168.0.1/project_name/hello-world:latest 因为在harbor中有项目的概念，也就是：访问地址/项目名称/镜像名称/版本标签 在使用dockerhub等进行镜像仓库的时候，用户名/id就是项目名称，因此不能创建多个项目名称，因为这种方式适合个人，但是不适用于企业。 企业中需要根据不同的项目类型进行分类存储，例如：apps、中间件等 证书问题证书生成： 1openssl req -sha256 -x509 -days 365 -nodes -newkey rsa:4096 -keyout harbar.wxh.com.key -out harbar.wxh.com.crt 注意，一些name的字段要配置成为域名harbar.wxh.com 生成之后，将证书存放到指定位置，然后修改配置文件指向这些证书文件 123less harbor.cfg | egrep -v &quot;^$|^#&quot;ssl_cert = /data/cert/harbar.wxh.com.crtssl_cert_key = /data/cert/harbar.wxh.com.key 然后需要对docker进行一些配置 mkdir -p /etc/docker/certs.d/harbar.wxh.com 然后将上面的文件复制到这个目录之下，并将/data/cert/harbar.wxh.com.crt重命名为/data/cert/harbar.wxh.com.cert 文件创建为目录问题/data1/harbor/data/secretkey secretkey为文件，而不是目录，在一些时候可能会出现这种问题，当出现这种问题的时候，将该目录清空，然后重新安装即可 汇总-docker常用命令12345678910111213141516docker build -t friendlyname . # Create image using this directory&apos;s Dockerfiledocker run -p 4000:80 friendlyname # Run &quot;friendlyname&quot; mapping port 4000 to 80docker run -d -p 4000:80 friendlyname # Same thing, but in detached modedocker container ls # List all running containersdocker container ls -a # List all containers, even those not runningdocker container stop &lt;hash&gt; # Gracefully stop the specified containerdocker container kill &lt;hash&gt; # Force shutdown of the specified containerdocker container rm &lt;hash&gt; # Remove specified container from this machinedocker container rm $(docker container ls -a -q) # Remove all containersdocker image ls -a # List all images on this machinedocker image rm &lt;image id&gt; # Remove specified image from this machinedocker image rm $(docker image ls -a -q) # Remove all images from this machinedocker login # Log in this CLI session using your Docker credentialsdocker tag &lt;image&gt; username/repository:tag # Tag &lt;image&gt; for upload to registrydocker push username/repository:tag # Upload tagged image to registrydocker run username/repository:tag # Run image from a registry]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>虚拟化</category>
        <category>Docker+k8s</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day06-面向对象编程]]></title>
    <url>%2F2018%2F08%2F20%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday06-%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[面向过程 VS 面向对象编程范式编程是 程序 员 用特定的语法+数据结构+算法组成的代码来告诉计算机如何执行任务的过程 （算法：其实就是解决一些问题的套路 一个程序是程序员为了得到一个任务结果而编写的一组指令的集合 正所谓条条大路通罗马，实现一个任务的方式有很多种不同的方式， 对这些不同的编程方式的特点进行归纳总结得出来的编程方式类别，即为编程范式。 不同的编程范式本质上代表对各种类型的任务采取的不同的解决问题的思路， 大多数语言只支持一种编程范式，当然也有些语言可以同时支持多种编程范式。 两种最重要的编程范式分别是面向过程编程和面向对象编程。 范式可以理解为某一个行业的标准，例如羽毛球中的标准动作（挥拍，高远球，走位等），基本上已经达成了统一的标准，那么编程也是一样的，目前已经想成了两种标准，分别适用于两种不同的应用场景，也可以理解为两套羽毛球标准，分别适用于不同的应用场景当中。 面向过程编程(Procedural Programming)Procedural programming uses a list of instructions to tell the computer what to do step-by-step. 面向过程编程，使用一系列的指令来告诉计算机一步一步的去做什么操作 面向过程编程依赖 - 你猜到了- procedures，一个procedure包含一组要被进行计算的步骤， 面向过程又被称为top-down languages， 就是程序从上到下一步步执行，一步步从上到下，从头到尾的解决问题 。 核心思想：基本设计思路就是程序一开始是要着手解决一个大的问题，然后把一个大问题分解成很多个小问题或子过程，这些子过程再执行的过程再继续分解直到小问题足够简单到可以在一个小步骤范围内解决。 举个典型的面向过程的例子， 数据库备份， 分三步，连接数据库，备份数据库，测试备份文件可用性。 这样做的问题也是显而易见的，就是如果你要对程序进行修改，对你修改的那部分有依赖的各个部分你都也要跟着修改，举个例子，如果程序开头你设置了一个变量值 为1 ， 但如果其它子过程依赖这个值 为1的变量才能正常运行，那如果你改了这个变量，那这个子过程你也要修改，假如又有一个其它子程序依赖这个子过程 ， 那就会发生一连串的影响，随着程序越来越大， 这种编程方式的维护难度会越来越高。 所以我们一般认为， 如果你只是写一些简单的脚本，去做一些一次性任务，用面向过程的方式是极好的，但如果你要处理的任务是复杂的，且需要不断迭代和维护 的， 那还是用面向对象最方便了。 面向对象编程OOP编程是利用“类”和“对象”来创建各种模型来实现对真实世界的描述，使用面向对象编程的原因一方面是因为它可以使程序的维护和扩展变得更简单，并且可以大大提高程序开发效率 ，另外，基于面向对象的程序可以使它人更加容易理解你的代码逻辑，从而使团队开发变得更从容。 面向对象的几个核心特性如下 Class 类一个类即是对一类拥有相同属性的对象的抽象、蓝图、原型。在类中定义了这些对象的都具备的属性（variables(data)）、共同的方法 世间万物，皆可分类！ 世间万物，皆为对象！ Object 对象一个对象即是一个类的实例化后实例，一个类必须经过实例化后方可在程序中调用，一个类可以实例化多个对象，每个对象亦可以有不同的属性，就像人类是指所有人，每个人是指具体的对象，人与人之前有共性，亦有不同 Encapsulation 封装在类中对数据的赋值、内部调用对外部用户是透明的，这使类变成了一个胶囊或容器，里面包含着类的数据和方法 例如，可以把类的方法都封装起来，内部的代码不会被暴露在外部，而是隐藏起来，只需要调用即可使用该功能 Inheritance 继承一个类可以派生出子类，在这个父类里定义的属性、方法自动被子类继承 Polymorphism 多态多态是面向对象的重要特性,简单点说:“一个接口，多种实现”，指一个基类中派生出了不同的子类，且每个子类在继承了同样的方法名的同时又对父类的方法做了不同的实现，这就是同一种事物表现出的多种形态。 编程其实就是一个将具体世界进行抽象化的过程，多态就是抽象化的一种体现，把一系列具体事物的共同点抽象出来, 再通过这个抽象的事物, 与不同的具体事物进行对话。对不同类的对象发出相同的消息将会有不同的行为。比如，你的老板让所有员工在九点钟开始工作, 他只要在九点钟的时候说：“开始工作”即可，而不需要对销售人员说：“开始销售工作”，对技术人员说：“开始技术工作”, 因为“员工”是一个抽象的事物, 只要是员工就可以开始工作，他知道这一点就行了。至于每个员工，当然会各司其职，做各自的工作。 在这里，工作就相当于父类的方法，而子类继承了之后，针对这个方法，会有不同的实现方式。 相当于是同一个东西，表面上是明确的不变，但是内部是不断在变化的。 多态允许将子类的对象当作父类的对象使用，某父类型的引用指向其子类型的对象,调用的方法是该子类型的方法。这里引用和调用方法的代码编译前就已经决定了,而引用所指向的对象可以在运行期间动态绑定 封装、继承、多态是面向对象的3个特性 面向对象编程(Object-Oriented Programming )介绍对于编程语言的初学者来讲，OOP不是一个很容易理解的编程方式，大家虽然都按老师讲的都知道OOP的三大特性是继承、封装、多态，并且大家也都知道了如何定义类、方法等面向对象的常用语法，但是一到真正写程序的时候，还是很多人喜欢用函数式编程来写代码，特别是初学者，很容易陷入一个窘境就是“我知道面向对象，我也会写类，但我依然没发现在使用了面向对象后，对我们的程序开发效率或其它方面带来什么好处，因为我使用函数编程就可以减少重复代码并做到程序可扩展了，为啥子还用面向对象？”。 对于此，我个人觉得原因应该还是因为你没有充分了解到面向对象能带来的好处，今天我就写一篇关于面向对象的入门文章，希望能帮大家更好的理解和使用面向对象编程。 无论用什么形式来编程，我们都要明确记住以下原则： 写重复代码是非常不好的低级行为 你写的代码需要经常变更 开发正规的程序跟那种写个运行一次就扔了的小脚本一个很大不同就是，你的代码总是需要不断的更改，不是修改bug就是添加新功能等，所以为了日后方便程序的修改及扩展，你写的代码一定要遵循易读、易改的原则（专业数据叫可读性好、易扩展）。 如果你把一段同样的代码复制、粘贴到了程序的多个地方以实现在程序的各个地方调用 这个功能，那日后你再对这个功能进行修改时，就需要把程序里多个地方都改一遍，这种写程序的方式是有问题的，因为如果你不小心漏掉了一个地方没改，那可能会导致整个程序的运行都 出问题。 因此我们知道 在开发中一定要努力避免写重复的代码，否则就相当于给自己再挖坑。 还好，函数的出现就能帮我们轻松的解决重复代码的问题，对于需要重复调用的功能，只需要把它写成一个函数，然后在程序的各个地方直接调用这个函数名就好了，并且当需要修改这个功能时，只需改函数代码，然后整个程序就都更新了。 其实OOP编程的主要作用也是使你的代码修改和扩展变的更容易，那么小白要问了，既然函数都能实现这个需求了，还要OOP干毛线用呢？ 呵呵，说这话就像，古时候，人们打仗杀人都用刀，后来出来了枪，它的主要功能跟刀一样，也是杀人，然后小白就问，既然刀能杀人了，那还要枪干毛线，哈哈，显而易见，因为枪能更好更快更容易的杀人。函数编程与OOP的主要区别就是OOP可以使程序更加容易扩展和易更改。 __init__和self类的写法是下面这个样子： 123456789101112class Dog(object): def __init__(self,name,type): self.name = name self.type = type def sayhi(self): print (&quot;hello, I am a dog,my name is &#123;name&#125;&quot;.format(name=self.name))dog1 = Dog(&apos;wxh&apos;,&apos;二哈&apos;)dog1.sayhi() 其实self,就是实例本身！你实例化时python会自动把这个实例本身通过self参数传进去。 上面的这个init()叫做初始化方法(或构造方法)， 在类被调用时，这个方法(虽然它是函数形式，但在类中就不叫函数了,叫方法)会自动执行，进行一些初始化的动作我们这里写__init__(self,name,role,weapon,life_value=100,money=15000)就是要在创建一个角色时给它设置这些属性，那么这第一个参数self是干毛用的呢？ 初始化一只狗，就需要调用这个类一次： 1`r1 ``=` `Role(``&apos;Alex&apos;``,``&apos;police&apos;``,&apos;AK47’) ``#生成一个角色 , 会自动把参数传给Role下面的__init__(...)方法``r2 ``=` `Role(``&apos;Jack&apos;``,``&apos;terrorist&apos;``,&apos;B22’) ``#生成一个角色` 我们看到，上面的创建角色时，我们并没有给__init__传值，程序也没未报错，是因为，类在调用它自己的init(…)时自己帮你给self参数赋值了， 我们再来定义一个类 123456789class Role(object): #定义一个类， class是定义类的语法，Role是类名，(object)是新式类的写法，必须这样写，以后再讲为什么 def __init__(self,name,role,weapon,life_value=100,money=15000): #初始化函数，在生成一个角色时要初始化的一些属性就填写在这里 self.name = name #__init__中的第一个参数self,和这里的self都 是什么意思？ 看下面解释 self.role = role self.weapon = weapon self.life_value = life_value self.money = money def buy_gun(self,gun_name): print(“%s has just bought %s” %(self.name,gun_name) ) 当执行r1 = Role(‘Alex’,’police’,’AK47’)创建一个对象时，python的解释器其实干了两件事： 在内存中开辟一块空间指向r1这个变量名 调用Role这个类并执行其中的__init__(…)方法，相当于Role.__init__(r1,’Alex’,’police’,AK47’),这么做是为什么呢？ 是为了把’Alex’,’police’,’AK47’这3个值跟刚开辟的r1关联起来，是为了把’Alex’,’police’,’AK47’这3个值跟刚开辟的r1关联起来，是为了把’Alex’,’police’,’AK47’这3个值跟刚开辟的r1关联起来，重要的事情说3次， 因为关联起来后，你就可以直接r1.name, r1.weapon 这样来调用啦。所以，为实现这种关联，在调用__init__方法时，就必须把r1这个变量也传进去，否则__init__不知道要把那3个参数跟谁关联呀。 所以这个__init__(…)方法里的，self.name = name , self.role = role 等等的意思就是要把这几个值 存到r1的内存空间里。 __init__(…)基本懂了，但后面的那几个函数，噢 不对，后面那几个方法 为什么也还需要self参数么？ 不是在初始化角色的时候 ，就已经把角色的属性跟r1绑定好了么？ 上面这个方法通过类调用的话要写成如下： 1`r1 ``=` `Role(``&apos;Alex&apos;``,``&apos;police&apos;``,``&apos;AK47&apos;``)``r1.buy_gun(``&quot;B21”) #python 会自动帮你转成 Role.buy_gun(r1,”B21&quot;``)` 执行结果 #Alex has just bought B21 我们依然没给self传值 ，但Python还是会自动的帮你把r1 赋值给self这个参数， 为什么呢？ 因为，你在buy_gun(..)方法中可能要访问r1的一些其它属性呀， 比如这里就访问 了r1的名字，怎么访问呢？你得告诉这个方法呀，于是就把r1传给了这个self参数，然后在buy_gun里调用 self.name 就相当于调用r1.name 啦，如果还想知道r1的生命值 有多少，直接写成self.life_value就可以了。 说白了就是在调用类中的一个方法时，你得告诉人家你是谁。 好啦， 总结一下2点： 上面的这个r1 = Role(‘Alex’,’police’,’AK47’)动作，叫做类的“实例化”， 就是把一个虚拟的抽象的类，通过这个动作，变成了一个具体的对象了， 这个对象就叫做实例 刚才定义的这个类体现了面向对象的第一个基本特性，封装，其实就是使用构造方法将内容封装到某个具体对象中，然后通过对象直接或者self间接获取被封装的内容 父类继承object的原因引用知乎，链接：https://www.zhihu.com/question/19754936/answer/202650790 继承 object 类的是新式类，不继承 object 类的是经典类，在 Python 2.7 里面新式类和经典类在多继承方面会有差异： 1234567891011121314151617class A: def foo(self): print(&apos;called A.foo()&apos;)class B(A): passclass C(A): def foo(self): print(&apos;called C.foo()&apos;)class D(B, C): passif __name__ == &apos;__main__&apos;: d = D() d.foo() B、C 是 A 的子类，D 多继承了 B、C 两个类，其中 C 重写了 A 中的 foo() 方法。 如果 A 是经典类（如上代码），当调用 D 的实例的 foo() 方法时，Python 会按照深度优先的方法去搜索 foo() ，路径是 B-A-C ，执行的是 A 中的 foo() ； 如果 A 是新式类，当调用 D 的实例的 foo() 方法时，Python 会按照广度优先的方法去搜索 foo() ，路径是 B-C-A ，执行的是 C 中的 foo() 。 因为 D 是直接继承 C 的，从逻辑上说，执行 C 中的 foo() 更加合理，因此新式类对多继承的处理更为合乎逻辑。 在 Python 3.x 中的新式类貌似已经兼容了经典类，无论 A 是否继承 object 类， D 实例中的 foo() 都会执行 C 中的 foo() 。但是在 Python 2.7 中这种差异仍然存在，因此还是推荐使用新式类，要继承 object 类。 类变量12345678910111213141516171819class animal(object): n = &quot;dff&quot; def __init__(self,name,type): self.name = name self.type = type def sayhi(self): print (&quot;hello, I am a dog,my name is &#123;name&#125;&quot;.format(name=self.name)) def talk(self): raise NotImplementedError(&quot;Subclass must implement abstract method&quot;)a1 = animal(&quot;wxh&quot;,&quot;二哈&quot;)print (animal.n)print (a1.n,a1.name)执行后输出为：dffdff wxh 注意：如果类变量和实例变量的名称一致，那么生效的是实例变量，也就是局部生效 类变量：所有实例共用的属性，节省开销 析构函数作用：在实例/对象释放、销毁的时候自动执行的，通常用于一些收尾工作，例如关闭一些数据库连接，关闭打开的临时文件。 注意：不是在实例/对象结束的时候执行，而是在释放或者销毁的时候自动执行，通过下方的代码可以看出效果 书写格式如下所示： 1234567891011121314151617181920class animal(object): name = &quot;dff&quot; def __init__(self,name,type): self.name = name self.type = type def sayhi(self): print (&quot;hello, I am a dog,my name is &#123;name&#125;&quot;.format(name=self.name)) def talk(self): raise NotImplementedError(&quot;Subclass must implement abstract method&quot;) def __del__(self): print(&quot;析构函数&quot;)a1 = animal(&quot;wxh&quot;,&quot;二哈&quot;)a2 = animal(&quot;wxg&quot;,&quot;金毛&quot;)print (animal.name)print (a1.name)print(a2.name) 执行后输出如下： 12345dffwxhwxg析构函数析构函数 手动的删除 123456789101112131415161718192021class animal(object): name = &quot;dff&quot; def __init__(self,name,type): self.name = name self.type = type def sayhi(self): print (&quot;hello, I am a dog,my name is &#123;name&#125;&quot;.format(name=self.name)) def talk(self): raise NotImplementedError(&quot;Subclass must implement abstract method&quot;) def __del__(self): print(&quot;析构函数&quot;)a1 = animal(&quot;wxh&quot;,&quot;二哈&quot;)a2 = animal(&quot;wxg&quot;,&quot;金毛&quot;)print (animal.name)print (a1.name)del a1print(a2.name) 这种情况下执行后的输出为： 12345dffwxh析构函数wxg析构函数 私有属性在构造方法中定义的私有属性，直接调用获取是不行的，要想使用的话，需要在定义一个方法，在内部进行访问之后，再将值返回出去。 代码如下： 1234567891011121314151617181920212223class animal(object): name = &quot;dff&quot; def __init__(self,name,type,attr): self.name = name self.type = type self.__private_att = attr def sayhi(self): print (&quot;hello, I am a dog,my name is &#123;name&#125;&quot;.format(name=self.name)) def talk(self): raise NotImplementedError(&quot;Subclass must implement abstract method&quot;) def __del__(self): print(&quot;析构函数&quot;) def show_pri(self): print (&quot;the private attr is &#123;private&#125;&quot;.format(private=self.__private_att))a1 = animal(&quot;wxh&quot;,&quot;二哈&quot;,&quot;pri_test&quot;)print (a1.name)a1.show_pri()print (a1.__private_att) 执行后输出如下： 1234567wxhthe private attr is pri_testTraceback (most recent call last):析构函数 File &quot;/Users/wangxiaohua/PycharmProjects/python14/day06/classtest.py&quot;, line 23, in &lt;module&gt; print (a1.__private_att)AttributeError: &apos;animal&apos; object has no attribute &apos;__private_att&apos; 可以看到，我们使用定义的这个方法去调用是不会报错的，但是直接显示该对象的私有属性的时候，是无法显示的。 私有方法私有方法和私有属性也是一样的，在定义的是前面加上__ 123456789101112131415161718192021222324class animal(object): name = &quot;dff&quot; def __init__(self,name,type,attr): self.name = name self.type = type self.__private_att = attr def __sayhi(self): print (&quot;hello, I am a dog,my name is &#123;name&#125;&quot;.format(name=self.name)) def talk(self): raise NotImplementedError(&quot;Subclass must implement abstract method&quot;) def __del__(self): print(&quot;析构函数&quot;) def show_pri(self): print (&quot;the private attr is &#123;private&#125;&quot;.format(private=self.__private_att))a1 = animal(&quot;wxh&quot;,&quot;二哈&quot;,&quot;pri_test&quot;)print (a1.name)a1.show_pri()a1.__sayhi() 执行后输出为： 1234567wxhTraceback (most recent call last):the private attr is pri_test File &quot;/Users/wangxiaohua/PycharmProjects/python14/day06/classtest.py&quot;, line 24, in &lt;module&gt;析构函数 a1.__sayhi()AttributeError: &apos;animal&apos; object has no attribute &apos;__sayhi&apos; 子类继承保留父类属性在继承之后，可以在子类中将父类的方法进行重构，但是重构的话，父类原有的动作就不会保留，那么，当我们需要保留父类的内容，也就是说子类是添加操作，在调用的时候，先执行父类的代码，再执行子类的代码，那么这种方式应该如何实现？ 1234567891011121314151617181920class People(object): def __init__(self,name,age): self.name = name self.age = age def eat(self): print(&quot;&#123;name&#125; is eating&quot;.format(name=self.name)) def age(self): print(&quot;&#123;name&#125; is &#123;age&#125; years old&quot;.format(name=self.name,age=self.age))class Man(People): def eat(self): People.eat(self) print(&quot;subclass content&quot;)man1 = Man(&quot;wxh&quot;,11)man1.eat() 执行后输出如下： 12wxh is eatingsubclass content 默认情况下，我们不做任何修改的话，就会继承父类的属性 子类添加私有属性在继承父类的之后，如果想要添加自己的属性，那么需要使用下面的这种方式： 123456789101112131415161718192021class People(object): def __init__(self,name,age): self.name = name self.age = age def eat(self): print(&quot;&#123;name&#125; is eating&quot;.format(name=self.name)) def age(self): print(&quot;&#123;name&#125; is &#123;age&#125; years old&quot;.format(name=self.name,age=self.age))class Man(People): def __init__(self,name,age,money): People.__init__(self,name,age) self.money = money print (&quot;&#123;name&#125; has &#123;money&#125;$&quot;.format(name=self.name,money=self.money)) def eat(self): People.eat(self) print(&quot;subclass content&quot;)man1 = Man(&quot;wxh&quot;,11,&quot;1000&quot;) 执行后输出如下： 1wxh has 1000 $ 可以知道，这个输出并没有调用什么方法，而是子类的构造函数（__init__）输出的 说明： 因为是完全覆盖的父类，因此需要把父类的参数全部写一遍 然后再调用父类的方法 在子类中重新编写构造方法，注意在定义的时候，父类的属性还是要保留，不能直接覆盖，因为在后续使用的时候，实例化这个子类之后，如果还需要调用父类的属性的时候，还需要有这个属性 子类的构造方法中需要需要再调用父类的构造方法（因为父类的构造方法中可能会比较复杂，所有采取直接调用的方式），注意，传入的参数是子类在最外层继承父类的，需要保持一致 调用了父类的构造方法之后，再在下方定义子类的属性 父类的继承还有另外一种写法： 123People.__init__(self,name,age)可以写成super(Man,self).__init__(name,age) super是一种内置的方法 使用这种方式的话，之后如果父类的名称修改了，那么只需要在继承的括号中修改，函数体中不需要再修改。 但是在涉及到继承多个类的时候，并且父类的属性不同时，这种方式就比不是太友好 多继承1234567891011121314151617181920212223242526272829303132333435class People(object): def __init__(self,name,age): self.name = name self.age = age def eat(self): print(&quot;&#123;name&#125; is eating&quot;.format(name=self.name)) def age(self): print(&quot;&#123;name&#125; is &#123;age&#125; years old&quot;.format(name=self.name,age=self.age))class Relation(object): def makefriend(self,object): print (&quot;&#123;name1&#125; is make friend with &#123;name2&#125;&quot;.format(name1=self.name,name2=object.name))class Man(People,Relation): def __init__(self,name,age,money): # People.__init__(self,name,age) super(Man,self).__init__(name,age) self.money = money # print (&quot;&#123;name&#125; has &#123;money&#125;$&quot;.format(name=self.name,money=self.money)) def eat(self): People.eat(self) print(&quot;subclass content&quot;)class Woman(People,Relation): def __init__(self,name,age): People.__init__(self,name,age) def get_birth(self): print (&quot;&#123;name&#125; git_birth&quot;.format(name=self.name))man1 = Man(&quot;wxh&quot;,11,&quot;1000&quot;)women1 = Woman(&quot;xxx&quot;,11) 执行后输出如下： 1wxh is make friend with xxx 多态多态特性：一种接口，多种实现 多态性（polymorphisn）是允许你将父对象设置成为和一个或更多的他的子对象相等的技术，赋值之后，父对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。简单的说，就是一句话：允许将子类类型的指针赋值给父类类型的指针。 那么，多态的作用是什么呢？我们知道，封装可以隐藏实现细节，使得代码模块化；继承可以扩展已存在的代码模块（类）；它们的目的都是为了——代码重用。而多态则是为了实现另一个目的——接口重用！多态的作用，就是为了类在继承和派生的时候，保证使用“家谱”中任一类的实例的某一属性时的正确调用。 Pyhon 很多语法都是支持多态的，比如 len(),sorted(), 你给len传字符串就返回字符串的长度，传列表就返回列表长度。 Python多态示例 123456789101112131415161718192021222324252627282930#_*_coding:utf-8_*_ class Animal(object): def __init__(self, name): # Constructor of the class self.name = name def talk(self): # Abstract method, defined by convention only raise NotImplementedError(&quot;Subclass must implement abstract method&quot;) class Cat(Animal): def talk(self): print(&apos;%s: 喵喵喵!&apos; %self.name) class Dog(Animal): def talk(self): print(&apos;%s: 汪！汪！汪！&apos; %self.name) def func(obj): #一个接口，多种形态 obj.talk() c1 = Cat(&apos;小晴&apos;)d1 = Dog(&apos;李磊&apos;) func(c1)func(d1) 简单的说，多态其实就是子类重新实现父类的方法，实现接口的重用，然后通过重新定义一个接口去匹配调用 最终，我们要把这个函数放置到父类当中 然后通过下面的方式去调用 12man1 = Man(&quot;wxh&quot;,11,&quot;1000&quot;)People.people_eat(man1) 领域模型很多同学都是学会了面向对象的语法，却依然写不出面向对象的程序，原因是什么呢？原因就是因为你还没掌握一门面向对象设计利器， 你说我读书少别骗我， 什么利器？ 答案就是:领域建模。 从领域模型开始,我们就开始了面向对象的分析和设计过程,可以说,领域模型是完成从需求分析到面向 对象设计的一座桥梁。 领域模型,顾名思义,就是需求所涉及的领域的一个建模,更通俗的讲法是业务模型。 参考百度百科(http://baike.baidu.cn/view/757895.htm ),领域模型定义如下: 从这个定义我们可以看出,领域模型有两个主要的作用: 发掘重要的业务领域概念 建立业务领域概念之间的关系 领域建模三字经 领域模型如此重要,很多同学可能会认为领域建模很复杂,需要很高的技巧。然而事实上领域建模非常简 单,简单得有点难以让人相信,领域建模的方法概括一下就是“找名词”! 许多同学看到这个方法后估计都会笑出来:太假了吧,这么简单,找个初中生都会啊,那我们公司那些分 析师和设计师还有什么用哦? 分析师和设计师当然有用,后面我们会看到,即使是简单的找名词这样的操作,也涉及到分析和提炼,而 不是简单的摘取出来就可,这种情况下分析师和设计师的经验和技能就能够派上用场了。但领域模型分析 也确实相对简单,即使没有丰富的经验和高超的技巧,至少也能完成一个能用的领域模型。 虽然我们说“找名词”很简单,但一个关键的问题还没有说明:从哪里找? 如果你还记得领域模型是“需求到面向对象的桥梁”,那么你肯定一下子就能想到:从需求模型中找,具 体来说就是从用例中找。 归纳一下域建模的方法就是“从用例中找名词”。 当然,找到名词后,为了能够更加符合面向对象的要求和特点,我们还需要对这些名词进一步完善,这就 是接下来的步骤:加属性,连关系! 最后我们总结出领域建模的三字经方法:找名词、加属性、连关系。]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python import模块相关问题]]></title>
    <url>%2F2018%2F08%2F16%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fpython-import%E6%A8%A1%E5%9D%97%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[参考文献： 关于python——import问题 python导入模块的几种姿势 python import在python中，每个py文件被称之为模块，每个具有__init__.py文件的目录被称为包。只要模块或者包所在的目录在sys.path中，就可以使用import 模块或import 包来使用。 作为一名新手Python程序员，你首先需要学习的内容之一就是如何导入模块或包。但是我注意到，那些许多年来不时使用Python的人并不是都知道Python的导入机制其实非常灵活。在本文中，我们将探讨以下话题： 常规导入（regular imports） 使用from语句导入 相对导入（relative imports） 可选导入（optional imports） 本地导入（local imports） 导入注意事项 常规导入常规导入应该是最常使用的导入方式，大概是这样的： 1import sys 你只需要使用import一词，然后指定你希望导入的模块或包即可。通过这种方式导入的好处是可以一次性导入多个包或模块： 1import os, sys, time 虽然这节省了空间，但是却违背了Python风格指南。Python风格指南建议将每个导入语句单独成行。 有时在导入模块时，你想要重命名这个模块。这个功能很容易实现： 123import sys as systemprint(system.platform) 上面的代码将我们导入的sys模块重命名为system。我们可以按照和以前一样的方式调用模块的方法，但是可以用一个新的模块名。也有某些子模块必须要使用点标记法才能导入。 1import urllib.error 这个情况不常见，但是对此有所了解总是没有坏处的。 注意： import导入为绝对导入 import 只能导入模块，不能导入模块中的对象（类、函数、变量等) Python 中所有加载到内存的模块都放在 sys.modules 。当 import 一个模块时首先会在这个列表中查找是否已经加载了此模块，如果没有加载则从 sys.path 目录中按照模块名称查找模块文件，找到后将模块载入内存，并加到 sys.modules 中。只有存在sys.path中的模块才会被正确导入。 一个模块不会重复载入。多个不同的模块都可以用 import 引入同一个模块到自己的 Local 名字空间，其实背后的 PyModuleObject 对象只有一个。 一个容易忽略的问题：import 只能导入模块，不能导入模块中的对象（类、函数、变量等）。例如：模块 A（A.py）中有个函数 getName，另一个模块不能通过 import A.getName 将 getName导入到本模块，只能用 from A import getName。 同级目录下，可以使用import直接导入所需模块 使用from语句导入很多时候你只想要导入一个模块或库中的某个部分。我们来看看在Python中如何实现这点： 1from functools import lru_cache 上面这行代码可以让你直接调用lru_cache。如果你按常规的import方式导入functools，那么你就必须像这样调用lru_cache： 1functools.lru_cache(*args) 根据你实际的使用场景，上面的做法可能是更好的。在复杂的代码库中，能够看出某个函数是从哪里导入的这点很有用的。不过，如果你的代码维护的很好，模块化程度高，那么只从某个模块中导入一部分内容也是非常方便和简洁的。 当然，你还可以使用from方法导入模块的全部内容，就像这样： 1from os import * 这种做法在少数情况下是挺方便的，但是这样也会打乱你的命名空间。问题在于，你可能定义了一个与导入模块中名称相同的变量或函数，这时如果你试图使用os模块中的同名变量或函数，实际使用的将是你自己定义的内容。因此，你最后可能会碰到一个相当让人困惑的逻辑错误。标准库中我唯一推荐全盘导入的模块只有Tkinter。 如果你正好要写自己的模块或包，有人会建议你在__init__.py文件中导入所有内容，让模块或者包使用起来更方便。我个人更喜欢显示地导入，而非隐式地导入。 你也可以采取折中方案，从一个包中导入多个项： 12from os import path, walk, unlinkfrom os import uname, remove 在上述代码中，我们从os模块中导入了5个函数。你可能注意到了，我们是通过多次从同一个模块中导入实现的。当然，如果你愿意的话，你也可以使用圆括号一次性导入多个项： 12from os import (path, walk, unlink, uname, remove, rename) 这是一个有用的技巧，不过你也可以换一种方式： 12from os import path, walk, unlink, uname, \ remove, rename 上面的反斜杠是Python中的续行符，告诉解释器这行代码延续至下一行。 相对导入PEP 328介绍了引入相对导入的原因，以及选择了哪种语法。具体来说，是使用句点来决定如何相对导入其他包或模块。这么做的原因是为了避免偶然情况下导入标准库中的模块产生冲突。这里我们以PEP 328中给出的文件夹结构为例，看看相对导入是如何工作的： 12345678910my_package/ __init__.py subpackage1/ __init__.py module_x.py module_y.py subpackage2/ __init__.py module_z.py module_a.py 在本地磁盘上找个地方创建上述文件和文件夹。在顶层的__init__.py文件中，输入以下代码： 12from . import subpackage1from . import subpackage2 接下来进入subpackage1文件夹，编辑其中的__init__.py文件，输入以下代码： 12from . import module_xfrom . import module_y 现在编辑module_x.py文件，输入以下代码： 1234from .module_y import spam as hamdef main(): ham() 最后编辑module_y.py文件，输入以下代码： 12def spam(): print(&apos;spam &apos; * 3) 打开终端，cd至my_package包所在的文件夹，但不要进入my_package。在这个文件夹下运行Python解释器。我使用的是IPython，因为它的自动补全功能非常方便： 1234567In [1]: import my_packageIn [2]: my_package.subpackage1.module_xOut[2]: &lt;module &apos;my_package.subpackage1.module_x&apos; from &apos;my_package/subpackage1/module_x.py&apos;&gt;In [3]: my_package.subpackage1.module_x.main()spam spam spam 相对导入适用于你最终要放入包中的代码。如果你编写了很多相关性强的代码，那么应该采用这种导入方式。你会发现PyPI上有很多流行的包也是采用了相对导入。还要注意一点，如果你想要跨越多个文件层级进行导入，只需要使用多个句点即可。不过，PEP 328建议相对导入的层级不要超过两层。 还要注意一点，如果你往module_x.py文件中添加了if __name__ == ‘__main__’，然后试图运行这个文件，你会碰到一个很难理解的错误。编辑一下文件，试试看吧！ 12345678from . module_y import spam as hamdef main(): ham()if __name__ == &apos;__main__&apos;: # This won&apos;t work! main() 现在从终端进入subpackage1文件夹，执行以下命令： 1python module_x.py 如果你使用的是Python 2，你应该会看到下面的错误信息： 1234Traceback (most recent call last): File &quot;module_x.py&quot;, line 1, in &lt;module&gt; from . module_y import spam as hamValueError: Attempted relative import in non-package 如果你使用的是Python 3，错误信息大概是这样的： 1234Traceback (most recent call last): File &quot;module_x.py&quot;, line 1, in &lt;module&gt; from . module_y import spam as hamSystemError: Parent module &apos;&apos; not loaded, cannot perform relative import 这指的是，module_x.py是某个包中的一个模块，而你试图以脚本模式执行，但是这种模式不支持相对导入。 如果你想在自己的代码中使用这个模块，那么你必须将其添加至Python的导入检索路径（import search path）。最简单的做法如下： 123import syssys.path.append(&apos;/path/to/folder/containing/my_package&apos;)import my_package 注意，你需要添加的是my_package的上一层文件夹路径，而不是my_package本身。原因是my_package就是我们想要使用的包，所以如果你添加它的路径，那么将无法使用这个包。 我们接下来谈谈可选导入。 可选导入（Optional imports）如果你希望优先使用某个模块或包，但是同时也想在没有这个模块或包的情况下有备选，你就可以使用可选导入这种方式。这样做可以导入支持某个软件的多种版本或者实现性能提升。以github2包中的代码为例： 123456789try: # For Python 3 from http.client import responsesexcept ImportError: # For Python 2.5-2.7 try: from httplib import responses # NOQA except ImportError: # For Python 2.4 from BaseHTTPServer import BaseHTTPRequestHandler as _BHRH responses = dict([(k, v[0]) for k, v in _BHRH.responses.items()]) lxml包也有使用可选导入方式： 1234567try: from urlparse import urljoin from urllib2 import urlopenexcept ImportError: # Python 3 from urllib.parse import urljoin from urllib.request import urlopen 正如以上示例所示，可选导入的使用很常见，是一个值得掌握的技巧。 局部导入当你在局部作用域中导入模块时，你执行的就是局部导入。如果你在Python脚本文件的顶部导入一个模块，那么你就是在将该模块导入至全局作用域，这意味着之后的任何函数或方法都可能访问该模块。例如： 12345678910111213import sys # global scopedef square_root(a): # This import is into the square_root functions local scope import math return math.sqrt(a)def my_pow(base_num, power): return math.pow(base_num, power)if __name__ == &apos;__main__&apos;: print(square_root(49)) print(my_pow(2, 3)) 这里，我们将sys模块导入至全局作用域，但我们并没有使用这个模块。然后，在square_root函数中，我们将math模块导入至该函数的局部作用域，这意味着math模块只能在square_root函数内部使用。如果我们试图在my_pow函数中使用math，会引发NameError。试着执行这个脚本，看看会发生什么。 使用局部作用域的好处之一，是你使用的模块可能需要很长时间才能导入，如果是这样的话，将其放在某个不经常调用的函数中或许更加合理，而不是直接在全局作用域中导入。老实说，我几乎从没有使用过局部导入，主要是因为如果模块内部到处都有导入语句，会很难分辨出这样做的原因和用途。根据约定，所有的导入语句都应该位于模块的顶部。 导入注意事项在导入模块方面，有几个程序员常犯的错误。这里我们介绍两个。 循环导入（circular imports） 覆盖导入（Shadowed imports，暂时翻译为覆盖导入） 先来看看循环导入。 循环导入如果你创建两个模块，二者相互导入对方，那么就会出现循环导入。例如： 12345678# a.pyimport bdef a_test(): print(&quot;in a_test&quot;) b.b_test()a_test() 然后在同个文件夹中创建另一个模块，将其命名为b.py。 1234567import adef b_test(): print(&apos;In test_b&quot;&apos;) a.a_test()b_test() 如果你运行任意一个模块，都会引发AttributeError。这是因为这两个模块都在试图导入对方。简单来说，模块a想要导入模块b，但是因为模块b也在试图导入模块a（这时正在执行），模块a将无法完成模块b的导入。我看过一些解决这个问题的破解方法（hack），但是一般来说，你应该做的是重构代码，避免发生这种情况。 覆盖导入当你创建的模块与标准库中的模块同名时，如果你导入这个模块，就会出现覆盖导入。举个例子，创建一个名叫math.py的文件，在其中写入如下代码： 123456import mathdef square_root(number): return math.sqrt(number)square_root(72) 现在打开终端，试着运行这个文件，你会得到以下回溯信息（traceback）： 12345678Traceback (most recent call last): File &quot;math.py&quot;, line 1, in &lt;module&gt; import math File &quot;/Users/michael/Desktop/math.py&quot;, line 6, in &lt;module&gt; square_root(72) File &quot;/Users/michael/Desktop/math.py&quot;, line 4, in square_root return math.sqrt(number)AttributeError: module &apos;math&apos; has no attribute &apos;sqrt&apos; 这到底是怎么回事？其实，你运行这个文件的时候，Python解释器首先在当前运行脚本所处的的文件夹中查找名叫math的模块。在这个例子中，解释器找到了我们正在执行的模块，试图导入它。但是我们的模块中并没有叫sqrt的函数或属性，所以就抛出了AttributeError。 总结在本文中，我们讲了很多有关导入的内容，但是还有部分内容没有涉及。PEP 302中介绍了导入钩子（import hooks），支持实现一些非常酷的功能，比如说直接从github导入。Python标准库中还有一个importlib模块，值得查看学习。当然，你还可以多看看别人写的代码，不断挖掘更多好用的妙招。]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAC操作技巧]]></title>
    <url>%2F2018%2F08%2F11%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7%2FMAC%E4%BD%BF%E7%94%A8%2FMAC%E6%93%8D%E4%BD%9C%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[美式键盘对应关系参考链接：https://support.apple.com/zh-cn/HT202676 在Mac的快捷键中经常会有一些符号，比如⌘、⌥、⇧、⌃等，而Mac下只有command键上有一个⌘的符号，而其他按键均没有符号，很多人可能不知道这是什么意思，之所以只有command键上有一个符号，而其他按键上没有，是因为： 只有command健才是Mac下唯一独有的一个特殊按键，而shift、alt（option）、control、caps lock、tab等在其他系统下都有，所以Mac在command键上做一个符号，用于表示这一按键的特殊性； 我们在生活中能接触到的外接键盘基本上都是美式键盘，下面是两种键盘的布局对应关系，在使用外接键盘的时候，需要有充分的了解。 文字描述： ⌘ —— Command (Windows键) ⌃ —— Control(Ctrl键) ⌥ —— Option (Alt) ⇧ —— Shift ⇪ —— Caps Lock FN —— FN(Insert) 括号里面是Windows对应的按键。以前Ctrl+C,Ctrl+V 现在要用Win+C,Win+V。 图形展示： Windows 标志：按下 Command (⌘) 键 退格或删除：按下 Delete 键 回车或 ⏎：按下 Return 键 Alt（左）：按下 Option 键 Alt GR（右）：按下 Option + Control 组合键 应用程序：Apple 键盘上没有这个按键 MAC常用快捷键概览先来一张图 全局操作 ⌃⌘ + f: 进入全屏模式 强制退出应用如果 Mac 上的某个应用停止响应，并且您无法正常退出该应用，则可以使用“强制退出”来关闭该应用。 同时按住三个按键：Option、Command 和 Esc (Escape) 键。这类似于在 PC 上按下 Control-Alt-Delete。或者，在屏幕左上角的苹果 () 菜单中选取“强制退出”。 强制刷新页面 正常刷新：command+r 强制刷新页面（刷新页面缓存）：command+shift+r 切换全屏页面ctrl+方向键的左右 控制中心ctrl+上箭头 软件包管理MAC上管理软件包我们一般使用Homebrew来实现 Homebrew是MAC必备神器之一，作为Mac OSX上的软件包管理工具，它能在Mac中方便的安装软件或者卸载软件， 简单到只需要一个命令。 安装： 1ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 命令参数： 123456brew install 安装软件brew list 列出已安装的软件brew update 更新brewbrew home 用浏览器打开brew的官方网站brew info 显示软件信息brew deps 显示包依赖 MAC下实现AutoHotKey功能在MAC下没有类似autohotkey的软件，但是它给我们提供了相应的工具，我们可以自定义的去实现功能 步骤1：从其他中进入automator（中文版的名称为：“自动操作”） 就是下面这位仁兄： 步骤2：创建服务 步骤3： 创建applescript，如下图所示，用鼠标将applescript选中并拖到右栏中 注意，需要先将服务收到一栏中从文本修改为没有输入 步骤4：编辑applescript 有关applescript的相关内容，网友可以自行查找，网上有非常多的资料。 简单说明下： tell语句，在这里调用谷歌浏览器程序（程序的实际名称可以打开终端，进入/Applications目录下ls查看） activate语句，这这里将调用出来的窗口显示在最前端 open location 语句，实际的操作，后面的参数是具体的链接地址 end tell语句，结束调用 步骤5：运行测试 点击两个运行中任一一个，可以看到网页会在最前端弹出，代码执行成功之后，缩进和颜色都会发生相应的变化。 步骤6： 保存为服务 输入command+s，在弹出的对话框中，输入自定义的名称 步骤7：设置快捷键 打开系统偏好设置–&gt;键盘—&gt;快捷键–&gt;服务–&gt;通用—&gt;选中刚才保存的服务–&gt;双击—&gt;在编辑器中，敲下自定义的快捷键，系统将会自动识别显示，如下图所示： 这个时候，设置就全部完毕，接下来我们就可以随时根据快捷键调用浏览器打开网页。 Iterm2操作快捷键标签 新建标签：command + t 关闭标签：command + w 切换标签：command + 数字 command + 左右方向键 切换全屏：command + enter 查找：command + f 分屏 垂直分屏：command + d 水平分屏：command + shift + d 切换屏幕：command + option + 方向键 或者 command + [ ] 命令 查看历史命令：command + ; 查看剪贴板历史：command + shift + h 上一条命令：ctrl + p 搜索命令历史：ctrl + r 行内 清除当前行：ctrl + u 到行首：ctrl + a 到行尾：ctrl + e 前进后退：ctrl + f/b (相当于左右方向键) 删除当前光标的字符：ctrl + d 删除光标之前的字符：ctrl + h 删除光标之前的单词：ctrl + w 删除到文本末尾：ctrl + k 交换光标处文本：ctrl + t 其他 清屏1：command + r 清屏2：ctrl + l 清屏3：clear 进入和退出全屏: Command + Enter 查看当前终端中光标的位置: Command + / 开启和关闭背景半透明: Command + u 清屏（重置当前终端）: Command + r 连接jumpserver Profile -&gt; Open Profiles… -&gt; Edit Profiles… 点击左下角+号 输入Profile Name，比如jumper 右边Command下选择Command，然后输入 1ssh -i /Users/yourname/.ssh/id_rsa username@ip -p port 关闭所有窗口 在Iterm2的一个窗口中选择右键New Tab或者command+o,在弹出的页面中选择刚创建的jumper，然后回车就登录上了。 注意，如果给RSA秘钥设置了密码，又不想每次在登录的时候都输出密码，这个时候我们可以在命令行中输入以下命令 1ssh-add -K /Users/yourname/.ssh/id_rsa 输入一次之后，后续就不用再次输入。 实现rz/sz功能Mac上iTerm原生不支持rz/sz命令，也就是不支持Zmodem来进行文件传输，不过只要通过简单的配置就可以实现。网上的教程一大把，这里就简单的记录一下过程。 安装lrzsz首先安装Homebrew(这里不写这个过程)，然后通过它先给Mac安装lrzsz。在终端下输入brew install lrzsz，静等一会即可安装完毕。 1brew install lrzsz 下载iTerm2辅助文件iTerm不能直接使用lrzsz，不过网上有大神提供了两个辅助脚本。我们只需要把文件下载到 /usr/local/bin/目录下并赋予可执行权限即可。 12345cd /usr/local/binwget https://raw.githubusercontent.com/mmastrac/iterm2-zmodem/master/iterm2-send-zmodem.shwget https://raw.githubusercontent.com/mmastrac/iterm2-zmodem/master/iterm2-recv-zmodem.shchmod +x iterm2-recv-zmodem.sh iterm2-send-zmodem.sh 这两个脚本实际是使用AppleScript来弹出文件选择窗口，然后把选中的文件名称传递给rzsz命令。我们打开其中一个看下代码。如果这一部分看不懂没关系，直接跳过即可，对后续的配置使用没有任何不良影响 配置iTerm2触发器这一步最关键，是在iTerm里面配置触发器，当监控到特定字符串的时候执行刚才下载的两个文件。为了使用方便，我专门建立了一个Profile配置，名字是Remote，并且配合后面的autossh使用。 打开iTerm2 -&gt; Preferences -&gt; Profiles 选择 Advanced 设置 Triggers ，点击 Edit 在弹出窗口中进行如下配置，最后的Instant一定要勾选上。 配置的具体内容在这里 1234567Regular expression: rz waiting to receive.\*\*B0100Action: Run Silent CoprocessParameters: /usr/local/bin/iterm2-send-zmodem.shRegular expression: \*\*B00000000000000Action: Run Silent CoprocessParameters: /usr/local/bin/iterm2-recv-zmodem.sh 重新启动iTerm之后，rz/sz就应该可以正常使用了。 Forklift操作在文件夹中搜索文件：command+s 常用文件夹-Favorites：alt+command+f ftp等传输工具：command+k 前进/后退：command+[/] 其他操作pycharm-光标变粗问题mac下默认的pycharm的光标是为粗体的改写模式，这是因为安装的时候装了ideaVim插件，改为竖线光标的方法：把ideaVim插件去掉（点击pycharm–&gt;preference–&gt;plugins–&gt;搜索ideavim，然后将该插件勾除掉即可） MAC版本snipaste截图后无法输入中文问题参考资料：https://jingyan.baidu.com/article/c1a3101e635d6ade646deb56.html 点击菜单栏截图软件的图标，选择退出软件。 接着按键盘上面的control+space ，选择拼音输入法。 这个时候就可以启动截图软件了，按键盘上的cmmand+space，在黑色框输入软件的名字回车。 点击软件图标，选择截图或者是按fn+f1，进行桌面的截图。 在截图上面，按空格键调出截图软件工具条，然后点击工具条上面的T，这个时候就可以在图片上面进行中文的标注了。总结就是用不了重启软件即可。]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>MAC操作技巧</category>
      </categories>
      <tags>
        <tag>MAC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day05-常用模块学习]]></title>
    <url>%2F2018%2F08%2F08%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday05-%E5%B8%B8%E7%94%A8%E6%A8%A1%E5%9D%97%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[基础知识 定义 模块：本质就是.py结尾的python文件 用来从逻辑上组织python代码（变量、函数、类、逻辑），目的是实现功能 包：用来从逻辑上组织模块，本质就是一个目录，必须带有一个init.py文件 导入包的本质其实就是执行该包下的init.py文件。 导入/使用方法 From import和import的区别？ 因为存在定义同名方法等的问题，因此不建议使用import* import本质（路径搜索和搜索路径） 导入模块的本质就是把python文件再解释一遍 导入优化 模块的分类 标准库 开源模块 自定义模块 内置模块time与datetime1234567891011121314151617181920212223import time# print(time.clock()) #返回处理器时间,3.3开始已废弃 , 改成了time.process_time()测量处理器运算时间,不包括sleep时间,不稳定,mac上测不出来# print(time.altzone) #返回与utc时间的时间差,以秒计算\# print(time.asctime()) #返回时间格式&quot;Fri Aug 19 11:14:16 2016&quot;,# print(time.localtime()) #返回本地时间 的struct time对象格式# print(time.gmtime(time.time()-800000)) #返回utc时间的struc时间对象格式# print(time.asctime(time.localtime())) #返回时间格式&quot;Fri Aug 19 11:14:16 2016&quot;,#print(time.ctime()) #返回Fri Aug 19 12:38:29 2016 格式, 同上# 日期字符串 转成 时间戳# string_2_struct = time.strptime(&quot;2016/05/22&quot;,&quot;%Y/%m/%d&quot;) #将 日期字符串 转成 struct时间对象格式# print(string_2_struct)# ## struct_2_stamp = time.mktime(string_2_struct) #将struct时间对象转成时间戳# print(struct_2_stamp)#将时间戳转为字符串格式# print(time.gmtime(time.time()-86640)) #将utc时间戳转换成struct_time格式# print(time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;,time.gmtime()) ) #将utc struct_time格式转成指定的字符串格式 123456789101112131415#时间加减import datetime# print(datetime.datetime.now()) #返回 2016-08-19 12:47:03.941925#print(datetime.date.fromtimestamp(time.time()) ) # 时间戳直接转成日期格式 2016-08-19# print(datetime.datetime.now() )# print(datetime.datetime.now() + datetime.timedelta(3)) #当前时间+3天# print(datetime.datetime.now() + datetime.timedelta(-3)) #当前时间-3天# print(datetime.datetime.now() + datetime.timedelta(hours=3)) #当前时间+3小时# print(datetime.datetime.now() + datetime.timedelta(minutes=30)) #当前时间+30分## c_time = datetime.datetime.now()# print(c_time.replace(minute=3,hour=2)) #时间替换 random123456789101112131415161718192021222324随机数mport randomprint random.random() 随机浮点数，生产0-1之间的随机数，可以查看帮助文档 print random.randint(1,2) 生成指定范围内的整数 -print random.randrange(1,10，2) 在指定范围内取值，并且是递增关系，同时不会取最后一个数，间隔是2print random.choice(&apos;wxh&apos;) 随机取出一个字符shufflp用于将一个列表中的元素打乱，执行之后，原有的列表内容将会被改变p = [&apos;this&apos;,&apos;is&apos;,&apos;for&apos;,&apos;test&apos;]random.shuffle(p)print (p) 执行之后的输出为：[&apos;this&apos;, &apos;for&apos;, &apos;test&apos;, &apos;is&apos;]random.sample 从指定序列中随机获取指定长度的片断p = [&apos;this&apos;,&apos;is&apos;,&apos;for&apos;,&apos;test&apos;]res = random.sample(p,3)print (res)print (p)执行之后的输出为：[&apos;is&apos;, &apos;for&apos;, &apos;this&apos;][&apos;this&apos;, &apos;is&apos;, &apos;for&apos;, &apos;test&apos;] 12345678910111213生成随机验证码import randomcheckcode = &apos;&apos;for i in range(4): current = random.randrange(0,4) if current != i: temp = chr(random.randint(65,90)) else: temp = random.randint(0,9) checkcode += str(temp)print checkcode string参考链接：https://docs.python.org/3/library/string.html?highlight=string#module-string string.ascii_lowercase 生成小写字母串 The lowercase letters &#39;abcdefghijklmnopqrstuvwxyz&#39;. This value is not locale-dependent and will not change. string.ascii_uppercase 生成大写字母串The uppercase letters &#39;ABCDEFGHIJKLMNOPQRSTUVWXYZ&#39;. This value is not locale-dependent and will not change. string.digits 生成数字串 The string &#39;0123456789&#39;. os模块This module provides a portable way of using operating system dependent functionality os模块主要用于和操作系统之间的交互，这个模块提供了一种方便的使用操作系统函数的方法。 1234567891011121314151617181920212223242526272829os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径os.chdir(&quot;dirname&quot;) 改变当前脚本工作目录；相当于shell下cdos.curdir 返回当前目录: (&apos;.&apos;)os.pardir 获取当前目录的父目录字符串名：(&apos;..&apos;)os.makedirs(&apos;dirname1/dirname2&apos;) 可生成多层递归目录os.removedirs(&apos;dirname1&apos;) 若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推os.mkdir(&apos;dirname&apos;) 生成单级目录；相当于shell中mkdir dirnameos.rmdir(&apos;dirname&apos;) 删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirnameos.listdir(&apos;dirname&apos;) 列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印，相当于ls -laos.remove() 删除一个文件os.rename(&quot;oldname&quot;,&quot;newname&quot;) 重命名文件/目录os.stat(&apos;path/filename&apos;) 获取文件/目录信息,相当于shell中的stat命令，会显示各种事件信息os.sep 输出操作系统特定的路径分隔符，win下为&quot;\\&quot;,Linux下为&quot;/&quot;os.linesep 输出当前平台使用的行终止符，win下为&quot;\t\n&quot;,Linux下为&quot;\n&quot;os.pathsep 输出用于分割文件路径的字符串os.name 输出字符串指示当前使用平台。win-&gt;&apos;nt&apos;; Linux-&gt;&apos;posix&apos;os.system(&quot;bash command&quot;) 运行shell命令，直接显示os.environ 获取系统环境变量os.path.abspath(path) 返回path规范化的绝对路径os.path.split(path) 将path分割成目录和文件名二元组返回os.path.dirname(path) 返回path的目录。其实就是os.path.split(path)的第一个元素os.path.basename(path) 返回path最后的文件名。如何path以／或\结尾，那么就会返回空值。即os.path.split(path)的第二个元素os.path.exists(path) 如果path存在，返回True；如果path不存在，返回Falseos.path.isabs(path) 如果path是绝对路径，返回Trueos.path.isfile(path) 如果path是一个存在的文件，返回True。否则返回Falseos.path.isdir(path) 如果path是一个存在的目录，则返回True。否则返回Falseos.path.join(path1[, path2[, ...]]) 将多个路径组合后返回，第一个绝对路径之前的参数将被忽略os.path.getatime(path) 返回path所指向的文件或者目录的最后存取时间os.path.getmtime(path) 返回path所指向的文件或者目录的最后修改时间 123a = os.popen(&quot;pwd&quot;)x = a.read()print (x) sys模块This module provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter. sys模块主要用于和python解释器之间的交互，这个模块可供访问由解释器使用或维护的变量和与解释器进行交互的函数。 123456789sys.argv 命令行参数List，第一个元素是程序本身路径sys.exit(n) 退出程序，正常退出时exit(0)sys.version 获取Python解释程序的版本信息sys.maxint 最大的Int值sys.path 返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值,获取指定模块搜索路径的字符串集合，可以将写好的模块放在得到的某个路径下，就可以在程序中import时正确找到。sys.platform 返回操作系统平台名称sys.stdout.write(&apos;please:&apos;)val = sys.stdin.readline()[:-1] shutil 模块高级的 文件、文件夹、压缩包 处理模块 shutil.copyfileobj(fsrc, fdst[, length])将文件内容拷贝到另一个文件中，可以部分内容 shutil.copyfile(src, dst)拷贝文件 shutil.copymode(src, dst)仅拷贝权限。内容、组、用户均不变 shutil.copystat(src, dst)拷贝状态的信息，包括：mode bits, atime, mtime, flags shutil.copy(src, dst)拷贝文件和权限 shutil.copy2(src, dst)拷贝文件和状态信息 shutil.ignore_patterns(*patterns)shutil.copytree(src, dst, symlinks=False, ignore=None)递归的去拷贝文件 例如：copytree(source, destination, ignore=ignore_patterns(‘.pyc’, ‘tmp‘)) shutil.rmtree(path[, ignore_errors[, onerror]])递归的去删除文件 shutil.move(src, dst)递归的去移动文件 shutil.make_archive(base_name, format,…) 创建压缩包并返回文件路径，例如：zip、tar base_name： 压缩包的文件名，也可以是压缩包的路径。只是文件名时，则保存至当前目录，否则保存至指定路径，如：www =&gt;保存至当前路径如：/Users/wupeiqi/www =&gt;保存至/Users/wupeiqi/ format： 压缩包种类，“zip”, “tar”, “bztar”，“gztar” root_dir： 要压缩的文件夹路径（默认当前目录） owner： 用户，默认当前用户 group： 组，默认当前组 logger： 用于记录日志，通常是logging.Logger对象 shutil 对压缩包的处理是调用 ZipFile 和 TarFile 两个模块来进行的，详细： json &amp; pickle 模块用于序列化的两个模块 json，用于字符串 和 python数据类型间进行转换 pickle，用于python特有的类型 和 python的数据类型间进行转换 Json模块提供了四个功能：dumps、dump、loads、load pickle模块提供了四个功能：dumps、dump、loads、load json的作用是把数据进行序列化，一个在内存中的数据对象，比如说是字典、列表等，不能直接写到文件里面，因此要把数据写入到文件里面，那么这个文件只能存byte类型或者是字符串，那就就需要把这些数据转换成为字符串。 将这些数据转换成为字符串之后，以后想要再加载这些数据的时候，因此需要确保文件中的内容的数据类型没有被破坏 json：帮助你把python中的内存数据转成字符串；想在其他的程序内再调用这些数据的时候，load一下就可以使用了。 这解决了：不同的语言，不同的平台之间的数据交换，使python可以和php、java等语言的数据进行交换 json这一部分还需要再深入下 shelve 模块shelve模块是一个简单的k,v将内存数据通过文件持久化的模块，可以持久化任何pickle可支持的python数据格式 123456789101112131415161718192021222324252627282930import shelve#写s = shelve.open(&apos;shelve.txt&apos;)class Test(): def __init__(self,n): self.n = nt = Test(1233)t2 = Test(1111)name = [&apos;111&apos;,&apos;sdaf&apos;,&apos;sd&apos;]s[&quot;test&quot;] = names[&quot;t1&quot;] = ts[&quot;t2&quot;] = t2s.close()# 读d = shelve.open(&apos;shelve.txt&apos;)print (d.get(&quot;test&quot;))d.close() xml处理模块xml是实现不同语言或程序之间进行数据交换的协议，跟json差不多，但json使用起来更简单，不过，古时候，在json还没诞生的黑暗年代，大家只能选择用xml呀，至今很多传统公司如金融行业的很多系统的接口还主要是xml。 xml的格式如下，就是通过&lt;&gt;节点来区别数据结构的: 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot;?&gt;&lt;data&gt; &lt;country name=&quot;Liechtenstein&quot;&gt; &lt;rank updated=&quot;yes&quot;&gt;2&lt;/rank&gt; &lt;year&gt;2008&lt;/year&gt; &lt;gdppc&gt;141100&lt;/gdppc&gt; &lt;neighbor name=&quot;Austria&quot; direction=&quot;E&quot;/&gt; &lt;neighbor name=&quot;Switzerland&quot; direction=&quot;W&quot;/&gt; &lt;/country&gt; &lt;country name=&quot;Singapore&quot;&gt; &lt;rank updated=&quot;yes&quot;&gt;5&lt;/rank&gt; &lt;year&gt;2011&lt;/year&gt; &lt;gdppc&gt;59900&lt;/gdppc&gt; &lt;neighbor name=&quot;Malaysia&quot; direction=&quot;N&quot;/&gt; &lt;/country&gt; &lt;country name=&quot;Panama&quot;&gt; &lt;rank updated=&quot;yes&quot;&gt;69&lt;/rank&gt; &lt;year&gt;2011&lt;/year&gt; &lt;gdppc&gt;13600&lt;/gdppc&gt; &lt;neighbor name=&quot;Costa Rica&quot; direction=&quot;W&quot;/&gt; &lt;neighbor name=&quot;Colombia&quot; direction=&quot;E&quot;/&gt; &lt;/country&gt;&lt;/data&gt; xml协议在各个语言里的都 是支持的，在python中可以用以下模块操作xml 123456789101112131415import xml.etree.ElementTree as ET tree = ET.parse(&quot;xmltest.xml&quot;)root = tree.getroot()print(root.tag) #遍历xml文档for child in root: print(child.tag, child.attrib) for i in child: print(i.tag,i.text) #只遍历year 节点for node in root.iter(&apos;year&apos;): print(node.tag,node.text) 修改和删除xml文档内容 123456789101112131415161718192021import xml.etree.ElementTree as ET tree = ET.parse(&quot;xmltest.xml&quot;)root = tree.getroot() #修改for node in root.iter(&apos;year&apos;): new_year = int(node.text) + 1 node.text = str(new_year) node.set(&quot;updated&quot;,&quot;yes&quot;) tree.write(&quot;xmltest.xml&quot;) #删除nodefor country in root.findall(&apos;country&apos;): rank = int(country.find(&apos;rank&apos;).text) if rank &gt; 50: root.remove(country) tree.write(&apos;output.xml&apos;) 自己创建xml文档 12345678910111213141516import xml.etree.ElementTree as ET new_xml = ET.Element(&quot;namelist&quot;)name = ET.SubElement(new_xml,&quot;name&quot;,attrib=&#123;&quot;enrolled&quot;:&quot;yes&quot;&#125;)age = ET.SubElement(name,&quot;age&quot;,attrib=&#123;&quot;checked&quot;:&quot;no&quot;&#125;)sex = ET.SubElement(name,&quot;sex&quot;)sex.text = &apos;33&apos;name2 = ET.SubElement(new_xml,&quot;name&quot;,attrib=&#123;&quot;enrolled&quot;:&quot;no&quot;&#125;)age = ET.SubElement(name2,&quot;age&quot;)age.text = &apos;19&apos; et = ET.ElementTree(new_xml) #生成文档对象et.write(&quot;test.xml&quot;, encoding=&quot;utf-8&quot;,xml_declaration=True) ET.dump(new_xml) #打印生成的格式 ConfigParser模块用于生成和修改常见配置文档，当前模块的名称在 python 3.x 版本中变更为 小写的configparser。 来看一个好多软件的常见文档格式如下 123456789101112[DEFAULT]ServerAliveInterval = 45Compression = yesCompressionLevel = 9ForwardX11 = yes [bitbucket.org]User = hg [topsecret.server.com]Port = 50022ForwardX11 = no 如果想用python生成一个这样的文档怎么做呢？ 1234567891011121314151617import configparser config = configparser.ConfigParser()config[&quot;DEFAULT&quot;] = &#123;&apos;ServerAliveInterval&apos;: &apos;45&apos;, &apos;Compression&apos;: &apos;yes&apos;, &apos;CompressionLevel&apos;: &apos;9&apos;&#125; config[&apos;bitbucket.org&apos;] = &#123;&#125;config[&apos;bitbucket.org&apos;][&apos;User&apos;] = &apos;hg&apos;config[&apos;topsecret.server.com&apos;] = &#123;&#125;topsecret = config[&apos;topsecret.server.com&apos;]topsecret[&apos;Host Port&apos;] = &apos;50022&apos; # mutates the parsertopsecret[&apos;ForwardX11&apos;] = &apos;no&apos; # same hereconfig[&apos;DEFAULT&apos;][&apos;ForwardX11&apos;] = &apos;yes&apos;with open(&apos;example.ini&apos;, &apos;w&apos;) as configfile: config.write(configfile) 写完了还可以再读出来 123456789101112131415161718192021222324252627282930&gt;&gt;&gt; import configparser&gt;&gt;&gt; config = configparser.ConfigParser()&gt;&gt;&gt; config.sections()[]&gt;&gt;&gt; config.read(&apos;example.ini&apos;)[&apos;example.ini&apos;]&gt;&gt;&gt; config.sections()[&apos;bitbucket.org&apos;, &apos;topsecret.server.com&apos;]&gt;&gt;&gt; &apos;bitbucket.org&apos; in configTrue&gt;&gt;&gt; &apos;bytebong.com&apos; in configFalse&gt;&gt;&gt; config[&apos;bitbucket.org&apos;][&apos;User&apos;]&apos;hg&apos;&gt;&gt;&gt; config[&apos;DEFAULT&apos;][&apos;Compression&apos;]&apos;yes&apos;&gt;&gt;&gt; topsecret = config[&apos;topsecret.server.com&apos;]&gt;&gt;&gt; topsecret[&apos;ForwardX11&apos;]&apos;no&apos;&gt;&gt;&gt; topsecret[&apos;Port&apos;]&apos;50022&apos;&gt;&gt;&gt; for key in config[&apos;bitbucket.org&apos;]: print(key)...usercompressionlevelserveraliveintervalcompressionforwardx11&gt;&gt;&gt; config[&apos;bitbucket.org&apos;][&apos;ForwardX11&apos;]&apos;yes&apos; configparser增删改查语法 1234567891011121314151617181920212223242526272829303132333435363738[section1]k1 = v1k2:v2 [section2]k1 = v1 import ConfigParser config = ConfigParser.ConfigParser()config.read(&apos;i.cfg&apos;) # ########## 读 ###########secs = config.sections()#print secs#options = config.options(&apos;group2&apos;)#print options #item_list = config.items(&apos;group2&apos;)#print item_list #val = config.get(&apos;group1&apos;,&apos;key&apos;)#val = config.getint(&apos;group1&apos;,&apos;key&apos;) # ########## 改写 ###########sec = config.remove_section(&apos;group1&apos;)#config.write(open(&apos;i.cfg&apos;, &quot;w&quot;)) #sec = config.has_section(&apos;wupeiqi&apos;)#sec = config.add_section(&apos;wupeiqi&apos;)#config.write(open(&apos;i.cfg&apos;, &quot;w&quot;)) #config.set(&apos;group2&apos;,&apos;k1&apos;,11111)#config.write(open(&apos;i.cfg&apos;, &quot;w&quot;)) #config.remove_option(&apos;group2&apos;,&apos;age&apos;)#config.write(open(&apos;i.cfg&apos;, &quot;w&quot;)) hashlib模块 用于加密相关的操作，3.x里代替了md5模块和sha模块，主要提供 SHA1, SHA224, SHA256, SHA384, SHA512 ，MD5 算法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import hashlib m = hashlib.md5()m.update(b&quot;Hello&quot;)m.update(b&quot;It&apos;s me&quot;)print(m.digest())m.update(b&quot;It&apos;s been a long time since last time we ...&quot;) print(m.digest()) #2进制格式hashprint(len(m.hexdigest())) #16进制格式hash&apos;&apos;&apos;def digest(self, *args, **kwargs): # real signature unknown &quot;&quot;&quot; Return the digest value as a string of binary data. &quot;&quot;&quot; pass def hexdigest(self, *args, **kwargs): # real signature unknown &quot;&quot;&quot; Return the digest value as a string of hexadecimal digits. &quot;&quot;&quot; pass &apos;&apos;&apos;import hashlib # ######## md5 ######## hash = hashlib.md5()hash.update(&apos;admin&apos;)print(hash.hexdigest()) # ######## sha1 ######## hash = hashlib.sha1()hash.update(&apos;admin&apos;)print(hash.hexdigest()) # ######## sha256 ######## hash = hashlib.sha256()hash.update(&apos;admin&apos;)print(hash.hexdigest()) # ######## sha384 ######## hash = hashlib.sha384()hash.update(&apos;admin&apos;)print(hash.hexdigest()) # ######## sha512 ######## hash = hashlib.sha512()hash.update(&apos;admin&apos;)print(hash.hexdigest()) 还不够吊？python 还有一个 hmac 模块，它内部对我们创建 key 和 内容 再进行处理然后再加密 散列消息鉴别码，简称HMAC，是一种基于消息鉴别码MAC（Message Authentication Code）的鉴别机制。使用HMAC时,消息通讯的双方，通过验证消息中加入的鉴别密钥K来鉴别消息的真伪； 一般用于网络通信中消息加密，前提是双方先要约定好key,就像接头暗号一样，然后消息发送把用key把消息加密，接收方用key ＋ 消息明文再加密，拿加密后的值 跟 发送者的相对比是否相等，这样就能验证消息的真实性，及发送者的合法性了。 123import hmach = hmac.new(b&apos;天王盖地虎&apos;, b&apos;宝塔镇河妖&apos;)print h.hexdigest() 更多关于md5,sha1,sha256等介绍的文章看这里https://www.tbs-certificates.co.uk/FAQ/en/sha256.html re模块 常用正则表达式符号 12345678910111213141516171819202122232425262728293031323334353637&apos;.&apos; 默认匹配除\n之外的任意一个字符，若指定flag DOTALL,则匹配任意字符，包括换行&apos;^&apos; 匹配字符开头，若指定flags MULTILINE,这种也可以匹配上(r&quot;^a&quot;,&quot;\nabc\neee&quot;,flags=re.MULTILINE)&apos;$&apos; 匹配字符结尾，或e.search(&quot;foo$&quot;,&quot;bfoo\nsdfsf&quot;,flags=re.MULTILINE).group()也可以&apos;*&apos; 匹配*号前的字符0次或多次，re.findall(&quot;ab*&quot;,&quot;cabb3abcbbac&quot;) 结果为[&apos;abb&apos;, &apos;ab&apos;, &apos;a&apos;]&apos;+&apos; 匹配前一个字符1次或多次，re.findall(&quot;ab+&quot;,&quot;ab+cd+abb+bba&quot;) 结果[&apos;ab&apos;, &apos;abb&apos;]&apos;?&apos; 匹配前一个字符1次或0次&apos;&#123;m&#125;&apos; 匹配前一个字符m次&apos;&#123;n,m&#125;&apos; 匹配前一个字符n到m次，re.findall(&quot;ab&#123;1,3&#125;&quot;,&quot;abb abc abbcbbb&quot;) 结果&apos;abb&apos;, &apos;ab&apos;, &apos;abb&apos;]&apos;|&apos; 匹配|左或|右的字符，re.search(&quot;abc|ABC&quot;,&quot;ABCBabcCD&quot;).group() 结果&apos;ABC&apos;&apos;(...)&apos; 分组匹配，re.search(&quot;(abc)&#123;2&#125;a(123|456)c&quot;, &quot;abcabca456c&quot;).group() 结果 abcabca456c &apos;\A&apos; 只从字符开头匹配，re.search(&quot;\Aabc&quot;,&quot;alexabc&quot;) 是匹配不到的&apos;\Z&apos; 匹配字符结尾，同$&apos;\d&apos; 匹配数字0-9&apos;\D&apos; 匹配非数字&apos;\w&apos; 匹配[A-Za-z0-9]&apos;\W&apos; 匹配非[A-Za-z0-9]&apos;s&apos; 匹配空白字符、\t、\n、\r , re.search(&quot;\s+&quot;,&quot;ab\tc1\n3&quot;).group() 结果 &apos;\t&apos; &apos;(?P&lt;name&gt;...)&apos; 分组匹配 re.search(&quot;(?P&lt;province&gt;[0-9]&#123;4&#125;)(?P&lt;city&gt;[0-9]&#123;2&#125;)(?P&lt;birthday&gt;[0-9]&#123;4&#125;)&quot;,&quot;371481199306143242&quot;).groupdict(&quot;city&quot;) 结果&#123;&apos;province&apos;: &apos;3714&apos;, &apos;city&apos;: &apos;81&apos;, &apos;birthday&apos;: &apos;1993&apos;&#125;匹配分割import reres = re.split(&quot;[0-9]&quot;,&quot;wang123xiao123hua&quot;)print (res)输出为：[&apos;wang&apos;, &apos;&apos;, &apos;&apos;, &apos;xiao&apos;, &apos;&apos;, &apos;&apos;, &apos;hua&apos;]匹配替换import reres = re.sub(&quot;[0-9]&quot;,&quot;#&quot;,&quot;wang123xiao123hua123@wangxiaohua123&quot;,count=2)print (res)输出为：wang##3xiao123hua123@wangxiaohua123 最常用的匹配语法 12345re.match 从头开始匹配re.search 匹配包含re.findall 把所有匹配到的字符放到以列表中的元素返回re.splitall 以匹配到的字符当做列表分隔符re.sub 匹配字符并替换 反斜杠的困扰与大多数编程语言相同，正则表达式里使用”\”作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”\”，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\“：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\“表示。同样，匹配一个数字的”\d”可以写成r”\d”。有了原生字符串，你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。 仅需轻轻知道的几个匹配模式 123re.I(re.IGNORECASE): 忽略大小写（括号内是完整写法，下同）M(MULTILINE): 多行模式，改变&apos;^&apos;和&apos;$&apos;的行为（参见上图）S(DOTALL): 点任意匹配模式，改变&apos;.&apos;的行为 测试代码如下： 12345678910res = re.search(&quot;[a-z]+&quot;,&quot;abcdA&quot;)print (res)执行后输出为：&lt;re.Match object; span=(0, 4), match=&apos;abcd&apos;&gt;修改后：res = re.search(&quot;[a-z]+&quot;,&quot;abcdA&quot;,flags=re.I)print (res)执行后输出为：&lt;re.Match object; span=(0, 5), match=&apos;abcdA&apos;&gt; 12345678res = re.search(&quot;^a&quot;,&quot;\nabcd\nioush&quot;)print (res)Noneres = re.search(&quot;^a&quot;,&quot;\nabcd\nioush&quot;,flags=re.M)print (res)执行后输出为：&lt;re.Match object; span=(1, 2), match=&apos;a&apos;&gt; 123456789res = re.search(&quot;.+&quot;,&quot;\nabcd\nghde&quot;)print (res)&lt;re.Match object; span=(1, 5), match=&apos;abcd&apos;&gt;res = re.search(&quot;.+&quot;,&quot;\nabcd\nghde&quot;,flags=re.S)print (res)执行后输出为：&lt;re.Match object; span=(0, 10), match=&apos;\nabcd\nghde&apos;&gt;]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day04-函数装饰器迭代器生成器]]></title>
    <url>%2F2018%2F07%2F13%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday04-%E5%87%BD%E6%95%B0%E8%A3%85%E9%A5%B0%E5%99%A8%E8%BF%AD%E4%BB%A3%E5%99%A8%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[装饰器器：代表函数的意思。也就是说，装饰器本质是函数，基本语法都是使用def关键字去定义的 那么它的本质是函数，它的功能是什么？ 定义：装饰器的本质是函数：装饰其他函数的函数【就是为其他函数添加附加功能】 在实际生产环境中，需要新增功能的时候，有以下原则 不能修改现有函数的源代码 函数一旦写好了，原则上就不能再去修改它的源代码 函数的调用方式也不能被修改 装饰器有自己独特的需要遵循的原则： 不能修改被装饰的函数的源代码 不能修改被装饰的函数的调用方式 也就是，被装饰的函数式完全透明的（调用函数的一方不知道这个函数被装饰过，函数本身也感知不到装饰器的存在） 实现装饰器的知识储备： 函数即“变量” 高阶函数 把一个函数名都当做实参传递给另外一个函数【在一般的函数使用中，给形参传递的都是实参变量，那么，函数即变量之后，就可以把==函数==当做一个变量实参传递给另外一个函数】 这一步可以做到，在不修改被装饰函数源代码的情况下，为其添加功能 返回值中包含函数名【一般函数的返回值中吗，可以是字符串，列表，数字等等，因为函数是变量，那么在返回值中是也可以包含函数的】 不修改函数的调用方式 函数嵌套 函数嵌套指的是，在一个函数的函数体之内用def去声明一个新的函数，而不是去调用它 高阶函数+嵌套函数==》装饰器 案例演示原型1234567891011121314151617181920212223import timedef test1(): time.sleep(1) print (&quot;in the test1&quot;)def test2(): time.sleep(1) print (&quot;in the test2&quot;)def timer(func): def deco(): start_time = time.time() func() stop_time = time.time() print (&quot;func is cost &#123;cost&#125;&quot;.format(cost=stop_time-start_time)) return deco# 返回该函数（这里是deco函数）的内存地址test1 = timer(test1)test1()#test1执行，实际上是在执行deco这个函数 执行后的输出如下所示： 12in the test1func is cost 1.0031695365905762 说明： 函数的执行，主要是执行函数体中的内容，而我们在真正执行函数的时候，是通过函数名称进行调用的（也就是一个变量），因此，在函数真正执行之前，我们可以修改这个函数名称对应的函数体中的内容 装饰器的编写步骤： 首先编写一个函数，其中调用这个被装饰的函数，并在其中添加上新的功能 将这个函数的函数体，也就是内存地址拿出来，重新赋值给这个被装饰的函数 实现第2步，就需要使用函数的嵌套，以此来返回这个函数的内存地址（函数嵌套了函数之后，是直接将子函数的内存地址返回，而没有执行这个子函数） 而将这个被装饰的源函数传递给这个装饰函数执行，就需要使用高阶函数 改良123456789101112131415161718import timedef timer(func): def deco(): start_time = time.time() func() stop_time = time.time() print (&quot;func is cost &#123;cost&#125;&quot;.format(cost=stop_time-start_time)) return deco@timerdef test1(): time.sleep(1) print (&quot;in the test1&quot;)def test2(): time.sleep(1) print (&quot;in the test2&quot;) 说明： 在这里，@timer=test1 = timer(test1) 注意，使用这种方式的时候，timer函数的定义要在这些被装饰函数的前方 如果函数还涉及到参数，那么，我们就需要重新编写定义装饰器，将它写成通用的方式，不管被装饰的函数传递的是几个函数（0个或多个），都能够正确的读取。 添加函数传递功能 匿名函数1234res = lambda x:x*3print (res(3))执行后输出结果为：9 生成器通过列表生成式【列表解析】，我们可以直接创建一个列表。但是，受到内存限制，列表容量肯定是有限的。而且，创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在Python中，这种一边循环一边计算的机制，称为生成器：generator。 要创建一个generator，有很多种方法。第一种方法很简单，只要把一个列表生成式的[]改成()，就创建了一个generator： 12345678a = [i*2 for i in range(11)]b = (i*2 for i in range(11))print (a)print (b)执行后输出如下所示：[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]&lt;generator object &lt;genexpr&gt; at 0x058D5360&gt; 注意，在进行调用的时候，传统的方式能够直接通过列表下标的方式获取到相应的元素【因为元素已经生成并存在于内存当中】，但是生成器是只有你调用到我这一次的时候，我才会生成这一个，也就是必须循环到这个指定的下标的时候，我才会产生这个元素的值，因此，在前面的数据没有生成的情况下，直接调用中间的某个元素，因为不存在这个元素，因此就会产生报错,不支持这种数据获取方式 调用生成器的时候，只能使用for循环的方式一个个取用，当不想要获取全部的数据，只需要获取部分数据的时候，使用生成器提供的next方法进行操作【next方法获取当前】。 1c.__next()__() 注意：没有previous方法用户获取上一个值，因为，生成器只会当前的位置，不知道前边和后边 总结： 生成器只有在调用时，才会生成相应的数据 只会记录当前位置 只有一个__next__()方法（2.7中为next()） 我们创建了一个generator后，基本上永远不会调用next()，而是通过for循环来迭代它，并且不需要关心StopIteration的错误。 generator非常强大。如果推算的算法比较复杂，用类似列表生成式的for循环无法实现的时候，还可以用函数来实现。 比如，著名的斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到： 1, 1, 2, 3, 5, 8, 13, 21, 34, … 斐波拉契数列用列表生成式写不出来，但是，用函数把它打印出来却很容易： yield的作用：保存函数的中断状态，yield返回当前状态的值，并且将函数保持停留在这里 对生成器使用send()方法，可以将参数传递给这个生成器，yield就会接受到这个参数 next()只是单纯的调用yield，它不会给yield传值；send()给yield传值，同时调用yield 迭代器我们已经知道，可以直接作用于for循环的数据类型有以下几种： 一类是集合数据类型，如list、tuple、dict、set、str等； 一类是generator，包括生成器和带yield的generator function。 这些可以直接作用于for循环的对象统称为可迭代对象：Iterable。 重点： 可以直接作用于for循环的对象统称为可迭代对象：Iterable 生成器不但可以作用于for循环，还可以被next()函数不断调用并返回下一个值，直到最后抛出StopIteration错误表示无法继续返回下一个值了。 可以被next()方法调用并不断返回下一个值的对象称为迭代器：Iterator。 迭代器和next()方法相关联，有next()方法的才能称之为迭代器 查看一个对象能够调用的所有方法：dir(a) 可以使用isinstance()判断一个对象是否是Iterator对象【是否是迭代器对象】： 1234567891011121314print (isinstance([1,2,3],Iterator))print (isinstance([],Iterator))print (isinstance((x for x in range(10)),Iterator))FalseFalseTrue------a = [1,2,3]b = iter(a)print (isinstance(b,Iterator))True 注意： 生成器都是Iterator对象，但list、dict、str虽然是Iterable，却不是Iterator。 把list、dict、str等Iterable变成Iterator可以使用iter()函数： 你可能会问，为什么list、dict、str等数据类型不是Iterator？ 这是因为Python的Iterator对象表示的是一个数据流，Iterator对象可以被next()函数调用并不断返回下一个数据，直到没有数据时抛出StopIteration错误。可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过next()函数实现按需计算下一个数据，所以Iterator的计算是惰性的，只有在需要返回下一个数据时它才会计算。 Iterator甚至可以表示一个无限大的数据流，例如全体自然数。而使用list是永远不可能存储全体自然数的。 内置方法python中有以下内置函数 Built-in Functions abs() delattr() hash() memoryview() set() all() dict() help() min() setattr() any() dir() hex() next() slice() ascii() divmod() id() object() sorted() bin() enumerate() input() oct() staticmethod() bool() eval() int() open() str() breakpoint() exec() isinstance() ord() sum() bytearray() filter() issubclass() pow() super() bytes() float() iter() print() tuple() callable() format() len() property() type() chr() frozenset() list() range() vars() classmethod() getattr() locals() repr() zip() compile() globals() map() reversed() __import__() complex() hasattr() max() round() all()：判断输出的值是否都为true 12345print (all([9,3]))print (all([0,9,3]))TrueFalse any()：一个数据为真，就返回真，如果可迭代对象为空，返回也为False eval()：将字符串变成字典 json序列化序列化：把内存中的数据对象变成字符串 反序列化： 把磁盘中的数据加载到内存当中 注意：json只能处理简单的数据类型，列表、字典、字符串等，因为json是所有语言都通用的，json主要的作用是用于不同语言之间进行数据交互，因为一些复杂的东西，例如python和java里面，类的定义和使用方式、一些特性等等，各语言之间很多东西都有很大的差异性，如果需要转换类、函数等对象就会变得相当复杂。所以，json默认只是支持这些比较简单的。 xml知识补充：xml正在逐渐的被json所取代 xml是一种标记语言， picklepickle的用法和json完全一样，但是它在序列化的时候，会把内存转换成为二进制的形式，所以在操作文件的时候，需要在序列化和反序列化的时候使用的方法为：wb和rb pickle有自己的一套语法映射关系，将数据转换为二进制数据，因此系统的字符集识别之后将会显示为乱码 dumps()和dump()以及loads()和load()区别注意，在序列化的时候，使用dumps和loads操作文件的时候，需要使用文件本身的f.write()或者f.read()方法；但是如果使用dump()和load()的时候，该方法中就可以嵌入了对文件的操作，也就是说不需要再额外的使用以上两个文件方法。 123456789f.write(pickle.dumps(info))等价于pickle.dump(info,f)---data = pickle.loads(f.read())等价于data = pickle.load(f) 注意，我们可以dump很多次，但是dump很多次之后的这个文件，直接使用load是打不开的。 也就是说，在python3中，最多只能dump一次。 在编写程序时的一个准则： 只dump一次，只load一次 如果还是想使用原来的文件，那么就把原来的内容覆盖掉 例如虚拟机的快照，虚拟机的快照是每一个快照都会对应一个文件，而不是把所有的快照内容都存在一起 如果想保存好几个状态，那么就dump好几个文件。 软件目录结构规范为什么要设计好目录结构?“设计项目目录结构”，就和”代码编码风格”一样，属于个人风格问题。对于这种风格上的规范，一直都存在两种态度: 一类同学认为，这种个人风格问题”无关紧要”。理由是能让程序work就好，风格问题根本不是问题。 另一类同学认为，规范化能更好的控制程序结构，让程序具有更高的可读性。 我是比较偏向于后者的，因为我是前一类同学思想行为下的直接受害者。我曾经维护过一个非常不好读的项目，其实现的逻辑并不复杂，但是却耗费了我非常长的时间去理解它想表达的意思。从此我个人对于提高项目可读性、可维护性的要求就很高了。”项目目录结构”其实也是属于”可读性和可维护性”的范畴，我们设计一个层次清晰的目录结构，就是为了达到以下两点: 可读性高: 不熟悉这个项目的代码的人，一眼就能看懂目录结构，知道程序启动脚本是哪个，测试目录在哪儿，配置文件在哪儿等等。从而非常快速的了解这个项目。 可维护性高: 定义好组织规则后，维护者就能很明确地知道，新增的哪个文件和代码应该放在什么目录之下。这个好处是，随着时间的推移，代码/配置的规模增加，项目结构不会混乱，仍然能够组织良好。 所以，我认为，保持一个层次清晰的目录结构是有必要的。更何况组织一个良好的工程目录，其实是一件很简单的事儿。 目录组织方式关于如何组织一个较好的Python工程目录结构，已经有一些得到了共识的目录结构。在Stackoverflow的这个问题上，能看到大家对Python目录结构的讨论。 这里面说的已经很好了，我也不打算重新造轮子列举各种不同的方式，这里面我说一下我的理解和体会。 假设你的项目名为foo, 我比较建议的最方便快捷目录结构这样就足够了: 12345678910111213141516171819Foo/|-- bin/| |-- foo||-- foo/| |-- tests/| | |-- __init__.py| | |-- test_main.py| || |-- __init__.py| |-- main.py||-- docs/| |-- conf.py| |-- abc.rst||-- setup.py|-- requirements.txt|-- README 简要解释一下: bin/: 存放项目的一些可执行文件，当然你可以起名script/之类的也行。 foo/: 存放项目的所有源代码。(1) 源代码中的所有模块、包都应该放在此目录。不要置于顶层目录。(2) 其子目录tests/存放单元测试代码； (3) 程序的入口最好命名为main.py。 docs/: 存放一些文档。 setup.py: 安装、部署、打包的脚本。 requirements.txt: 存放软件依赖的外部Python包列表。 README: 项目说明文件。 除此之外，有一些方案给出了更加多的内容。比如LICENSE.txt,ChangeLog.txt文件等，我没有列在这里，因为这些东西主要是项目开源的时候需要用到。如果你想写一个开源软件，目录该如何组织，可以参考这篇文章。 下面，再简单讲一下我对这些目录的理解和个人要求吧。 注意：有__init__.py这个空文件的目录就叫做包，没有的就叫做目录 关于README的内容这个我觉得是每个项目都应该有的一个文件，目的是能简要描述该项目的信息，让读者快速了解这个项目。 它需要说明以下几个事项: 软件定位，软件的基本功能。 运行代码的方法: 安装环境、启动命令等。 简要的使用说明。 代码目录结构说明，更详细点可以说明软件的基本原理。 常见问题说明。 我觉得有以上几点是比较好的一个README。在软件开发初期，由于开发过程中以上内容可能不明确或者发生变化，并不是一定要在一开始就将所有信息都补全。但是在项目完结的时候，是需要撰写这样的一个文档的。 可以参考Redis源码中Readme的写法，这里面简洁但是清晰的描述了Redis功能和源码结构。 关于requirements.txt和setup.pysetup.py一般来说，用setup.py来管理代码的打包、安装、部署问题。业界标准的写法是用Python流行的打包工具setuptools来管理这些事情。这种方式普遍应用于开源项目中。不过这里的核心思想不是用标准化的工具来解决这些问题，而是说，一个项目一定要有一个安装部署工具，能快速便捷的在一台新机器上将环境装好、代码部署好和将程序运行起来。 这个我是踩过坑的。 我刚开始接触Python写项目的时候，安装环境、部署代码、运行程序这个过程全是手动完成，遇到过以下问题: 安装环境时经常忘了最近又添加了一个新的Python包，结果一到线上运行，程序就出错了。 Python包的版本依赖问题，有时候我们程序中使用的是一个版本的Python包，但是官方的已经是最新的包了，通过手动安装就可能装错了。 如果依赖的包很多的话，一个一个安装这些依赖是很费时的事情。 新同学开始写项目的时候，将程序跑起来非常麻烦，因为可能经常忘了要怎么安装各种依赖。 setup.py可以将这些事情自动化起来，提高效率、减少出错的概率。”复杂的东西自动化，能自动化的东西一定要自动化。”是一个非常好的习惯。 setuptools的文档比较庞大，刚接触的话，可能不太好找到切入点。学习技术的方式就是看他人是怎么用的，可以参考一下Python的一个Web框架，flask是如何写的: setup.py 当然，简单点自己写个安装脚本（deploy.sh）替代setup.py也未尝不可。 requirements.txt这个文件存在的目的是: 方便开发者维护软件的包依赖。将开发过程中新增的包添加进这个列表中，避免在setup.py安装依赖时漏掉软件包。 方便读者明确项目使用了哪些Python包。 这个文件的格式是每一行包含一个包依赖的说明，通常是flask&gt;=0.10这种格式，要求是这个格式能被pip识别，这样就可以简单的通过 pip install -r requirements.txt来把所有Python包依赖都装好了。具体格式说明： 点这里。 关于配置文件的使用方法注意，在上面的目录结构中，没有将conf.py放在源码目录下，而是放在docs/目录下。很多项目对配置文件的使用做法是: 配置文件写在一个或多个python文件中，比如此处的conf.py。 项目中哪个模块用到这个配置文件就直接通过import conf这种形式来在代码中使用配置。 这种做法我不太赞同: 这让单元测试变得困难（因为模块内部依赖了外部配置） 另一方面配置文件作为用户控制程序的接口，应当可以由用户自由指定该文件的路径。 程序组件可复用性太差，因为这种贯穿所有模块的代码硬编码方式，使得大部分模块都依赖conf.py这个文件。 所以，我认为配置的使用，更好的方式是， 模块的配置都是可以灵活配置的，不受外部配置文件的影响。 程序的配置也是可以灵活控制的。 能够佐证这个思想的是，用过nginx和mysql的同学都知道，nginx、mysql这些程序都可以自由的指定用户配置。 所以，不应当在代码中直接import conf来使用配置文件。上面目录结构中的conf.py，是给出的一个配置样例，不是在写死在程序中直接引用的配置文件。可以通过给main.py启动参数指定配置路径的方式来让程序读取配置内容。当然，这里的conf.py你可以换个类似的名字，比如settings.py。或者你也可以使用其他格式的内容来编写配置文件，比如settings.yaml之类的。 作业作业需求： 模拟实现一个ATM + 购物商城程序 额度 15000或自定义 实现购物商城，买东西加入 购物车，调用信用卡接口结账 可以提现，手续费5% 每月22号出账单，每月10号为还款日，过期未还，按欠款总额 万分之5 每日计息 支持多账户登录 支持账户间转账 记录每月日常消费流水 提供还款接口 ATM记录操作日志 提供管理接口，包括添加账户、用户额度，冻结账户等。。。 用户认证用装饰器 相关代码及说明记录在pycharm当中]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内核模块操作命令-lsmod+rmmod+modinfo+modprobe]]></title>
    <url>%2F2018%2F07%2F13%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FLinux%E5%91%BD%E4%BB%A4%2F%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4-lsmod%2Brmmod%2Bmodinfo%2Bmodprobe%2F</url>
    <content type="text"><![CDATA[本篇主要讲解和Linux内核模块相关的操作命令 lsmod-查看内核模块信息lsmod命令用于显示已经加载到内核中的模块的状态信息。执行lsmod命令后会列出所有已载入系统的模块。 Linux操作系统的核心具有模块化的特性，应此在编译核心时，可以不用把全部的功能都放入核心，而是将这些功能编译成一个个单独的模块，待需要时再分别载入使用。 命令的输出如下： 1234567[root@lvs001 modprobe.d]# lsmod Module Size Used byiptable_nat 5923 0 nf_nat 22676 1 iptable_natnf_conntrack_ipv4 9186 3 iptable_nat,nf_natnf_conntrack 79537 3 iptable_nat,nf_nat,nf_conntrack_ipv4nf_defrag_ipv4 1483 1 nf_conntrack_ipv4 12345[root@lvs001 modprobe.d]# lsmod | grep ip_vsip_vs_rr 1420 0 ip_vs 126705 2 ip_vs_rrlibcrc32c 1246 1 ip_vsipv6 336368 913 ip_vs,ib_ipoib,ib_addr 说明： 第1列：表示模块的名称。 第2列：表示模块的大小。 第3列：表示该模块调用其他模块的个数 第4列：显示该模块被其他什么模块调用 通常在使用lsmod命令时，都会采用类似lsmod | grep -i ipvs这样的命令来查询当前系统是否加载了某些模块。 modinfo-查看内核模块信息modinfo会显示kernel模块的对象文件，以显示该模块的相关信息。 modinfo列出Linux内核中命令行指定的模块的信息。若模块名不是一个文件名，则会在/lib/modules/version 目录中搜索，就像modprobe一样。 modinfo默认情况下，为了便于阅读，以下面的格式列出模块的每个属性：fieldname : value。 123456参 数： -a或--author 显示模块开发人员。 -d或--description 显示模块的说明。 -h或--help 显示modinfo的参数使用方法。 -p或--parameters 显示模块所支持的参数。 -V或--version 显示版本信息。 1234567[root@lvs001 modprobe.d]# modinfo ip_vsfilename: /lib/modules/2.6.32-696.el6.x86_64/kernel/net/netfilter/ipvs/ip_vs.kolicense: GPLsrcversion: 0FB85919D62C4255E412E5Cdepends: ipv6,libcrc32cvermagic: 2.6.32-696.el6.x86_64 SMP mod_unload modversions parm: conn_tab_bits:Set connections&apos; hash size (int) 注意，使用lsmod不能看到内核的相关参数配置，而使用modinfo命令则可以显示 rmmod-卸载内核模块rmmod命令 用于从当前运行的内核中移除指定的内核模块。 执行rmmod指令，可删除不需要的模块。 12345选项信息：-v：显示指令执行的详细信息；-f：强制移除模块，使用此选项比较危险；-w：等待着，直到模块能够被除时在移除模块；-s：向系统日志（syslog）发送错误信息。 12[root@lvs001 modprobe.d]# rmmod ip_vsERROR: Module ip_vs is in use by ip_vs_rr 使用rmmod卸载模块的时候，提示信息会比使用modprobe -r 的输出更详细，此时会显示该模块的被调用情况 insmod-载入内核模块insmod(install module)命令用于载入模块。 Linux有许多功能是通过模块的方式，在需要时才载入kernel。如此可使kernel较为精简，进而提高效率，以及保有较大的弹性。这类可载入的模块，通常是设备驱动程序。 语法: 1insmod [-fkmpsvxX][-o &lt;模块名称&gt;][模块文件][符号名称 = 符号值] 1234567891011参数说明：-f 不检查目前kernel版本与模块编译时的kernel版本是否一致，强制将模块载入。-k 将模块设置为自动卸除。-m 输出模块的载入信息。-o&lt;模块名称&gt; 指定模块的名称，可使用模块文件的文件名。-p 测试模块是否能正确地载入kernel。-s 将所有信息记录在系统记录文件中。-v 执行时显示详细的信息。-x 不要汇出模块的外部符号。-X 汇出模块所有的外部符号，此为预设置。 在Linux中，modprobe和insmod都可以用来加载module，不过现在一般都推荐使用modprobe而不是insmod了。modprobe和insmod的区别是什么呢？ modprobe可以解决load module时的依赖关系，比如load moudleA就必须先load mouduleB之类的，它是通过/lib/modules//modules.dep文件来查找依赖关系的。而insmod不能解决依赖问题。 modprobe默认会去/lib/modules/目录下面查找module，而insmod只在给它的参数中去找module（默认在当前目录找）。 但是insmod也有它的有用之处，举个例子吧。 有/root/my-mod.ko这个module，cd /root/，然后用insmod my-mod.ko(insmod /root/my-mod.ko)就可以insert这个module了， 但是用modprobe my-mod.ko(modprobe /root/my-mod.ko)却提示”FATAL: Module my-mod.ko not found”，这就是因为modprobe是到/lib/modules/uname -r/下去找module的，如果没找到就是这样了。 depmod-分析模块依赖性modprobe-内核模块操作modprobe命令用于智能地向内核中加载模块或者从内核中移除模块。 modprobe可载入指定的个别模块，或是载入一组相依的模块。 modprobe会根据depmod所产生的相依关系，决定要载入哪些模块。若在载入过程中发生错误，在modprobe会卸载整组的模块。 1234567891011参数选项-a或--all：载入全部的模块/指定模块；-c或--show-conf：显示所有模块的设置信息；-d或--debug：使用排错模式；-l或--list：显示可用的模块；-r或--remove：卸载模块；-t或--type：指定模块类型；-v或--verbose：执行时显示详细的信息；-V或--version：显示版本信息；-help：显示帮助。 例如： 12卸载：modprobe -r ip_vs 载入：modprobe -a ip_vs get_module需要安装sysfsutils包之后才能产生该命令 1yum -y install sysfsutils 12345678910111213141516171819202122232425262728293031323334[root@lvs001 modprobe.d]# get_module ip_vs initstate : live refcnt : 2 srcversion : 0FB85919D62C4255E412E5CParameters: conn_tab_bits : 12Sections: .altinstr_replacement : 0xffffffffa039c2b8 .altinstructions : 0xffffffffa039ef98 .bss : 0xffffffffa03a1c60 .data : 0xffffffffa039ff00 .data.cacheline_aligned : 0xffffffffa03a1580 .data.read_mostly : 0xffffffffa03a1040 .exit.text : 0xffffffffa039c40e .gnu.linkonce.this_module : 0xffffffffa03a1a20 .init.text : 0xffffffffa03aa000 .note.gnu.build-id : 0xffffffffa039c454 .rheldata : 0xffffffffa039fee0 .rodata : 0xffffffffa039c480 .rodata.str1.1 : 0xffffffffa039d6e8 .rodata.str1.8 : 0xffffffffa039dc90 .smp_locks : 0xffffffffa039eb68 .strtab : 0xffffffffa03ae2f8 .symtab : 0xffffffffa03aa4d0 .text : 0xffffffffa038a000 __kcrctab_gpl : 0xffffffffa039f540 __kcrctab : 0xffffffffa039fe80 __ksymtab_gpl : 0xffffffffa039f4f0 __ksymtab_strings : 0xffffffffa039f590 __ksymtab : 0xffffffffa039fdc0 __mcount_loc : 0xffffffffa039f6e8 __param : 0xffffffffa039f568 __verbose : 0xffffffffa03a1980]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>Linux命令</category>
      </categories>
      <tags>
        <tag>lsmod</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python常见模块+方法+函数记录]]></title>
    <url>%2F2018%2F07%2F11%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fpython%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[模块sys模块os模块time模块在平常的代码中，我们常常需要与时间打交道。在Python中，与时间处理有关的模块包括：time，datetime以及calendar。 在开始之前，首先要说明这几点： 在Python中，通常有这几种方式来表示时间： 1）时间戳 2）格式化的时间字符串 3）元组（struct_time）共九个元素。由于Python的time模块实现主要调用C库，所以各个平台可能有所不同。 UTC（Coordinated Universal Time，世界协调时）亦即格林威治天文时间，世界标准时间。在中国为UTC+8。DST（Daylight Saving Time）即夏令时。 时间戳（timestamp）的方式：通常来说，时间戳表示的是从1970年1月1日00:00:00开始按秒计算的偏移量。我们运行“type(time.time())”，返回的是float类型。返回时间戳方式的函数主要有time()，clock()等。 元组（struct_time）方式：struct_time元组共有9个元素，返回struct_time的函数主要有gmtime()，localtime()，strptime()。下面列出这种方式元组中的几个元素： 索引（Index） 属性（Attribute） 值（Values） 0 tm_year（年） 比如2011 1 tm_mon（月） 1 - 12 2 tm_mday（日） 1 - 31 3 tm_hour（时） 0 - 23 4 tm_min（分） 0 - 59 5 tm_sec（秒） 0 - 61 6 tm_wday（weekday） 0 - 6（0表示周日） 7 tm_yday（一年中的第几天） 1 - 366 8 tm_isdst（是否是夏令时） 默认为-1 获取当前时间戳123print (time.time())输出如下：1531317129.0039742 时间元祖123print (time.localtime())输出如下：time.struct_time(tm_year=2018, tm_mon=7, tm_mday=11, tm_hour=22, tm_min=4, tm_sec=18, tm_wday=2, tm_yday=192, tm_isdst=0) 格式化时间最简单的获取可读模式的方法是asctime() 123print (time.asctime())输出如下：Wed Jul 11 21:52:09 2018 使用指定的格式输出，在这里，使用strftime方法 123print (time.strftime(&quot;%Y-%m-%d %H:%M:%S&quot;,time.localtime()))输入如下：2018-07-11 22:02:27 补充-python中时间日期格式化符号 python中时间日期格式化符号： %y 两位数的年份表示（00-99） %Y 四位数的年份表示（000-9999） %m 月份（01-12） %d 月内中的一天（0-31） %H 24小时制小时数（0-23） %I 12小时制小时数（01-12） %M 分钟数（00=59） %S 秒（00-59） %a 本地简化星期名称 %A 本地完整星期名称 %b 本地简化的月份名称 %B 本地完整的月份名称 %c 本地相应的日期表示和时间表示 %j 年内的一天（001-366） %p 本地A.M.或P.M.的等价符 %U 一年中的星期数（00-53）星期天为星期的开始 %w 星期（0-6），星期天为星期的开始 %W 一年中的星期数（00-53）星期一为星期的开始 %x 本地相应的日期表示 %X 本地相应的时间表示 %Z 当前时区的名称 %% %号本身 sleepPython time sleep() 方法推迟调用线程的运行，可通过参数secs指秒数，表示进程挂起的时间。 语法如下： 1time.sleep(t) commands模块-3.x已废弃用Python写运维脚本时，经常需要执行linux shell的命令，Python中的commands模块专门用于调用Linux shell命令，并返回状态和结果。 下面是commands模块的几个主要方法： commands.getoutput(‘shell command’)执行shell命令，返回结果（string类型） 案例如下： 12345678910111213输出指定进程的pidwxh@wxh-virtual-machine:~/python_files$ cat tt.py#!/usr/bin/env python2import sys,commandscmdline = sys.argv[1]cmdline1 = sys.argv[2]cmd = &quot;ps -ef|grep &quot; + cmdline + &quot;|grep &quot; + cmdline1 + &quot;|grep -v grep|grep -v python|awk &apos;&#123;print $2&#125;&apos;&quot;c1 = commands.getoutput(cmd)print (c1)print (type(c1)) 执行后输出如下所示： 1234wxh@wxh-virtual-machine:~/python_files$ python2 ./tt.py unity-panel-service lockscreen-mode126263&lt;type &apos;str&apos;&gt; commands.getstatusoutput(‘shell command’)执行shell命令, 返回两个元素的元组tuple(status, result)，status为int类型，result为string类型。 因为cmd的执行方式是{ cmd ; } 2&gt;&amp;1, 故返回结果包含标准输出和标准错误. 第一个值为命令执行的返回状态码，执行成功则返回的是0，不成功则返回的是非0 案例如下： 123456789wxh@wxh-virtual-machine:~/python_files$ cat tt.py #!/usr/bin/env python2import sys,commandscmdline = sys.argv[1]cmdline1 = sys.argv[2]cmd = &quot;ps -ef|grep &quot; + cmdline + &quot;|grep &quot; + cmdline1 + &quot;|grep -v grep|grep -v python|awk &apos;&#123;print $2&#125;&apos;&quot;res = commands.getstatusoutput(cmd)print (res) 执行后输出如下所示： 12wxh@wxh-virtual-machine:~/python_files$ python2 ./tt.py unity-panel-service lockscreen-mode(0, &apos;126263&apos;) subprocess模块用于检测linux进程的状态 实例如下： def redis_status(new_port): p = subprocess.Popen([&quot;netstat&quot;, &quot;-unptl&quot;], stdout=subprocess.PIPE) out, err = p.communicate() if (new_port in str(out) ): print (&quot;redis {PORT} instance is running...&quot;.format(PORT=new_port)) else: print (&quot;start redis {PORT} faild.please check again...&quot;.format(PORT=new_port)) 方法文件操作truncate() 方法truncate() 方法用于截断文件，如果指定了可选参数 size，则表示截断文件的 size 个字符。 如果没有指定 size，则从当前位置起截断（截断余下的所有字符）；截断之后 size 后面的所有字符被删除。 seek()方法]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网卡中断与CPU绑定]]></title>
    <url>%2F2018%2F07%2F11%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%2F%E7%BD%91%E7%BB%9C%E8%B0%83%E4%BC%98%2F%E7%BD%91%E5%8D%A1%E4%B8%AD%E6%96%AD%E4%B8%8ECPU%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[参考文献： Linux 性能调优] 网卡中断与CPU的绑定问题 简单介绍下linux下的中断（interrupt）- 一切皆有可能 - 51CTO技术博客 把网卡中断绑定到CPU,最大化网卡的吞吐量 - SegmentFault Linux 多核下绑定硬件中断到不同 CPU（IRQ Affinity） | vpsee.com Linux系统CPU的性能监控及调优 - 简书 Tech Items - Linux NIC Interrupts Overloading Single CPUs - ChinaNetCloud Linux网卡中断使单个CPU过载 - 推酷 网卡软中断调优 - deven的博客 - 51CTO技术博客 除了不让多个中断集中到单个CPU，还有更进一步的方法: 调整网卡驱动参数使之采用多个队列，这样多个CPU可以各自处理一个队列。 当然，这依赖于网卡是否支持 多队列网卡及网卡中断绑定阐述 – 运维那点事 (这篇文章讲得很全面，推荐阅读） 网卡多队列及中断绑定 - wyaibyn的专栏 - CSDN博客 8.6. Receive-Side Scaling (RSS) - Performance Tuning Guide - Red Hat Enterprise Linux 6 即使网卡只支持单个队列，我们可以在系统层面模拟层多个队列，这个涉及到被称为Receive Packet Steering (RFS)和Receive Flow Steering (RFS）的两个技术 多队列网卡及网卡中断绑定阐述 – 运维那点事 8.7. Receive Packet Steering (RPS) - Performance Tuning Guide - Red Hat Enterprise Linux 6 8.8. Receive Flow Steering (RFS) - Performance Tuning Guide - Red Hat Enterprise Linux 6 在Linux的网络调优方面，如果你发现网络流量上不去，那么有一个方面需要去查一下：网卡处理网络请求的中断是否被绑定到单个CPU（或者说跟处理其它中断的是同一个CPU）。 背景网卡与操作系统的交互一般有两种方式： 一种是中断（IRQ，网卡在收到了网络信号之后，主动发送中断到CPU，而CPU将会立即停下手边的活以便对这个中断信号进行分析）， 另一种叫DMA（Direct Memory Access, 也就是允许硬件在无CPU干预的情况下将数据缓存在指定的内存空间内，在CPU合适的时候才处理） 在网卡方面，大部分还是在用IRQ方式（据说DMA技术仅仅被应用在少数高端网卡上; 另一个说法是：DMA方式会使外部设备的控制器独占PCI总线，从而CPU无法与外部设备进行交互，这对通用型操作系统Linux来说，是很难接收的，所以DMA方式在Linux内核里使用得很少）。 但是（再来一个但是），在现在的对称多核处理器（SMP）上，一块网卡的IRQ还是只有一个CPU来响应，其它CPU无法参与，如果这个CPU还要忙其它的中断（其它网卡或者其它使用中断的外设（比如磁盘）），那么就会形成瓶颈。 问题判定网上不少讲这个问题的文章都是直接让查询IRQ跟CPU的绑定情况，甚至直接修改。但我们应该先判断我们的系统是不是受这个问题影响，然后再来看怎么解决。 首先，让你的网络跑满（比如对于MySQL/MongoDB服务，可以通过客户端发起密集的读操作; 或者执行一个i大文件传送任务） 第一个要查明的是：是不是某个CPU在一直忙着处理IRQ？ 这个问题我们可以从 mpstat -P ALL 1 的输出中查明：里面的 %irq一列即说明了CPU忙于处理中断的时间占比 12345618:20:33 CPU %user %nice %sys %iowait %irq %soft %steal %idle intr/s18:20:33 all 0,23 0,00 0,08 0,11 6,41 0,02 0,00 93,16 2149,2918:20:33 0 0,25 0,00 0,12 0,07 0,01 0,05 0,00 99,49 127,0818:20:33 1 0,14 0,00 0,03 0,04 0,00 0,00 0,00 99,78 0,0018:20:33 2 0,23 0,00 0,02 0,03 0,00 0,00 0,00 99,72 0,0218:20:33 3 0,28 0,00 0,15 0,28 25,63 0,03 0,00 73,64 2022,19 上面的例子中，第四个CPU有25.63%时间在忙于处理中断（这个数值还不算高，如果高达80%（而同时其它CPU这个数值很低）以上就说明有问题了），后面那个 intr/s 也说明了CPU每秒处理的中断数（从上面的数据也可以看出，其它几个CPU都不怎么处理中断）。 然后我们就要接着查另外一个问题：这个忙于处理中断的CPU都在处理哪个（些）中断？ 1234567891011121314cat /proc/interrupts CPU0 CPU1 CPU2 CPU3 0: 245 0 0 7134094 IO-APIC-edge timer 8: 0 0 49 0 IO-APIC-edge rtc 9: 0 0 0 0 IO-APIC-level acpi 66: 67 0 0 0 IO-APIC-level ehci_hcd:usb2 74: 902214 0 0 0 PCI-MSI eth0169: 0 0 79 0 IO-APIC-level ehci_hcd:usb1177: 0 0 0 7170885 IO-APIC-level ata_piix, b4xxp185: 0 0 0 59375 IO-APIC-level ata_piixNMI: 0 0 0 0 LOC: 7104234 7104239 7104243 7104218 ERR: 0MIS: 0 这里记录的是自启动以来，每个CPU处理各类中断的数量（第一列是中断号，最后一列是对应的设备名）[详细说明: E.2.10 /proc/interrupts - Deployment Guide - RedHat Enterprise Linux 6 )，从上面可以看到： eth0所出发的中断全部都是 CPU0在处理，而CPU0所处理的中断请求中，主要是eth0和LOC中断。 （有时我们会看到几个CPU对同一个中断类型所处理的的请求数相差无几（比如上面的LOC一行），这并不一定是说多个CPU会轮流处理同一个中断，而是因为这里记录的是“自启动以来”的统计，中间可能因为irq balancer重新分配过处理中断的CPU——当然，也可能是谁手工调节过）。 解决问题首先说明几点： 首先应该根据上面的诊断方法查明当前系统是不是受这个原因影响，如果不是，那么就没有必要往下看了; 现在的多数Linux系统中已经有了IRQ Balance这个服务（服务程序一般是 /usr/sbin/irqbalance），它可以自动调节分配各个中断与CPU的绑定关系，以避免所有中断的处理都集中在少数几个CPU上; 在某些情况下，这个IRQ Balance反而会导致问题，会出现 irqbalance 这个进程反而自身占用了较高的CPU（当然也就影响了业务系统的性能） 下面来说手工将中断限定到少数几个CPU的方法。 首先当然要查明，该网卡的中断当前是否已经限定到某些CPU了？具体是哪些CPU？ 根据上面 /proc/interrupts 的内容我们可以看到 eth0 的中断号是74，然后我们来看看该中断号的CPU绑定情况（或者说叫亲和性 affinity） 12$ sudo cat /proc/irq/74/smp_affinityffffff 这个输出是一个16进制的数值，0xffffff = ‘0b111111111111111111111111’，这就意味着这里有24个CPU，所有位都为1表示所有CPU都可以被该中断干扰。 另一个例子: 12$ sudo cat /proc/irq/67/smp_affinity00000001 这个例子说明，只有CPU0处理编号为67的中断。 修改配置的方法： 我们可以用 echo 2 &gt; /proc/irq/74/smp_affinity 的方法来修改这个设置（设置为2表示将该中断绑定到CPU1上，0x2 = 0b10，而第一个CPU为CPU0）]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>性能调优</category>
        <category>网络调优</category>
      </categories>
      <tags>
        <tag>性能调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LVS性能指标及监控]]></title>
    <url>%2F2018%2F07%2F10%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F4%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1-LVS%2FLVS%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87%E5%8F%8A%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[参考文献： Performance and Tuning - LVSKB 性能参数LVS 的性能主要通过以下几个方面来提高 ipvs connection table size-最大连接数官方的解释如下： 12345678910111213141516171819202122232425The IPVS connection hash table uses the chaining scheme to handlehash collisions. Using a big IPVS connection hash table will greatlyreduce conflicts when there are hundreds of thousands of connectionsin the hash table.Note the table size must be power of 2. The table size will be thevalue of 2 to the your input number power. The number to choose isfrom 8 to 20, the default number is 12, which means the table sizeis 4096. Don&apos;t input the number too small, otherwise you will loseperformance on it. You can adapt the table size yourself, accordingto your virtual server application. It is good to set the table sizenot far less than the number of connections per second multiplyingaverage lasting time of connection in the table. For example, yourvirtual server gets 200 connections per second, the connection lastsfor 200 seconds in average in the connection table, the table sizeshould be not far less than 200x200, it is good to set the tablesize 32768 (2**15).Another note that each connection occupies 128 bytes effectively andeach hash entry uses 8 bytes, so you can estimate how much memory isneeded for your box.You can overwrite this number setting conn_tab_bits module parameteror by appending ip_vs.conn_tab_bits=? to the kernel command lineif IP VS was compiled built-in. 说明： LVS的连接信息使用IPVS connection hash table这个哈希表去保存，它记录每个进来的连接及路由去向的信息 任何一个报文到达都需要查找连接Hash表。Hash表的查找复杂度为O(n/m)，其中n为Hash表中对象的个数，m为Hash表的桶个数。当对象在Hash表中均匀分布和Hash表的桶个数与对象个数一样多时，Hash表的查找复杂度可以接近O(1)。 table size使用2的幂次方进行配置指定，范围为8-20，也就是说连接数的取值范围为：2^8-2^20 默认配置为2^12，也就是4096个连接数上限 在生产环境中，我们一般设置为最大值，也就是2^20（1048576） 注意，这些连接是需要占用内存的，因此要考虑到内存大小的因素 每一个TCP连接需要占用约128字节，哈希表的每个条目需要占用8字节 以设置为最大值为例，那么，这些连接以及条目共占用内存如下： 2^20*(128byte+8byte) = 142606336byte = 136MB 配置： 在/etc/modprobe.d/目录下添加文件ip_vs.conf，内容为： options ip_vs conn_tab_bits=22（文档中写的上限是20，但是实际配置的时候发现22也是可以的） 123echo &apos;options ip_vs conn_tab_bits=22&apos; &gt; /etc/modprobe.d/ipvs.confmodprobe -r ip_vs &amp;&amp; modprobe -a ip_vsipvsadm -Ln 注意，在卸载内核模块的时候，可能会有依赖关系，这时候使用lsmod先查看依赖调用关系，将调用的模块卸载之后再进行操作，例如，这里的操作如下： 1234[root@lvs001 modprobe.d]# modprobe -r ip_vs_rr[root@lvs001 modprobe.d]# modprobe -r ip_vs[root@lvs001 modprobe.d]# modprobe -a ip_vs[root@lvs001 modprobe.d]# modprobe -a ip_vs_rr CPU Soft Interrupt -CPU软中断在Linux的网络调优方面，如果你发现网络流量上不去，那么有一个方面需要去查一下：网卡处理网络请求的中断是否被绑定/发送到单个CPU，导致只有一个CPU处理网络请求 但是，在当前的对称多核处理器服务器上，一块网卡的IRQ还是只有一个CPU来响应，其它CPU无法参与，如果这个CPU还要忙其它的中断（其它网卡或者其它使用中断的外设（比如磁盘）），那么就会形成瓶颈。 动态查看CPU的irq情况 12命令：mpstat -P ALL 1 %irq一列即说明了CPU忙于处理中断的时间占比 查看CPU处理中断的情况 12cat /proc/interrupts 这里记录的是自启动以来，每个CPU处理各类中断的数量（第一列是中断号，最后一列是对应的设备名） 我们进行过滤，获取网卡的中断号，然后再分析CPU的中断情况 获取对应的中断号 123456789101112131415161718192021[root@lvs001 ~]# cat /proc/interrupts | egrep &apos;em1|em2|p1p1|p1p2&apos; | awk &apos;&#123;print $1&#125;&apos;157:158:159:160:161:162:163:164:165:166:167:168:169:170:171:172:173:174:175:176: 获取CPU的处理信息 1234567891011121314151617181920212223[root@lvs001 ~]# for i in &#123;157..176&#125;;do cat /proc/interrupts | egrep -w $i ;done 157: 13529132 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em1-tx-0 158: 32642550 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em1-rx-1 159: 30481981 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em1-rx-2 160: 15555217 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em1-rx-3 161: 25509530 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em1-rx-4 162: 13538297 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em2-tx-0 163: 25653580 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em2-rx-1 164: 25741710 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em2-rx-2 165: 35448970 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em2-rx-3 166: 25494937 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge em2-rx-4 167: 256824 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p1-tx-0 168: 281534 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p1-rx-1 CAL: 133 863797 189 189 189 189 188 189 189 189 189 189 189 189 189 189 188 188 168 185 188 186 188 188 188 188 188 188 188 189 187 130 Function call interrupts 169: 64639 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p1-rx-2 170: 65879 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p1-rx-3 171: 425700 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p1-rx-4 172: 256754 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p2-tx-0 173: 43230 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p2-rx-1 174: 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p2-rx-2 175: 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p2-rx-3 176: 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 IR-PCI-MSI-edge p1p2-rx-4[root@lvs001 ~]# 这里显示不友好，建议复制到编辑器中查看 可以看到，这些网卡的中断都是由CPU0来处理的 查看 1[root@lvs002 ~]# for i in &#123;157..176&#125;;do cat /proc/irq/$i/smp_affinity;done 配置 1for i in &#123;157..176&#125;;do echo ffffffff &gt; /proc/irq/$i/smp_affinity;done Netfilter Connection Track-连接跟踪原文： IPVS uses its own simple and fast connection tracking for performance reasons, instead of using netfilter connection tracking. So, if you don’t use firewalling feature at load balancer and you need an extremely fast load balancer, do not load netfilter conntrack modules into you system, because there is no need to do double tracking. Note that LVS/NAT should work too without the conntrack modules. Julian compared the performance of IPVS with ip_conntrack and without ip_conntrack. See http://archive.linuxvirtualserver.org/html/lvs-users/2001-12/msg00141.html 默认情况下LVS自身会记录连接信息，但是 iptables 也会记录 connection 的状态，但是很多情况下，我们并不需要 iptables 来做这件事， 我们可以告诉它 NOTRACK，不要记录这些信息。 配置： 增加raw表，在其他表处理之前，-j NOTRACK跳过其它表处理 123456iptables -t raw -A PREROUTING -d 103.13.244.16/29 -p tcp --dport 80 -j NOTRACK iptables -t raw -A OUTPUT -d 103.13.244.16/29 -p tcp --dport 80 -j NOTRACK iptables -t raw -A PREROUTING -d 103.13.244.16/29 -p tcp --dport 443 -j NOTRACK iptables -t raw -A OUTPUT -d 103.13.244.16/29 -p tcp --dport 443 -j NOTRACK [root@lvs002 ~]# /etc/init.d/iptables save 与之同时，因为涉及到内网之间的通信，因此这里也将连接跟踪表进行调大 123456# vim /etc/sysctl.confnet.netfilter.nf_conntrack_max = 3065536 net.nf_conntrack_max = 3065536 # sysctl -p Real Server - syn cookie参数参考链接： lvs-users IPVS SYN-cookies SYN Cookie是对TCP服务器端的三次握手协议作一些修改，专门用来防范SYN Flood攻击的一种手段。它的原理是，在TCP服务器收到TCP SYN包并返回TCP SYN+ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。在收到TCP ACK包时，TCP服务器在根据那个cookie值检查这个TCP ACK包的合法性。如果合法，再分配专门的数据区进行处理未来的TCP连接。 SYN Flood攻击利用的是IPv4中TCP协议的三次握手（Three-Way Handshake）过程进行的攻击。TCP协议规定，一端向另一端发起TCP连接时，它需要首先发送SYN 包到对方，对方收到后发送一个SYN+ACK包回来，发起方再发送 ACK包回去，这样三次握手就结束了。我们把TCP连接的发起方叫作”TCP客户机（TCP Client）”，TCP连接的接收方叫作”TCP服务器（TCP Server）”。值得注意的是在TCP服务器收到TCP SYN request包时，在发送TCP SYN+ACK包回TCP客户机前，TCP服务器要先分配好一个数据区专门服务于这个即将形成的TCP连接。一般把收到SYN包而还未收到ACK包时的连接状态称为半开连接（Half-open Connection）。 在最常见的SYN Flood攻击中，攻击者在短时间内发送大量的TCP SYN包给受害者，这时攻击者是TCP客户机，受害者是TCP服务器。根据上面的描述，受害者会为每个TCP SYN包分配一个特定的数据区，只要这些SYN包具有不同的源地址（这一点对于攻击者来说是很容易伪造的）。这将给TCP服务器系统造成很大的系统负担，最终导致系统不能正常工作。 内核文档说明 123456789101112131415161718192021222324tcp_syncookies - BOOLEAN Only valid when the kernel was compiled with CONFIG_SYN_COOKIES Send out syncookies when the syn backlog queue of a socket overflows. This is to prevent against the common &apos;SYN flood attack&apos; Default: 1 Note, that syncookies is fallback facility. It MUST NOT be used to help highly loaded servers to stand against legal connection rate. If you see SYN flood warnings in your logs, but investigation shows that they occur because of overload with legal connections, you should tune another parameters until this warning disappear. See: tcp_max_syn_backlog, tcp_synack_retries, tcp_abort_on_overflow. syncookies seriously violate TCP protocol, do not allow to use TCP extensions, can result in serious degradation of some services (f.e. SMTP relaying), visible not by you, but your clients and relays, contacting you. While you see SYN flood warnings in logs not being really flooded, your server is seriously misconfigured. If you want to test which effects syncookies have to your network connections you can set this knob to 2 to enable unconditionally generation of syncookies. 注意，即使开启该机制并不意味着所有的连接都是用SYN cookies机制来完成连接的建立，只有在半连接队列已满的情况下才会触发SYN cookies机制。由于SYN cookies机制严重违背TCP协议，不允许使用TCP扩展，可能对某些服务造成严重的性能影响（如SMTP转发），对于防御SYN flood攻击的确有效。对于没有收到攻击的高负载服务器，不要开启此选项，可以通过修改tcp_max_syn_backlog、tcp_synack_retries和tcp_abort_on_overflow系统参数来调节。 tcp_max_syn_backlog变量告诉你在内存中可以缓存多少个SYN请求。该变量需要打开tcp_syncookies才有效。如果服务器负载很高，可以尝试提高该变量的值。 tcp_synack_retries变量用于TCP三次握手机制中第二次握手，当收到客户端发来的SYN连接请求后，服务端将回复SYN+ACK包，这时服务端处于SYN_RCVD状态，并等 待客户端发来的回复ACK包。如果服务端没有收到客户端的ACK包，会重新发送SYN+ACK包，直到收到客户端的ACK包。该变量设置发送 SYN+ACK包的次数，超过这个次数，服务端将放弃连接。默认值是5。 tcp_abort_on_overflow变量的值是个布尔值，默认值为0（FALSE关闭）。如果开启，当服务端接收新连接的速度变慢时，服务端会发送RST包（reset包）给客户端，令客户端 重新连接。这意味着如果突然发生溢出，将重获连接。仅当你真的确定不能通过调整监听进程使接收连接的速度变快，可以启用该选项。该选项会影响到客户的连接。 配置： 12345678# vim /etc/sysctl.conf net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_max_syn_backlog = 2048保存退出后，执行：# sysctl -p 参数说明如下： net.ipv4.tcp_syncookies = 1#表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN*，默认为0，表示关闭； net.ipv4.tcp_tw_reuse = 1#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；为1，开启； 这个酌情开启，这里暂时不开启 net.ipv4.tcp_tw_recycle = 1#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭；为1，开启； net.ipv4.tcp_fin_timeout #修改系統默认的 TIMEOUT 时间，这里根据服务器的实际情况设置。默认为60秒 另外细心的朋友可能发现了，报错信息： Possible SYN flooding on port 13370. Sending cookies.后面跟了句”Check SNMP counters”。这句我当时差点被误导，因为我的服务器上正好跑了一个snmp抓流量的服务，开始以为是它导致的，后来一想那是udp的协议，和tcp没关系呀。查了kernel的代码发现，原来那是print打印的固定info输出： 1234567891011121314151617181920212223static bool tcp_syn_flood_action(const struct sock *sk, const struct sk_buff *skb, const char *proto)&#123; struct request_sock_queue *queue = &amp;inet_csk(sk)-&gt;icsk_accept_queue; const char *msg = &quot;Dropping request&quot;; bool want_cookie = false; struct net *net = sock_net(sk);#ifdef CONFIG_SYN_COOKIES if (net-&gt;ipv4.sysctl_tcp_syncookies) &#123; msg = &quot;Sending cookies&quot;; want_cookie = true; __NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPREQQFULLDOCOOKIES); &#125; else#endif __NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPREQQFULLDROP); if (!queue-&gt;synflood_warned &amp;&amp; net-&gt;ipv4.sysctl_tcp_syncookies != 2 &amp;&amp; xchg(&amp;queue-&gt;synflood_warned, 1) == 0) pr_info(&quot;%s: Possible SYN flooding on port %d. %s. Check SNMP counters.\n&quot;, proto, ntohs(tcp_hdr(skb)-&gt;dest), msg); return want_cookie;&#125; 关闭网卡LRO和GRO现在大多数网卡都具有LRO/GRO功能，即 网卡收包时将同一流的小包合并成大包 （tcpdump抓包可以看到&gt;MTU 1500bytes的数据包）交给 内核协议栈；LVS内核模块在处理&gt;MTU的数据包时，会丢弃； 因此，如果我们用LVS来传输大文件，很容易出现丢包，传输速度慢； 解决方法，关闭LRO/GRO功能，命令： 12345678910111213ethtool -k eth0 查看LRO/GRO当前是否打开ethtool -K eth0 lro off 关闭GROethtool -K eth0 gro off 关闭GRO查看：[root@lvs001 ~]# ethtool -k p1p1 | grep offload[root@lvs001 ~]# ethtool -k p1p2 | grep offload配置：[root@lvs001 ~]# ethtool -K p1p1 lro off[root@lvs001 ~]# ethtool -K p1p1 gro off[root@lvs001 ~]# ethtool -K p1p2 lro off[root@lvs001 ~]# ethtool -K p1p2 gro off offload特性，主要是指将原本在协议栈中进行的IP分片、TCP分段、重组、checksum校验等操作，转移到网卡硬件中进行，降低系统CPU的消耗，提高处理性能。 包括 LSO/LRO、GSO/GRO、TSO/UFO 等。 LSO/LRO 分别对应到发送和接收两个方向，是 Large Segment Offload 和 Large Receive Offload。 首先来看 LSO。我们知道计算机网络上传输的数据基本单位是离散的网包，既然是网包，就有大小限制，这个限制就是 MTU（Maximum Transmission Unit）的大小，一般是1518字节。比如我们想发送很多数据出去，经过os协议栈的时候，会自动帮你拆分成几个不超过MTU的网包。然而，这个拆分是比较费计算资源的（比如很多时候还要计算分别的checksum），由 CPU 来做的话，往往会造成使用率过高。那可不可以把这些简单重复的操作 offload 到网卡上呢？ 于是就有了 LSO，在发送数据超过 MTU 限制的时候（太容易发生了），OS 只需要提交一次传输请求给网卡，网卡会自动的把数据拿过来，然后进行切，并封包发出，发出的网包不超过 MTU 限制。 接下来看 LSO，当网卡收到很多碎片包的时候，LRO 可以辅助自动组合成一段较大的数据，一次性提交给 OS处理。 一般的，LSO 和 LRO 主要面向 TCP 报文。 GSO/GRO Generic Segmentation Offload 和 Generic Receive Offload，分别比 LSO 和 LRO 更通用，自动检测网卡支持特性，支持分包则直接发给网卡，否则先分包后发给网卡。新的驱动一般用 GSO/GRO。 TSO/UFO TCP Segmentation Offload 和 UDP fragmentation offload，分别对应 TCP 报文和 UDP 报文。 很典型的，TCP 协议中就考虑了分片存在的情况，往往是切分 TCP 的数据包，叫做 TSO。而一般的情况，则称为 LSO 或者 GSO。 对于其他不支持切片的协议例如 UDP，则只能进行 IP 层上的切片。 检查与开关 可以通过 ethtool -k eth0 命令来查看各个选项的当前状态，注意输出中各种 off-load 选项的状态。 总结 也就是说，在将数据包转发出去的时候，包的大小必须小于1500字节，但是在处理收到的数据包的时候，包的大小没有1500字节的限制 发送模式： TSO GSO UFO 接收模式： LRO GRO RSS 注意 目前常用的抓包工具大部分都是从协议栈中（如数据链路层）捕获数据包，而网卡的offload特性会将数据包的分片、重组等工作转移到协议栈以下的硬件层面进行，因此在开启TSO、GRO等机制的情况下，我们使用tcpdump、wireshark等工具抓取到的数据包往往不能真实反应链路上实际的数据帧，给网络流量特征的分析造成不利影响。 在某些情况下，例如分片攻击等攻击方式，甚至可能会因为网卡设备的offload机制处理，而规避防火墙、IDS以及人工的检查。针对这些情况，可以选择关闭网卡offload的相关选项，或者在链路的其他节点进行抓包。 /proc下的IP_VS参数设置根据前文的介绍，可以通过ipvsadm命令和LVS内核打交道； 除此之外，我们还可以通过proc参数，来 配置全局参数 和 获取统计信息； 配置全局参数，位于目录/proc/sys/net/ipv4/vs/下； 获取统计信息，位于目录/proc/net/下； 参考资料：官方内核文档 1234567891011121314151617[root@lvs001 ~]# ll /proc/sys/net/ipv4/vs | awk &apos;&#123;print $9&#125;&apos;am_droprateamemthreshcache_bypassconn_reuse_modedrop_entrydrop_packetexpire_nodest_connexpire_quiescent_templatenat_icmp_sendsecure_tcpsync_qlen_maxsync_refresh_periodsync_retriessync_sock_sizesync_thresholdsync_version 有一些几个参数需要进行调整 cache_bypass 12345678cache_bypass - BOOLEAN 0 - disabled (default) not 0 - enabled If it is enabled, forward packets to the original destination directly when no cache server is available and destination address is not local (iph-&gt;daddr is RTN_UNICAST). It is mostly used in transparent web cache cluster. 主要用于缓存体系，enable之后，当后端配置的是缓存系统的时候，当没有可用的sever时，直接将数据包转发给后端的数据产生节点 conn_reuse_mode 1234567891011121314151617181920conn_reuse_mode - INTEGER 1 - default Controls how ipvs will deal with connections that are detected port reuse. It is a bitmap, with the values being: 0: disable any special handling on port reuse. The new connection will be delivered to the same real server that was servicing the previous connection. This will effectively disable expire_nodest_conn. bit 1: enable rescheduling of new connections when it is safe. That is, whenever expire_nodest_conn and for TCP sockets, when the connection is in TIME_WAIT state (which is only possible if you use NAT mode). bit 2: it is bit 1 plus, for TCP connections, when connections are in FIN_WAIT state, as this is the last state seen by load balancer in Direct Routing mode. This bit helps on adding new real servers to a very busy cluster. 用户后端server开启端口reuse（端口复用，服务器上启动多个进程监听同一个端口，在tenginx中使用时能够极大的提高性能）的情况。 当设置enable的时候，接受到新连接之后，将进行重新调度，将连接请求分发到启动该端口的其他进程上 expire_nodest_conn 1234567891011121314151617expire_nodest_conn - BOOLEAN 0 - disabled (default) not 0 - enabled The default value is 0, the load balancer will silently drop packets when its destination server is not available. It may be useful, when user-space monitoring program deletes the destination server (because of server overload or wrong detection) and add back the server later, and the connections to the server can continue. If this feature is enabled, the load balancer will expire the connection immediately when a packet arrives and its destination server is not available, then the client program will be notified that the connection is closed. This is equivalent to the feature some people requires to flush connections when its destination is not available. 设置为0时，当后端的server被检测为不可用时，不会立即将连接断开，而是会保持一段时间，让其自然过期失效，如果在这个过程当中，server又恢复正常，那么将继续使用这个连接 当设置为为enable（非0）时，当检测到后端的server不可用时，将会立即将这个连接关闭。 expire_quiescent_template 123456789101112131415expire_quiescent_template - BOOLEAN 0 - disabled (default) not 0 - enabled When set to a non-zero value, the load balancer will expire persistent templates when the destination server is quiescent. This may be useful, when a user makes a destination server quiescent by setting its weight to 0 and it is desired that subsequent otherwise persistent connections are sent to a different destination server. By default new persistent connections are allowed to quiescent destination servers. If this feature is enabled, the load balancer will expire the persistence template if it is to be used to schedule a new connection and the destination server is quiescent. 默认值为0，当RS的weight为0时（例如健康监测失败时，LB会将RS的权重重置为0），会话保持的新建连接还会继续调度到该RS上 如果设置为非0，那么当weight为0时，LB会将话保持的连接模板置为无效，重新调度新的RS； sync_threshold 123456789101112sync_threshold - vector of 2 INTEGERs: sync_threshold, sync_period default 3 50 It sets synchronization threshold, which is the minimum number of incoming packets that a connection needs to receive before the connection will be synchronized. A connection will be synchronized, every time the number of its incoming packets modulus sync_period equals the threshold. The range of the threshold is from 0 to sync_period. When sync_period and sync_refresh_period are 0, send sync only for state changes or only once when pkts matches sync_threshold 同步阈值设置，该文件中的值为两个整数，默认为3 50 数值表示含义如下（以3 50为例）：接受到3个数据包及以上，该连接就可以被同步 Linux系统调优-网络内核参数12345678910net.ipv4.tcp_tw_recyle=1net.ipv4.tcp_tw_reuse=1net.ipv4.tcp_max_syn_backlog=8192net.ipv4.tcp_keepalive_time=1800net.ipv4.tcp_fin_timeout=30net.core.rmem_max=16777216net.core.wmem_max=16777216net.ipv4.tcp_rmem=4096 87380 16777216net.ipv4.tcp_wmem=4096 65536 16777216net.core.netdev_max_backlog=3000 算法优化SH调度算法-尽量不要采用 一些业务为了支持会话保持，选择SH调度算法，以实现 同一源ip的请求调度到同一台RS上；但 SH算法本省没有实现一致性hash，一旦一台RS down，当前所有连接都会断掉；如果配置了inhibit_on_failure，那就更悲剧了，调度到该RS上的流量会一直损失； 实际线上使用时，如需会话保持，建议配置persistence_timeout参数，保证一段时间同一源ip的请求到同一RS上； WLC调度算法-注意RS donw-&gt;up的影响 WLC算法下，RS一旦出现down后up的情况，瞬间所有的新建连接都会调度到该RS上，可能会超过该RS处理请求的上限； 快速配置[root@lvs002 ~]# vim /etc/sysctl.conf [root@lvs002 ~]# sysctl -p 1234567891011121314151617181920212223242526net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.core.netdev_max_backlog = 2048net.ipv4.ip_local_port_range = 10000 65000net.ipv4.tcp_max_tw_buckets = 462144vm.swappiness = 1net.ipv4.tcp_max_syn_backlog = 65535net.core.somaxconn = 32768net.ipv4.ip_forward = 1net.netfilter.nf_conntrack_max = 3065536net.nf_conntrack_max = 3065536net.ipv4.tcp_syncookies = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_fin_timeout = 30net.ipv4.tcp_keepalive_time = 1800net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.ipv4.tcp_rmem = 4096 87380 16777216net.ipv4.tcp_wmem = 4096 65536 16777216net.core.netdev_max_backlog = 3000 LVS监控一般情况下，我们可以通过watch ipvsadm -ln来监视lvs的当前状态，但如果我们想分析一段时间（一周，一月或者更长）的连接数情况，ipvsadm就无能为力了。我们可以借助一个叫lvs-rrd的小工具来达到这个目的。 lvs-rrd官网链接：http://tepedino.org/lvs-rrd/ 但是在这里，由于这个工具只能收集连接数的数据，因此我们还是采用zabbix进行集中监控 使用lvs-rrd监控lvs状态lvs_rrd工具实现了网页的形式来查看lvs状态功能。 其主要有两个脚本组成：信息收集脚本和图像绘制脚本。 信息收集脚本是将lvs的信息生成rrd格式的数据文件，然后利用图像绘制脚本生成图像，并生成一个php页面，这个页面中引用其所生成的图像，这样我们可以通过web页面的形式查看生成的php页面，就可以时时的查看lvs的状态信息。 lvs_rrd需要部署在LVS-Master和LVS-Backup上，更准确的说lvs_rrd中的信息收集脚本一定要在LVS director 上运行（不能安装在其他服务器上）。 但是通过配置图像生成脚本和图像的生成目录，我们也可以将源数据时时的复制到其他的服务器中，再在其他服务器上生成图像展示 下面简单的介绍部署的步骤 下载安装rrdtool（画图）工具 123456789wget https://oss.oetiker.ch/rrdtool/pub/rrdtool-1.4.7.tar.gzyum -y install cairo-devel libxml2-devel pango-devel pango libpng-devel freetype freetype-devel libart_lgpl-devel perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker dejavu-lgc-sans-fonts./configure --prefix=/usr/local/rrdtoolmake &amp;&amp; make install echo &quot;/usr/local/rrdtool/lib&quot; &gt;&gt; /etc/ld.so.confldconfig 安装nginx 123456789yum -y install pcre pcre-devel php php-fpmuseradd -s /sbin/nologin nginxwget https://nginx.org/download/nginx-1.14.0.tar.gz./configure --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module --with-pcremake &amp;&amp; make install 注意修改nginx的监听端口为非80 nginx+php配置 12/etc/init.d/php-fpm startchkconfig php-fpm on 在nginx配置文件中添加以下内容 location ~ \.php$ { root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 下载安装lvs-rrd工具 这里使用最新的0.7版本，该版本要求rrdtool版本最低为： 1.2.x 将lvs-rrd-v0.7.tar.gz解压后将文件夹复制到/data/www/目录下并更名为lvs 1234wget http://tepedino.org/lvs-rrd/lvs-rrd-v0.7.tar.gztar -zxvf lvs-rrd-v0.7.tar.gzmv lvs-rrd-v0.7 /usr/local/nginx/html/lvs-rrd 修改相应的脚本文件： 12345vim lvs.rrd.update 修改以下内容RRDTOOL=&quot;/usr/local/rrdtool/bin/rrdtool&quot; #rrdtool可执行程序路径IPVSADM=&quot;/sbin/ipvsadm&quot; #ipvsadm命令路径WORKDIR=&quot;/data1/lvs-rrd&quot; #rrdtool收集的数据的存放路径 12345678vim graph-lvs.sh 修改以下内容# WORKDIR must match the directory used in the update script.WORKDIR=&quot;/data1/lvs-rrd&quot; #rrdtool收集的数据的存放路径,同上面一致RRDTOOL=&quot;/usr/local/rrdtool/bin/rrdtool&quot; #rrdtool可执行程序路径# Where to put the graphs. GRAPHS=&quot;/data1/lvs-rrd/graphs&quot; #生成的图片保存路径WEBPATH=&quot;/lvs-rrd/graphs&quot; #web访问的路径 123456vim lvs-rrd.php&lt;?phpheader(&quot;Cache-Control: max-age=300, must-revalidate&quot;);system(&quot;/usr/local/nginx/html/lvs-rrd/graph-lvs.sh -H&quot;);?&gt; 注意：WEBPATH的配置是浏览器实际访问时图片的访问路径，也就是http://ip:port/webpath/xxx.gif 在日志中的输出显示为： /usr/local/nginx/html/lvs-rrd/graphs/lvs.All.All.All.All.All-year.gif 因此需要手动在站点目录下创建该目录并创建软链接，将生成的图片保存路径链接到该目录 12mkdir -p /usr/local/nginx/html/lvs-rrd/graphsln -s /data1/lvs-rrd/graphs /usr/local/nginx/html/lvs-rrd/graphs 配置nginx认证 在nginx配置文件的server中配置如下两行 12auth_basic &quot;dwd&quot;;auth_basic_user_file htpasswd; 然后执行以下命令创建加密文件 1htpasswd -bc htpasswd ops-lvs Dwd_Ops_123 配置计划任务 这里，将更新数据的间隔时间设置为30s 1234* * * * * /usr/local/nginx/html/lvs-rrd/lvs.rrd.update &gt;/dev/null 2&gt;&amp;1* * * * * /usr/local/nginx/html/lvs-rrd/graph-lvs.sh -H &gt; /dev/null 2&gt;&amp;1* * * * * sleep 30 ; /usr/local/nginx/html/lvs-rrd/lvs.rrd.update &gt;/dev/null 2&gt;&amp;1* * * * * sleep 30 ; /usr/local/nginx/html/lvs-rrd/graph-lvs.sh -H &gt; /dev/null 2&gt;&amp;1 Zabbix监控LVS监控指标： 动态的数据： cps(connect per second) ，每秒的连接数情况 InPPS(input packge per second)，每秒的入向数据包数量情况 OutPPS(output packge per second)，每秒的出向数据包数量情况 InBPS（input byte per second）,每秒的流入字节数情况 OutBPS(output byte per second)，每秒的流出字节数情况 ActiveConn，处于ESAT的连接（使用系统的netstat无法看到） InActConn，处于非ESAT的连接（使用系统的netstat无法看到） 静态统计数据： Conns，自启动之后的总连接数 InPkts，自启动之后的总入向数据包数量统计 OutPkts，自启动之后的总出向数据包数量统计 InBytes，自启动之后的总入向字节数统计 OutBytes，自启动之后的总出向字节数统计 监控逻辑： 使用ipvsadm命令从服务器中采集数据 所使用的命令分别为： ipvsadm -Ln –rate ipvsadm -Ln –stats 注意：zabbix配置文件中需要打开sudo的权限，拥有root的权限之后才能执行ipvsadm命令去获取数据]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>运维架构</category>
        <category>高并发</category>
        <category>负载均衡</category>
        <category>4层负载均衡-LVS</category>
      </categories>
      <tags>
        <tag>LVS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day03-集合及文件操作知识补充+函数]]></title>
    <url>%2F2018%2F07%2F08%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday03-%E9%9B%86%E5%90%88%E5%8F%8A%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%E7%9F%A5%E8%AF%86%E8%A1%A5%E5%85%85%2B%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[集合集合是一个无序的，不重复的数据组合，它的主要作用如下： 去重，把一个列表变成集合，就自动去重了 关系测试，测试两组数据之前的交集、差集、并集等关系 集合创建： 12345678910list = [1,2,3,4,5,7,6,6,1,7,8]list_set = set(list)print (list_set,type(list_set))set1 = set()print (set1,type(set1))执行后输出如下：&#123;1, 2, 3, 4, 5, 6, 7, 8&#125; &lt;class &apos;set&apos;&gt;set() &lt;class &apos;set&apos;&gt; 高级操作： 1234567a = t | s # t 和 s的并集 b = t &amp; s # t 和 s的交集 c = t – s # 求差集（项在t中，但不在s中） d = t ^ s # 对称差集（项在t或s中，但不会同时出现在二者中），也就是在并集中去除掉了交集 其他操作： 123t.add(&apos;x&apos;) # 添加一项 s.update([10,37,42]) # 在s中添加多项 12345使用remove()可以删除一项： t.remove(&apos;H&apos;) 还有discard()方法可以删除，但是当元素不存在的时候，它不会和remove一样报错 123456789101112131415161718192021222324252627282930313233343536373839404142434445len(s) set 的长度 x in s 测试 x 是否是 s 的成员 x not in s 测试 x 是否不是 s 的成员 s.issubset(t) s &lt;= t 测试是否 s 中的每一个元素都在 t 中 s.issuperset(t) s &gt;= t 测试是否 t 中的每一个元素都在 s 中 s.union(t) s | t 返回一个新的 set 包含 s 和 t 中的每一个元素 s.intersection(t) s &amp; t 返回一个新的 set 包含 s 和 t 中的公共元素 s.difference(t) s - t 返回一个新的 set 包含 s 中有但是 t 中没有的元素 s.symmetric_difference(t) s ^ t 返回一个新的 set 包含 s 和 t 中不重复的元素 s.copy() 返回 set “s”的一个浅复制 判断两个集合是否有交集s1 = set([1,2,3,4,5,6])s2 = set([2,4,6,8,10])s3 = set([11,22,44,55])print (s1.isdisjoint(s2))print (s1.isdisjoint(s3))输出为：FalseTrue 文件文件操作相关知识文件读取read()方法，一次性读取文件的所有内容，当文件非常大的时候非常不建议 readline()方法，一次只读取文件的一行，从上往下的顺序 readlines()方法，将文件的内容按行一次性重新输出为一个==列表==，每行一个元素 read()和readlines()方法都是一次性读取文件的全部内容，只适合于小文件，不适合大文件 readline()是一行一行的读取，在大文件的时候也是十分占用内存的 注意，以上这三种方法只适合读取小文件，在读取大文件的时候，不能够再使用这种方法。 思路：文件的内容，打印完一行之后就不再需要这一行了，因此已经读取的内容就没有必要再存储在内存当中，在内存中永远只保存一行 写法如下： 12345f = open(r&apos;C:\Users\Administrator\PycharmProjects\files\login.txt&apos;, &apos;r&apos;)for line in f: print(line)f.close() tell()和seek()-文件位置tell打印当前文件内容的输出位置，seek将当前光标重新定向到指定的位置 例如： 1234567891011print(f.readline())print(f.readline())print (f.tell())f.seek(0)print (f.readline())执行后输出为：wxh:wxh123wsy:wsy12324wxh:wxh123 缓存区-flush()在进行循环等操作的时候，程序需要等循环完毕才输出，也就是缓存区满了之后再进行显示 1234567import sys,timefor i in range(50): sys.stdout.write(&quot;#&quot;) sys.stdout.flush() time.sleep(0.1) 执行后的程序输出将会是持续的输出# 使用flush()方法，可以在操作时立即输出 程序练习实现shell sed替换功能用户输入旧的需要替换的字符和新的字符，通过给脚本传入参数来实现 可以使用sys模块的argv进行参数获取，然后进行替换操作 修改haproxy配置文件需求 进入程序之后，可以选择：增、删、改、查等操作 123456789101112131415161718192021222324251、查 输入：www.oldboy.org 获取当前backend下的所有记录2、新建 输入： arg = &#123; &apos;bakend&apos;: &apos;www.oldboy.org&apos;, &apos;record&apos;:&#123; &apos;server&apos;: &apos;100.1.7.9&apos;, &apos;weight&apos;: 20, &apos;maxconn&apos;: 30 &#125; &#125;3、删除 输入： arg = &#123; &apos;bakend&apos;: &apos;www.oldboy.org&apos;, &apos;record&apos;:&#123; &apos;server&apos;: &apos;100.1.7.9&apos;, &apos;weight&apos;: 20, &apos;maxconn&apos;: 30 &#125; &#125; 源文件内容如下： 1234567891011121314151617181920212223242526272829global log 127.0.0.1 local2 daemon maxconn 256 log 127.0.0.1 local2 infodefaults log global mode http timeout connect 5000ms timeout client 50000ms timeout server 50000ms option dontlognulllisten stats :8888 stats enable stats uri /admin stats auth admin:1234frontend oldboy.org bind 0.0.0.0:80 option httplog option httpclose option forwardfor log global acl www hdr_reg(host) -i www.oldboy.org use_backend www.oldboy.org if wwwbackend www.oldboy.org server 100.1.7.9 100.1.7.9 weight 20 maxconn 3000 使用eval实现 函数基础知识函数结构面向对象：类 class 面向过程：过程 def 【过程实际上可以理解为没有返回值的函数】 函数式编程：函数 def 【函数式逻辑结构化和过程化的一种编程方法】 注意，过程和函数的定义都是使用def进行标识的 在python中定义一个函数的结构如下所示： 1234567def test(x): &quot;&quot;&quot;define the function for test&quot;&quot;&quot; x += 1 return xa = test(1)print (a) def：定义函数的关键字 test：函数名称 ()：参数列表空间，内可定义形参 中间是代码块，用于实现程序处理逻辑 return：定义返回值 在python当中，过程也是被当做函数来处理，python其实也给过程隐式的定义了返回值None，因此在调用过程的时候，我们也能看到返回值，但是返回值是None 参数传递将实参传递给形参的时候，有两种方法， 一种是在括号中直接写实参，例如：test(1,2)，这个时候将会按照这个顺序进行参数的传递，与形参一一对应 一种是人为的指定赋值对象，例如：test1(x=2,y=1)，这个时候将会按照指定的值进行赋值导入，与形参的顺序无关 函数为什么要有返回值函数有返回值的一个最主要的原因是，我想要这个函数整个的执行结果 后面的处理逻辑需要根据这个返回值的结果进行相应的操作 定义不限制数量的函数形参个数例如： 12345678910111213141516171819202122输出为元祖类型：def test(x,*wxh): print (x) print (wxh)test(1,2,2,34,45)执行后输出如下所示：1(2, 2, 34, 45)输出为字典类型：def test(x,**wxh): print (x) print (wxh)test(1,name=&quot;wxh&quot;,age=6)执行后输出如下所示：1&#123;&apos;name&apos;: &apos;wxh&apos;, &apos;age&apos;: 6&#125; 局部变量测试代码如下所示： 123456789101112131415def change_name(name): print (&quot;befor change&quot;,name) name = &quot;wang xiao hua&quot; print (&quot;after change&quot;,name)name = &quot;wxh&quot;a1= change_name(name)print (name)print (a1)执行后的输出如下所示:befor change wxhafter change wang xiao huawxhNone 这个测试的效果就是局部变量，局部变量只会在函数里面生效，可以理解为，这个函数就是这个变量的作用域，在这个函数之外 函数内操作全局变量默认情况下，在函数体中操作的都是局部变量，但是有些情况需要在函数体中操作全局变量，这个时候就需要在变量的前面加上标志信息：global 注意，在外部定义的全局变量，只有字符串和单独的整数这种是不能再函数中去修改的，而像列表字典元祖集合等比较复杂的数据类型，这些都是可以直接在局部里面直接修改全局的 递归在函数内部，可以调用其他函数。如果一个函数在内部调用自己本身，那么这个函数就是递归函数。 递归的特性递归函数应该拥有以下特性： 必须有一个明确的结束条件 每次进入更深一层的递归时，问题规模相比上次递归都应有所减少 递归效率不高，递归层次过多会导致栈溢出（在计算机中，函数调用时通过栈（stack）这种数据结构实现的，每当进入一个函数调用，栈就会加一层栈帧，每当函数返回，栈就会减一层栈帧。由于栈的大小不是无限的，所以，递归调用的次数过多，会导致栈溢出。） 演示代码如下： 1234567891011def cal(n): print (n) if int(n/2)&gt;0: return (cal(int(n/2)))cal(10)输出为：10521这就是一个有明确结束条件的递归函数 函数式编程高阶函数演示代码如下： 12345678def add(a,b,f): return f(a),f(b)res = add(-5,-4,abs)print (res)输出如下：(5, 4)]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day02-模块初始及列表字典等深入]]></title>
    <url>%2F2018%2F06%2F27%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday02-%E6%A8%A1%E5%9D%97%E5%88%9D%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[模块简介模块的简单介绍：用户写好了一堆功能，将其封装在一个文件当中，从网上下载下来之后，导入之后就可以使用，不用再去重新编写相对应的功能代码。这个文件就叫做模块，又可以叫做库 模块（库）主要分为两种： 一个是标准库（不需要额外安装下载，就可以直接导入的库，比如说getpass,os,sys模块等） 一个是第三方库（必须要额外的下载安装之后，才可以使用，例如django） 几个要点： 模块在系统中是以.py结尾的文件方式存在的 这些模块文件在python有一个寻找路径/环境变量（存储路径可以通过sys模块的path方法进行查看，默认情况下，会最优先从当前目录下进行寻找）【这个是python的全局变量，和系统的path环境变量不一样】，这个python全局变量，存储的是路径信息 123456C:\Users\Administrator&gt;pythonPython 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 16:07:46) [MSC v.1900 32 bit (Intel)] on win32Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import sys&gt;&gt;&gt; print (sys.path)[&apos;&apos;, &apos;D:\\software\\python\\python36.zip&apos;, &apos;D:\\software\\python\\DLLs&apos;, &apos;D:\\software\\python\\lib&apos;, &apos;D:\\software\\python&apos;, &apos;D:\\software\\python\\lib\\site-packages&apos;] 一般情况下，python安装的第三方库都是存放在lib\site-packages路径下 sys模块1234import sysprint (sys.path)print(sys.argv) 输出信息如下所示： 123[&apos;C:\Users\Administrator\PycharmProjects\python14\day02&apos;, &apos;C:\Users\Administrator\PycharmProjects\python14&apos;, &apos;D:\software\python\python36.zip&apos;, &apos;D:\software\python\DLLs&apos;, &apos;D:\software\python\lib&apos;, &apos;D:\software\python&apos;, &apos;D:\software\python\lib\site-packages&apos;][&apos;C:/Users/Administrator/PycharmProjects/python14/day02/moudles.py&apos;] path方法输出python定义的环境变量信息 argv方法输出当前文件所在相对路径信息（注意是相对路径，这里输出是因为在IDE中调用的时候写的脚本名字的路径就是绝对路径，pycharm在调用的时候写的是绝对路径） OS模块OS模块是跟操作系统进行交互 从python中调用shell的命令，或者在系统上创建一个文件、目录等 比如 执行命令，使用方法：os.system() 1234#!/usr/bin/pythonimport oscmd_res = os.system(&quot;df -h&quot;)print (cmd_res) 执行后的输出为： 123456789[root@redis001 ~]# python test.pyFilesystem Size Used Avail Use% Mounted on/dev/sda2 197G 1.4G 186G 1% /tmpfs 63G 24K 63G 1% /dev/shm/dev/sda1 283M 37M 232M 14% /boot/dev/sda6 1.3T 203M 1.3T 1% /data1/dev/sda3 99G 60M 94G 1% /home/dev/sda5 50G 52M 47G 1% /tmp0 注意：在使用os.system执行命令的时候，这个结果的输出是直接输出到屏幕上的，而不是存到这个变量中，所以输出之后就没有了 0 是命令执行成功与否的返回状态码 上面的system是执行命令，但是不保存结果 那么，我们就想保存结果的时候，该做什么操作？ 这个时候我们使用popen方法 popen()方法输出的是一个内存的对象地址 12345678[root@redis001 ~]# cat test.py #!/usr/bin/pythonimport oscmd_res = os.popen(&quot;ls&quot;)print (cmd_res)[root@redis001 ~]# python test.py&lt;open file &apos;ls&apos;, mode &apos;r&apos; at 0x7ff2cce43c00&gt;ls: write error: Broken pipe 那么，想要真正的结果，则需要再调用一下read() 12345678910[root@redis001 ~]# cat test.py #!/usr/bin/pythonimport oscmd_res = os.popen(&quot;ls&quot;).read()print (cmd_res)[root@redis001 ~]# python test.pyanaconda-ks.cfginstall.loginstall.log.syslogtest.py 解析：在执行完popen()之后，这个结果是保存在内存的一个临时的地方，这个地方，必须通过read()方法，再去取出来 其他知识列表列表切片 1234list = [&quot;wxh&quot;,&quot;wsy&quot;,&quot;dabadou&quot;,&quot;badou&quot;,&quot;wxh&quot;]print (list[1:3])输出为：[&apos;wsy&apos;, &apos;dabadou&apos;] 打印列表中item的数量-使用count方法 12list = [&quot;wxh&quot;,&quot;wsy&quot;,&quot;dabadou&quot;,&quot;badou&quot;,&quot;wxh&quot;]print(list.count(&quot;wxh&quot;)) 清除列表-clear方法-注意这里只是清空了但是不会被删除 1list.clear() 列表反转-reverse()方法 列表合并-extend()方法 123456list = [&quot;wxh&quot;,&quot;wsy&quot;,&quot;dabadou&quot;,&quot;badou&quot;,&quot;wxh&quot;]list2 = [1,2,3,4]list.extend(list2)print (list)输出为：[&apos;wxh&apos;, &apos;wsy&apos;, &apos;dabadou&apos;, &apos;badou&apos;, &apos;wxh&apos;, 1, 2, 3, 4] 列表删除-del命令 123list2 = [1,2,3,4]del list2print (list2) 列表嵌套列表及子列表赋值 12345list = [&quot;wxh&quot;,&quot;wsy&quot;,&quot;dabadou&quot;,[&quot;wxh&quot;,&quot;heheh&quot;,&quot;haha&quot;],&quot;badou&quot;,&quot;wxh&quot;]list[3][1] = &quot;WXH&quot;print(list)执行后输出为：[&apos;wxh&apos;, &apos;wsy&apos;, &apos;dabadou&apos;, [&apos;wxh&apos;, &apos;WXH&apos;, &apos;haha&apos;], &apos;badou&apos;, &apos;wxh&apos;] 列表复制-使用copy模块的copy方法 1234567891011import copylist = [&quot;wxh&quot;,&quot;wsy&quot;,&quot;dabadou&quot;,[&quot;wxh&quot;,&quot;heheh&quot;,&quot;haha&quot;],&quot;badou&quot;,&quot;wxh&quot;]list2 = copy.copy(list)print (list2)输出为：[&apos;wxh&apos;, &apos;wsy&apos;, &apos;dabadou&apos;, [&apos;wxh&apos;, &apos;heheh&apos;, &apos;haha&apos;], &apos;badou&apos;, &apos;wxh&apos;]也可以使用下面这种方式：list = [&quot;wxh&quot;,&quot;wsy&quot;,&quot;dabadou&quot;,[&quot;wxh&quot;,&quot;heheh&quot;,&quot;haha&quot;],&quot;badou&quot;,&quot;wxh&quot;]list2 = list[:]print (list2) 使用这种列表再赋值的方式，可以拿来作为联合账号类功能，也就是说前者最开始的列表将会连带的影响所有的列表。 列表循环： 12for i in list:print (i) 在循环的时候-按照步长进行输出 1print(list[0:-1:2]) 元祖元祖和列表差不多，只不过一旦创建之后就不能再次修改，因此又叫做只读列表 元祖使用()进行定义，而不是列表的[] 元祖只有两个方法，count和index方法 购物车程序需求如下： 启动程序之后，让用户输入工资，然后打印商品列表 允许用户根据商品编号购买商品 用户选择商品后，检测余额是否足够，够久直接扣款，不够就提醒（不够的话可以选择便宜的，也就是说进入下一次循环） 可以随时退出，退出时，打印已经购买的商品和余额 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839# Author:XiaoHua Wanggoods = [(&quot;iphone&quot;,7000),(&quot;Ipad pro&quot;,5000),(&quot;Mac pro&quot;,22000),(&quot;tea&quot;,40),(&quot;bag&quot;,2000),(&quot;Nike&quot;,860),(&quot;book&quot;,105)]salary = int(input(&quot;Please input your salary: &quot;))message2 = &quot;Please choice which number to buy,enter q to quit in any time:&quot;buy_goods = []while True: print(&quot;These are all goods you can buy:&quot;)# for i in range(len(goods)):# print(str(i) + &quot; &quot; + str(goods[i])) for item in goods: print (goods.index(item),item) Tag = input(message2) jude = Tag.isdigit() if Tag == &quot;q&quot;: break if jude != True: print (&quot;sorry,input error,please enter number or q&quot;) break consume_moneny = int(goods[int(Tag)][1]) salary1 = salary salary = salary - consume_moneny if salary &lt; 0: print (&quot;sorry,you The amount is not enough,please select again&quot;) print( &quot;rest salary is &#123;Salary&#125;&quot;.format(Salary=salary1) ) salary = salary1 continue# if salary == 0: if salary == 0: print(&quot;Add &quot; + str(goods[int(Tag)]) ) print(&quot;consume all money just right,&quot;+ &quot;rest salary is 0 . you can&apos;t buy again.&quot;) buy_goods = buy_goods.append(goods[int(Tag)][0]) break print(&quot;Add &quot; + str(goods[int(Tag)]))# print(&quot;rest salary is &quot; + str(salary)) print(&quot;rest salary is &#123;Salary&#125;&quot;.format(Salary=salary)) buy_goods.append(goods[int(Tag)][0]) continueprint (&quot;you have buy blow goods: &quot;)print (buy_goods) 注意：匹配列表的索引和对应的值还可以使用下面的方法： 12345678910111213141516171819202122goods = [(&quot;iphone&quot;,7000),(&quot;Ipad pro&quot;,5000),(&quot;Mac pro&quot;,22000),(&quot;tea&quot;,40),(&quot;bag&quot;,2000),(&quot;Nike&quot;,860),(&quot;book&quot;,105)]for item in goods: print(goods.index(item), item)#或者for index,item in enumerate(goods): print (index,item)执行后输出如下：0 (&apos;iphone&apos;, 7000)1 (&apos;Ipad pro&apos;, 5000)2 (&apos;Mac pro&apos;, 22000)3 (&apos;tea&apos;, 40)4 (&apos;bag&apos;, 2000)5 (&apos;Nike&apos;, 860)6 (&apos;book&apos;, 105)0 (&apos;iphone&apos;, 7000)1 (&apos;Ipad pro&apos;, 5000)2 (&apos;Mac pro&apos;, 22000)3 (&apos;tea&apos;, 40)4 (&apos;bag&apos;, 2000)5 (&apos;Nike&apos;, 860)6 (&apos;book&apos;, 105) 字符串常用操作字符串对应位置替换 123456name = &quot;wangxiaohua&quot;p = str.maketrans(&quot;abcdefg&quot;,&quot;1234567&quot;)print (name.translate(p))执行之后的输出如下所示：w1n7xi1ohu1 临时替换 12345print (&quot;wangxiaohua&quot;.replace(&apos;a&apos;,&apos;A&apos;,2))执行后输出如下：wAngxiAohua格式为：旧字符，新字符，替换的格式个数 split分割-按照字符 将字符串的值，按照指定的分隔符号，重新定义为列表 1234num = &quot;1+2+3+4&quot;print (num.split(&quot;+&quot;))执行后输出如下：[&apos;1&apos;, &apos;2&apos;, &apos;3&apos;, &apos;4&apos;] split分割-按照行 split分割按照行来进行区分的时候，我们就需要使用splitlines()方法 12345678num = &quot;1+2+3\n+4+\n5+6&quot;print (num)print (num.split(&quot;+&quot;))print (num.splitlines())执行后输出如下所示：[&apos;1&apos;, &apos;2&apos;, &apos;3\n&apos;, &apos;4&apos;, &apos;\n5&apos;, &apos;6&apos;][&apos;1+2+3&apos;, &apos;+4+&apos;, &apos;5+6&apos;] 注意：在linux和windows平台上使用splitlines()方法的时候，它会自动的识别换行符（Linux和windows的换行符号是不一样的） Title格式 12345678name = &quot;wang xiao hua&quot;name1 = &quot;wangxiaohua&quot;print (name.title())print (name1.title())执行后的输出如下所示：Wang Xiao HuaWangxiaohua 将输入的字符串输出为标题的格式，也就是首字母大写的格式 字典操作字典的数据类型是一种key-value类型 字典的特性： dict是无序的 key必须是唯一的，因此字典天生就具备去重的功能 在输出的时候，默认是没有顺序的，因此可能写在最后的在最前面输出，因为字典没有下标信息，因为列表是通过索引下标进行查找，但是字典是通过key进行查找的 在取值的时候，用法和列表的相似，不过是在[]中将索引下标数字修改成为key值 删除字典有几种方法，使用pop的时候，可以再进行赋值，使用del的时候就是真的删除了 字典的查找，可以使用get方法，也可以使用in的用法 字典中有该值则返回，没有的话则返回None 1234567891011121314info = &#123; &quot;name&quot;:&quot;wangxiaohua&quot;, &quot;age&quot;:&quot;26&quot;, &quot;sex&quot;:&quot;man&quot;&#125;print (info.get(&quot;name&quot;))print (info.get(&quot;named&quot;))if &quot;name&quot; in info: print (&quot;Yes&quot;)执行后的输出如下所示：wangxiaohuaNoneYes 字典的特殊赋值-如果能取到值则返回取到的值，如果值不存在则创建一个新的-setdefault()方法 12345678910info = &#123; &quot;name&quot;:&quot;wangxiaohua&quot;, &quot;age&quot;:&quot;26&quot;, &quot;sex&quot;:&quot;man&quot;&#125;info.setdefault(&quot;name&quot;,&quot;hehe&quot;)print (info)执行后输出如下所示：&#123;&apos;name&apos;: &apos;wangxiaohua&apos;, &apos;age&apos;: &apos;26&apos;, &apos;sex&apos;: &apos;man&apos;&#125; 字典的合并更新-存在交叉的key值进行覆盖，不存在的则进行插入 123456789101112131415info = &#123; &quot;name&quot;:&quot;wangxiaohua&quot;, &quot;age&quot;:&quot;26&quot;, &quot;sex&quot;:&quot;man&quot;&#125;info2 = &#123; &quot;name&quot;:&quot;dabadou&quot;, &quot;city&quot;:&quot;hangzhou&quot;&#125;info.update(info2)print (info)执行后的输出如下所示：&#123;&apos;name&apos;: &apos;dabadou&apos;, &apos;age&apos;: &apos;26&apos;, &apos;sex&apos;: &apos;man&apos;, &apos;city&apos;: &apos;hangzhou&apos;&#125; 字典的循环 字典的循环，一般使用的是items()方法，但是使用下面这种方法，会比items()方法高效很多 1234567891011121314151617181920info = &#123; &quot;name&quot;:&quot;wangxiaohua&quot;, &quot;age&quot;:&quot;26&quot;, &quot;sex&quot;:&quot;man&quot;&#125;for i in info: print (i,info[i])for k,v in info.items(): print (k,v) 执行后的输出如下所示：name wangxiaohuaage 26sex manname wangxiaohuaage 26sex man 上面的方式，是通过索引的形式（这里是key）就直接把value取出来了，但是下面这个items()相当于是把字典变成一个列表，因此就多了一个字典转换成列表的过程，在数据量大的时候，效率非常的差 因此字典的循环，最好使用上面的这种方式，尽量避免使用items()方法来实现 三级菜单程序 三级菜单【省市县】【例如，浙江省–&gt;杭州市–&gt;xx县/区】 可依次选择进入各个子菜单 所需新知识点：列表，字典 打开程序，列出中国所有的省，选择一个省，列出下面所有的城市，选中一个城市，再列出下面所有的县 在任何一个级别，可以返回上一级 在任何一个级别的时候，可以整个退出程序，输入例如quit等退出程序]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器双网卡bond配置]]></title>
    <url>%2F2018%2F06%2F26%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E8%BF%90%E7%BB%B4%E6%9E%B6%E6%9E%84%2F%E9%AB%98%E5%B9%B6%E5%8F%91%2F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F2%E5%B1%82%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2FLinux%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8F%8C%E7%BD%91%E5%8D%A1bond%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[参考文献： linux 网卡绑定 bonding Linux网卡绑定探析 Linux下网卡bonding配置 LINUX-网卡Bond Linux双网卡绑定bond详解 Linux网卡bond的七种模式详解 基础知识概述什么是bond网卡bond是通过多张网卡绑定为一个逻辑网卡，实现本地网卡的冗余，带宽扩容和负载均衡，在生产场景中是一种常用的技术。 通俗点讲就是两块网卡具有相同的IP地址而并行链接聚合成一个逻辑链路工作。 其实这项技术在Sun和Cisco中早已存在，被称为Trunking和Etherchannel 技术，在Linux的2.4.x的内核中开始采用这这种技术，被称为bonding。 内核支持在Linux Kernels 2.4.12及以后的版本均供bonding模块，以前的版本可以通过patch实现。可以通过以下命令确定内核是否支持 bonding： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@nginx001 ~]# cat /boot/config-2.6.32-696.el6.x86_64 | grep -i bond# CONFIG_PATA_WINBOND is not setCONFIG_BONDING=mCONFIG_WINBOND_840=mCONFIG_INPUT_WINBOND_CIR=mCONFIG_IR_WINBOND_CIR=mor[root@nginx001 ~]# cat /boot/config-2.6.32-696.el6.x86_64 | grep -i bondingCONFIG_BONDING=mor[root@ network-scripts]# modinfo bondingfilename: /lib/modules/2.6.32-696.el6.x86_64/kernel/drivers/net/bonding/bonding.koauthor: Thomas Davis, tadavis@lbl.gov and many othersdescription: Ethernet Channel Bonding Driver, v3.7.1version: 3.7.1license: GPLalias: rtnl-link-bondsrcversion: 454FF5806F146AD7FB41356depends: vermagic: 2.6.32-696.el6.x86_64 SMP mod_unload modversions parm: max_bonds:Max number of bonded devices (int)parm: tx_queues:Max number of transmit queues (default = 16) (int)parm: num_grat_arp:Number of peer notifications to send on failover event (alias of num_unsol_na) (int)parm: num_unsol_na:Number of peer notifications to send on failover event (alias of num_grat_arp) (int)parm: miimon:Link check interval in milliseconds (int)parm: updelay:Delay before considering link up, in milliseconds (int)parm: downdelay:Delay before considering link down, in milliseconds (int)parm: use_carrier:Use netif_carrier_ok (vs MII ioctls) in miimon; 0 for off, 1 for on (default) (int)parm: mode:Mode of operation; 0 for balance-rr, 1 for active-backup, 2 for balance-xor, 3 for broadcast, 4 for 802.3ad, 5 for balance-tlb, 6 for balance-alb (charp)parm: primary:Primary network device to use (charp)parm: primary_reselect:Reselect primary slave once it comes up; 0 for always (default), 1 for only if speed of primary is better, 2 for only on active slave failure (charp)parm: lacp_rate:LACPDU tx rate to request from 802.3ad partner; 0 for slow, 1 for fast (charp)parm: ad_select:803.ad aggregation selection logic; 0 for stable (default), 1 for bandwidth, 2 for count (charp)parm: min_links:Minimum number of available links before turning on carrier (int)parm: xmit_hash_policy:balance-xor and 802.3ad hashing method; 0 for layer 2 (default), 1 for layer 3+4, 2 for layer 2+3 (charp)parm: arp_interval:arp interval in milliseconds (int)parm: arp_ip_target:arp targets in n.n.n.n form (array of charp)parm: arp_validate:validate src/dst of ARP probes; 0 for none (default), 1 for active, 2 for backup, 3 for all (charp)parm: arp_all_targets:fail on any/all arp targets timeout; 0 for any (default), 1 for all (charp)parm: fail_over_mac:For active-backup, do not set all slaves to the same MAC; 0 for none (default), 1 for active, 2 for follow (charp)parm: all_slaves_active:Keep all frames received on an interface by setting active flag for all slaves; 0 for never (default), 1 for always. (int)parm: resend_igmp:Number of IGMP membership reports to send on link failure (int)parm: packets_per_slave:Packets to send per slave in balance-rr mode; 0 for a random slave, 1 packet per slave (default), &gt;1 packets per slave. (int)parm: lp_interval:The number of seconds between instances where the bonding driver sends learning packets to each slaves peer switch. The default is 1. (uint) 当看到有相关配置输出的时候则说明当前操作系统的内核版本是支持bond的 bond模式bonding的七种工作模式: bonding技术提供了七种工作模式，在使用的时候需要指定一种，每种有各自的优缺点. balance-rr (mode=0) 默认, 有高可用 (容错) 和负载均衡的功能, 需要交换机的配置，每块网卡轮询发包 (流量分发比较均衡). active-backup (mode=1) 只有高可用 (容错) 功能, 不需要交换机配置, 这种模式只有一块网卡工作, 对外只有一个mac地址。缺点是端口利用率比较低 balance-xor (mode=2) 不常用 broadcast (mode=3) 不常用 802.3ad (mode=4) IEEE 802.3ad 动态链路聚合，需要交换机配置，没用过 balance-tlb (mode=5) 不常用 balance-alb (mode=6) 有高可用 ( 容错 )和负载均衡的功能，不需要交换机配置 (流量分发到每个接口不是特别均衡) 具体的网上有很多资料，了解每种模式的特点根据自己的选择就行, 一般会用到0、1、4、6这几种模式。 一般常用的常用的有两种： mode=0（balance-rr） 表示负载分担round-robin，并且是轮询的方式比如第一个包走eth0，第二个包走eth1，直到数据包发送完毕。 优点：流量提高一倍 缺点：需要接入交换机做端口聚合，否则可能无法使用 mode=1（active-backup） 表示主备模式，即同时只有1块网卡在工作。 优点：冗余性高 缺点：链路利用率低，两块网卡只有1块在工作 实践操作配置子网卡源文件内容： 1234567891011[root@nginx001 network-scripts]# cat ifcfg-p1p1DEVICE=&quot;p1p1&quot;BOOTPROTO=&quot;dhcp&quot;DHCP_HOSTNAME=&quot;bigdata&quot;HWADDR=&quot;D0:94:66:5B:76:89&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;ONBOOT=&quot;no&quot;TYPE=&quot;Ethernet&quot;UUID=&quot;9126f785-f642-4ce4-84d8-558284f17623&quot; 修改后的文件内容如下： 12345678910111213[root@nginx001 network-scripts]# cat ifcfg-p1p1DEVICE=&quot;p1p1&quot;BOOTPROTO=&quot;static&quot;DHCP_HOSTNAME=&quot;bigdata&quot;HWADDR=&quot;D0:94:66:5B:76:89&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;ONBOOT=&quot;yes&quot;TYPE=&quot;Ethernet&quot;UUID=&quot;9126f785-f642-4ce4-84d8-558284f17623&quot;MASTER=bond1SLAVE=yes 同样的，在第二块网卡上进行配置，配置之后的文件内容如下所示： 12345678910111213[root@nginx001 network-scripts]# cat ifcfg-p1p2DEVICE=&quot;p1p2&quot;BOOTPROTO=&quot;static&quot;DHCP_HOSTNAME=&quot;bigdata&quot;HWADDR=&quot;D0:94:66:5B:76:8A&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;ONBOOT=&quot;yes&quot;TYPE=&quot;Ethernet&quot;UUID=&quot;a89099a9-0852-4c43-bef3-07e3999ec597&quot;MASTER=bond1SLAVE=yes 配置bond网卡子网卡配置完毕之后，我们开始配置bond网卡，vim创建文件，填入以下内容之后，保存退出： 1234567891011121314[root@nginx001 network-scripts]# vim ifcfg-bond1DEVICE=&quot;bond1&quot;BOOTPROTO=&quot;static&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;MTU=&quot;1500&quot;NM_CONTROLLED=&quot;yes&quot;ONBOOT=&quot;yes&quot;TYPE=&quot;Ethernet&quot;IPADDR=103.13.244.21NETMASK=255.255.255.248GATEWAY=103.13.244.17DNS1=223.5.5.5DNS2=223.6.6.6]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>运维架构</category>
        <category>高并发</category>
        <category>负载均衡</category>
        <category>2层负载均衡</category>
      </categories>
      <tags>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome常用操作]]></title>
    <url>%2F2018%2F06%2F25%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7%2FChrome%2FChrome%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[参考文献： chrome键盘快捷键 Windows和Linux标签页和窗口快捷键 操作 快捷键 打开新窗口 Ctrl + n 在无痕模式下打开新窗口 Ctrl + Shift + n 打开新的标签页，并跳转到该标签页 Ctrl + t 重新打开最后关闭的标签页，并跳转到该标签页 Ctrl + Shift + t 跳转到下一个打开的标签页 Ctrl + Tab 或 Ctrl + PgDn 跳转到上一个打开的标签页 Ctrl + Shift + Tab 或 Ctrl + PgUp 跳转到特定标签页 Ctrl + 1 到 Ctrl + 8 跳转到最后一个标签页 Ctrl + 9 在当前标签页中打开主页 Alt + Home 打开当前标签页浏览记录中记录的上一个页面 Alt + 向左箭头键 打开当前标签页浏览记录中记录的下一个页面 Alt + 向右箭头键 关闭当前标签页 Ctrl + w 或 Ctrl + F4 关闭当前窗口 Ctrl + Shift + w 最小化当前窗口 Alt + 空格键 + n 最大化当前窗口 Alt + 空格键 + x 关闭当前窗口 Alt + F4 退出 Google Chrome Ctrl + Shift + q Google Chrome 功能快捷键 操作 快捷键 打开 Chrome 菜单 Alt + f 或 Alt + e 或 F10 + Enter 键 显示或隐藏书签栏 Ctrl + Shift + b 打开书签管理器 Ctrl + Shift + o 在新标签页中打开“历史记录”页 Ctrl + h 在新标签页中打开“下载内容”页 Ctrl + j 打开 Chrome 任务管理器 Shift + Esc 将焦点放置在 Chrome 工具栏中的第一项上 Shift + Alt + t 将焦点放置在 Chrome 工具栏中的最后一项上 F10 将焦点移到未聚焦于的对话框（如果显示）中 F6 打开查找栏搜索当前网页 Ctrl + f 或 F3 跳转到与查找栏中搜索字词相匹配的下一条内容 Ctrl + g 跳转到与查找栏中搜索字词相匹配的上一条内容 Ctrl + Shift + g 打开“开发者工具” Ctrl + Shift + j 或 F12 打开“清除浏览数据”选项 Ctrl + Shift + Delete 在新标签页中打开 Chrome 帮助中心 F1 使用其他帐号登录或以访客身份浏览 Ctrl + Shift + m 打开反馈表单 Alt + Shift + i 地址栏快捷键 在地址栏中可使用以下快捷键： 操作 快捷键 使用默认搜索引擎进行搜索 输入搜索字词并按 Enter 键 使用其他搜索引擎进行搜索 输入搜索引擎名称，然后按 Tab 键 为网站名称添加 www. 和 .com，并在当前标签页中打开该网站 输入网站名称并按 Ctrl + Enter 键 打开新的标签页并执行 Google 搜索 输入搜索字词并按 Alt + Enter 键 跳转到地址栏 Ctrl + l、Alt + d 或 F6 从页面中的任意位置搜索 Ctrl + k 或 Ctrl + e 从地址栏中移除联想查询内容 按向下箭头键以突出显示相应内容，然后按 Shift + Delete 键 网页快捷键 操作 快捷键 打开选项以打印当前网页 Ctrl + p 打开选项以保存当前网页 Ctrl + s 重新加载当前网页 F5 或 Ctrl + r 重新加载当前网页（忽略缓存的内容） Shift + F5 或 Ctrl + Shift + r 停止加载网页 Esc 浏览下一个可点击项 Tab 浏览上一个可点击项 Shift + Tab 使用 Chrome 打开计算机中的文件 按住 Ctrl + o 键并选择文件 显示当前网页的 HTML 源代码（不可修改） Ctrl + u 将当前网页保存为书签 Ctrl + d 将所有打开的标签页以书签的形式保存在新文件夹中 Ctrl + Shift + d 开启或关闭全屏模式 F11 放大网页上的所有内容 Ctrl 和 + 缩小网页上的所有内容 Ctrl 和 - 将网页上的所有内容恢复到默认大小 Ctrl + 0 向下滚动网页，一次一个屏幕 空格键或 PgDn 向上滚动网页，一次一个屏幕 Shift + 空格键或 PgUp 转到网页顶部 首页 转到网页底部 末尾 在网页上水平滚动 按住 Shift 键并滚动鼠标滚轮 将光标移到文本字段中的上一个字词前面 Ctrl + 向左箭头键 将光标移到文本字段中的上一个字词后面 Ctrl + 向右箭头键 删除文本字段中的上一个字词 Ctrl + Backspace 在当前标签页中打开主页 Alt + Home 鼠标快捷键 以下快捷键要求您使用鼠标： 操作 快捷键 在当前标签页中打开链接（仅限鼠标） 将链接拖到标签页中 在新的后台标签页中打开链接 按住 Ctrl 键的同时点击链接 打开链接，并跳转到该链接 按住 Ctrl + Shift 键的同时点击链接 打开链接，并跳转到该链接（仅使用鼠标） 将链接拖到标签栏的空白区域 在新窗口中打开链接 按住 Shift 键的同时点击链接 在新窗口中打开标签页（仅使用鼠标） 将标签页拖出标签栏 将标签页移至当前窗口（仅限鼠标） 将标签页拖到现有窗口中 将标签页移回其原始位置 拖动标签页的同时按 Esc 将当前网页保存为书签 将相应网址拖动到书签栏中 下载链接目标 按住 Alt 键的同时点击链接 显示浏览记录 右键点击“后退”箭头 或“前进”箭头 ，或者点击（按住鼠标按键别松手）“后退”箭头 或“前进”箭头 在最大化模式和窗口模式间切换 双击标签栏的空白区域 放大网页上的所有内容 按住 Ctrl 键的同时向上滚动鼠标滚轮 缩小网页上的所有内容 按住 Ctrl 键的同时向下滚动鼠标滚轮 MAC标签页和窗口快捷键 操作 快捷键 打开新窗口 ⌘ + n 在无痕模式下打开新窗口 ⌘ + Shift + n 打开新的标签页，并跳转到该标签页 ⌘ + t 重新打开最后关闭的标签页，并跳转到该标签页 ⌘ + Shift + t 跳转到下一个打开的标签页 ⌘ + Option + 向右箭头键 跳转到上一个打开的标签页 ⌘ + Option + 向左箭头键 跳转到特定标签页 ⌘ + 1 到 ⌘ + 8 跳转到最后一个标签页 ⌘ + 9 打开当前标签页浏览记录中记录的上一个页面 ⌘ + [ 或 ⌘ + 向左箭头键 打开当前标签页浏览记录中记录的下一个页面 ⌘ + ] 或 ⌘ + 向右箭头键 关闭当前标签页或弹出式窗口 ⌘ + w 关闭当前窗口 ⌘ + Shift + w 最小化窗口 ⌘ + m 隐藏 Google Chrome ⌘ + h 退出 Google Chrome ⌘ + q Google Chrome 功能快捷键 操作 快捷键 显示或隐藏书签栏 ⌘ + Shift + b 打开书签管理器 ⌘ + Option + b 在新标签页中打开“设置”页 ⌘ + , 在新标签页中打开“历史记录”页 ⌘ + y 在新标签页中打开“下载内容”页 ⌘ + Shift + j 打开查找栏搜索当前网页 ⌘ + f 跳转到与查找栏中搜索字词相匹配的下一条内容 ⌘ + g 跳转到与查找栏中搜索字词相匹配的上一条内容 ⌘ + Shift + g 打开查找栏后，搜索选定文本 ⌘ + e 打开“开发者工具” ⌘ + Option + i 打开“清除浏览数据”选项 ⌘ + Shift + Delete 使用其他帐号登录或以访客身份浏览 ⌘ + Shift + m 地址栏快捷键 在地址栏中可使用以下快捷键： 操作 快捷键 使用默认搜索引擎进行搜索 输入搜索字词并按 Enter 键 使用其他搜索引擎进行搜索 输入搜索引擎名称，然后按 Tab 键 为网站名称添加 www. 和 .com，并在当前标签页中打开该网站 输入网站名称并按 Control + Enter 键 为网站名称添加 www. 和 .com，并在新标签页中打开该网站 输入网站名称并按 Control + Shift + Enter 键 在新的后台标签页中打开网站 输入网址并按 ⌘ + Enter 键 跳转到地址栏 ⌘ + l 从地址栏中移除联想查询内容 按向下箭头键以突出显示相应内容，然后按 Shift + fn + Delete 键 网页快捷键 操作 快捷键 打开选项以打印当前网页 ⌘ + p 打开选项以保存当前网页 ⌘ + s 打开“页面设置”对话框 ⌘ + Option + p 重新加载当前网页（忽略缓存的内容） ⌘ + Shift + r 停止加载网页 Esc 浏览下一个可点击项 Tab 浏览上一个可点击项 Shift + Tab 使用 Google Chrome 打开计算机中的文件 按住 ⌘ + o 键并选择文件 显示当前网页的 HTML 源代码（不可修改） ⌘ + Option + u 打开 JavaScript 控制台 ⌘ + Option + j 将当前网页保存为书签 ⌘ + d 将所有打开的标签页以书签的形式保存在新文件夹中 ⌘ + Shift + d 开启或关闭全屏模式 ⌘ + Ctrl + f 放大网页上的所有内容 ⌘ 和 + 缩小网页上的所有内容 ⌘ 和 - 将网页上的所有内容恢复到默认大小 ⌘ + 0 向下滚动网页，一次一个屏幕 空格键 向上滚动网页，一次一个屏幕 Shift + 空格键 搜索网络 ⌘ + Option + f 将光标移到文本字段中的上一个字词前面 Option + 向左箭头键 将光标移到文本字段中的上一个字词后面 Option + 向右箭头键 删除文本字段中的上一个字词 Option + Delete 在当前标签页中打开主页 ⌘ + Shift + h 鼠标快捷键 以下快捷键要求您使用鼠标： 操作 快捷键 在当前标签页中打开链接（仅限鼠标） 将链接拖到标签页中 在新的后台标签页中打开链接 按住 ⌘ 键的同时点击链接 打开链接，并跳转到该链接 按住 ⌘ + Shift 键的同时点击链接 打开链接，并跳转到该链接（仅使用鼠标） 将链接拖到标签栏的空白区域 在新窗口中打开链接 按住 Shift 键的同时点击链接 在新窗口中打开标签页（仅使用鼠标） 将标签页拖出标签栏 将标签页移至当前窗口（仅限鼠标） 将标签页拖到现有窗口中 将标签页移回其原始位置 拖动标签页的同时按 Esc 将当前网页保存为书签 将相应网址拖动到书签栏中 下载链接目标 按住 Option 键的同时点击链接 显示浏览记录 右键点击“后退”箭头 或“前进”箭头 ，或者点击（按住鼠标按键别松手）“后退”箭头 或“前进”箭头 将窗口高度最大化 双击标签栏的空白区域]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>Chrome</category>
      </categories>
      <tags>
        <tag>Chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第1章：中国人学习英语的误区]]></title>
    <url>%2F2018%2F06%2F24%2F%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0%2F%E8%B7%9F%E6%81%B6%E9%AD%94%E5%A5%B6%E7%88%B8%E5%AD%A6%E8%8B%B1%E8%AF%AD%2F%E7%AC%AC1%E7%AB%A0%EF%BC%9A%E4%B8%AD%E5%9B%BD%E4%BA%BA%E5%AD%A6%E4%B9%A0%E8%8B%B1%E8%AF%AD%E7%9A%84%E8%AF%AF%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[神功大力丸思想大部分人幻想通过一套教材就能够解决英语的所有问题，幻想简单、高效、快速、直接的一种方法，解决学习英语中遇到的所有难题 国内这种大力丸的思想的起源基本是来自于老师群体，培训机构的老师群体，把这种理念和方法进行包装，试图以一种简单的策略来解决所有的英语问题 语言学习是一个复杂的整体，分为不同的阶段，每个阶段的重点都不一样，需要选用的教材，方法，策略也都不一样。并且，因为每个人的学习习惯和作息习惯都不一样，因此选用的学习策略自然也不应该相同 在整个英语学习过程当中，需要输入大量的听力和阅读材料，不能只靠一套课本就彻底解决所有问题，你需要认真分析你所处的水平基础（每个人的水平和基础不一样），灵活选择不同的教材和不同的方法策略 国内的学习者总是喜欢想当然，一定要在某种方法和达到某种水平之间建立因果关系，也就是说，他们做了某事，就一定可以收获什么，如果说我不能收获到成果，可能不是因为方法材料不适合，而只是因为我不够努力和坚持。盲目应用不适合自己的方法和教材 坚持一切以考试为核心]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>英语学习</category>
        <category>跟恶魔奶爸学英语</category>
      </categories>
      <tags>
        <tag>英语学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每日碎片知识梳理-2018年]]></title>
    <url>%2F2018%2F06%2F24%2F%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F%E6%AF%8F%E6%97%A5%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86%2F2018%E5%B9%B4%2F%E6%AF%8F%E6%97%A5%E7%A2%8E%E7%89%87%E7%9F%A5%E8%AF%86%E6%A2%B3%E7%90%86-2018%E5%B9%B4%2F</url>
    <content type="text"><![CDATA[2018年6月6月24日标题：为泡妞之成功而读书 来源：《得到》-逻辑思维-第20期 内容： 传统的知识构成和今天我们要面对的知识构成是有区别的 近代化以来，教育是人类一项沉重的负担，因为随着工业化的发展，各个门类的知识持续增长，所以就必须建立一个体系，将这些知识灌输给年轻人 6月25日]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>每日碎片知识梳理</category>
        <category>2018年</category>
      </categories>
      <tags>
        <tag>每日碎片知识梳理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Typora]]></title>
    <url>%2F2018%2F06%2F24%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7%2FMarkdown%2FTypora%2F</url>
    <content type="text"><![CDATA[参考文献： Typora官方网站 基础知识软件介绍markdown编辑器有很多的选择，对比使用之后，目前在用的是一款叫Typora编辑器，特写文章记录一下。本文只是简单介绍，待亲自上手体验之后方可体会它的美感。 官方说明： Typora will give you a seamless experience as both a reader and a writer. It removes the preview window, mode switcher, syntax symbols of markdown source code, and all other unnecessary distractions. Replace them with a real live preview feature to help you concentrate the content itself. Markdown 编辑器，比较常见的是双栏布局：左边敲源码，右边显示渲染结果。 但是Typora 是单栏布局，是真正意义上的所见即所得，摒弃了传统的markdown编辑器的分栏设置（例如markdown pad 2左边是源码，右边是渲染之后的显示效果）以及其他非必须的内容，书写时直接显示成效图。光标一离开，就立刻显示为想要的样子，并且由用户选择何时进入源码模式（输入ctrl+/即可切换源码编辑模式） 入门实践快捷键操作标题操作插入标题： 一级标题：ctrl+1 二级标题：ctrl+2 三级标题：ctrl+3 四级标题：ctrl+4 五级标题：ctrl+5 增大标题级别：ctrl + = 减小标题级别：ctrl + - 表格操作插入表格： 编辑器中插入 直接ctrl+t插入表格，并且在弹出的提示框中可以自由选择表格的行和列数 外部复制（excel等专业表格软件中复制） 直接复制即可，Typora会自动把excel的格式转换为markdown的语法格式 代码块 行内代码块 使用``号将内容包含即可，快捷键为：ctrl+shift+反引号 行代码块 在开头输入```然后回车，在下方输入内容，内容将会自动的变成代码块的形式 指定格式的行代码块 在开头输入```bash/python/ruby然后回车，在下方输入内容，内容将会自动的变成指定代码块的形式 无序列表 基础无序列表： 使用 - content 即可 完成/未完成列表：-[] content or - [x] content 无序列表缩进问题 增大列表缩进（也就是右移，子列表）：ctrl+] 减小列表缩进（也就是左移，父列表）：ctrl+[ 网页链接与图片 编辑器中插入网页超链接 直接ctrl+k即可出现相对应的格式 给文字加上超链接 只需拷贝链接，然后选中文字，按一下ctrl + k，链接就添上了 编辑器中插入图片 ctrl+shift+i 图片拖拽 这个功能可以将拖入图片转化为插入图片，但是这个功能默认是关闭的，需要在设置中手动开启，设置的路径为: Preferences -&gt; Editor 切换源码/预览模式输入ctrl+/可以再源码模式和成像预览模式之间进行来回切换 其他常用操作 文字加粗：ctrl+b 文字倾斜：ctrl+i 文字下划线：ctrl+u 文字删除线：两个波浪线分别在文字的两边~~content~~ 清除格式：ctrl+\ 生成目录输出[toc]然后回车，将会自动产生一个目录，这个目录抽取了文章的所有标题，自动更新内容 软件本身操作文件快速打开输入ctrl+p之后，输入关键字，它会在当前文件夹下进行搜索 打开文件位置点击文件之后，在侧边栏中会有打开文件位置的选项，它能进入该文件所在的目录，这个功能十分的方便。 编辑查找ctrl+f 进行查找 替换ctrl+h进行替换 首行缩进在其中的空格与换行中，有首行缩进的选项，选中之后，会把所有内容中的首行内容进行缩进两个空格。 格式代码ctrl+shitf+` 删除线alt+shift+5 高亮==content== 效果如下： ==content== 清除样式ctrl+\]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>Typora</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[换行符报警问题]]></title>
    <url>%2F2018%2F06%2F23%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B%2FGit%2F%E6%8D%A2%E8%A1%8C%E7%AC%A6%E6%8A%A5%E8%AD%A6%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[在Windows环境下使用git进行add的时候，会提示： “warning:LF will be replacee by CRLF” 基本信息： CRLF – Carriage-Return Line-Feed 回车换行 回车(CR, 对应 ASCII 13, \r) 换行(LF, ASCII 10, \n)。 这里放上ASCII字符代码表的前半部分，可以直观的看到 注意： 这两个标识换行的ACSII字符不会在屏幕有任何输出，在Windows中广泛使用\r\n来标识一行的结束。而在Linux/UNIX系统中只使用\n来标识一行的结束。 这一点经常在windows和linux平台上进行操作的小伙伴基本都知道 也就是说在windows中的换行符为 CRLF， 而在linux下的换行符为：LF 原因分析： git配置中设置 core.autocrlf=true 后： 当我们执行git add将文件转入到暂存区时，系统将会把LF转换成CRLF 当我们执行commit提交时，会把暂存区的内容(也就是我们对工作区做的改动)再重新转化为LF然后放入版本库(repository) 从工作区转化暂存区时，如果发现里面存在 LF 换行符，LF 会被转化成 CRLF，并给出提到的那条警告：”LF will be replaced by CRLF” 这里有一个重要的知识点：git创建的项目，暂存区和运行平台挂钩，但是最终项目文件在版本库(repository)中的换行符是为LF【因为git最终是运行在Linux平台之上】 其实这句警告的下面其实还有一句很重要的话: warning: LF will be replaced by CRLF in . The file will have its original line endings in your working directory. (翻译下就是:“在工作区里,这个文件会保持它原本的换行符，也就是LF和CRLF混合存在。”) 深入延伸扩展 简单来说，在windows平台，我们工作区的文件都应该用 CRLF 来换行。如果改动文件时引入了 LF,或者设置 core.autocrlf 之前,工作区已经有 LF 换行符。那么提交改动时,git 会警告你哪些文件不是纯 CRLF 文件,但 git 不会擅自修改工作区的那些文件,而是对暂存区(我们对工作区的改动)进行修改。 也因此,当我们进行 git add 的操作时,只要 git 发现改动的内容里有 LF 换行符,就还会出现这个警告。 设置 core.autocrlf=true, 只要保持工作区都是纯 CRLF 文件,编辑器用 CRLF 换行,就不会出现警告。 git 默认让版本库里用 LF 换行,只要保持这条规则,多人协作就不会出什么大问题。 git 的 Windows 客户端基本都会默认设置 core.autocrlf=trueLinux 最好不要重新设置,因为这个配置算是为 Windows 平台定制。 如果 Windows 上设置 core.autocrlf=false,仓库里也没有配置 .gitattributes,很容易引入 CRLF 或者混合换行符(Mixed Line Endings,一个文件里既有 LF 又有CRLF)到版本库,这样就可能产生各种奇怪的问题。 如果有换行符不匹配本地平台的情况,建议你用 dos2unix 之类的工具转换下换行符,因为很多配置文件是严格要求文件编码和换行符的,谨慎一点比较好。 问题解决： 因为如果 Windows 上设置 core.autocrlf=false,仓库里也没有配置 .gitattributes,很容易引入 CRLF 或者混合换行符(Mixed Line Endings,一个文件里既有 LF 又有CRLF)到版本库,这样就可能产生各种奇怪的问题。 所以，解决最好保持工作区都是纯 CRLF 文件,编辑器用 CRLF 换行,就不会出现警告。 首先core.autocrlf = true在windows上才是正确的选择，不建议将其修改为false（网上大部分的解决方法都是：rm -rf .git &amp;&amp; git config –global core.autocrlf false &amp;&amp; git init &amp;&amp; git add . &amp;&amp; git remote add xx 这种解决方式，其实不是太友好），如果实在忍受不了，想要避免这些warning，那么执行下面的操作： 添加.gitattributes 设置core.safecrlf = true 使用dos2unix、notepad++等工具来将LF转换成CRLF 所以，建议保持默认效果]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>程序编程</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改主题超链接样式]]></title>
    <url>%2F2018%2F06%2F23%2F%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2FHexo%2F%E4%BF%AE%E6%94%B9%E4%B8%BB%E9%A2%98%E8%B6%85%E9%93%BE%E6%8E%A5%E6%A0%B7%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[因为我使用的是Next主题，这里说下Next主题的修改，其他主题的操作也都是一致的 Next默认对超链接只有下划线样式，在查看文章内容的时候很容易被忽略 主题样式是在\hexoBlog\themes\next\source\css,这里面保存了Muse,Mist和Pisces等主题的css文件 例如,字体和边框的颜色还有字体,图片的大小等保存在next\source\css_variables里. 而我们要修改的body超链接的样式在themes\next\source\css_common\components\post\post.styl里,编辑文件，在文件中添加以下内容: .post-body a { color: #428BCA; font-weight: bold; } 添加以后，我们需要执行clean操作生效 hexo clean hexo g -d 强制刷新我们的文章内容，就能看到超链接已经变成蓝色粗体的形式 如下图所示：]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>个人博客</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iperf命令]]></title>
    <url>%2F2018%2F06%2F12%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FLinux%E5%91%BD%E4%BB%A4%2Fiperf%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[参考文献： github主页 基础知识安装配置使用iperf时，涉及服务端和客户端的概念 因为iperf是使用C语言编写的，因此在安装之前服务器上要安装gcc编译器。 安装# wget http://downloads.es.net/pub/iperf/iperf-3.5.tar.gz # tar -zxvf iperf-3.5.tar.gz # cd iperf-3.5 # ./configure; make; make install 启动服务端执行即可，客户端不需要执行 # iperf3 -s -D iperf3版本启动之后，默认的监听端口为：5201 实际测试客户端指定发送一个5GB的数据包，每隔5秒钟输出一次传输状态，输出结果的显示单位为MB显示，并发3个线程发送 客户端侧执行 # iperf3 -c 10.11.6.3 -n 5000000000 -p 5201 -i 5 -f M -P 3]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>Linux命令</category>
      </categories>
      <tags>
        <tag>iperf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高速通道从入门到实践]]></title>
    <url>%2F2018%2F06%2F08%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E5%85%AC%E6%9C%89%E4%BA%91%E4%BA%A7%E5%93%81%2F%E9%98%BF%E9%87%8C%E4%BA%91%2F%E9%AB%98%E9%80%9F%E9%80%9A%E9%81%93%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[基础知识阿里云高速通道（Express Connect）服务，帮助您在VPC间、VPC与本地数据中心间搭建私网通信通道，提高网络拓扑的灵活性和跨网络通信的质量和安全性。使用高速通道可以使您避免绕行公网带来的网络质量不稳定问题，同时可以免去数据在传输过程中被窃取的风险。 VPC间内网通信 高速通道支持位于相同地域或不同地域，同一账号或不同账号的VPC之间进行内网互通。 阿里云通过在两侧VPC的路由器上分别创建路由器接口，以及自有的骨干传输网络来搭建高速通道，轻松实现两个VPC之间安全可靠，方便快捷的通信。 本地数据中心和阿里云上VPC间内网通信 您可以通过物理专线在物理层面上连接您的本地数据中心到阿里云，然后建立边界路由器和路由器接口来连接数据中心与阿里云VPC。 基础架构基于软件自定义网络（Software Defined Network，简称SDN）架构下的三层Overlay技术和交换机虚拟化技术，阿里云将客户的物理专线接入的端口隔离起来，并抽象成边界路由器。通过目前主流的隧道技术，阿里云将客户的数据包在交换机内部进行封装，在用户的物理专线和VPC的路由器之间加上隧道封装，然后将数据传输到VPC内。 路由器接口路由器接口是一种虚拟设备，具备搭建通信通道并控制其工作状态的功能。 高速通道通过在两侧的VPC路由器上分别创建路由器接口为两个VPC之间搭建内网通信通道。 在两个路由器接口建立连接后，两侧的路由器可以通过建立的通道相互发送消息。因此，两个VPC中的资源（比如ECS实例）就可以通过内网进行通信了。 发起端和接受端当两个路由器接口进行互连时，一个扮演连接发起端角色，另一个扮演连接接受端角色。只有发起端路由器接口才可以发起连接，接受端路由器接口只能等待发起端发起连接。发起端和接受端仅用于控制连接建立的过程，在实际进行网络通信时，通信链路是双向的，发起端和接受端没有任何差别。 对于同账号VPC互通，高速通道提供了同时创建两端的选项。在这种情况下，您不需要手动发起连接，系统会自动发起并建立连接。对于跨账号VPC互通，您必须手动发起路由器接口间的连接。 发起端与接受端的对比如下表所示。 注意： 和我们传统的路由器的发起和接受概念有点不一样，这里需要明确的指定 发起端需要指定接受端的路由器接口 接收端需要指定发起端的路由器接口 也就是说，这两个接口只能是给这一条通道使用 连接过程和连接状态路由器接口的连接过程为：发起端路由器接口发起连接 &gt; 接受端路由器接口接受连接 &gt; 连接成功。 在不同的连接过程和阶段，路由器接口的状态也不同如下表所示。路由器接口创建后的初始状态为未连接。 说明：在创建路由器接口时，如果您选择了同时创建两端，系统会自动发起并建立连接，此种情况下路由器接口直接变为已激活状态。 整个连接过程如下所示： 路由器接口规格高速通道提供小型（10MB-50MB）、中型（100MB-900MB）和大型（1GB-4.5GB）三种规格的路由器接口。 可选择的路由器接口规格在不同连接场景和不同地域中并不相同。您可以根据具体的配置在购买页面选择合适的路由器接口规格。同地域间VPC互连的路由器接口规格默认为大型2档（2GB）。 使用限制 两个VPC之间只能有一对连接成功的路由器接口。 路由器接口创建后无法修改连接角色。 边界路由器（VBR）必须是发起端。 物理专线物理专线是对阿里云接入点和本地数据中心之间建立的网络线路的抽象。您需要通过租用一条运营商的专线将本地数据中心连接到阿里云接入点，建立专线连接。 专线接入后，您可以创建一个边界路由器（VBR）将您本地数据中心和阿里云连接起来，构建混合云环境，使云上资源可以绕过公网通过私网访问本地数据中心。 物理专线的私网连接不通过公网，因此与传统的公网连接相比，物理专线连接更加安全、可靠、速度更快、延迟更低。 功能高速通道物理专线提供以下功能： 多种连接方式 您可以选择使用点对点以太网连接或MPLS VPN连接。物理专线支持以太格式的RJ45电口和LC模式光口, 可以提供1Mbps至10Gbps的传输速率。 冗余连接 物理专线通过等价路由实现两条物理线路冗余： 如果两条专线接入同地域下不同接入点，则两条线路形成天然冗余。 如果两条专线接入同地域下同一个接入点，您可以在申请第二条物理专线时，将第一条物理专线作为冗余线路。 使用限制物理专线使用限制如下： 物理专线不支持SDH的G.703、V.35格式接口。 阿里云在每个可接入的地域提供一个或多个接入点，不同的接入点有运营商限制。在申请专线接入前，您需要提交工单获取接入点以及运营商限制信息。 总结在物理专线接入之后，你会得到一个边界路由器 边界路由器（VBR）必须是发起端。 购买物理专线之后，其实不是直接连接到阿里云的机房，而是连接到这个边界路由器，边界路由器的对端再连接VPC的路由器 边界路由器边界路由器（Virtual border router, VBR）是您申请的物理专线接入交换机的产品映射，可以看做是CPE（Customer-premises equipment）设备和VPC之间的一个路由器，作为数据从VPC到本地数据中心的转发桥梁。 边界路由器同VPC中的路由器一样，同样管理一个路由表。在该路由表中配置路由条目，可以对边界路由器中的流量转发进行管理。 功能边界路由器提供如下功能： 作为VPC和本地数据中心的中间路由器，交换数据包。 在三层子接口模式下，可以识别或附加VLAN(Virtual Local Area Network)标签。 决定物理专线端口模式：三层路由接口或基于VLAN的三层子接口。 支持添加BGP动态路由。 使用限制 目前不支持源地址策略路由。 每个边界路由器有且只有1个路由表。 每个路由表支持48条自定义路由条目。 使用场景VPC私网互连您可以使用高速通道实现两个VPC间的的私网通信需求，既可以避免绕行公网带来的网络质量不稳定问题，也可以免去数据在传输过程中被窃取的风险。详情请参考跨地域VPC互连和跨账号VPC互连。 本地数据中心专线接入VPC如果您的本地数据中心需要与VPC进行私网通信，您可以使用高速通道的物理专线功能实现两侧的私网通信，您可以选择自行搭建专线接入阿里云或让阿里巴巴的合作伙伴为您搭建物理专线。通过物理专线可以实现本地数据中心和VPC间高质量、高可靠且安全性高的私网通信。您可以使用高速通道实现两个VPC间的的私网通信需求，既可以避免绕行公网带来的网络质量不稳定问题，也可以免去数据在传输过程中被窃取的风险。详情请参考同账号专线接入和跨账号专线接入。 两个VPC共用NAT网关如果您需要两个VPC共用一个NAT网关进行公网通信，您可以使用高速通道实现同两个VPC使用同一个NAT网关来访问公网。 使用限制 同一个路由器上的路由器接口不能互连。 边界路由器上的路由器接口只能作为发起端。 一对VPC之间只能同时存在一对互连的路由器接口。 一条物理专线上最多可以存在的边界路由器个数：50个。 一个用户名下最多可以存在的已激活的路由器接口个数：5个。 一个路由器上最多可以存在的已激活的路由器接口个数：5个。 一个账号最多可以在一个接入点接入的物理专线条数：2条。 一个账号下最多可以存在的空闲边界路由器（没有接口的边界路由器）个数：2个。 入门实践跨地域VPC互连本操作以如下同一个账号下的两个VPC为例演示如何使用高速通道实现VPC私网互通。 说明：同账号下同地域和跨地域VPC互连的操作步骤一样。 前提条件 确保要进行互连的VPC或交换机的网段不冲突。 文章内容：跨地域VPC互连 跨账号VPC互连前提条件 两个VPC中交换机地址不能冲突。 已获取双方的阿里云账号ID和路由器ID。 文章内容：跨账号VPC互连 物理专线文章内容：物理专线接入]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>公有云产品</category>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>高速通道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day01-Python基本用法]]></title>
    <url>%2F2018%2F06%2F07%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday01-python%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[格式化输出输出目标： -------- info of $ ------- Name: Age: Job: Salary: &apos;&apos;&apos; 让输出的内容按照指定的格式进行输出 传统方式：使用字符串拼接实现 代码如下： name = input(&quot;name: &quot;) age = input(&quot;age: &quot;) job = input(&quot;job:&quot;) salary = input(&quot;salary:&quot;) info = &apos;&apos;&apos; -------- info of &apos;&apos;&apos; + name + &quot;&quot;&quot; ------- Name:&quot;&quot;&quot; + name + &quot;&quot;&quot; Age: &quot;&quot;&quot; + age + &quot;&quot;&quot; Job: &quot;&quot;&quot; + job + &quot;&quot;&quot; Salary: &quot;&quot;&quot; + salary print (info) 使用注释拼接上变量的形式来创建指定的格式，不建议使用字符串拼接的方式去实现，因为它会开辟好几块的内存空间，效率比较低下 更高效简单的方法-参数替换 在shell脚本中，我们使用$符号引用外面定义的变量，在python中也提供了类似的功能。 在python中使用%s，占位符，相当于$的存在 代码如下： name = input(&quot;name: &quot;) age = int(input(&quot;age: &quot;)) job = input(&quot;job:&quot;) salary = input(&quot;salary:&quot;) print(&quot;name&quot;) info = &quot;&quot;&quot; -------- info of %s ----- name: %s age: %d job: %s salary: %s &quot;&quot;&quot;%(name,name,age,job,salary) print (info) 解释： 在这里 %s代表的是字符串string %d代表的是整数 digital %f代表的是浮点数 float int代表的是整型 integer 注意，在定义age的时候，使用的强制类型转换，因为如果不进行强制类型定义的话，则输入的会使默认的字符类型 如果想要知道输入的值在程序运行的时候的是什么类型，则可以使用type函数进行查看 print (type(name)) 因为python是一个强类型定义语言，所以在第一次赋值之后，这个变量的数据类型就固定了，要么强制转换，不然的话就一直是这个数据类型 更高效简单的方法-format方式 代码如下： name = input(&quot;name: &quot;) age = input(&quot;age: &quot;) job = input(&quot;job: &quot;) salary = input(&quot;salary: &quot;) info = &quot;&quot;&quot; --- info of {_name} --- name: {_name} age: {_age} job: {_job} salary: {_salary} &quot;&quot;&quot; .format(_name = name, _age = age, _job = job, _salary = salary) print (info) 在日常开发中，建议使用这种方式去格式化输出内容 用户输入username = input(&quot;username: &quot;) password = input(&quot;password: &quot;) print (username + &quot; &quot; + password ) 当使用input函数的时候，我们在输入内容的时候，所输入的内容是直接在屏幕明文显示的 因此，这里需要隐藏输入的明文显示，此时，使用标准库中的一个模块：getpass 标准库：直接import就能使用标准库中的模块，不需要再额外安装，因此在安装python的时候，就已经默认安装集成了这个标准库 我们从标准库中import getpass模块之后，直接调用它的方法 修改之后的代码如下所示： import getpass username = input(&quot;username: &quot;) password = getpass.getpass(&quot;password: &quot;) print (username,password) 注意： getpass在pycharm中有bug，在进行验证的时候可以使用cmd来进行 输出如下： C:\Users\Administrator\PycharmProjects\python14\day1&gt;python password.py username: wxh password: wxh wxh 优化之后的代码： import getpass _username = &quot;wxh&quot; _password = &quot;wxh123&quot; username = input(&quot;username: &quot;) password = getpass.getpass(&quot;password: &quot;) if username == _username and password == _password : print (&quot;Welcome user {name} login...&quot;.format(name=username)) print (username,password) else: print (&quot;Invalid username or password! &quot;) 输出 如下： C:\Users\Administrator\PycharmProjects\python14\day1&gt;python password.py username: wxh password: Invalid username or password! C:\Users\Administrator\PycharmProjects\python14\day1&gt;python password.py username: wxh password: Welcome user wxh login... wxh wxh123 C:\Users\Administrator\PycharmProjects\python14\day1&gt; 模块初始流程控制if判断wxh_age = 23 print (type(wxh_age)) message = &quot;Please input the number of wxh&apos;s age: &quot; guess_age = int(input (message)) if guess_age == wxh_age: print (&quot;yes,you got it. &quot;) elif guess_age &gt; wxh_age: print (&quot;think smaller...&quot;) else: print (&quot;think bigger...&quot;) print (&quot;the right answer is {Age}&quot;.format(Age=wxh_age)) 注意：当给变量赋值字符的时候，一定要记得带上引号，不带引号的话表示的是变量。 这段猜年龄的代码，没有循环效果，猜一次就要执行一次，接下来，我们添加循环功能 一次执行，猜三次，三次之后再退出 循环：循环执行 while:条件匹配循环for：固定次数循环 while循环 在这里：count = count +1 等价于：count +=1 这里限制猜的次数为3次，如果三次中间有猜中的，直接break退出，不然只有当次数达到3次之后，才会退出这个循环。 执行之后的输出如下所示： 代码如下： wxh_age = 23 message = &quot;Please input the number of wxh&apos;s age,input 00 to quit: &quot; tag = True count = 0 while tag: guess_age = int(input(message)) if guess_age == 00: break elif guess_age == wxh_age: print(&quot;Yes,you get it!&quot;) break elif guess_age &gt; wxh_age: print(&quot;please guess smaller...&quot;) else: print(&quot;plwase guess bigger...&quot;) count = count + 1 if count == 3: tag = False print (&quot;\n&quot;) print (&quot;You have input too many times,quit now!&quot;) print (&quot;\n&quot;) print (&quot;The right age is:{Age} &quot;.format(Age=wxh_age)) 或者 wxh_age = 23 message = &quot;Please input the number of wxh&apos;s age,input 00 to quit: &quot; tag = True count = 0 while tag: guess_age = int(input(message)) if guess_age == 00: break elif guess_age == wxh_age: print(&quot;Yes,you get it!&quot;) break elif guess_age &gt; wxh_age: print(&quot;please guess smaller...&quot;) else: print(&quot;plwase guess bigger...&quot;) count = count + 1 if count == 3: tag = False print (&quot;\n&quot;) else: print (&quot;You have input too many time,quit now!&quot;) print (&quot;\n&quot;) print (&quot;The right age is:{Age} &quot;.format(Age=wxh_age)) 注意，while也可以和else配合使用，当while所执行的条件不成立时，就会执行else块中的语句 执行后的输出如下： D:\software\python\python.exe C:/Users/Administrator/PycharmProjects/python14/day1/guess.py Please input the number of wxh&apos;s age,input 00 to quit: 24 please guess smaller... Please input the number of wxh&apos;s age,input 00 to quit: 11 plwase guess bigger... Please input the number of wxh&apos;s age,input 00 to quit: 28 please guess smaller... You have input too many times,quit now! The right age is:23 Process finished with exit code 0 and D:\software\python\python.exe C:/Users/Administrator/PycharmProjects/python14/day1/guess.py Please input the number of wxh&apos;s age,input 00 to quit: 11 plwase guess bigger... Please input the number of wxh&apos;s age,input 00 to quit: 23 Yes,you get it! The right age is:23 Process finished with exit code 0 and D:\software\python\python.exe C:/Users/Administrator/PycharmProjects/python14/day1/guess.py Please input the number of wxh&apos;s age,input 00 to quit: 22 plwase guess bigger... Please input the number of wxh&apos;s age,input 00 to quit: 00 The right age is:23 Process finished with exit code 0 将上述代码进行优化，添加重复的功能【达到3次之后，询问用户是否需要继续】 num = 0 while num &lt; 3: guess_age = int(input(message)) if guess_age == 00: break elif guess_age == wxh_age: print (&quot;Yes,you got it !!!&quot;) break elif guess_age &gt; wxh_age: print (&quot;guess smaller...&quot;) else: print (&quot;guess bigger...&quot;) num += 1 if num == 3: message2 = &quot;you guess too three times, do you want continue? Y/N： &quot; answer = input(message2) if answer == &quot;Y&quot;: num = 0 else: break print (&quot;The answer is 23.&quot;) for循环我们将上面的while循环使用for循环的方式进行重新编写 代码如下： wxh_age = 23 message = &quot;Please input the number of wxh&apos;s age(input 00 to quit): &quot; for num in range(3): guess_age = int(input(message)) if guess_age == 00: break elif guess_age == wxh_age: print (&quot;Yes,you got it!&quot;) break elif guess_age &lt; wxh_age: print (&quot;guess bigger...&quot;) else: print (&quot;guess smaller...&quot;) else: print (&quot;you have tried too many times...&quot;) print (&quot;The right answer is 23 &quot;) 输出数字代码： for i in range(0,10,2): print (&quot;loop&quot;,i) 注意，python中的步长是写在后面的，默认的步长是1 循环嵌套，查看效果【每大循环一次，就小循环一次】 代码如下： for i in range(3): print (&quot;-------&quot; + str(i)+ &quot;------&quot;) for j in range(3): print (j) 执行之后的输出如下所示： -------0------ 0 1 2 -------1------ 0 1 2 -------2------ 0 1 2 作业编写登录接口 输入用户名密码【需要允许多对用户名密码】 认证成功之后，显示欢迎信息 输出三次密码之后进行锁定 【可以根据用户名进行检测，那么这个信息就需要保存在某一个地方】 多级菜单 三级菜单【省市县】【例如，浙江省–&gt;杭州市–&gt;xx县/区】 可依次选择进入各个子菜单 所需新知识点：列表，字典 打开程序，列出中国所有的省，选择一个省，列出下面所有的城市，选中一个城市，再列出下面所有的县 在任何一个级别，可以返回上一级 在任何一个级别的时候，可以整个退出程序，输入例如quit等退出程序 作业完成登录接口：代码如下： 123456789101112131415161718192021222324252627282930313233343536373839# Author:XiaoHua Wang#定义提示信息message1 = &quot;please enter your username: &quot;message2 = &quot;please enter your password: &quot;# 定义空字典u_p_dict = &#123;&#125;# 打开文件并将文件内容进行截取（分隔符为“：”，然后将文件内容按照key:value的格式追加添加到字典u_p_dict中）file_object = open(r&apos;C:\Users\Administrator\PycharmProjects\files\login.txt&apos;, &apos;r&apos;)for txt_lines in file_object.readlines(): txt_lines = txt_lines.strip(&apos;\n&apos;) u_p_dict[txt_lines.split(&apos;:&apos;,1)[0]] = txt_lines.split(&apos;:&apos;,1)[1]file_object.close()# 使用while循环，控制循环次数为3次#打开记录了锁定用户信息的文件，进行判断，判断用户输入的用户是否已经被锁定i =0tmp_username = open(r&apos;C:\\Users\Administrator\PycharmProjects\files\lock_user.txt&apos;, &apos;r&apos;)tmp_user_list = tmp_username.readlines()tmp_username.close()while i &lt; 3: username = input(message1) password = input(message2) if username in tmp_user_list: print (&quot;you have enter passwd too many times befor,your account is locked&quot;) break if username not in u_p_dict.keys(): print (&quot;username enter error,please check...&quot;) continue if password == u_p_dict[username]: print(&quot;Welcome &#123;Username&#125;&quot;.format(Username=username)) break print (&quot;password enter error,please check...&quot;) i += 1 if i == 3: print (&quot;you have enter error password too many times.It&apos;s now being forced out&quot;) lock_username = username error_name = open(r&apos;C:\\Users\Administrator\PycharmProjects\files\lock_user.txt&apos;, &apos;a&apos;) error_name.write(lock_username+ &apos;\n&apos;) error_name.close() continue 多级菜单：代码如下：]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络专线]]></title>
    <url>%2F2018%2F06%2F06%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%2F%E7%BD%91%E7%BB%9C%E7%A7%91%E6%99%AE%E7%9F%A5%E8%AF%86%2F%E7%BD%91%E7%BB%9C%E4%B8%93%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[参考文献： 百度百科 概述什么是网络专线？笼统来说，网络专线就是为某个机构拉一条独立的网线，也就是一个独立的局域网，例如军事，银行等，让用户的数据传输变得可靠可信，专线的优点就是安全性好，QoS（ quality of service 服务质量）可以得到保证。不过，专线租用价格也相对比较高，而且管理也需要专业人员。 网络专线主要有两种信道： 物理专用信道。物理专用信道就是在服务商到用户之间铺设有一条专用的线路，线路只给用户独立使用，其他的数据不能进入此线路，而一般的线路就允许多用户共享信道； 【独享物理线路的形式】 虚拟专用信道；虚拟专用信道就是在一般的信道上为用户保留一定的带宽，使用户可以独享这部分带宽，就像在公用信道上又开了一个通道，只让相应用户使用，而且用户的数据是加密的，以此来保证可靠性与安全性；【在共享物理上创建逻辑独享线路】 这里连接的通道是用户端的出口网关设备（一般是路由器）到ISP的接入端这一段的线路。后续的上网还是通过ISP去实现 目前市面上的信道有： 帧中继（Frame Relay） 数字数据网（DDN Digital Data Network） 异步传输模式（ATM Asynchronous Transfer Mode） X.25（分组交换业务网） 第三代ADSL（非对称用户数字链路） 虚拟专用网络（VPN Virtual Private Network）以及E1等。 什么是互联网专线？互联网专线接入业务是指为客户提供各种速率的专用链路（主要提供传输速率为2M及以上速率），直接连接IP骨干网络，实现方便快捷的高速互联网上网服务。互联网专线接入业务按照客户需求可提供更高速率的专线接入，主要有2Mb/s、10Mb/s、100Mb/s、1000Mb/s等等。 和网络专线的区别 互联网专线跳过了ISP的环节，直接连接Internet骨干网络 主要特点 1.与普通互联网接入相比，其特点是客户通过相对永久的通信线路接入Internet。 2.与拨号上网的最大区别是专线与Internet之间保持着永久、高速、稳定的连接，客户可以实现24小时对Internet的访问，随时获取全球信息资源，提高商务交易的效率。 3.专线客户拥有固定的真实IP地址，可以相对方便地向Internet上的其他客户提供信息服务。 4.专线具有误码率低，时延小的特点。 5.专有带宽的整条电路资源仅为一个客户服务，全程带宽完全独享。 什么是裸光纤？裸光纤就是指专线光纤。通俗又权威的说法：裸光纤就是中间没有连接/经过任何传输设备的光纤，也就是直通光缆。 一般来讲，用户向电信或其他公司租用裸光纤，就是指电信或其他公司只提供光纤物理通道，不提供数据处理等服务，整条光纤干线也不经过任何数据处理设备，由用户自行配置两地的收发设备。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>网络知识及网络服务</category>
        <category>网络知识</category>
        <category>网络科普知识</category>
      </categories>
      <tags>
        <tag>网络专线</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ECS从入门到实践]]></title>
    <url>%2F2018%2F06%2F03%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E5%85%AC%E6%9C%89%E4%BA%91%E4%BA%A7%E5%93%81%2F%E9%98%BF%E9%87%8C%E4%BA%91%2FECS%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[参考文献： 阿里云官方文档 ECS基础知识ECS 概述云服务器Elastic Compute Service（ECS）是阿里云提供的一种基础云计算服务。使用云服务器ECS就像使用水、电、煤气等资源一样便捷、高效。您无需提前采购硬件设备，而是根据业务需要，随时创建所需数量的云服务器ECS实例。在使用过程中，随着业务的扩展，您可以随时扩容磁盘、增加带宽。如果不再需要云服务器，也能随时释放资源，节省费用。 名词解释在使用ECS之前，需要了解以下概念 地域和可用区：是指ECS资源所在的物理位置。 实例：等同于一台虚拟机，包含CPU、内存、操作系统、网络、磁盘等最基础的计算组件。 实例规格：是指实例的不同配置，包括vCPU核数、内存、网络性能等。实例规格决定了ECS实例的计算和存储能力。 镜像：是指ECS实例运行环境的模板，一般包括操作系统和预装的软件。操作系统支持多种Linux发行版本和不同的Windows版本。 块存储：包括基于分布式存储架构的 弹性块存储，以及基于物理机本地硬盘的 本地存储。 快照：是指某一个时间点上一块弹性块存储的数据备份。 网络类型：包括 - 专有网络：基于阿里云构建的一个隔离的网络环境，专有网络之间逻辑上彻底隔离。更多信息，请参考专有网络VPC。 - 经典网络：统一部署在阿里云公共基础内，规划和管理由阿里云负责。 安全组：由同一地域内具有相同保护需求并相互信任的实例组成，是一种虚拟防火墙，用于设置不同实例的网络访问控制。 SSH密钥对：远程登录Linux ECS实例的验证方式，阿里云存储公钥，您需要自己妥善保管私钥。您也可以选择使用 用户名密码 验证登录Linux ECS实例。 IP地址：包括用于 内网通信 的内网IP或私有IP，以及用于访问Internet的公网IP。 弹性公网IP：可以与实例反复绑定或解绑的静态公网IP地址。 云服务器管理控制台：是指ECS的Web操作界面。 ECS的优势与普通的IDC机房或服务器厂商相比，阿里云提供的云服务器ECS具有以下优势： 高可用性 安全 弹性 高可用性 相较于普通的IDC机房以及服务器厂商，阿里云会使用更严格的IDC标准、服务器准入标准以及运维标准，以保证云计算整个基础框架的高可用性、数据的可靠性以及云服务器的高可用性。 在此基础之上，阿里云所提供的每个地域都存在多可用区。当您需要更高的可用性时，可以利用阿里云的多可用区搭建自己的主备服务或者双活服务。对于面向金融领域的两地三中心的解决方案，您也可以通过多地域和多可用区搭建出更高的可用性服务。其中包括容灾、备份等服务，阿里云都有非常成熟的解决方案。 在阿里云的整个框架下，这些服务可以非常平滑地进行切换，相关的信息可以在阿里云行业解决方案中找到。无论是两地三中心，还是电子商务以及视频服务等，都可以在阿里云找到对应的行业解决方案。 此外，阿里云提供了如下三项支持： 提升可用性的产品和服务，包括云服务器、负载均衡、多备份数据库服务以及数据迁移服务DTS等。 行业合作伙伴以及生态合作伙伴，帮助您完成更高、更稳定的架构，并且保证服务的永续性。 多种多样的培训服务，让您从业务端到底层的基础服务端，在整条链路上实现高可用。 安全性 选择了云计算，最关心的问题就是云计算的安全与稳定。阿里云近期通过了很多的国际安全标准认证，包括ISO27001、MTCS等，这些所有的安全合规都要求对于用户数据的私密性、用户信息的私密性以及用户隐私的保护都有非常严格的要求。对于云计算，推荐您使用阿里云专有网络。 在阿里云专有网络之上，可以产生更多的业务可能性。您只需进行简单配置，就可在自己的业务环境下，与全球所有机房进行串接，从而提高了业务的灵活性、稳定性以及业务的可发展性。 对于原来拥有自建的IDC机房，也不会产生问题。阿里云专有网络可以拉专线到原有的IDC机房，形成混合云的架构。阿里云可以提供各种混合云的解决方案和非常多的网络产品，形成强大的网络功能，让您的业务更加灵活。结合阿里云的生态，您可以在云上发展出意想不到的业务生态。 阿里云专有网络更加稳定和安全。 稳定性：业务搭建在专有网络上，而网络的基础设施将会不停进化，使您每天都拥有更新的网络架构以及更新的网络功能，使得您的业务永远保持在一个稳定的状态。专有网络允许您自由地分割、配置和管理自己的网络。 安全性：面对互联网上不断的攻击流量，专有网络天然就具备流量隔离以及攻击隔离的功能。业务搭建在专有网络上后，专有网络会为业务筑起第一道防线。 总之，专有网络提供了稳定、安全、快速交付、自主可控的网络环境。对于传统行业以及未接触到云计算的行业和企业而言，借助专有网络混合云的能力和混合云的架构，它们将享受云计算所带来的技术红利。 弹性 云计算最大的优势就在于弹性。目前，阿里云已拥有在数分钟内开出一家中型互联网公司所需要的IT资源的能力，这就能够保证大部分企业在云上所构建的业务都能够承受巨大的业务量压力。 计算弹性 纵向弹性，即单个服务器的配置变更。传统IDC模式下，很难做到对单个服务器进行变更配置。而对于阿里云，当您购买了云服务器或者存储的容量后，可以根据业务量的增长或者减少自由变更自己的配置。关于纵向弹性的具体应用，详情请参考 升降配。 横向弹性。对于游戏应用或直播平台出现的高峰期，若在传统的IDC模式下，您根本无法立即准备资源；而云计算却可以使用弹性的方式帮助客户度过这样的高峰。当业务高峰消失时，您可以将多余的资源释放掉，以减少业务成本的开支。利用横向的扩展和缩减，配合阿里云的弹性伸缩，完全可以做到定时定量的伸缩，或者按照业务的负载进行伸缩。关于横向弹性的具体应用，详情请参考 弹性伸缩。 存储弹性。阿里云拥有很强的存储弹性。当存储量增多时，对于传统的IDC方案，您只能不断去增加服务器，而这样扩展的服务器数量是有限的。在云计算模式下，将为您提供海量的存储，当您需要时可以直接购买，为存储提供最大保障。关于存储弹性的具体应用，详情请参考磁盘扩容。 网络弹性。云上的网络也具有非常大的灵活性。只要您购买了阿里云的专有网络，那么所有的网络配置与线下IDC机房配置可以是完全相同的，并且可以拥有更多的可能性。可以实现各个机房之间的互联互通，各个机房之间的安全域隔离，对于专有网络内所有的网络配置和规划都会非常灵活。关于网络弹性的具体应用，详情请参考专有网络。 总之，对于阿里云的弹性而言，是计算的弹性、存储的弹性、网络的弹性以及您对于业务架构重新规划的弹性。您可以使用任意方式去组合自己的业务，阿里云都能够满足您的需求。 块存储概念阿里云为您的云服务器ECS提供了丰富的块存储产品类型，包括基于分布式存储架构的弹性块存储产品，以及基于物理机本地硬盘的本地存储产品。其中： 弹性块存储，是阿里云为云服务器ECS提供的数据块级别的随机存储，具有低时延、持久性、高可靠等性能，采用 三副本的分布式机制，为ECS实例提供99.9999999%的数据可靠性保证。可以随时创建或释放，也可以随时扩容。 本地存储，也称为本地盘，是指挂载在ECS云服务器所在物理机（宿主机）上的本地硬盘，是一种临时块存储。是专为对存储I/O性能有极高要求的业务场景而设计的存储产品。该类存储为实例提供块级别的数据访问能力，具有低时延、高随机IOPS、高吞吐量的I/O能力。 块存储、对象存储、文件存储的区别阿里云目前主要提供三种数据存储产品，分别是块存储、文件存储（NAS）和 对象存储（OSS）。 三者区别如下： 块存储：是阿里云为ECS云服务器提供的块设备，高性能、低时延，满足随机读写，可以像使用物理硬盘一样格式化建文件系统使用。可用于大部分通用业务场景下的数据存储。 对象存储（OSS，Object Storage Service）：可以理解是一个海量的存储空间，最适合存储互联网上产生的图片、短视频、音频等海量非结构化数据，您可以通过API在任何时间、任何地点访问对象存储里的数据。常用于互联网业务网站搭建、动静资源分离、CDN加速等业务场景。 文件存储（NAS，Network Attached Storage）：类似于对象存储，适合存储非结构化的海量数据。但是您需要通过标准的文件访问协议访问这些数据，比如 Linux 系统需要使用Network File System (NFS)协议，Windows系统需要使用Common Internet File System (CIFS)协议。您可以通过设置权限让不同的客户端同时访问同一份文件。文件存储适合企业部门间文件共享、广电非线编、高性能计算、Docker等业务场景。 块存储性能衡量块存储产品的性能指标主要包括：IOPS、吞吐量和访问时延。 IOPS IOPS是Input/Output Operations per Second，即每秒能处理的I/O个数，用于表示块存储处理读写（输出/输入）的能力。如果要部署事务密集型应用，需要关注IOPS性能。 最普遍的IOPS性能指标是顺序操作和随机操作，如下表所示。 吞吐量 吞吐量是指单位时间内可以成功传输的数据数量。 如果要部署大量顺序读写的应用，需要关注吞吐量。 访问延迟 访问时延是指块存储处理一个I/O需要的时间。 如果您的应用对时延比较敏感，比如数据库（过高的时延会导致应用报错），建议您使用固态硬盘介质的SSD云盘、SSD共享块存储或本地SSD盘类产品。 如果您的应用更偏重存储吞吐能力，对时延不太敏感，比如Hadoop离线计算等吞吐密集型应用，建议您使用本地HDD盘类产品，如d1或d1ne大数据型实例。 不同云盘之间的性能测试对比请看文档：云盘性能对比部分 弹性块存储弹性块存储，是阿里云为云服务器ECS提供的数据块级别的随机存储，具有低时延、持久性、高可靠等性能，采用 分布式三副本机制，为ECS实例提供99.9999999%的数据可靠性保证。弹性块存储支持在可用区内自动复制您的数据，防止意外硬件故障导致的数据不可用，保护您的业务免于组件故障的威胁。就像硬盘一样，您可以对挂载到ECS实例上的弹性块存储做分区、创建文件系统等操作，并持久存储数据。 您可以根据业务需要随时扩容弹性块存储。具体操作，请参见 扩容数据盘 和 扩容系统盘。您也可以为弹性块存储创建快照，备份数据。关于快照的更多信息，参见 快照。 根据是否可挂载到多台ECS实例，弹性块存储可以分为： 云盘：一块云盘只能挂载到同一地域、同一可用区的一台ECS实例。 共享块存储：一块共享块存储可以同时挂载到同一地域、同一可用区的16台ECS实例。 说明：共享块存储目前仍处于公测阶段，公测期间支持最多同时挂载到4台ECS实例上。 总结： 也就是说弹性块存储在使用的时候，可以被当做是本地的磁盘，也可以是当做网络存储，类似NFS等挂载到多台ECS主机上使用区分云盘和共享块存储的方式是能否被多台ECS同时挂载 云盘根据性能分类 根据性能不同，云盘可以分为： ESSD云盘：又称增强型SSD云盘，是阿里云全新推出的超高性能的云盘产品。基于新一代分布式块存储架构，结合25GE网络和RDMA技术，为您提供单盘高达100万的随机读写能力和低至100μs的单路时延能力。ESSD云盘处于邀测阶段，更多信息，请参见 ESSD云盘FAQ。 SSD云盘：采用固态硬盘作为存储介质，能够提供稳定的高随机I/O、高数据可靠性的高性能存储。 高效云盘：采用固态硬盘与机械硬盘的混合介质作为存储介质。 普通云盘：采用机械磁盘作为存储介质 根据用途分类 根据用途不同，云盘可以作： 系统盘：生命周期与系统盘所挂载的ECS实例相同，随实例一起创建和释放。不可共享访问。系统盘可选的容量范围与实例所选的镜像有关： Linux（不包括CoreOS）+ FreeBSD：20 GiB ~ 500 GiB CoreOS：30 GiB ~ 500 GiB Windows：40 GiB ~ 500 GiB 数据盘：可以与ECS实例同时创建，也可以 单独创建，不可共享访问。与ECS实例同时创建的数据盘，生命同期与实例相同，随实例一起创建和释放。单独创建的数据盘，可以 单独释放，也可以 设置为随ECS实例一起释放。数据盘的容量由云盘类型决定，详细信息，请参见 块存储性能。作数据盘用时，云盘与共享块存储共享数据盘配额，即一台实例最多挂载16块数据盘。 共享块存储共享块存储是一种支持多台ECS实例并发读写访问的数据块级存储设备，具备多并发、高性能、高可靠等特性，数据可靠性可以达到 99.9999999%。单块共享块存储最多可以同时挂载到16台ECS实例。目前尚处于公测阶段（申请公测资格），最多同时挂载到4台ECS实例。 共享块存储只能作数据盘用，只能单独创建，可以共享访问。您可以 设置共享块存储与挂载的ECS实例一起释放。 根据性能不同，共享块存储可以分为： SSD共享块存储：采用固态硬盘作为存储介质，能够提供稳定的高随机I/O、高数据可靠性的高性能存储。 高效共享块存储：采用固态硬盘与机械硬盘的混合介质作为存储介质。 挂载到实例上时，共享块存储与云盘共享数据盘配额，即一台实例最多挂载16块数据盘。 更多共享块存储的信息，请参见 共享块存储FAQ。 网络和安全性内网目前阿里云的云服务器ECS内网间，非I/O优化的实例为千兆共享的带宽，I/O优化的实例为万兆共享的带宽，没有特殊限制。由于是共享网络，因此无法保证带宽速度是不变的。 如果两台同地域的ECS实例之间需要传输数据，一般建议使用内网连接。同时，云数据库RDS、负载均衡（SLB） 以及 对象存储（OSS） 相关的内网速度也都是千兆共享的环境。这些产品间也都可以使用内网相互连接使用。 目前只要是相同地域下，SLB、云数据库RDS、OSS与ECS之间都可以直接内网互通连接使用。 弹性网卡弹性网卡（ENI）是一种可以附加到专有网络VPC类型ECS实例上的虚拟网卡，通过弹性网卡，您可以实现高可用集群搭建、低成本故障转移和精细化的网络管理。所有地域均支持弹性网卡。 使用场景弹性网卡适用于以下几种场景： 搭建高可用集群 满足系统高可用架构对于单实例多网卡的需求。 低成本故障迁移 通过将弹性网卡从ECS实例分离后再附加到另外一台ECS实例，将故障实例上的业务流量快速迁移到备用实例，实现服务快速恢复。 精细化网络管理 可以为实例配置多个弹性网卡，例如用于内部管理的弹性网卡及用于面向公网业务访问的弹性网卡等，完成管理数据和业务数据间的隔离。可以根据源IP、协议、端口等对每张弹性网卡配置精准的安全组规则，从而对每张弹性网卡的流量进行安全访问控制。 弹性网卡类型 弹性网卡分为两种类型： 主网卡 在创建专有网络实例时随实例默认创建的弹性网卡称作主网卡。主网卡的生命周期和实例保持一致，您无法分离主网卡与实例。 辅助网卡 您可以创建辅助网卡，并将其附加到实例上或从实例上分离。每个实例能附加的网卡上限与实例规格相关，详细信息，请参考 实例规格族。 弹性网卡属性 属性 数量 主私有IP地址 1个 MAC地址 1个 安全组 至少1个，最多5个 描述信息 1个 网卡名称 1个 限制约束 使用弹性网卡有如下限制： 一个账号在一个地域内默认最多可创建100个弹性网卡。如果需要更多，请 提交工单 申请。 ECS实例与弹性网卡必须在同一VPC的同一可用区中，可以分属于不同交换机。 每台实例允许附加的弹性网卡数量由实例规格决定。详细信息，请参见 实例规格族。 非I/O优化实例规格不支持弹性网卡。 您不能在一个实例上附加多个弹性网卡来提高实例带宽。 说明：实例的带宽能力由实例规格决定。 安全组安全组是一个逻辑上的分组，这个分组是由同一个地域（Region）内具有相同安全保护需求并相互信任的实例组成。每个实例至少属于一个安全组，在创建的时候就需要指定。同一安全组内的实例之间网络互通，不同安全组的实例之间默认内网不通。可以授权两个安全组之间互访。 安全组是一种虚拟防火墙，具备状态检测包过滤功能。安全组用于设置单台或多台云服务器的网络访问控制，它是重要的网络安全隔离手段，用于在云端划分安全域。 安全组限制 单个安全组内的实例个数不能超过 1000。如果您有超过 1000 个实例需要内网互访，可以将他们分配到多个安全组内，并通过互相授权的方式允许互访。 每个实例最多可以加入 5 个安全组。 每个用户的安全组最多 100 个。 对安全组的调整操作，对用户的服务连续性没有影响。 安全组是有状态的。如果数据包在 Outbound 方向是被允许的，那么对应的此连接在 Inbound 方向也是允许的。 安全组的网络类型分为经典网络和专有网络。 - 经典网络类型的实例可以加入同一地域（Region）下经典网络类型的安全组。 - 专有网络类型的实例可以加入同一专有网络（VPC）下的安全组。 安全组规则 安全组规则可以允许或者禁止与安全组相关联的云服务器 ECS 实例的公网和内网的入出方向的访问。 您可以随时授权和取消安全组规则。您的变更安全组规则会自动应用于与安全组相关联的ECS实例上。 在设置安全组规则的时候，安全组的规则务必简洁。如果您给一个实例分配多个安全组，则该实例可能会应用多达数百条规则。访问该实例时，可能会出现网络不通的问题。 安全组规则限制 每个安全组最多有 100 条安全组规则。 DDOS基础防护阿里云云盾默认为ECS实例免费提供5 Gbit/s恶意流量攻击，即 DDoS基础防护能力。这一功能可以有效防止云服务器ECS实例受到恶意攻击，从而保证ECS系统的稳定，即当流入ECS实例的流量超出实例规格对应的限制时，云盾就会帮助ECS实例限流，避免ECS系统出现问题。 企业版入门企业级用户在购买和使用云服务器ECS实例时，通常需考虑如下几点： 配置选型 估算成本 网络规划 配置安全组 制定快照策略 镜像迁移 用负载均衡实现ECS的高可用性 配置选型参考资料：阿里云官方资料 实例规格族实例是能够为您的业务提供计算服务的最小单位，它是以一定的规格来为您提供相应的计算能力的。 根据业务场景和使用场景，ECS实例可以分为多种规格族。同一个规格族里，根据CPU和内存的配置，可以分为多种不同的规格。 ECS实例规格定义了实例的CPU和内存（包括CPU型号、主频等）这两个基本属性。但是，ECS实例只有同时配合块存储、镜像和网络类型，才能唯一确定一台实例的具体服务形态。 用户指南安全组安全组限制 单个安全组内的实例个数不能超过 1000。如果您有超过 1000 个实例需要内网互访，可以将他们分配到多个安全组内，并通过互相授权的方式允许互访。 每个实例最多可以加入 5 个安全组。 每个用户的安全组最多 100 个。 对安全组的调整操作，对用户的服务连续性没有影响。 安全组是有状态的。如果数据包在 Outbound 方向是被允许的，那么对应的此连接在 Inbound 方向也是允许的。 安全组的网络类型分为经典网络和专有网络。 - 经典网络类型的实例可以加入同一地域（Region）下经典网络类型的安全组。 - 专有网络类型的实例可以加入同一专有网络（VPC）下的安全组。 每个安全组最多有 100 条安全组规则。 安全组注意事项 出方向的端口25默认受限，无法通过安全组规则打开，但是您可以 申请解封端口25。 安全组实践的基本建议在开始安全组的实践之前，下面有一些基本的建议： 最重要的规则：安全组应作为白名单使用。 开放应用出入规则时应遵循“最小授权”原则，例如，您可以选择开放具体的端口（如 80 端口）。 不应使用一个安全组管理所有应用，因为不同的分层一定有不同的需求。 对于分布式应用来说，不同的应用类型应该使用不同的安全组，例如，您应对 Web、Service、Database、Cache 层使用不同的安全组，暴露不同的出入规则和权限。 没有必要为每个实例单独设置一个安全组，控制管理成本。 优先考虑 VPC 网络。 不需要公网访问的资源不应提供公网 IP。 尽可能保持单个安全组的规则简洁。因为一个实例最多可以加入 5 个安全组，一个安全组最多可以包括 100 个安全组规则，所以一个实例可能同时应用数百条安全组规则。您可以聚合所有分配的安全规则以判断是否允许流入或留出，但是，如果单个安全组规则很复杂，就会增加管理的复杂度。所以，应尽可能地保持单个安全组的规则简洁。 调整线上的安全组的出入规则是比较危险的动作。如果您无法确定，不应随意更新安全组出入规则的设置。阿里云的控制台提供了克隆安全组和安全组规则的功能。如果您想要修改线上的安全组和规则，您应先克隆一个安全组，再在克隆的安全组上进行调试，从而避免直接影响线上应用。 设置安全组规则设置安全组的入网规则不要使用 0.0.0.0/0 的入网规则 允许全部入网访问是经常犯的错误。使用 0.0.0.0/0 意味着所有的端口都对外暴露了访问权限。这是非常不安全的。正确的做法是，先拒绝所有的端口对外开放。安全组应该是白名单访问。例如，如果您需要暴露 Web 服务，默认情况下可以只开放 80、8080 和 443 之类的常用TCP端口，其它的端口都应关闭。 { &quot;IpProtocol&quot; : &quot;tcp&quot;, &quot;FromPort&quot; : &quot;80&quot;, &quot;ToPort&quot; : &quot;80&quot;, &quot;SourceCidrIp&quot; : &quot;0.0.0.0/0&quot;, &quot;Policy&quot;: &quot;accept&quot;} , { &quot;IpProtocol&quot; : &quot;tcp&quot;, &quot;FromPort&quot; : &quot;8080&quot;, &quot;ToPort&quot; : &quot;8080&quot;, &quot;SourceCidrIp&quot; : &quot;0.0.0.0/0&quot;, &quot;Policy&quot;: &quot;accept&quot;} , { &quot;IpProtocol&quot; : &quot;tcp&quot;, &quot;FromPort&quot; : &quot;443&quot;, &quot;ToPort&quot; : &quot;443&quot;, &quot;SourceCidrIp&quot; : &quot;0.0.0.0/0&quot;, &quot;Policy&quot;: &quot;accept&quot;} , 关闭不需要的入网规则 如果您当前使用的入规则已经包含了 0.0.0.0/0，您需要重新审视自己的应用需要对外暴露的端口和服务。如果确定不想让某些端口直接对外提供服务，您可以加一条拒绝的规则。比如，如果您的服务器上安装了 MySQL 数据库服务，默认情况下您不应该将 3306 端口暴露到公网，此时，您可以添加一条拒绝规则，如下所示，并将其优先级设为100，即优先级最低。 { &quot;IpProtocol&quot; : &quot;tcp&quot;, &quot;FromPort&quot; : &quot;3306&quot;, &quot;ToPort&quot; : &quot;3306&quot;, &quot;SourceCidrIp&quot; : &quot;0.0.0.0/0&quot;, &quot;Policy&quot;: &quot;drop&quot;, Priority: 100} , 上面的调整会导致所有的端口都不能访问 3306 端口，极有可能会阻止您正常的业务需求。此时，您可以通过授权另外一个安全组的资源进行入规则访问。 授权另外一个安全组入网访问 不同的安全组按照最小原则开放相应的出入规则。对于不同的应用分层应该使用不同的安全组，不同的安全组应有相应的出入规则。 例如，如果是分布式应用，您会区分不同的安全组，但是，不同的安全组可能网络不通，此时您不应该直接授权 IP 或者 CIDR 网段，而是直接授权另外一个安全组 ID 的所有的资源都可以直接访问。比如，您的应用对 Web、Database 分别创建了不同的安全组：sg-web 和 sg-database。在sg-database 中，您可以添加如下规则，授权所有的 sg-web 安全组的资源访问您的 3306 端口。 { &quot;IpProtocol&quot; : &quot;tcp&quot;, &quot;FromPort&quot; : &quot;3306&quot;, &quot;ToPort&quot; : &quot;3306&quot;, &quot;SourceGroupId&quot; : &quot;sg-web&quot;, &quot;Policy&quot;: &quot;accept&quot;, Priority: 2} , 授权另外一个 CIDR 可以入网访问 经典网络中，因为网段不太可控，建议您使用安全组 ID 来授信入网规则。 VPC 网络中，您可以自己通过不同的 VSwitch 设置不同的 IP 域，规划 IP 地址。所以，在 VPC 网络中，您可以默认拒绝所有的访问，再授信自己的专有网络的网段访问，直接授信可以相信的 CIDR 网段。 { &quot;IpProtocol&quot; : &quot;icmp&quot;, &quot;FromPort&quot; : &quot;-1&quot;, &quot;ToPort&quot; : &quot;-1&quot;, &quot;SourceCidrIp&quot; : &quot;10.0.0.0/24&quot;, Priority: 2} , { &quot;IpProtocol&quot; : &quot;tcp&quot;, &quot;FromPort&quot; : &quot;0&quot;, &quot;ToPort&quot; : &quot;65535&quot;, &quot;SourceCidrIp&quot; : &quot;10.0.0.0/24&quot;, Priority: 2} , { &quot;IpProtocol&quot; : &quot;udp&quot;, &quot;FromPort&quot; : &quot;0&quot;, &quot;ToPort&quot; : &quot;65535&quot;, &quot;SourceCidrIp&quot; : &quot;10.0.0.0/24&quot;, Priority: 2} , 总结： 安全组的实质是白名单 不适用0.0.0.0/0的入网规则 如果已经存在了0.0.0.0/0这种规则，那么需要设置关闭不安全的入网规则，例如关闭3306端口等，这里需要设置优先级为最小值100 不同应用使用不同的安全组，在这种情况下，需要在入向规则中添加安全组授权，比如数据库的安全组中授权web的安全组 最佳实践安全常见问题]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>公有云产品</category>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>ECS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[带宽计算方法及B与b说明]]></title>
    <url>%2F2018%2F05%2F30%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FIT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2FIT%E7%A7%91%E6%99%AE%E7%9F%A5%E8%AF%86%2F%E5%B8%A6%E5%AE%BD%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E5%8F%8AB%E4%B8%8Eb%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[参考文献： 带宽计算方法及大B与小b说明 bit与Byte的关系源信息 在计算机科学中，bit（比特）是表示信息的最小单位，叫做二进制位；一般用0和1表示。 Byte叫做字节，由8个比特位（8bit）组成一个字节(1Byte)，用于表示计算机中的一个字符。 bit与Byte之间可以进行换算，其换算关系为：1Byte=8bit（或简写为：1B=8b） 在实际应用中一般用简称， 即1bit简写为1b(注意是小写英文字母b)，1Byte简写为1B（注意是大写英文字母B）。 ISP的表示 在计算机网络或者是网络运营商(Internet service provider)中，一般宽带速率的表示单位用bps(或b/s，小b)表示； bps表示比特每秒即表示每秒钟传输多少位信息，是bit per second的缩写。在实际所说的1M带宽的意思是1Mbps（是兆比特每秒Mbps不是兆字节每秒MBps） 换算公式: 1Byte = 8bit 1B = 8b---------- 1B/s=8b/s(或1Bps=8bps) 1KB = 1024B---------- 1KB/s=1024B/s 1MB = 1024KB ---------- 1MB/s=1024KB/s 最终： 1Mbps = 1024*1024 bps = 1024 Kbps = 1024/8 KBps = 128KBps = 128KB/s 规范提示： 在实际书写中，B应表示Byte(字节)，b应表示bit(比特)，但是我们在实际书写中很容易把bit和Byte都混写为b ，如把Mb/s和MB/s都混写为Mb/s，导致人们在实际计算中因单位的混淆而出错。 实际应用在实际上网应用中，下载软件时常常看到诸如下载速度显示为128KB（KB/s），103KB/s等等宽带速率大小字样，因为ISP提供的线路带宽使用的单位是比特（bit，即小b），而一般下载软件显示的是字节（byte，1byte＝8bits），所以要通过换算，才能得实际值。 所以，我们可以按照公式换算一下： 128KB/s=128×8(Kb/s)=1024Kb/s=1Mb/s即：128KB/s=1Mb/s。 也就是说1Mb的带宽，下载速度为128KB/s秒 在一些软件的带宽的显示页面，通常的显示页面也是以bps的方式来显示，这个时候，我们就需要进行一下换算，例如下面的页面截图（阿里云带宽使用情况） 图中所选的这个值是：13272120 bps(bits/s)，我们下面进行换算： 13272120 bps = 13272120/1024 Kbps = 13272120/1024/1024 Mbps = 12.65723 Mbps 换算之后，我们可以看到这里显示的带宽是12.6M 补充：ADSL宽带知识ADSL（Asymmetric Digital Subscriber Loop）技术是一种不对称数字用户线实现宽带接入互连网的技术，ADSL作为一种传输层的技术，充分利用现有的铜线资源，在一对双绞线上提供上行640kbps（理论上行1Mbps）下行8Mbps的带宽，从而克服了传统用户在”最后一公里”的”瓶颈”，实现了真正意义上的宽带接入。 上行速率：是指用户电脑向网络发送信息时的数据传输速率。 下行速率： 是指网络向用户电脑发送信息时的传输速率。比如用 FTP上传文件到网上去，影响上传速度的就是“上行速率”；而从网上下载文件，影响下载速度的就是“下行速率”。 当然，在实际上传下载过程中，线路、设备 (含计算机及其他设备)等的质量也会对速度造成或多或少的影响。 上行速率对上行速率的影响 TCP/IP规定，每一个封包，都需要有acknowledge信息的回传，也就是说，传输的资料，需要有一个收到资料的信息回复，才能决定后面的传输速度，并决定是否重新传输遗失的资料。 行的带宽一部分就是用来传输这些acknowledge(确认)资料的，当上行负载过大的时候，就会影响acknowledge资料的传送速度，并进而影响到下载速度。这对非对称数字环路也就是ADSL这种上行带宽远小于下载带宽的连接来说影响尤为明显。 有试验证明，当上传满载时，下载速度讲变为理想速度的40%，这就可以解释为什么很多朋友用BT下载的时候稍微限速反而能够获得更大的下载速度。 总结在网络运营商提供的宽带速率单位中，”bps”是指”bit per second” 而我们在日常生活中，使用的一般是”Byte persecond”(Bps) 我们说的带宽几M几M指的是 2Mbps、8Mbps这种格式，为了便于更加直观的查看，我们会转回成为KB的形式，也就是说，我们拿到这个数字之后，需要先*1024，将M变成K，然后再/8，最后的单位就是我们最常使用的单位了 举个栗子： 1M的带宽，理论的下载速度为：1*1024/8= 128KB/s 8M的带宽，理论的下载速度为：8*1024/8 = 1024KB/s = 1MB/s 在8M带宽之后，我们的换算，可以直接除以8来得到结果 100M的带宽，理论的下载速度为： 100/8 = 12.5MB/s]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>IT基础知识</category>
        <category>IT科普知识</category>
      </categories>
      <tags>
        <tag>带宽计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[day01-Python基础知识]]></title>
    <url>%2F2018%2F05%2F24%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E8%80%81%E7%94%B7%E5%AD%A9%E8%A7%86%E9%A2%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2Fday01-Python%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Python简介Python擅长领域Web开发 django pyramid tornado bottle flask webpy 网络编程 twisted request scrapy paramiko scipy pandas ipython GUI图形开发 wxpython pyqt kivy 运维自动化 openstack saltstack ansible 腾讯蓝鲸 编程语言概述编程语言主要从以下几个角度为进行分类： 低级语言与高级语言 编译型和解释型 静态语言和动态语言 强类型定义语言和弱类型定义语言 每个分类代表什么意思呢，我们一起来看一下。 低级语言与高级语言低级语言 最初的计算机程序都是使用0和1的序列表示的，程序员直接使用的是机器指令，无需翻译，从纸带打孔输入即可得到结果。后来为了记忆方便，就将用0、1序列表示的机器指令都用符号助记，这些与机器指令一一对应的助记符号就成为了汇编指令，从而诞生了汇编语言。 无论是机器指令还是汇编指令，都是面向机器的，这些统称为低级语言。因此是针对特定机器的机器指令的助记符，所以汇编语言是无法独立于机器（特定的CPU体系结构）的 但是汇编语言也是需要经过翻译才能转变为机器指令，所以也就有了将运行在一种机器上的汇编语言翻译成为另一类机器上的机器指令的方法，这被称之为：交叉汇编技术 高级语言 高级语言是从人类的逻辑思维角度出发的计算机语言，因此，抽象程度大大提高，需要经过编译成特定机器上的目标代码才能执行，一条高级语言的语句往往需要若干条机器指令来完成。 高级语言独立于机器的特性是靠编译器为不同机器生成不同的目标代码（或者机器指令）来实现的。具体来说，要将高级语言编译到什么程度，这跟编译的技术相挂钩，可以编译成为直接可以执行的目标代码，也可以变成成为一种中间表示，然后拿到不同的机器和系统上面去执行，这种情况通常是又需要支撑环境，比如解释器或者虚拟机的支持，Java程序编译成为bytecode，再由不同平台上的虚拟机执行就是很好的例子。所以，说高级语言不依赖于机器，指的是在不同的机器或者平台上高级语言的程序本身不变，而通过编译器编译得到的目标代码去使用不同的机器。从这个意义来说，通过交叉编译，一些汇编程序也可以获得不同机器之间的可移植性，但是这种途径获得的移植性远远不如高级语言来的方便和实用。总结我们说的低级语言和高级语言，主要的区别点在于主要针对的对象，低级语言主要针对的对象是特定的机器，而高级语言，主要针对的对象是人类的逻辑。### 编译型和解释型 ###概念编译器是把源程序的每一条语句都编译成机器语言,并保存成二进制文件,这样运行时计算机可以直接以机器语言来运行此程序,速度很快;解释器则是只在执行程序时,才一条一条的解释成机器语言给计算机来执行,所以运行速度是不如编译后的程序运行的快的.这是因为计算机不能直接认识并执行我们写的语句,它只能认识机器语言(是二进制的形式)以下是各语言的分类编译型and解释型- 编译型优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。也就是说，使用编译器将源代码文件进行编译之后，生成文件之后，计算机就可以直接运行，不再需要借助其他的东西，因此运行效率是最高的，但是这要求前期的准备工作必须做的非常完善，因为如果有代码需要修改的话，需要重新编译是生成执行文件。- 解释型&gt; 优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（一般我们也称之为虚拟机）。灵活，修改代码的时候可以直接修改，可以快速部署，不用停机维护&gt; 缺点：每次运行的时候都需要使用解释器解释一遍，因此在性能上是不如编译型语言的。&gt;解释型语言可以无视运行的系统平台，只要有解释器的存在，能将源代码解释翻译成为计算机能够识别的机器语言即可。两者对比编译是将源程序翻译成可执行的目标代码，翻译与执行是分开的；而解释是对源程序的翻译与执行一次性完成，不生成可存储的目标代码。这只是表象，二者背后的最大区别是：对解释执行而言，程序运行时的控制权在解释器而不在用户程序；对编译执行而言，运行时的控制权在用户程序。解释具有良好的动态特性和可移植性，比如在解释执行时可以动态改变变量的类型、对程序进行修改以及在程序中插入良好的调试诊断信息等，而将解释器移植到不同的系统上，则程序不用改动就可以在移植了解释器的系统上运行。同时解释器也有很大的缺点，比如执行效率低，占用空间大，因为不仅要给用户程序分配空间，解释器本身也占用了宝贵的系统资源。【这就是为什么JAVA虚拟机优化知识相当重要】编译器是把源程序的每一条语句都编译成机器语言,并保存成二进制文件,这样运行时计算机可以直接以机器语言来运行此程序,速度很快;而解释器则是只在执行程序时,才一条一条的解释成机器语言给计算机来执行,所以运行速度是不如编译后的程序运行的快的。深度扩展我们先看看编译型，其实它和汇编语言是一样的：也是有一个负责翻译的程序来对我们的源代码进行转换，生成相对应的可执行代码。这个过程说得专业一点，就称为编译（Compile），而负责编译的程序自然就称为编译器（Compiler）。如果我们写的程序代码都包含在一个源文件中，那么通常编译之后就会直接生成一个可执行文件，我们就可以直接运行了。但对于一个比较复杂的项目，为了方便管理，我们通常把代码分散在各个源文件中，作为不同的模块来组织。这时编译各个文件时就会生成目标文件（Object file）而不是前面说的可执行文件。一般一个源文件的编译都会对应一个目标文件。这些目标文件里的内容基本上已经是可执行代码了，但由于只是整个项目的一部分，所以我们还不能直接运行。待所有的源文件的编译都大功告成，我们就可以最后把这些半成品的目标文件“打包”成一个可执行文件了，这个工作由另一个程序负责完成，由于此过程好像是把包含可执行代码的目标文件连接装配起来，所以又称为链接（Link），而负责链接的程序就叫……就叫链接程序（Linker）。链接程序除了链接目标文件外，可能还有各种资源，像图标文件啊、声音文件啊什么的，还要负责去除目标文件之间的冗余重复代码，等等，所以……也是挺累的。链接完成之后，一般就可以得到我们想要的可执行文件了。上面我们大概地介绍了编译型语言的特点，现在再看看解释型。噢，从字面上看，“编译”和“解释”的确都有“翻译”的意思，它们的区别则在于翻译的时机安排不大一样。打个比方：假如你打算阅读一本外文书，而你不知道这门外语，那么你可以找一名翻译，给他足够的时间让他从头到尾把整本书翻译好，然后把书的母语版交给你阅读；或者，你也立刻让这名翻译辅助你阅读，让他一句一句给你翻译，如果你想往回看某个章节，他也得重新给你翻译。两种方式，前者就相当于我们刚才所说的编译型：一次把所有的代码转换成机器语言，然后写成可执行文件；而后者就相当于我们要说的解释型：在程序运行的前一刻，还只有源程序而没有可执行程序；而程序每执行到源程序的某一条指令，则会有一个称之为解释程序的外壳程序将源代码转换成二进制代码以供执行，总言之，就是不断地解释、执行、解释、执行……所以，解释型程序是离不开解释程序的。像早期的BASIC就是一门经典的解释型语言，要执行BASIC程序，就得进入BASIC环境，然后才能加载程序源文件、运行。解释型程序中，由于程序总是以源代码的形式出现，因此只要有相应的解释器，移植几乎不成问题。编译型程序虽然源代码也可以移植，但前提是必须针对不同的系统分别进行编译，对于复杂的工程来说，的确是一件不小的时间消耗，况且很可能一些细节的地方还是要修改源代码。而且，解释型程序省却了编译的步骤，修改调试也非常方便，编辑完毕之后即可立即运行，不必像编译型程序一样每次进行小小改动都要耐心等待漫长的Compiling…Linking…这样的编译链接过程。不过凡事有利有弊，由于解释型程序是将编译的过程放到执行过程中，这就决定了解释型程序注定要比编译型慢上一大截，像几百倍的速度差距也是不足为奇的。编译型与解释型，两者各有利弊。前者由于程序执行速度快，同等条件下对系统要求较低，因此像开发操作系统、大型应用程序、数据库系统等时都采用它，像C/C++、Pascal/Object Pascal（Delphi）、VB等基本都可视为编译语言，而一些网页脚本、服务器脚本及辅助开发接口这样的对速度要求不高、对不同系统平台间的兼容性有一定要求的程序则通常使用解释性语言，如Java、JavaScript、VBScript、Perl、Python等等。但既然编译型与解释型各有优缺点又相互对立，所以一批新兴的语言都有把两者折衷起来的趋势，例如Java语言虽然比较接近解释型语言的特征，但在执行之前已经预先进行一次预编译，生成的代码是介于机器码和Java源代码之间的中介代码，运行的时候则由JVM（Java的虚拟机平台，可视为解释器）解释执行。它既保留了源代码的高抽象、可移植的特点，又已经完成了对源代码的大部分预编译工作，所以执行起来比“纯解释型”程序要快许多。而像VB6（或者以前版本）、C#这样的语言，虽然表面上看生成的是.exe可执行程序文件，但VB6编译之后实际生成的也是一种中介码，只不过编译器在前面安插了一段自动调用某个外部解释器的代码（该解释程序独立于用户编写的程序，存放于系统的某个DLL文件中，所有以VB6编译生成的可执行程序都要用到它），以解释执行实际的程序体。C#（以及其它.net的语言编译器）则是生成.net目标代码，实际执行时则由.net解释系统（就像JVM一样，也是一个虚拟机平台）进行执行。当然.net目标代码已经相当“低级”，比较接近机器语言了，所以仍将其视为编译语言，而且其可移植程度也没有Java号称的这么强大，Java号称是“一次编译，到处执行”，而.net则是“一次编码，到处编译”。呵呵，当然这些都是题外话了。总之，随着设计技术与硬件的不断发展，编译型与解释型两种方式的界限正在不断变得模糊。### 静态语言和动态语言 ###通常我们所说的动态语言、静态语言是指动态类型语言和静态类型语言。【主要指的是数据类型】- 动态类型语言：动态类型语言是指在运行期间才去做数据类型检查的语言，也就是说，在用动态类型的语言编程时，永远也不用给任何变量指定数据类型，该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。Python和Ruby就是一种典型的动态类型语言，其他的各种脚本语言如VBScript也多少属于动态类型语言。- 静态类型语言：静态类型语言与动态类型语言刚好相反，它的数据类型是在编译其间检查的，也就是说在写程序时要声明所有变量的数据类型，C/C++是静态类型语言的典型代表，其他的静态类型语言还有C#、JAVA等。### 强类型定义语言和弱类型定义语言 ###- 强类型定义语言：强制数据类型定义的语言。也就是说，一旦一个变量被指定了某个数据类型，如果不经过强制转换，那么它就永远是这个数据类型了。举个例子：如果你定义了一个整型变量a,那么程序根本不可能将a当作字符串类型处理。强类型定义语言是类型安全的语言。- 弱类型定义语言：数据类型可以被忽略的语言。它与强类型定义语言相反, 一个变量可以赋不同数据类型的值。强类型定义语言在速度上可能略逊色于弱类型定义语言，但是强类型定义语言带来的严谨性能够有效的避免许多错误。另外，“这门语言是不是动态语言”与“这门语言是否类型安全”之间是完全没有联系的！例如：Python是动态语言，是强类型定义语言（类型安全的语言）; VBScript是动态语言，是弱类型定义语言（类型不安全的语言）; JAVA是静态语言，是强类型定义语言（类型安全的语言）。注意：&gt; 固定了数据类型，并不是说该变量就不能再被赋值了，如果变量被重新赋值了，那么相应的，它的数据类型也可能会发生变化。&gt;这里说的是，赋值这个，数据类型就固定了，在后续使用这个变量的时候，数据类型不会发生改变。通过上面这些介绍，我们可以得出，python是一门动态解释性的强类型定义高级语言。那这些基因成就了Python的哪些优缺点呢？我们继续往下看。## Python的优缺点 ##### 优点 ###- Python的定位是“优雅”、“明确”、“简单”，所以Python程序看上去总是简单易懂，初学者学Python，不但入门容易，而且将来深入下去，可以编写那些非常非常复杂的程序。- 开发效率非常高，Python有非常强大的第三方库，基本上你想通过计算机实现任何功能，Python官方库里都有相应的模块进行支持，直接下载调用后，在基础库的基础上再进行开发，大大降低开发周期，避免重复造轮子。- 高级语言————当你用Python语言编写程序的时候，你无需考虑诸如如何管理你的程序使用的内存一类的底层细节- 可移植性————由于它的开源本质，Python已经被移植在许多平台上（经过改动使它能够工 作在不同平台上）。如果你小心地避免使用依赖于系统的特性，那么你的所有Python程序无需修改就几乎可以在市场上所有的系统平台上运行 &gt; 比如某些程序，必须要调用windows的dll，那么就会依赖操作系统，因此我们要做的就是尽量避免依赖这些- 可扩展性————如果你需要你的一段关键代码运行得更快或者希望某些算法不公开，你可以把你的部分程序用C或C++编写，然后在你的Python程序中使用它们。- 可嵌入性————你可以把Python嵌入你的C/C++程序，从而向你的程序用户提供脚本功能。### 缺点 ###- 速度慢，Python 的运行速度相比C语言确实慢很多，跟JAVA相比也要慢一些，因此这也是很多所谓的大牛不屑于使用Python的主要原因，但其实这里所指的运行速度慢在大多数情况下用户是无法直接感知到的，必须借助测试工具才能体现出来，比如你用C运一个程序花了0.01s,用Python是0.1s,这样C语言直接比Python快了10倍,算是非常夸张了，但是你是无法直接通过肉眼感知的，因为一个正常人所能感知的时间最小单位是0.15-0.4s左右，哈哈。其实在大多数情况下Python已经完全可以满足你对程序速度的要求，除非你要写对速度要求极高的搜索引擎等，这种情况下，当然还是建议你用C去实现的。- 代码不能加密，因为PYTHON是解释性语言，它的源码都是以名文形式存放的，不过我不认为这算是一个缺点，如果你的项目要求源代码必须是加密的，那你一开始就不应该用Python来去实现。- 线程不能利用多CPU问题，这是Python被人诟病最多的一个缺点，GIL即全局解释器锁（Global Interpreter Lock），是计算机程序设计语言解释器用于同步线程的工具，使得任何时刻仅有一个线程在执行，Python的线程是操作系统的原生线程。在Linux上为pthread，在Windows上为Win thread，完全由操作系统调度线程的执行。一个python解释器进程内有一条主线程，以及多条用户程序的执行线程。即使在多核CPU平台上，由于GIL的存在，所以禁止多线程的并行执行。关于这个问题的折衷解决方法，我们在以后线程和进程章节里再进行详细探讨。任何一门语言都不是完美的，都有擅长和不擅长做的事情，建议各位不要拿一个语言的劣势去跟另一个语言的优势来去比较，语言只是一个工具，是实现程序设计师思想的工具，就像我们之前中学学几何时，有的时候需要要圆规，有的时候需要用三角尺一样，拿相应的工具去做它最擅长的事才是正确的选择。## Python解释器 ##当我们编写Python代码时，我们得到的是一个包含Python代码的以.py为扩展名的文本文件。要运行代码，就需要Python解释器去执行.py文件。由于整个Python语言从规范到解释器都是开源的，所以理论上，只要水平够高，任何人都可以编写Python解释器来执行Python代码（当然难度很大）。事实上，确实存在多种Python解释器。CPython当我们从Python官方网站下载并安装好Python 2.7后，我们就直接获得了一个官方版本的解释器：CPython。这个解释器是用C语言开发的，所以叫CPython。在命令行下运行python就是启动CPython解释器。CPython是使用最广的Python解释器。教程的所有代码也都在CPython下执行。IPythonIPython是基于CPython之上的一个交互式解释器，也就是说，IPython只是在交互方式上有所增强，但是执行Python代码的功能和CPython是完全一样的。好比很多国产浏览器虽然外观不同，但内核其实都是调用了IE。CPython用&gt;&gt;&gt;作为提示符，而IPython用In [序号]:作为提示符。PyPyPyPy是另一个Python解释器，它的目标是执行速度。PyPy采用JIT技术(即时编译技术)，对Python代码进行动态编译（注意不是解释），所以可以显著提高Python代码的执行速度。绝大部分Python代码都可以在PyPy下运行，但是PyPy和CPython有一些是不同的，这就导致相同的Python代码在两种解释器下执行可能会有不同的结果。如果你的代码要放到PyPy下执行，就需要了解PyPy和CPython的不同点。&gt; Python创始人说：如果想代码跑的快，那就使用pypyJythonJython是运行在Java平台上的Python解释器，可以直接把Python代码编译成Java字节码执行。IronPythonIronPython和Jython类似，只不过IronPython是运行在微软.Net平台上的Python解释器，可以直接把Python代码编译成.Net的字节码。总结：Python的解释器很多，但使用最广泛的还是CPython。如果要和Java或.Net平台交互，最好的办法不是用Jython或IronPython，而是通过网络调用来交互，确保各程序之间的独立性。## 变量 ##变量的作用：存储数据，为了后面调用变量存储在内存当中，每一个拥有独立的内存空间。### Python变量的定义规则 ###- 变量名只能是 字母、数字或下划线的任意组合- 变量名的第一个字符不能是数字- 以下关键字不能声明为变量名&gt;&gt; [‘and’, ‘as’, ‘assert’, ‘break’, ‘class’, ‘continue’, ‘def’, ‘del’, ‘elif’, ‘else’, ‘except’, ‘exec’, ‘finally’, ‘for’, ‘from’, ‘global’, ‘if’, ‘import’, ‘in’, ‘is’, ‘lambda’, ‘not’, ‘or’, ‘pass’, ‘print’, ‘raise’, ‘return’, ‘try’, ‘while’, ‘with’, ‘yield’]### 变量和常量 ###注意，在C++等语言中可以定义常量，但是在python中没有常量的概念那么，如果我们在python中想要定义一个常量，我们就将这个变量名大写。这是一种自发遵守的代码规范，并不是说不能再次修改，只是便于人类识别。例如： PIE = “watchmen”## 字符编码编码 ##### 字符编码说明 ###计算机的底层就是电路，电路到最底层就只有两种状态，一种是通电，一种是不通电，那么也就是只能表示两种状态。 128 64 32 16 8 4 2 1 1 1 1 1 1 1 1 1进位：后面的数字表示有上限之后，才进位到前面，例如：8+4+2+1=15，在表示16的时候，需要在前面表示进一位表示第n位数表示的值：2^n-1,例如16=2^5-1=2^4 = 8+4+2+1+1第n位数之前的值的总和是：2^n-1 -1。例如第5位数的前4位数的总和为：2^4-1=16-1也就是说，我们可以通过这种方式来计算，n位数的总和：2^n-1上面这些是二进制和数字的对应关系现在可以将数字和字符进行对应，指定某个数字对应某个字母根据这种对应关系，人们就创建了ASCII编码方式ASCII（American Standard Code for Information Interchange，美国标准信息交换代码）是基于拉丁字母的一套电脑编码系统，主要用于显示现代英语和其他西欧语言，其最多只能用 8 位来表示（一个字节），即：28 = 256-1，所以，ASCII码最多只能表示 255 个符号。图中显示的是ASCII的上半部分，一共127个，剩余的128-255个是预留的。预留的这128个空间，无法存储下中文，因此重新创造了编码方式（扩展编码）将指定的空间，用来存储索引信息，只要是定位到这个空间，那么就将指向另外的一张中文表（大约7000+个汉字），这就是GB2312编码（1980年创建）为了处理汉字，程序员设计了用于简体中文的GB2312和用于繁体中文的big5。GB2312(1980年)一共收录了7445个字符，包括6763个汉字和682个其它符号。汉字区的内码范围高字节从B0-F7，低字节从A1-FE，占用的码位是72*94=6768。其中有5个空位是D7FA-D7FE。GB2312 支持的汉字太少。1995年的汉字扩展规范GBK1.0收录了21886个符号，它分为汉字区和图形符号区。汉字区包括21003个字符。2000年的 GB18030是取代GBK1.0的正式国家标准。该标准收录了27484个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。现在的PC平台必须支持GB18030，对嵌入式产品暂不作要求。所以手机、MP3一般只支持GB2312。从ASCII、GB2312、GBK 到GB18030，这些编码方法是向下兼容的，即同一个字符在这些方案中总是有相同的编码，后面的标准支持更多的字符。在这些编码中，英文和中文可以统一地处理。区分中文编码的方法是高字节的最高位不为0。按照程序员的称呼，GB2312、GBK到GB18030都属于双字节字符集 (DBCS)。有的中文Windows的缺省内码还是GBK，可以通过GB18030升级包升级到GB18030。不过GB18030相对GBK增加的字符，普通人是很难用到的，通常我们还是用GBK指代中文Windows内码。 Unicode显然ASCII码无法将世界上的各种文字和符号全部表示，所以，就需要新出一种可以代表所有字符和符号的编码，即：UnicodeUnicode（统一码、万国码、单一码）是一种在计算机上使用的字符编码。Unicode 是为了解决传统的字符编码方案的局限而产生的，它为每种语言中的每个字符设定了统一并且唯一的二进制编码，规定虽有的字符和符号最少由 16 位来表示（2个字节），即：2 16 = 65536，注：此处说的的是最少2个字节，可能更多UTF-8，是对Unicode编码的压缩和优化，他不再使用最少使用2个字节，而是将所有的字符和符号进行分类：&gt; ascii码中的内容用1个字节保存、欧洲的字符用2个字节保存，东亚的字符用3个字节保存..UTF-8，可以动态改变长度，可以动态变化的编码集## 注释 ##单行注释： # 被注释内容 or “被注释内容” 也就是使用单引号或者双引号【注意，和shell不同，在python中，这两者没有区别】多行注释： “”” 被注释内容 “”” or ‘’’被注释内容’’’代码： message =””” line1 line2 line3””” print (message)程序输出为： line1 line2 line3## Python2和Python3的区别 ##PRINT IS A FUNCTION在python中，print是以函数的方式存在的 Old: print “The answer is”, 22 New: print(“The answer is”, 22) Old: print x, # Trailing comma suppresses newline New: print(x, end=” “) # Appends a space instead of a newline Old: print # Prints a newline New: print() # You must call the function! Old: print &gt;&gt;sys.stderr, “fatal error” New: print(“fatal error”, file=sys.stderr) Old: print (x, y) # prints repr((x, y)) New: print((x, y)) # Not the same as print(x, y)!ALL IS UNICODE NOWpython3默认支持UTF-8，也就是说，默认就支持中文在python中，在文件的开头要使用下方命令指定该文件的编码方式 #_coding:utf-8_## 帮助文档查看 ##python的一个优势是有着大量自带和在线的模块(module)资源，可以提供丰富的功能，在使用这些模块的时候，如果每次都去网站找在线文档会过于耗费时间，结果也不一定准确。因此这里介绍下python自带的查看帮助功能，可以在编程时不中断地迅速找到所需模块和函数的使用方法在python命令行中键入help(),可以看到：进入help帮助文档界面，根据屏幕提示可以继续键入相应关键词进行查询这是python的通用的查询帮助，可以查到几乎所有的帮助文档，但我们很多时候不需要这样层级式地向下查询，接下来会介绍如何直接查询特定的模块和函数帮助信息。- 键入modules可以列出当前所有安装的模块- 键入相应的模块名称得到该模块的帮助信息例如要查询math模块的使用方法，可以如下操作： &gt;&gt;&gt; import math &gt;&gt;&gt; help(math)使用help(module_name)时首先需要import该模块，有些教程中不进行导入而在模块名中加入引号help(‘module_name’)，这种方法可能会带来问题，大家可以用math模块测试，建议使用先导入再使用help()函数查询查看模块下所有函数： &gt;&gt;&gt; dir(math) [‘doc‘, ‘loader‘, ‘name‘, ‘package‘, ‘spec‘, ‘acos’, ‘acosh’, ‘asin’, ‘asinh’, ‘atan’, ‘atan2’, ‘atanh’, ‘ceil’, ‘copysign’, ‘cos’, ‘cosh’, ‘degrees’, ‘e’, ‘erf’, ‘erfc’, ‘exp’, ‘expm1’, ‘fabs’, ‘factorial’, ‘floor’, ‘fmod’, ‘frexp’, ‘fsum’, ‘gamma’, ‘gcd’, ‘hypot’, ‘inf’, ‘isclose’, ‘isfinite’, ‘isinf’, ‘isnan’, ‘ldexp’, ‘lgamma’, ‘log’, ‘log10’, ‘log1p’, ‘log2’, ‘modf’, ‘nan’, ‘pi’, ‘pow’, ‘radians’, ‘sin’, ‘sinh’, ‘sqrt’, ‘tan’, ‘tanh’, ‘tau’, ‘trunc’] &gt;&gt;&gt;## 模块初识 ##Python的强大之处在于他有非常丰富和强大的标准库和第三方库，几乎你想实现的任何功能都有相应的Python库支持，以后的课程中会深入讲解常用到的各种库，现在，我们先简单介绍两个在运维中常用的sys模块 wxh@wxh-virtual-machine:~/python-14/day01$ cat modules-sys.py import sys print (sys.argv) wxh@wxh-virtual-machine:~/python-14/day01$ python modules-sys.py ni hao [‘modules-sys.py’, ‘ni’, ‘hao’]os模块 wxh@wxh-virtual-machine:~/python-14/day01$ cat modules-os.py import os os.system(“df -h”) wxh@wxh-virtual-machine:~/python-14/day01$ python modules-os.py Filesystem Size Used Avail Use% Mounted on udev 960M 0 960M 0% /dev tmpfs 198M 19M 179M 10% /run /dev/sda1 97G 5.6G 86G 7% / tmpfs 986M 320K 986M 1% /dev/shm tmpfs 5.0M 4.0K 5.0M 1% /run/lock tmpfs 986M 0 986M 0% /sys/fs/cgroup tmpfs 198M 68K 198M 1% /run/user/1000后续会涉及到自己自己写一些python文件，然后将它转换为模块。默认情况下模块只能在当前目录下导入，如果想在系统的何何一个地方都使用怎么办呢？此时你就要把这个xxx.py模块文件放到python全局环境变量目录里啦，基本一般都放在一个叫 Python/2.7/site-packages 目录下，这个目录在不同的OS里放的位置不一样，用 print(sys.path) 可以查看python环境变量列表。 &gt;&gt;&gt; print (sys.path) [‘’, ‘/usr/lib/python35.zip’, ‘/usr/lib/python3.5’, ‘/usr/lib/python3.5/plat-x86_64-linux-gnu’, ‘/usr/lib/python3.5/lib-dynload’, ‘/usr/local/lib/python3.5/dist-packages’, ‘/usr/lib/python3/dist-packages’] &gt;&gt;&gt;## .pyc是什么？ ##编译型语言在程序执行之前，先会通过编译器对程序执行一个编译的过程，把程序转变成机器语言。运行时就不需要翻译，而直接执行就可以了。最典型的例子就是C语言。解释型语言就没有这个编译的过程，而是在程序运行的时候，通过解释器对程序逐行作出解释，然后直接运行，最典型的例子是bash、python、Ruby等。但是我们也不能一概而论，一些解释型语言也可以通过解释器的优化来在对程序做出翻译时对整个程序做出优化，从而在效率上超过编译型语言。此外，随着Java等基于虚拟机的语言的兴起，我们又不能把语言纯粹地分成解释型和编译型这两种。用Java来举例，Java首先是通过编译器编译成字节码文件，然后在运行时通过解释器给解释成机器文件。所以我们说Java是一种先编译后解释的语言。重点来了： 其实Python和Java/C#一样，也是一门基于虚拟机的语言，我们先来从表面上简单地了解一下Python程序的运行过程吧。 当我们在命令行中输入python hello.py时，其实是激活了Python的“解释器”，告诉“解释器”：你要开始工作了。可是在“解释”之前，其实执行的第一项工作和Java一样，是编译。 熟悉Java的同学可以想一下我们在命令行中如何执行一个Java的程序： javac hello.java java hello 只是我们在用Eclipse之类的IDE时，将这两部给融合成了一部而已。其实Python也一样，当我们执行python hello.py时，他也一样执行了这么一个过程，所以我们应该这样来描述Python，Python是一门先编译后解释的语言。 Python的运行过程在说这个问题之前，我们先来说两个概念，PyCodeObject和pyc文件。 我们在硬盘上看到的pyc自然不必多说，而其实PyCodeObject则是Python编译器真正编译成的结果。我们先简单知道就可以了，继续向下看。 当python程序运行时，编译的结果则是保存在位于内存中的PyCodeObject中，当Python程序运行结束时，Python解释器则将PyCodeObject写回到pyc文件中。 当python程序第二次运行时，首先程序会在硬盘中寻找pyc文件，如果找到，则直接载入，否则就重复上面的过程。 所以我们应该这样来定位PyCodeObject和pyc文件，我们说pyc文件其实是PyCodeObject的一种持久化保存方式。 也就是说，只有在第二次执行的时候，才会用到pyc Python数据类型数字int（整型） 在32位机器上，整数的位数为32位，取值范围为-231～231-1，即-2147483648～2147483647 在64位系统上，整数的位数为64位，取值范围为-263～263-1，即-9223372036854775808～9223372036854775807 long（长整型） 跟C语言不同，Python的长整数没有指定位宽，即：Python没有限制长整数数值的大小，但实际上由于机器内存有限，我们使用的长整数数值不可能无限大。注意，自从Python2.2起，如果整数发生溢出，Python会自动将整数数据转换为长整数，所以如今在长整数数据后面不加字母L也不会导致严重后果了。 float（浮点型） 浮点数用来处理实数，即带有小数的数字。类似于C语言中的double类型，占8个字节（64位），其中52位表示底，11位表示指数，剩下的一位表示符号。 complex（复数） 复数由实数部分和虚数部分组成，一般形式为x＋yj，其中的x是复数的实数部分，y是复数的虚数部分，这里的x和y都是实数。 注：Python中存在小数字池：-5 ～ 257 例如： 12342 是一个整数的例子。长整数 不过是大一些的整数。3.23和52.3E-4是浮点数的例子。E标记表示10的幂。在这里，52.3E-4表示52.3 * 10-4。(-5+4j)和(2.3-4.6j)是复数的例子，其中-5,4为实数，j为虚数，数学中表示复数是什么？ 补充：复数 实数 有理数 无理数 有理数 数学上，有理数是一个整数a和一个非零整数b的比，例如3/8，通则为a/b，又称作分数。0也是有理数。有理数是整数和分数的集合，整数也可看做是分母为一的分数。 有理数的小数部分是有限或为无限循环的数。不是有理数的实数称为无理数，即无理数的小数部分是无限不循环的数。 无理数 无理数，也称为无限不循环小数，不能写作两整数之比。若将它写成小数形式，小数点之后的数字有无限多个，并且不会循环。 常见的无理数有非完全平方数的平方根、圆周率（Pi）和e 实数 实数，是有理数和无理数的总称 浮点数 浮点数是属于有理数中某特定子集的数的数字表示，在计算机中用以近似表示任意某个实数。具体的说，这个实数由一个整数或定点数（即尾数）乘以某个基数（计算机中通常是2）的整数次幂得到，这种表示方法类似于基数为10的科学计数法。 科学记数法 把一个绝对值大于10的实数记为a×10n的形式(1≤|a|&lt;10，n为整数),这种记数法叫做科学记数法。这是一种记数的方法。例如19971400000000=1.99714×10^13。计算器或电脑表达10的的幂是一般是用E或e，也就是1.99714E13=19971400000000 复数 复数是指能写成如下形式的数：a+bi 这里a和b是实数，i是虚数单位(即-1开根)。在复数a+bi中，a称为复数的实部，b称为复数的虚部，i称为虚数单位。当虚部等于零时，这个复数就是实数；当虚部不等于零时，这个复数称为虚数 字符串python中的字符串在C语言中体现为是一个字符数组，因此每次创建字符串时候需要在内存中开辟一块连续的空间，并且一旦需要修改字符串的话，就需要再次开辟空间，+号每出现一次就会在内存中重新开辟一块空间。 列表创建列表： 123name_list = [&apos;alex&apos;, &apos;seven&apos;, &apos;eric&apos;]或name_list ＝ list([&apos;alex&apos;, &apos;seven&apos;, &apos;eric&apos;]) 元祖(不可变列表)创建元祖 123ages = (11, 22, 33, 44, 55)或ages = tuple((11, 22, 33, 44, 55)) 字典（无序）创建字典 123person = &#123;&quot;name&quot;: &quot;mr.wu&quot;, &apos;age&apos;: 18&#125;或person = dict(&#123;&quot;name&quot;: &quot;mr.wu&quot;, &apos;age&apos;: 18&#125;) 布尔值真或假 1 或 0 数据运算算数运算 运算符 描述 实例 + 加 - 两个对象相加 a + b 输出结果 30 - 减 - 得到负数或是一个数减去另一个数 a - b 输出结果 -10 * 乘 - 两个数相乘或是返回一个被重复若干次的字符串 a * b 输出结果 200 / 除 - x除以y b / a 输出结果 2 % 取模 - 返回除法的余数 b % a 输出结果 0 ** 幂 - 返回x的y次幂 a**b 为10的20次方， 输出结果 100000000000000000000 // 取整除 - 返回商的整数部分 9//2 输出结果 4 , 9.0//2.0 输出结果 4.0 比较运算 运算符 描述 实例 == 等于 - 比较对象是否相等 (a == b) 返回 False。 != 不等于 - 比较两个对象是否不相等 (a != b) 返回 true. &lt;&gt; 不等于 - 比较两个对象是否不相等 (a &lt;&gt; b) 返回 true。这个运算符类似 != 。 &gt; 大于 - 返回x是否大于y (a &gt; b) 返回 False。 &lt; 小于 - 返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量True和False等价。 (a &lt; b) 返回 true。 &gt;= 大于等于 - 返回x是否大于等于y。 (a &gt;= b) 返回 False。 &lt;= 小于等于 - 返回x是否小于等于y。 (a &lt;= b) 返回 true。 赋值运算 运算符 描述 实例 = 简单的赋值运算符 c = a + b 将 a + b 的运算结果赋值为 c += 加法赋值运算符 c += a 等效于 c = c + a -= 减法赋值运算符 c -= a 等效于 c = c - a *= 乘法赋值运算符 c = a 等效于 c = c a /= 除法赋值运算符 c /= a 等效于 c = c / a %= 取模赋值运算符 c %= a 等效于 c = c % a **= 幂赋值运算符 c = a 等效于 c = c a //= 取整除赋值运算符 c //= a 等效于 c = c // a 逻辑运算 运算符 逻辑表达式 描述 实例 and x and y 布尔”与” - 如果 x 为 False，x and y 返回 False，否则它返回 y 的计算值。 (a and b) 返回 20。 or x or y 布尔”或” - 如果 x 是非 0，它返回 x 的值，否则它返回 y 的计算值。 (a or b) 返回 10。 not not x 布尔”非” - 如果 x 为 True，返回 False 。如果 x 为 False，它返回 True。 not(a and b) 返回 False 成员运算除了以上的一些运算符之外，Python还支持成员运算符，测试实例中包含了一系列的成员，包括字符串，列表或元组。 运算符 描述 实例 in 如果在指定的序列中找到值返回 True，否则返回 False。 x 在 y 序列中 , 如果 x 在 y 序列中返回 True。 not in 如果在指定的序列中没有找到值返回 True，否则返回 False。 x 不在 y 序列中 , 如果 x 不在 y 序列中返回 True。 身份运算身份运算符用于比较两个对象的存储单元 运算符 描述 实例 is is 是判断两个标识符是不是引用自一个对象 x is y, 类似 id(x) == id(y) , 如果引用的是同一个对象则返回 True，否则返回 False is not is not 是判断两个标识符是不是引用自不同对象 x is not y ， 类似 id(a) != id(b)。如果引用的不是同一个对象则返回结果 True，否则返回 False。 位运算 运算符 描述 实例 &amp; 按位与运算符：参与运算的两个值,如果两个相应位都为1,则该位的结果为1,否则为0 (a &amp; b) 输出结果 12 ，二进制解释： 0000 1100 \ 按位或运算符：只要对应的二个二进位有一个为1时，结果位就为1。 (a \ b) 输出结果 61 ，二进制解释： 0011 1101 ^ 按位异或运算符：当两对应的二进位相异时，结果为1 (a ^ b) 输出结果 49 ，二进制解释： 0011 0001 ~ 按位取反运算符：对数据的每个二进制位取反,即把1变为0,把0变为1 。~x 类似于 -x-1 (~a ) 输出结果 -61 ，二进制解释： 1100 0011，在一个有符号二进制数的补码形式。 &lt;&lt; 左移动运算符：运算数的各二进位全部左移若干位，由 &lt;&lt; 右边的数字指定了移动的位数，高位丢弃，低位补0。 a &lt;&lt; 2 输出结果 240 ，二进制解释： 1111 0000 &gt;&gt; 右移动运算符：把”&gt;&gt;”左边的运算数的各二进位全部右移若干位，&gt;&gt; 右边的数字指定了移动的位数 a &gt;&gt; 2 输出结果 15 ，二进制解释： 000 Python运算符优先级以下表格列出了从最高到最低优先级的所有运算符： 运算符 描述 ** 指数 (最高优先级) ~ + - 按位翻转, 一元加号和减号 (最后两个的方法名为 +@ 和 -@) * / % // 乘，除，取模和取整除 + - 加法减法 &gt;&gt; &lt;&lt; 右移，左移运算符 &amp; 位 ‘AND’ ^ \ 位运算符 &lt;= &lt; &gt; &gt;= 比较运算符 &lt;&gt; == != 等于运算符 = %= /= //= -= += = *= 赋值运算符 is is not 身份运算符 in not in 成员运算符 not or and 逻辑运算符 三元运算result = 值1 if 条件 else 值2 如果条件为真：result = 值1 如果条件为假：result = 值2 例如： d = a if a&gt;b else c 1234&gt;&gt;&gt; a,b,c=1,2,3&gt;&gt;&gt; d = a if a&gt;b else c&gt;&gt;&gt; print (d)3 根据if条件判断的结果来进行赋值]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>老男孩视频学习笔记</category>
      </categories>
      <tags>
        <tag>老男孩视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT书籍资料]]></title>
    <url>%2F2018%2F05%2F20%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FIT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2FIT%E7%B1%BB%E4%B9%A6%E7%B1%8D%E8%B5%84%E6%96%99%2FIT%E7%B1%BB%E4%B9%A6%E7%B1%8D%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[说明： 名称 类型 作者 出版年份 这里仅写第一次印刷的时间 出版社 很多出版社会出版同一本书，众多出版社中肯定有好坏之分 译者 如果是一些国外经典，往往有很多译本，众多译本中肯定有相对好坏之分 备注 科普读物 名称 类型 作者 出版年份 出版社 译者 备注 浪潮之巅 书籍 吴军 数学之美 书籍 吴军 数据库Mysql： 名称 类型 作者 出版年份 出版社 译者 备注 MySQL技术内幕_InnoDB存储引擎.第2版 书籍 高性能mysql 书籍 MySQL 5.5从零开始学 书籍 Redis 名称 类型 作者 出版年份 出版社 译者 备注 Redis运维与开发 书籍 付磊、张益军 2017年4月 无 搜狐视频团队出品，其还开源了cachecloud云平台。非常不错的一本好书。 编程Python 名称 类型 作者 出版年份 出版社 译者 备注 Python编程从入门到实践 书籍 Linux运维自动化 名称 类型 作者 出版年份 出版社 译者 备注 SaltStack技术入门与实践 书籍 刘继伟、沈灿、赵舜东 2016年1月]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>IT基础知识</category>
        <category>IT书籍资料</category>
      </categories>
      <tags>
        <tag>IT书籍资料</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装Python3]]></title>
    <url>%2F2018%2F05%2F20%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2FPython%2FCentos7%E5%AE%89%E8%A3%85Python3%2F</url>
    <content type="text"><![CDATA[在centos 7中，默认安装的python版本为2.7,一般情况下，我们都需要对python进行升级 [root@master ~]# cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) [root@master ~]# python --version Python 2.7.5 环境说明[root@master ~]# which python /usr/bin/python [root@master ~]# ll /usr/bin/python lrwxrwxrwx 1 root root 7 Apr 13 16:50 /usr/bin/python -&gt; python2 [root@master ~]# ll /usr/bin/python2 lrwxrwxrwx 1 root root 9 Apr 13 16:50 /usr/bin/python2 -&gt; python2.7 [root@master ~]# ll /usr/bin/python2.7 -rwxr-xr-x 1 root root 7136 Aug 4 2017 /usr/bin/python2.7 我们知道我们的python命令是在/usr/bin目录下 可以看到，python指向的是python2，python2指向的是python2.7 因此我们可以装个python3，然后将python指向python3，然后python2指向python2.7，那么两个版本的python就能共存了。 正式安装下载python3的源码包 wget https://www.python.org/ftp/python/3.6.5/Python-3.6.5.tgz 解压编译安装 [root@master software]# tar -zxvf Python-3.6.5.tgz [root@master software]# cd Python-3.6.5 [root@master Python-3.6.5]# ./configure --prefix=/usr/local/python3 [root@master Python-3.6.5]# make &amp;&amp; make install 添加软链接 [root@master Python-3.6.5]# mv /usr/bin/python /usr/bin/python.bak [root@master Python-3.6.5]# ln -s /usr/local/python3/bin/python3.6 /usr/bin/python [root@master Python-3.6.5]# python --version Python 3.6.5 补充操作更改yum配置安装完毕之后，我们需要修改yum的配置，因为其要使用python2执行，此时我们修改了python的指向路径，不修改则会导致yum无法正常使用。 vim /usr/bin/yum 把#! /usr/bin/python修改为#! /usr/bin/python2 vim /usr/libexec/urlgrabber-ext-down 把#! /usr/bin/python 修改为#! /usr/bin/python2]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>基础环境配置</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RDS从入门到实践]]></title>
    <url>%2F2018%2F05%2F14%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E5%85%AC%E6%9C%89%E4%BA%91%E4%BA%A7%E5%93%81%2F%E9%98%BF%E9%87%8C%E4%BA%91%2FRDS%2F</url>
    <content type="text"><![CDATA[官方文档 基础知识阿里云关系型数据库（Relational Database Service，简称 RDS）是一种稳定可靠、可弹性伸缩的在线数据库服务。基于阿里云分布式文件系统和SSD盘高性能存储，RDS 支持 MySQL、SQL Server、PostgreSQL 和 PPAS（Postgre Plus Advanced Server，一种高度兼容 Oracle 的数据库）引擎，并且提供了容灾、备份、恢复、监控、迁移等方面的全套解决方案，彻底解决数据库运维的烦恼。 RDS的特点云数据库RDS作为一个公共的关系型数据库，高可用和高安全是其首要优势，其次才是高性能，因为没人会使用既不稳定又不安全的服务。RDS的优势主要体现在如下几点： RDS提供了主备双节点的实例，双节点可以在同一地域的不同可用区，MySQL实例的双节点还可以在不同地域，当主实例出现故障时可快速切换到备实例，保障了RDS的稳定性。 RDS在数据的存取上加入了中间层，所有请求都会经过中间层，而且有SQL注入的请求都会被中间层拦截掉。在底层数据写入上，RDS采用了最高安全级别的写入，保证在主机异常掉电的情况下数据不会出现丢失。以此来保障数据库的高安全性。 RDS源码团队持续对MySQL进行源码优化，在标准的基准测试中性能和稳定性上都是高于社区版本的。 关于这部分内容可以查看：对比ECS自建数据库与RDS性能时的注意事项 访问控制数据库账号 当用户创建实例后，RDS并不会为用户创建任何初始的数据库账号。 有如下两种方式来创建数据库帐号： 用户可以通过控制台或者API来创建普通数据库账号，并设置数据库级别的读写权限。 如果用户需要更细粒度的权限控制，比如表、视图，字段级别的权限，也可以通过控制台或者API先创建高权限数据库账号，并使用数据库客户端和高权限数据库账号来创建普通数据库账号。高权限数据库账号可以为普通数据库账号设置表级别的读写权限。 说明：通过高权限数据库账号创建的普通数据库账号，无法通过控制台或者API进行管理。 IP白名单 虽然RDS不支持ECS的安全组功能，但是RDS提供了IP白名单来实现网络安全访问控制。 默认情况下，RDS实例被设置为不允许任何IP访问，即127.0.0.1。 用户可以通过控制台的数据安全性模块或者API来添加IP白名单规则。IP白名单的更新无需重启RDS实例，因此不会影响用户的使用。 IP白名单可以设置多个分组，每个分组可配置1000个IP或IP段。 设置白名单后，只有以下服务器才能访问RDS实例： 白名单中 IP 地址所属的服务器 白名单中 ECS 安全组内的 ECS 实例 注意事项： 系统会给每个实例创建一个默认的default白名单分组，该白名单分组只能被修改或清空，但不能被删除。 对于新建的RDS实例，系统默认会将回送地址127.0.0.1添加到default白名单分组中，IP地址127.0.0.1代表禁止所有IP地址或IP段访问该RDS实例。所以，在您设置白名单时，需要先将127.0.0.1删除，然后再添加您允许访问该RDS实例的IP地址或IP段。 若将白名单设置为%或者0.0.0.0/0，代表允许任何IP访问RDS实例。该设置将极大降低数据库的安全性，如非必要请勿使用。 安全组 目前仅杭州、青岛、香港地域支持 ECS 安全组。 目前仅支持添加一个安全组。 对白名单中的 ECS 安全组的更新将实时应用到白名单中。 系统安全 RDS 处于多层防火墙的保护之下，可以有力地抗击各种恶意攻击，保证数据的安全。 RDS 服务器不允许直接登录，只开放特定的数据库服务所需要的端口。 RDS 服务器不允许主动向外发起连接，只能接受被动访问。 数据链路服务阿里云数据库提供全数据链路服务，包括 DNS、负载均衡、Proxy 等。因为 RDS 使用原生的 DB Engine，对数据库的操作高度类似，基本没有学习成本。 DNS DNS 模块提供域名到 IP 的动态解析功能，以便规避 RDS 实例 IP 地址改变带来的影响。在连接池中设置域名后，即使对应的IP地址发生了变化，仍然可以正常访问 RDS 实例。 例如，某 RDS 实例的域名为 test.rds.aliyun.com，对应的 IP 地址为 10.10.10.1。某程序连接池中设置为 test.rds.aliyun.com 或 10.10.10.1 都可以正常访问 RDS 实例。 一旦该 RDS 实例发生了可用区迁移或者版本升级后，IP 地址可能变为 10.10.10.2。如果程序连接池中设置的是域名 test.rds.aliyun.com，则仍然可以正常访问 RDS 实例。但是如果程序连接池中设置的是IP地址 10.10.10.1，就无法访问 RDS 实例了。 负载均衡 负载均衡 模块提供实例 IP 地址（包括内网 IP 和外网 IP），以便屏蔽物理服务器变化带来的影响。 例如，某 RDS 实例的内网 IP 地址为 10.1.1.1，对应的 Proxy 或者 DB Engine 运行在 192.168.0.1 上。在正常情况下，负载均衡 模块会将访问 10.1.1.1 的流量重定向到 192.168.0.1 上。当 192.168.0.1 发生了故障，处于热备状态的 192.168.0.2 接替了 192.168.0.1 的工作。此时 负载均衡 模块会将访问 10.1.1.1 的流量重定向到 192.168.0.2 上，RDS 实例仍旧正常提供服务。 Proxy Proxy 模块提供数据路由、流量探测和会话保持等功能。 数据路由功能：支持大数据场景下的分布式复杂查询聚合和相应的容量管理。 流量探测功能：降低 SQL 注入的风险，在必要情况下支持 SQL 日志的回溯。 会话保持功能：解决故障场景下的数据库连接中断问题。 高可用服务高可用服务由 Detection、Repair、Notice 等模块组成，主要保障数据链路服务的可用性，除此之外还负责处理数据库内部的异常。 另外，RDS 还通过迁移到支持多可用区的地域和采用适当的高可用策略，提升 RDS 的高可用服务。 Detection Detection 模块负责检测 DB Engine 的主节点和备节点是否提供了正常的服务。通过间隔为 8~10 秒的心跳信息，HA 节点可以轻易获得主节点的健康情况，结合备节点的健康情况和其它 HA 节点的心跳信息，Detection 模块可以排除网络抖动等异常引入的误判风险，在 30 秒内完成异常切换操作。 Repair Repair 模块负责维护 DB Engine 的主节点和备节点之间的复制关系，还会修复主节点或者备节点在日常运行中出现的错误。 例如： 主备复制异常断开的自动修复 主备节点表级别损坏的自动修复 主备节点 Crash 的现场保存和自动修复 Notice Notice 模块负责将主备节点的状态变动通知到 负载均衡 或者 Proxy，保证用户访问正确的节点。 例如：Detection 模块发现主节点异常，并通知 Repair 模块进行修复。Repair 模块进行了尝试后无法修复主节点，通知 Notice 进行流量切换。Notice 模块将切换请求转发至 负载均衡 或者Proxy，此时用户流量全部指向备节点。与此同时，Repair 在别的物理服务器上重建了新的备节点，并将变动同步给 Detection 模块。Detection 模块开始重新检测实例的健康状态。 多可用区 RDS在特定地域提供了多可用区部署的能力，也就是将RDS的主备实例分别部署于同一地域的不同可用区。相对于单可用区 RDS 实例，多可用区 RDS 实例可以承受更高级别的灾难。 目前多可用区 RDS 不额外收取任何费用，用户可以直接在已开通多可用区的地域购买多可用区 RDS 实例，也可以通过跨可用区迁移将单可用区 RDS 实例转化成多可用区 RDS 实例。 注意： 因为多可用区之间存在一定的网络延迟，因此多可用区 RDS 实例在采用半同步数据复制方案的时候，对于单个更新的响应时间会比单可用区实例长。这种情况最好通过提高并发量的方式来实现整体吞吐量的提高。 高可用策略 高可用策略是根据用户自身业务的特点，采用服务优先级和数据复制方式之间的不同组合，以组合出适合自身业务特点的高可用策略。 服务优先级有以下两个级别： RTO（Recovery Time Objective）优先：数据库应该尽快恢复服务，即可用时间最长。对于数据库在线时间要求比较高的用户应该使用 RTO 优先策略。 RPO（Recovery Point Objective）优先：数据库应该尽可能保障数据的可靠性，即数据丢失量最少。对于数据一致性要求比较高的用户应该使用 RPO 优先策略。 数据复制方式有以下三种方式： 异步复制（Async）：应用发起更新（含增加、删除、修改操作）请求，Master 完成相应操作后立即响应应用，Master 向 Slave 异步复制数据。因此异步复制方式下，Slave 不可用不影响主库上的操作，而 Master 不可用有较小概率会引起数据不一致。 强同步复制（Sync）：应用发起更新（含增加、删除、修改操作）请求，Master 完成操作后向 Slave 复制数据，Slave 接收到数据后向 Master 返回成功信息，Master 接到 Slave 的反馈后再响应应用。Master 向 Slave 复制数据是同步进行的，因此 Slave 不可用会影响 Master 上的操作，而 Master 不可用不会引起数据不一致。 半同步复制（Semi-Sync）：正常情况下数据复制方式采用强同步复制方式，当 Master 向 Slave 复制数据出现异常的时候（Slave 不可用或者双节点间的网络异常），Master 会暂停对应用的响应，直到复制方式超时退化成异步复制。如果允许应用在此时更新数据，则 Master 不可用会引起数据不一致。当双节点间的数据复制恢复正常（Slave 恢复或者网络恢复），异步复制会恢复成强同步复制。恢复成强同步复制的时间取决于半同步复制的实现方式，阿里云数据库 MySQL 5.5 版和 MySQL 5.6 版有所不同。 实际操作MySQL数据库版本阿里云上的MySQL提供基础版、高可用版和金融版三种版本 基础版一般就是用于个人学习、或开发测试时使用。目前基础版只提供MySQL 5.7版本，并且只提供单节点部署，性价比非常高。基础版采用计算节点与存储分离的实现方式，也就是说假如计算节点宕机，MySQL就不可用啦，但数据都存在云盘里面不会丢，数据一致性还是可以得到保证，不用担心数据丢失。可用性不高这是基础版的最大问题，反正只是用于不重要的场景，生产环境大家是不会选用基础版的。 高可用版顾名思义，为应用提供了数据库的高可用保障，也就是说至少要用双节点。RDS MySQL高可用版采用一主一备的经典高可用架构，采用基于binlog的数据复制技术维护数据库的可用性和数据一致性。同时，高可用版从性能上也可以保障业务生产环境的需求，配置上采用物理服务器部署，本地SSD硬盘，提供最佳性能，各方面表现均衡。 最高级的是金融版，针对像金融、证券、保险等行业的核心数据库，他们对数据安全性、可用性要求非常高。金融版采用三节点，实现一主两备的部署架构，通过binlog日志多副本多级别复制，确保数据的强一致性，可提供金融级的数据可靠性和跨机房容灾能力。 规格阿里云上MySQL有三种规格类型：通用型、独享型和独占型。 其中通用型和独享型都是在一台物理服务器上划分多个资源隔离的区域，为不同用户提供MySQL数据库实例。他们的不同点在于，通用型对于CPU和存储空间采用了复用的技术。当部署在同一台服务器上的所有MySQL 实例都很繁忙的情况下，有可能会出现实例间的CPU争抢，或存储的争抢；而独享型虽然也是多个数据库实例共享一台物理服务器，但资源隔离策略上确保每个用户都可以独享所分配到的CPU、内存、I/O、存储，不会出现多个实例发生资源争抢的情况。 最高级别的一种是独占型，是指一个MySQL实例独占一台服务器，会获得最好的性能，当然价格也最贵。最求极致性能但对价格不敏感的客户一般会在重要业务系统采用独占型实例。 使用流程通常，从新购实例到可以开始使用实例，需要完成如下操作： 使用限制高权限账号数据库连接注意：目前只支持同一个可用区的连接，不同可用区无法连接，如果需要跨越可用区，需要进行设置 目前RDS连接可以使用DMS连接或者第三方工具连接 跨可用区访问管理工具-DMSDMS 是一款访问管理云端数据库的Web服务，支持Redis、 MySQL、SQL Server、PostgreSQL和MongoDB等数据源。DMS提供了数据管理、对象管理、数据流转和实例管理四部分功能。DMS使用也非常简单： 数据迁移-DTS相关资料： 文档中心 帮助中心 ECS自建数据库迁移到RDS DTS概述数据传输(Data Transmission)服务DTS是阿里云提供的一种支持RDBMS(关系型数据库)、NoSQL、OLAP等多种数据源之间数据交互的数据服务。它提供了数据迁移、实时数据订阅及数据实时同步等多种数据传输能力。通过数据传输可实现不停服数据迁移、数据异地灾备、跨境数据同步、缓存更新策略等多种业务应用场景，助您构建安全、可扩展、高可用的数据架构。 数据传输服务DTS的目标是帮用户将复杂的数据交互工作承担下来，让用户可以专注于上层的业务开发，数据传输服务承诺99.95%的链路稳定性。 数据传输服务DTS支持多种数据源类型，例如： 关系型数据库：Oracle、MySQL、SQLServer、PostgreSQL NoSQL: Redis OLAP: 分析型数据库AnalyticDB 迁移服务主要帮助用户把数据从本地数据库迁移到阿里云数据库，或者把阿里云数据库的一个实例迁移到另一实例中。阿里云数据库提供了数据传输服务DTS（Data Transfer Service）工具，方便用户快速的迁移数据库。 DTS是一个云上的数据传输服务，能快速的将本地数据库或者RDS中的实例迁移到另一个RDS实例中。关于DTS简介，请参见DTS产品概述。 DTS提供了三种迁移模式，分别为结构迁移、全量迁移和增量迁移： 结构迁移：DTS会将迁移对象的结构定义迁移到目标实例，目前支持结构迁移的对象有表、视图、触发器、存储过程和存储函数。 全量迁移：DTS会将源数据库迁移对象已有数据全部迁移到目标实例中。 注意：在全量迁移过程中，为了保证数据一致性，无主键的非事务表会被锁定。锁定期间这些表无法写入，锁定时长依赖于这些表的数据量大小。在这些无主键非事务表迁移完成后，锁才会释放。 增量迁移：DTS会将迁移过程中数据变更同步到目标实例。 , 注意：如果迁移期间进行了DDL操作，这些结构变更不会同步到目标实例。 源及目标数据迁移支持的源实例类型包括: (1) RDS实例 (2) 本地自建数据库 (3) ECS自建数据库 数据迁移支持的目标实例包括： (1) RDS实例 (2) ECS自建数据库 (3) Redis实例 Mysql迁移限制对于本地 MySQL-&gt;RDS for MySQL 的数据迁移，DTS 支持结构迁移、全量数据迁移及增量数据迁移，各迁移类型的功能及限制如下： 迁移过程中，不支持 DDL 操作。 结构迁移不支持 event 的迁移。 如果使用了对象名映射功能后，依赖这个对象的其他对象可能迁移失败。 当选择增量迁移时，源端的本地 MySQL 实例需要按照要求开启 binlog。 当选择增量迁移时，源库的 binlog_format 需要设置为 row。 当选择增量迁移且源 MySQL 实例如果为 5.6 或以上版本时，它的 binlog_row_image 必须为 full。 数据同步数据实时同步功能旨在帮助用户实现两个数据源之间的数据实时同步。通过数据实时同步功能可实现数据异地灾备、本地数据灾备、跨境数据同步及在线离线数据打通(OLTP-&gt;OLAP数据同步)等多种业务场景。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>公有云产品</category>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>RDS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP请求]]></title>
    <url>%2F2018%2F05%2F13%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%2FHTTP%2FHTTP%E8%AF%B7%E6%B1%82%2F</url>
    <content type="text"><![CDATA[本文转载自：HTTP深入浅出 http请求 概述HTTP(HyperText Transfer Protocol)是一套计算机通过网络进行通信的规则。 计算机专家设计出HTTP，使HTTP客户（如Web浏览器）能够从HTTP服务器(Web服务器)请求信息和服务，HTTP目前协议的版本是1.1。 HTTP是一种无状态的协议，无状态是指Web浏览器和Web服务器之间不需要建立持久的连接，这意味着当一个客户端向服务器端发出请求，然后Web服务器返回响应(response)，连接就被关闭了，在服务器端不保留连接的有关信息.HTTP遵循请求(Request)/应答(Response)模型。Web浏览器向Web服务器发送请求，Web服务器处理请求并返回适当的应答。所有HTTP连接都被构造成一套请求和应答。 HTTP使用内容类型，是指Web服务器向Web浏览器返回的文件都有与之相关的类型。所有这些类型在MIME Internet邮件协议上模型化，即Web服务器告诉Web浏览器该文件所具有的种类，是HTML文档、GIF格式图像、声音文件还是独立的应用程序。大多数Web浏览器都拥有一系列的可配置的辅助应用程序，它们告诉浏览器应该如何处理Web服务器发送过来的各种内容类型。 通信过程在一次完整的HTTP通信过程中，Web浏览器与Web服务器之间将完成下列7个步骤： 1. 建立TCP连接 在HTTP工作开始之前，Web浏览器首先要通过网络与Web服务器建立连接，该连接是通过TCP来完成的，该协议与IP协议共同构建Internet，即著名的TCP/IP协议族，因此Internet又被称作是TCP/IP网络。HTTP是比TCP更高层次的应用层协议，根据规则，只有低层协议建立之后才能，才能进行更层协议的连接，因此，首先要建立TCP连接，一般TCP连接的端口号是80 2. Web浏览器向Web服务器发送请求命令 一旦建立了TCP连接，Web浏览器就会向Web服务器发送请求命令 例如：GET/sample/hello.jsp HTTP/1.1 3. Web浏览器发送请求头信息 浏览器发送其请求命令之后，还要以头信息的形式向Web服务器发送一些别的信息，之后浏览器发送了一空白行来通知服务器，它已经结束了该头信息的发送。 4. Web服务器应答 客户机向服务器发出请求后，服务器会客户机回送应答， HTTP/1.1 200 OK 应答的第一部分是协议的版本号和应答状态码 5. Web服务器发送应答头信息 正如客户端会随同请求发送关于自身的信息一样，服务器也会随同应答向用户发送关于它自己的数据及被请求的文档。 6. Web服务器向浏览器发送数据 Web服务器向浏览器发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以Content-Type应答头信息所描述的格式发送用户所请求的实际数据 7. Web服务器关闭TCP连接 一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码Connection:keep-alive 添加之后，TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。 HTTP请求HTTP请求格式当浏览器向Web服务器发出请求时，它向服务器传递了一个数据块，也就是请求信息，HTTP请求信息由3部分组成： 请求方法URI协议/版本 请求头(Request Header) 请求正文 下面是一个HTTP请求的例子： GET/sample.jspHTTP/1.1 Accept:image/gif.image/jpeg,*/* Accept-Language:zh-cn Connection:Keep-Alive Host:localhost User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0) Accept-Encoding:gzip,deflate username=jinqiao&amp;password=1234 说明： （1）请求方法URI协议/版本 请求的第一行是“方法URL议/版本”：GET/sample.jsp HTTP/1.1 以上代码中“GET”代表请求方法，“/sample.jsp”表示URI，“HTTP/1.1代表协议和协议的版本。 根据HTTP标准，HTTP请求可以使用多种请求方法。例如：HTTP1.1支持7种请求方法：GET、POST、HEAD、OPTIONS、PUT、DELETE和TARCE。在Internet应用中，最常用的方法是GET和POST。 URL完整地指定了要访问的网络资源，通常只要给出相对于服务器的根目录的相对目录即可，因此总是以“/”开头，最后，协议版本声明了通信过程中使用HTTP的版本。 （2）请求头(Request Header) 请求头包含许多有关的客户端环境和请求正文的有用信息。例如，请求头可以声明浏览器所用的语言，请求正文的长度等。 Accept:image/gif.image/jpeg.*/* Accept-Language:zh-cn Connection:Keep-Alive Host:localhost User-Agent:Mozila/4.0(compatible:MSIE5.01:Windows NT5.0) Accept-Encoding:gzip,deflate. （3）请求正文 请求头和请求正文之间是一个空行，这个行非常重要，它表示请求头已经结束，接下来的是请求正文。 请求正文中可以包含客户提交的查询字符串信息：username=jinqiao&amp;password=1234 在以上的例子的HTTP请求中，请求的正文只有一行内容。当然，在实际应用中，HTTP请求正文可以包含更多的内容。 HTTP请求方法我这里只讨论GET方法与POST方法 GET方法 GET方法是默认的HTTP请求方法，我们日常用GET方法来提交表单数据，然而用GET方法提交的表单数据只经过了简单的编码，同时它将作为URL的一部分向Web服务器发送，因此，如果使用GET方法来提交表单数据就存在着安全隐患上。例如Http://127.0.0.1/login.jsp?Name=zhangshi&amp;Age=30&amp;Submit=%cc%E+%BD%BB从上面的URL请求中，很容易就可以辩认出表单提交的内容。（？之后的内容）另外由于GET方法提交的数据是作为URL请求的一部分所以提交的数据量不能太大 POST方法 POST方法是GET方法的一个替代方法，它主要是向Web服务器提交表单数据，尤其是大批量的数据。POST方法克服了GET方法的一些缺点。通过POST方法提交表单数据时，数据不是作为URL请求的一部分而是作为标准数据传送给Web服务器，这就克服了GET方法中的信息无法保密和数据量太小的缺点。因此，出于安全的考虑以及对用户隐私的尊重，通常表单提交时采用POST方法。 从编程的角度来讲，如果用户通过GET方法提交数据，则数据存放在QUERY＿STRING环境变量中，而POST方法提交的数据则可以从标准输入流中获取。 HTTP响应HTTP应答与HTTP请求相似，HTTP响应也由3个部分构成，分别是： 协议状态版本代码描述 响应头(Response Header) 响应正文 下面是一个HTTP响应的例子： HTTP/1.1 200 OK Server:Apache Tomcat/5.0.12 Date:Mon,6Oct2003 13:23:42 GMT Content-Length:112 &lt;html&gt; &lt;head&gt; &lt;title&gt;HTTP响应示例&lt;title&gt; &lt;/head&gt; &lt;body&gt; Hello HTTP! &lt;/body&gt; &lt;/html&gt; （1）协议状态版本代码描述 协议状态代码描述HTTP响应的第一行类似于HTTP请求的第一行，它表示通信所用的协议是HTTP1.1服务器已经成功的处理了客户端发出的请求（200表示成功）: HTTP/1.1 200 OK （2）响应头 响应头(Response Header)响应头也和请求头一样包含许多有用的信息，例如服务器类型、日期时间、内容类型和长度等： Server:Apache Tomcat/5.0.12 Date:Mon,6Oct2003 13:13:33 GMT Content-Type:text/html Last-Moified:Mon,6 Oct 2003 13:23:42 GMT Content-Length:112 （3）响应正文 响应正文响应正文就是服务器返回的HTML页面： &lt;html&gt; &lt;head&gt; &lt;title&gt;HTTP响应示例&lt;title&gt; &lt;/head&gt; &lt;body&gt; Hello HTTP! &lt;/body&gt; &lt;/html&gt; 响应头和正文之间也必须用空行分隔。 HTTP应答码 HTTP应答码也称为状态码，它反映了Web服务器处理HTTP请求状态。HTTP应答码由3位数字构成，其中首位数字定义了应答码的类型： 1XX－信息类(Information),表示收到Web浏览器请求，正在进一步的处理中 2XX－成功类（Successful）,表示用户请求被正确接收，理解和处理例如：200 OK 3XX-重定向类(Redirection),表示请求没有成功，客户必须采取进一步的动作。 4XX-客户端错误(Client Error)，表示客户端提交的请求有错误 例如：404 NOT Found，意味着请求中所引用的文档不存在。 5XX-服务器错误(Server Error)表示服务器不能完成对请求的处理：如 500 常见请求方法 GET 通过请求URI得到资源 POST用于添加新的内容 PUT用于修改某个内容 DELETE删除某个内容 CONNECT,用于代理进行传输，如使用SSL OPTIONS询问可以执行哪些方法 PATCH,部分文档更改 PROPFIND, (wedav)查看属性 PROPPATCH, (wedav)设置属性 MKCOL, (wedav)创建集合（文件夹） COPY, (wedav)拷贝 MOVE, (wedav)移动 LOCK, (wedav)加锁 UNLOCK (wedav)解锁 TRACE用于远程诊断服务器 HEAD类似于GET, 但是不返回body信息，用于检查对象是否存在，以及得到对象的元数据]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>网络知识及网络服务</category>
        <category>网络知识</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>HTTP请求</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL普通用户无法本地登录的解决方法及MySQL的用户认证算法]]></title>
    <url>%2F2018%2F05%2F02%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FMysql%2FMySQL%E9%97%AE%E9%A2%98%2FMySQL%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E6%97%A0%E6%B3%95%E6%9C%AC%E5%9C%B0%E7%99%BB%E5%BD%95%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%E5%8F%8AMySQL%E7%9A%84%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考文献： MySQL普通用户无法本地登录的解决方法及MySQL的用户认证算法 问题在启动cachecloud项目的时候，发现日志中出现大量的连接数据库报错 我的授权命令为： mysql&gt; grant all privileges on cache_cloud.* to &apos;cachecloud&apos;@&apos;%&apos; identified by &apos;Cache_cloud123&apos;; Query OK, 0 rows affected (0.00 sec) 这样的配置，按道理来说，是不应该出现连不上的（%代表任意的主机来源，并且已经排查了防火墙等因素） 在本地登录发现发现存在如下问题： 当输入之前设置的密码时，将会一直提示：“ERROR 1045 (28000): Access denied”，而当我们不输入密码，也就是说输入密码为空时则能正常进入数据库。 我们使用USER()和CURRENT_USER()两个函数查看所使用的用户。 mysql&gt; SELECT USER(), CURRENT_USER(); +----------------------+----------------+ | USER() | CURRENT_USER() | +----------------------+----------------+ | cachecloud@localhost | @localhost | +----------------------+----------------+ 1 row in set (0.00 sec) mysql&gt; USER()函数返回你在客户端登陆时指定的用户名和主机名。 CURRENT_USER()函数返回的是MySQL使用授权表中的哪个用户来认证你的登录请求。 这里发现，之前设置的授权规则并没有生效，是数据库使用的是’’@’localhost’这个来源信息来进行登录认证，而’’@’localhost’这个匿名用户是没有密码的，因此我输入空密码登录成功了。但是登录后，所对应的用户的匿名用户。 一般在MySQL在安装完毕后，我们使用mysql_install_db这个脚本生成授权表，会默认创建’’@’localhost’这个匿名用户。正是因为这个匿名用户，影响了其他用户从本地登录的认证。 原因那么MySQL是如何进行用户身份认证呢？ MySQL的简要认证算法如下： 当用户从客户端请求登陆时，MySQL将授权表中的条目与客户端所提供的条目进行比较，包括用户的用户名，密码和主机。 授权表中的Host字段是可以使用通配符作为模式进行匹配的，如test.example.com, %.example.com, %.com和%都可以匹配test.example.com这个主机。 授权表中的User字段不允许使用模式匹配，但是可以有一个空字符的用户名代表匿名用户，并且空字符串可以匹配所有的用户名，就像通配符一样。 当user表中的Host和User有多个值可以匹配客户端提供的主机和用户名时，MySQL将user表读入内存，并且按照一定规则排序，按照排序规则读取到的第一个匹配客户端用户名和主机名的条目对客户端进行身份验证。 排序规则： 对于Host字段，按照匹配的精确程度进行排序，越精确的排序越前，例如当匹配test.example.com这个主机时, %.example.com比%.com更精确，而test.example.com比%.example.com更精确。 对于User字段，非空的字符串用户名比空字符串匹配的用户名排序更靠前。 User和Host字段都有多个匹配值，MySQL使用主机名排序最前的条目，在主机名字段相同时再选取用户名排序更前的条目。 因此，如果User和Host字段都有多个匹配值，主机名最精确匹配的条目被用户对用户进行认证。 了解了这个规则之后，我们就知道为什么cachecloud登录失败了。 在使用该用户进行本机登录的时候，mysql中有2个匹配条目 ‘cachecloud’@’%’ ‘’@’localhost’ 匿名用户能够匹配的原因上面说过，空字符串可以匹配所有的用户名，就像通配符一样。 根据MySQL认证时的排序规则，第一个条目的用户名排序更前，第二个条目的主机名更精确，排序更前。 而MySQL会优先使用主机名排序第一的条目进行身份认证，因此’’@’localhost’被用户对客户端进行认证。因此，只有使用匿名用户的空密码才能登录进数据库。就会出现刚才上面的情况了。 解决删除匿名用户【仅仅是为了安全也有这个必要】 为什么root用户不会受影响，而只有普通用户不能从本地登录？ 因为mysql_install_db脚本会在授权表中生成’root’@’localhost’这个账户。同样的，使用root登录MySQL时，’root’@’localhost’和’’@’localhost’都能匹配登录的账户，但是根据排序规则，主机名相同，而用户名非空字符串优先，因此’roo’@’localhost’这个条目的排序更靠前。使用root本地登录是不会被匿名用户遮盖。 [root@qa1-common004 ~]# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 942 Server version: 5.6.40 MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. mysql&gt; mysql&gt; select user,host from mysql.user; +------------+---------------------------+ | user | host | +------------+---------------------------+ | cachecloud | % | | root | 127.0.0.1 | | root | ::1 | | | localhost | | root | localhost | | | qa1-common004.ecs.east1-b | | root | qa1-common004.ecs.east1-b | +------------+---------------------------+ 7 rows in set (0.00 sec) mysql&gt; delete from mysql.user where user=&apos;&apos;; Query OK, 2 rows affected (0.00 sec) mysql&gt; select user,host from mysql.user; +------------+---------------------------+ | user | host | +------------+---------------------------+ | cachecloud | % | | root | 127.0.0.1 | | root | ::1 | | root | localhost | | root | qa1-common004.ecs.east1-b | +------------+---------------------------+ 5 rows in set (0.00 sec) mysql&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) mysql&gt; exit 退出之后再次登录，问题得到解决。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>数据库</category>
        <category>MySQL</category>
        <category>MySQL问题</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下JDK的安装配置]]></title>
    <url>%2F2018%2F04%2F28%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2FJDK%2FLinux%E4%B8%8BJDK%E7%9A%84%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[在Linux中JDK的配置主要分为以下几个步骤： 下载 解压 软链接 配置系统/用户环境变量 下载：官方下载链接：下载 JAVA环境的配置主要分为两种，一种是由root用户操作，针对所有用户全局生效的配置，一种是由具体普通用户操作，仅针对该用户生效的配置 因此，以下的配置根据实际需求。 全局生效-管理员权限操作解压+软链接 # tar -zxvf jdk-7u75-linux-x64.tar.gz -C /usr/local/ # cd /usr/local/ # ln -s /usr/local/jdk1.7.0_75/ /usr/local/JDK 创建软链接目的：灵活的版本升级切换 配置系统环境变量： # vim /etc/profile 在文件末尾添加以下内容 export JAVA_HOME=/usr/local/JDK export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib export PATH=$JAVA_HOME/bin:$JRE_HOME/bin::$CLASSPATH:$PATH # source /etc/profile 用户局部生效-用户环境变量**注意提示符的变化，这里以appdev用户为例 解压+软链接 $ tar -zxvf jdk-7u75-linux-x64.tar.gz $ ln -s /home/appdev/jdk1.7.0_75/ /home/appdev/JDK 创建软链接目的：灵活的版本升级切换 配置系统环境变量： $ vim .bash_profile 在文件末尾添加以下内容 export JAVA_HOME=/home/appdev/JDK export JRE_HOME=$JAVA_HOME/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib export PATH=$JAVA_HOME/bin:$JRE_HOME/bin::$CLASSPATH:$PATH $ source .bash_profile]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>基础环境配置</category>
        <category>JDK</category>
      </categories>
      <tags>
        <tag>JDK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cachecloud-Redis云平台]]></title>
    <url>%2F2018%2F04%2F28%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2FRedis%2FCacheCloud-Redis%E4%BA%91%E5%B9%B3%E5%8F%B0%2FCachecloud%2F</url>
    <content type="text"><![CDATA[Cachecloud介绍有关cachecloud的一些基础知识，官方都有非常详细的文档，这里不再花费篇幅进行复述，下面是相关的资料链接，请自行查看。 github官网： https://github.com/sohutv/cachecloud Wiki: https://github.com/sohutv/cachecloud/wiki 博客： https://cachecloud.github.io/ 官方视频： http://my.tv.sohu.com/pl/9100280/index.shtml 简介： CacheCloud提供一个Redis云管理平台：实现多种类型(Redis Standalone、Redis Sentinel、Redis Cluster)自动部署、解决Redis实例碎片化现象、提供完善统计、监控、运维功能、减少开发人员的运维成本和误操作，提高机器的利用率，提供灵活的伸缩性，提供方便的接入客户端。 提供的功能： 监控统计： 提供了机器、应用、实例下各个维度数据的监控和统计界面。 一键开启： Redis Standalone、Redis Sentinel、Redis Cluster三种类型的应用，无需手动配置初始化。 Failover： 支持哨兵,集群的高可用模式。 伸缩： 提供完善的垂直和水平在线伸缩功能。 完善运维： 提供自动运维和简化运维操作功能，避免纯手工运维出错。 方便的客户端 方便快捷的客户端接入。 元数据管理： 提供机器、应用、实例、用户信息管理。 流程化： 提供申请，运维，伸缩，修改等完善的处理流程 一键导入： 一键导入已经存在Redis 须知： Redis集群、redis哨兵集群、Redis单实例等在CacheCloud中都是以应用的形式存在，一个应用对应一个appid 一个redis集群是一个应用，分配一个appid（不管其中有几个节点） 一个哨兵集群是一个应用，分配一个appid（不管其中有几个主从节点和哨兵节点） 一个单实例是一个应用，分配一个appid 如何使用： 我们在平台上的执行任何操作都需要**账号**，创建的单节点、哨兵、集群等都是以用户申请的应用形式存在的。普通用户的主要工单有 注册用户申请 应用申请 应用扩容 应用配置修改 管理员的界面可操作的选项较多，此处不做详细说明。 客户端如何连接： 客户端在第一次启动的时候去CacheCloud通过appId拿到Redis的节点信息，之后不会与CacheCloud打交道了。 流程图如下所示： 安装部署这里只说单机环境，高可用环境将在下面章节说明：CacheCloud高可用架构 环境要求： JDK 7+ Maven 3+ MySQL 5.5+ Redis 3+ 基础环境JDK+MavenJDK： 步骤： 下载 解压 软链接 配置系统环境变量 操作如下： [root@qa1-common004 local]# java -version java version &quot;1.8.0_77&quot; Java(TM) SE Runtime Environment (build 1.8.0_77-b03) Java HotSpot(TM) 64-Bit Server VM (build 25.77-b03, mixed mode) [root@qa1-common004 local]# which java /usr/local/jdk/bin/java [root@qa1-common004 local]# ll /usr/local/jdk lrwxrwxrwx 1 root root 11 Apr 17 17:01 /usr/local/jdk -&gt; jdk1.8.0_77 这里我使用的是1.8版本。 详细操作请看文章：Linux下JDK的安装配置 Maven 步骤： 下载 下载链接 解压 软链接 配置系统环境变量 操作如下： # wget http://www-eu.apache.org/dist/maven/maven-3/3.5.3/binaries/apache-maven-3.5.3-bin.tar.gz # tar -zxvf apache-maven-3.5.3-bin.tar.gz -C /usr/local/ # cd /usr/local/ # ln -s /usr/local/apache-maven-3.5.3/ /usr/local/maven # vim /etc/profile 在文件末尾添加以下内容，保存退出 M3_HOME=/usr/local/maven export PATH=$M3_HOME/bin:$PATH [root@host-192-168-8-37 ~]# source /etc/profile 下载CacheCloud项目# yum -y install git # git clone https://github.com/sohutv/cachecloud.git # ls cachecloud/ cachecloud-open-client cachecloud-open-common cachecloud-open-web LICENSE pom.xml README.md script MySQL这里安装mysql5.7版本 配置yum源并安装 centos6.8 【6.8安装5.6版本，安装5.7时涉及依赖关系过多】 # wget http://repo.mysql.com/mysql-community-release-el6-5.noarch.rpm # rpm -ivh mysql-community-release-el6-5.noarch.rpm # yum -y install mysql-community-server centos 7.x 【5.7版本】 # wget https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm # rpm -ivh mysql57-community-release-el7-11.noarch.rpm # yum -y install mysql-server 修改mysql配置文件 # vim /etc/my.cnf [mysqld] character-set-server=utf8 启动 # /etc/init.d/mysqld start 数据库配置创建数据库 mysql&gt; create database cache_cloud default charset utf8; Query OK, 1 row affected (0.00 sec) 创建cachecloud用户 mysql&gt; grant all privileges on cache_cloud.* to &apos;cachecloud&apos;@&apos;%&apos; identified by &apos;Cache_cloud123&apos;; Query OK, 0 rows affected (0.00 sec) 导入初始化数据注意，这里已经不是在数据库中了 [root@qa1-common004 script]# pwd /root/software/cachecloud/script [root@qa1-common004 script]# mysql -u root -p cache_cloud &lt; cachecloud.sql Enter password: 修改cachecloud配置数据库设置 [root@qa1-common004 swap]# pwd /root/software/cachecloud/cachecloud-open-web/src/main/swap [root@qa1-common004 swap]# cat online.properties cachecloud.db.url = jdbc:mysql://172.24.64.132:3306/cache_cloud?useUnicode=true&amp;amp;characterEncoding=UTF-8 cachecloud.db.user = cachecloud cachecloud.db.password = Cache_cloud123 cachecloud.maxPoolSize = 20 isClustered = true isDebug = false spring-file=classpath:spring/spring-online.xml log_base=/opt/cachecloud-web/logs web.port=8585 log.level=WARN 注意这里需要提前在数据库中删除匿名用户 开启机器监控功能 # pwd /root/software/cachecloud/cachecloud-open-web/src/main/java/com/sohu/cache/schedule/jobs # vim ServerJob.java 将稳中的注释去掉，修改之后的文件如下所示： 如果公司已经有完善的监控，那么不建议开启机器监控，能够一定程度上减小数据库的压力。 cachecloud构建及启动项目构建 在cachecloud的根目录下执行以下maven命令，该命令会进行项目的构建 [root@qa1-common004 cachecloud]# pwd /root/software/cachecloud [root@qa1-common004 cachecloud]# [root@host-192-168-8-37 cachecloud]# mvn clean compile install -Ponline [root@host-192-168-8-37 cachecloud]# cd script/ [root@host-192-168-8-37 script]# sh deploy.sh /root/software/ 启动 # sh /opt/cachecloud-web/start.sh 启动成功之后的web页面如下图所示： 实际使用redis数据节点初始化执行初始化脚本 sh cachecloud-init.sh cachecloud 添加主机redis应用模板配置注意：在部署redis相关应用之前，一定要先进行模板的配置，因为默认配置下，redis的守护进程模式为关系，保护模式也是开启的 修改配置： 配置名称：daemonize；配置值：yes;配置说明：是否守护进程 新增配置： 配置名称：protected-mode；配置值：no;配置说明：保护模式 配置名称：bind；配置值：0.0.0.0;配置说明：绑定ip 注意：哨兵的配置模板中只需要新增protected-mode参数即可。 部署哨兵应用导入已经存在的redis实例redis哨兵cachecloud使用优化哨兵复用问题： 使用cachecloud部署哨兵集群时，每次生成的哨兵节点都是不一样的，这种情况，会造成一定的资源浪费（每一对主从都需要至少3个哨兵节点，对服务器的端口资源、内存资源等都会造成一定的浪费） 因此，我们采取复用哨兵节点的方式来实现redis的主从高可用 实现步骤： 哨兵模板中设置端口，将端口固定，为了后续的配置方便 手动创建主从节点 哨兵中添加新建的主从节点 在cachecloud平台上导入这个应用 相当于其实是导入redis哨兵的方式 哨兵配置： redis-cli -p 6388 sentinel monitor master-test-qa1 172.24.64.134 6385 2&amp;&amp;redis-cli -p 6388 SENTINEL set master-test-qa1 auth-pass redis123&amp;&amp;redis-cli -p 6388 sentinel set master-test-qa1 down-after-milliseconds 20000&amp;&amp;redis-cli -p 6388 sentinel set master-test-qa1 failover-timeout 60000 关闭master节点的持久化 AOF持久化：appendonly 配置为no cachecloud坑- CacheCloud安装部署及使用常见问题及注意事项 数据库版本问题： 如果使用mysql5.7，则需要进行针对sql文件做一些设置（only_full_group_by模式设置等） cachecloud平台乱码问题： 需要修改online.properties配置文件中的连接串（使用这种方式：jdbc:mysql://127.0.0.1:3306/cache_cloud?useUnicode=true&amp;characterEncoding=UTF-8） cachecloud后台配置模板：默认配置下，redis没有开启守护进程运行方式、开启了保护模式等，需要做一些配置修改之后才可以正常启动 机器监控数据无法展示问题：除了在程序文件中去掉相应的代码注释，还需要将cachecloud-open-web/nmon下指定系统版本的nmon文件放到/opt/cachecloud/soft/目录下 密码配置问题：密码配置栏中，输入密码之后，还需要点击更新才可以生效 Jedis支持redis版本问题：Jedis暂时无法稳定支持redis4.x版本，因此涉及到的集群水平扩容等功能是无法实现的（集群创建等还是可以支持的），因此我们建议使用3版本，后续关注Jedis的版本发布情况。 应用导入时提示：节点不是存活的 cachecloud节点上需要安装redis，因为他会使用redis-cli 去ping指定的节点，没有返回pong时，则会报错 哨兵导入问题： 如果哨兵是复用的，也就是说一组哨兵节点监听了多对主从节点，那么在导入的时候回出现问题，目前导入功能只支持一个mastername 主机名设置问题： 注意hosts文件需要进行配置]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>数据库</category>
        <category>Redis</category>
        <category>CacheCloud-Redis云平台</category>
      </categories>
      <tags>
        <tag>cachecloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python零碎知识记录]]></title>
    <url>%2F2018%2F04%2F23%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fpython%E9%9B%B6%E7%A2%8E%E7%9F%A5%E8%AF%86%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[零碎知识 CharField类型必须添加max_length来指定长度上限，如果要想没有限制，则考虑使用TextField类型 删除字符串中指定符号源文件 1234567wxh:wxh123wsy:wsy123badou:badou123dabadou:dabadou123 此时我要根据冒号（:）将两边的内容都截取出来 传统的字符串截取方式是根据索引进行区分的，这种事不能实现这种需求，这个时候需要使用函数split() Python中有split()和os.path.split()两个函数，具体作用如下： split()：拆分字符串。通过指定分隔符对字符串进行切片，并返回分割后的字符串列表（list） os.path.split()：按照路径将文件名和路径分割开 如下方代码所示： 12345with open (r&apos;C:\Users\Administrator\PycharmProjects\files\login.txt&apos;,&apos;r&apos;) as file_object: for lines in file_object: lines = lines.strip(&apos;\n&apos;) file_username = lines.split(&apos;:&apos;, 1)[0] file_password = lines.split(&apos;:&apos;, 1)[1] Python 按行读取文件并去掉换行12345with open(&apos;./activity.sql&apos;, &apos;r&apos;) as fp: for line in fp: line = line.strip(&apos;\n&apos;) print line # do something python字典追加python调用shell命令并获取输出123code = os.popen(cmd)check_code = code.read()code.close() 查看python执行过程-类似sh -x123#详细追踪 python -m trace --trace script.py #显示调用了哪些函数 python -m trace --trackcalls script.py 版本变化##django## 外键： Django2.0版本之后，创建外键时需要在后面加上on_delete topic = models.ForeignKey(Topic) 应该修改为：topic = models.ForeignKey(Topic,on_delete=models.CASCADE) django.core.urlresolvers变化 Django 2.0 removes the django.core.urlresolvers module, which was moved to django.urls in version 1.10. You should change any import to use django.urls instead. pycharm使用解决pycharm问题：module ‘pip’ has no attribute ‘main’1更新pip之后，Pycharm安装package出现报错：module &apos;pip&apos; has no attribute &apos;main&apos; 1找到安装目录下 helpers/packaging_tool.py文件，找到如下代码： 1234567891011121314def do_install(pkgs): try: import pip except ImportError: error_no_pip() return pip.main([&apos;install&apos;] + pkgs)def do_uninstall(pkgs): try: import pip except ImportError: error_no_pip() return pip.main([&apos;uninstall&apos;, &apos;-y&apos;] + pkgs) 修改为如下，保存即可。 12345678910111213141516171819202122def do_install(pkgs): try: # import pip try: from pip._internal import main except Exception: from pip import main except ImportError: error_no_pip() return main([&apos;install&apos;] + pkgs)def do_uninstall(pkgs): try: # import pip try: from pip._internal import main except Exception: from pip import main except ImportError: error_no_pip() return main([&apos;uninstall&apos;, &apos;-y&apos;] + pkgs) 创建directory和python package的区别对于python而言，有一点是要认识明确的，python作为一个相对而言轻量级的，易用的脚本语言（当然其功能并不仅限于此，在此只是讨论该特点），随着程序的增长，可能想要把它分成几个文件，以便逻辑更加清晰，更好维护，亦或想要在几个程序中均使用某个函数，而不必将其复制粘贴到所有程序中。 为了支持这一点，Python有一种方法将定义函数放在一个文件中，并在脚本中使用它们，这样的文件叫做模块，一个模块中的定义可以被导入到其他模块，或者主模块中。 简单来说在python中模块就是指一个py文件，如果我们将所有相关的代码都放在一个py文件中，则该py文件既是程序由是模块，但是程序和模块的设计目的是不同的，程序的目的是为了运行，而模块的目的是为了其他程序进行引 Dictionary Dictionary在pycharm中就是一个文件夹，放置资源文件，对应于在进行JavaWeb开发时用于放置css/js文件的目录，或者说在进行物体识别时，用来存储背景图像的文件夹。该文件夹其中并不包含 init.py 文件 Python package 对于Python package 文件夹而言，与Dictionary不同之处在于其会自动创建 init.py 文件。 简单的说，python package就是一个目录，其中包括一组模块和一个 init.py 文件。 Image/ _init _.py jpg.py tiff.py bmp.py 只要image目录是我们程序目录的子目录，我们就可以导入image目录下的任意模块来为我们所用，使用时可如下： init .py 该文件与Python的import机制有关，这关乎到你的哪些.py文件是对外可访问的。有些时候，如果一个包下有很多模块，在调用方import如此多模块是很费事，且不优雅的，此时可以通过修改 init .py来完成该任务。在 init_ .py中定义特殊变量_all_,将要包含的模块复制给该变量。 例如在Image/ init .py中定义 _all_=[‘tiff’,’bmp’,’jpg’],这里的all 对应的就是 from …import 中代指的模块，此时在引用方使用如下语句： 12from image import *tool = tiff.read(&apos;a.tiff&apos;) 其实 init_ .py可以为空，当其为空时，from Image import *将Image包下所有的模块都进行引用，如果想要控制引用的模块，则可以自行定义 all python 异常处理在出现异常的时候，出现一堆error，该选取哪一个error进行try python的dict和json的区别工作中和其他语言的工程师交流，合作与联调中经常会涉及到数据的传输，这个数据的传输通常为json字符串，这个json格式数据和python自身的dict数据对象非常像，所以很自然的会思考这两者究竟区别在哪里？ 首先，两者不一样 区别 Python 的字典是一种数据结构，JSON 是一种数据格式。 json 就是一个根据某种约定格式编写的纯字符串，不具备任何数据结构的特征。而 python 的字典的字符串表现形式的规则看上去和 json 类似，但是字典本身是一个完整的数据结构，实现了一切自身该有的算法。 Python的字典key可以是任意可hash对象，json只能是字符串。 形式上有些相像，但JSON是纯文本的，无法直接操作。 1.python dict 字符串用单引号，json强制规定双引号。 2.python dict 里可以嵌套tuple,json里只有array。 json.dumps({1:2}) 的结果是 ｛”1”:2}； json.dumps((1,2)) 的结果是[1,2] 3.json key name 必须是字符串, python 是hashable, {(1,2):1} 在python里是合法的,因为tuple是hashable type；{[1,2]:1} 在python里TypeError: unhashable “list” 4.json: true false null ； python:True False None python {“me”: “我”} 是合法的； json 必须是 {“me”: “\u6211”} 联系dict 存在于内存中，可以被序列化成 json 格式的数据（string），之后这些数据就可以传输或者存储了。 JSON 是一种数据传输格式。 也就是说，这些字符串以 JSON 这样的格式来传输，至于你怎么 parse 这些信息，甚至是是否 parse，是否储存，都不是 JSON 的事情。 用 Python 举个例子: 某段程序可以把字符串 &quot;{A:1, B:2}&quot; parse 成 一对 tuple( (&quot;A&quot;, 1), (&quot;B&quot;, 2) )而不是 dictionary {&quot;A&quot;: 1, &quot;B&quot;: 2}。Python 的 dictionary 是对 Hash Table 这一数据结构的一种实现。它使用其内置的哈希函数来规划键对应的内容的储存位置，从而获得 O(1) 的数据读取速度。所以 JSON 是一种数据传输格式，它能被解析成 Python 的 Dictionary 或者其他形式，但解析成什么内容是和 JSON 这种格式无关的。Python 的 Dictionary 则是 Python 对 Hash Table 的实现，一套从存储到提取都封装好了的方案。 Python 2.7.12 源码安装pipwget https://bootstrap.pypa.io/get-pip.py ./python get-pip.py if name == ‘main‘ 如何正确理解?这里的作用主要是作为整个程序的一个入口 对于很多编程语言来说，程序都必须要有一个入口，比如 C，C++，以及完全面向对象的编程语言 Java，C# 等。如果你接触过这些语言，对于程序入口这个概念应该很好理解，C 和 C++ 都需要有一个 main 函数来作为程序的入口，也就是程序的运行会从 main 函数开始。同样，Java 和 C# 必须要有一个包含 Main 方法的主类来作为程序入口。 而 Python 则有不同，它属于脚本语言，不像编译型语言那样先将程序编译成二进制再运行，而是动态的逐行解释运行。也就是从脚本第一行开始运行，没有统一的入口。 一个 Python 源码文件除了可以被直接运行外，还可以作为模块（也就是库）被导入。不管是导入还是直接运行，最顶层的代码都会被运行（Python 用缩进来区分代码层次）。而实际上在导入的时候，有一部分代码我们是不希望被运行的。 详细内容可以看这篇文章：http://blog.konghy.cn/2017/04/24/python-entry-program/ 获取当前py文件目录 当前目录 1path.dirname(__file__) 上级目录 1path.abspath(path.dirname(path.dirname(__file__)))]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python版本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python中方法与函数的区别]]></title>
    <url>%2F2018%2F04%2F22%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2F%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2Fpython%E4%B8%AD%E6%96%B9%E6%B3%95%E4%B8%8E%E5%87%BD%E6%95%B0%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[定义: function(函数) —— A series of statements which returns some value toa caller. It can also be passed zero or more arguments which may beused in the execution of the body. method(方法) —— A function which is defined inside a class body. Ifcalled as an attribute of an instance of that class, the methodwill get the instance object as its first argument (which isusually called self). Function包含一个函数头和一个函数体, 支持0到n个形参 而Method则是在function的基础上, 多了一层类的关系, 正因为这一层类, 所以区分了 function 和 method.而这个过程是通过 PyMethod_New实现的 也就是说，函数可以脱离于类单独存在，在使用的时候，需要往函数中传入参数（实参） 而方法是与某个对象紧密联系的，不能脱离于类而存在方法的作用域只是在一个类中，只能在该类实例化后被该类使用 方法的绑定, 肯定是伴随着class的实例化而发生,我们都知道, 在class里定义方法, 需要显示传入self参数, 因为这个self是代表即将被实例化的对象。 定义角度： 从定义的角度上看，我们知道函数(function)就相当于一个数学公式，它理论上不与其它东西关系，它只需要相关的参数就可以。所以普通的在module中定义的称谓函数是很有道理的。 那么方法的意思就很明确了，它是与某个对象相互关联的，也就是说它的实现与某个对象有关联关系。这就是方法。虽然它的定义方式和函数是一样的。也就是说，在Class定义的函数就是方法。 总结： 函数是一段代码，通过名字来进行调用。它能将一些数据（参数）传递进去进行处理，然后返回一些数据（返回值），也可以没有返回值。所有传递给函数的数据都是显式传递的。 方法也是一段代码，也通过名字来进行调用，但它跟一个对象相关联。方法和函数大致上是相同的，但有两个主要的不同之处： 方法中的数据是隐式传递的； 方法可以操作类内部的数据（请记住，对象是类的实例化–类定义了一个数据类型，而对象是该数据类型的一个实例化）]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>python方法与函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[湿气的产生及预防治疗]]></title>
    <url>%2F2018%2F04%2F22%2F%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F%E8%BF%90%E5%8A%A8%E8%90%A5%E5%85%BB%E4%B8%8E%E5%81%A5%E5%BA%B7%2F%E8%BA%AB%E4%BD%93%E4%B9%8B%E9%81%93%2F%E6%B9%BF%E6%B0%94%E7%9A%84%E4%BA%A7%E7%94%9F%E5%8F%8A%E9%A2%84%E9%98%B2%E6%B2%BB%E7%96%97%2F</url>
    <content type="text"><![CDATA[文章结构： 第一部分：是什么-湿气的概念 &amp;&amp; 为什么-湿气的产生原因 第二部分：怎么做-如何预防及治疗 参考文献： 知乎-湿气是怎么回事，人为什么会有湿气？ 湿气（中医理论概念） 1. 湿气概念及产生原因 1.1 概念1.1.1 湿 我们在日常生活中，感受到湿的时候一般是物体含水量超出一定范围，这个水分可以依附到很多物体上，比如湿巾、湿木头、湿衣服等等（无法正常排出的水）。 但含水量也不能超过一定限度，依附不住的水就不叫做湿，而是自由的水，比如湿衣服滴下来的水，这就不称为湿。 1.1.2 湿气 湿气是一种中医理论中的概念。通俗的来说，就是人体内有多余的水份无法正常代谢排出，堆积在身体之内，从而影响身体健康。（具体原因可能是个人体质、疾病或生活习惯不良，造成体内水分调控系统失衡） 就像我们日常生活中所看见的：食物放在潮湿的地方相比干燥的地方，很快就会发霉，类比到人上，当人的湿气较重之后，会产生一系列疾病。 一般也把湿气称之为：湿邪 在致病的风、寒、暑、湿、燥、火这“六淫邪气” 中，中医最怕湿邪。 湿是最容易渗透的。湿邪从来不孤军奋战，总是要与别的邪气狼狈为奸。 湿气遇寒则成为寒湿，这就好比冬天的时候，如果气候干燥，不管怎么冷，人都还是能接受的，但如果湿气重，人就很难受了。南方的冬天比北方的冬天更令人难受，就是因为南方湿气比较重，寒湿袭人。 湿气遇热则成为湿热，这就好比夏天的桑拿天，又热又湿，让人喘不过气来，明显不如烈日当空、气候干燥的时候来得痛快。 湿气遇风则成为风湿，驱风很容易，但一旦成了风湿，就往往是慢性疾病，一时半会儿治不好了。 湿气在皮下，就形成肥胖，也是不好处理的健康问题…… 为什么现代人的病那么复杂，那么难治？因为他们体内有湿，体外的邪气总是和体内的湿气里应外合，纠缠不清！以前仅仅盛行于我国西南的川菜，风行全国，就是因为川味是辛辣的，以前只有生活在湿邪比较重的西南一带人需要用它来化解体内的湿气；全国人体内都有湿气了，这就需要辛辣来化解。 主导湿气的人体器官是：脾 因此，湿气问题的根本原因是各种原因导致的脾功能下降（也有可能是其他器官导致，因为脾在工作时要需要借助胃肝肾等器官），具体见下文。 1.2 产生原因-湿气是怎么来的？1.2.1 外在原因 一个是因为外在的环境，也就是湿邪进入到了身体。 比如长期居住在湿气重的地方，比如淋了雨还不及时擦干，比如晚上洗头没吹干就睡觉，让外界的湿气进入到体内。 湿气进入身体后常常奔着脾胃去，导致脾的运化能力下降，而这又会容易导致体内生湿。 1.2.2 内因 另外一个就是饮食习惯差，导致脾运化能力下降而生湿。【饮食不当，伤害脾胃，这是产生湿气的罪归祸首】 此外夏天的时候狂开空调，狂吃冷饮，硬生生的把要出来的水份给逼回去了。还有缺乏运动，没有及时的增强脾的工作能力。 脾主运化，吃进来的食物通过它来运化出精微物质，剩下的糟粕排出体外。当因为各种原因导致脾虚、运化能力下降的时候，精微物质就没法完全提炼出来。 1.2.3 原因解析 从微观的角度讲，物质没有完全被消化时，就成了携带营养物质的“垃圾”，成分复杂且分子比较大，没法被人体吸收，但又不像糟粕那么大块头好分辨，那么容易把它们驱逐。 它们的分子量和体积远大于水分子，潜伏着，聚集起来，极其容易把周围的水分子吸附住、束缚住，使含水量超出正常的生理水平，于是形成了湿。 脾被湿气困住，更加影响它的运化工作，导致湿气加重。湿一直凝聚不化，时间长了就成为痰，身体出于自保自救，把其中一部分水、二氧化碳和营养垃圾打包成了脂肪。所以中医常说胖人多痰湿，就是这个道理。【So，减肥先去湿气】 1.3 湿气的特点1.3.1 笨重并且混浊 湿气依附在身体某些地方，和身边的物体紧紧结合，难舍难离。物体湿的状态时会比干燥的时候重很多,所以体内有湿气的时候，我们往往觉得身体或头部沉重；湿气浊会导致身体气血流通不畅，长期聚集身体又没法整治它,导致有湿气的地方脏乱差，滋生各种毒害。 1.3.2 难缠粘人 什么东西被湿邪盯上，就好像被缠上了粘液，各种不爽，比如小便不畅，大便黏腻不爽等。此外它还很难去除，经常和你缠缠绵绵，病程较长，比如风湿病、温湿病。 1.3.3 阻遏气机、损伤阳气 湿气本质上属于阴邪，靠着它黏腻难缠的劲头，赖在脏腑经络上不走，导致气机升降无能，于是阳气就没法正常生发了。所以一般被湿邪困住的人，阳气都不太旺，会有脸色淡白，精力不济的现象。 1.4 湿气重的表现 头发爱出油、面部油亮, 小肚子大(常有胀气)，身体浮肿。 身体发沉、发重，浑身无力。 皮肤上会有湿疹，胃口不好，嘴里发黏。 常感到疲倦，精力不集中睡觉打呼噜，痰多，咳嗽,睡觉留口水、口臭、身体有异味，耳内湿（耳禅湿）毛发粗糙，易脱落。 舌质很胖，颜色偏淡。症状严重的，舌头边上会有齿痕，这叫“裙边舌”。 眼袋下垂，黑圆圈严重，肥胖，减肥后反弹，机能衰退，对房事不感兴趣质量不高等。 大便溏稀不成型，正常的大便是光滑的呈圆柱体，每次大便之后，不会粘在光滑的马桶壁上，如果你每次上完厕所，大便冲不干净，那么一定是体内湿气在作怪。而且，湿气会让便秘如影随形。下一次，当你大便的时候，很可能就会出现便秘。 等等等等 当湿气演变成为顽固性湿气的时候，身体会出现数十种不适： 以上症状，如果你占了2种以上，要引起注意了，这说明体内有湿气。湿气不除，是引发及恶化疾病的关键。 并且现代人由于工作强度、压力等都更大，因此运动量也原来越小，体内阴盛阳虚从而湿邪内郁。这也是当前越来越多的年轻人有湿气相关疾病的原因。 2. 如何预防及治疗 在这里，我们将预防和治疗两者结合在一起说明，因为光靠预防不能完全杜绝，或多或少肯定都还是会产生湿气。 湿气很重，不要只会傻傻拔罐。 2.1 药物目前没有什么比较好的药物，一般采用饮食结合运动的方式来预防和治疗湿气。 2.2 饮食这里只说该吃什么，至于不该吃什么，请看日常生活章节 薏米赤小豆桂圆粥 薏米：性寒。因此要用赤小豆来中和，并且每次的量不宜太多 赤小豆：性，。注意赤小豆是扁的，红豆是圆的 桂圆/枣：桂圆甘温。有的人体质偏寒，里面可以加一点温补的食物，像桂圆、大枣都可以 如果着凉感冒了，或是体内有寒，胃中寒痛，食欲不佳，可在薏米赤小豆汤中加几片生姜。生姜性温，能温中祛寒，健脾和胃。 肾虚的人，可在薏米赤小豆汤中加一些黑豆。因为黑色入肾，豆的形状也跟肾十分相似，以形补形，是补肾的佳品。 人们常说的脚气病，是典型的湿热下注。可在薏米赤小豆汤中加点碎黄豆，用熬出来的汤泡脚，这是治脚气的一个小秘方。 学会薏米赤小豆汤的加减变化，使用得当可以对生活中大部分常见病起到很好的治疗效果。 如下图所示： 2.3 运动现代人动脑多、体力消耗少，加上长期待在密闭空调内，很少流汗，身体调控湿度的能力变差。因此这也为产生湿气创造了条件。 运动出汗是很好的去湿气方式 2.4 日常生活2.4.1 不宜 不过食生冷肥甘厚腻甜辛辣， 避开生冷食物。这里说的生冷食物指的是冷饮、凉拌菜等，而不是水果。【这一点在夏天的时候最为明显，一些人在夏天时喝冷饮、和冰镇啤酒、吃冰镇西瓜、吃凉菜等毫无节制】 夏天尽量不吹空调 睡前务必吹干头发 饮食口味重，日常饮食口味经常过重的话，由于细胞渗透压的作用，浓度低的会向浓度高的一方渗透，力求平衡，从而会使身体处于不正常状态 不宜久坐，一小时不动两小时不动三小时不动，身体以为你不会动了，它的运行也会慢下来慢下来 不宜大量吃水果。 2.4.2 宜 晚上用热水泡脚。 每天晚上坚持用热水泡脚半小时（注意：时间是半小时），泡到微微出汗。 泡脚的同时敲打肘窝、腘和腋窝各5分钟。这三个地方是排湿气的重要部位。腋窝都知道，肘窝就是手肘后面弯曲部位，腘就是膝盖后面弯曲部位。 天气好的日子，勤晒衣物和被子，减少病菌，降低生病的可能。 夏天时家中易闷热潮湿，每天要适度开窗换气，新鲜的空气可以减少细菌病毒的滋生，以傍晚最适宜。 清淡饮食 保持衣物干爽,不要穿潮湿未干的衣服、盖潮湿的被子，被子(垫絮)要经常晒。 夏天不要贪凉睡地板 2.5 总结食疗、运动最多只能暂时缓解症状，找到自身湿气产生的原因，才能从根上断绝它。 我们不能怪罪脾胃太虚弱，吃那么多它累死也消化不完啊；不要怪它懒罢工不干活，湿气困着它，它也很无奈；别说它工作不到位，身体消耗少，营养物质只能不断堆积。 不形成良好的生活习惯，喝再多薏米粥、吃再多健脾祛湿的方药都是白搭！所以与其总是寻医问药寻找除湿气的方法，不如老老实实先好好吃饭、合理饮食、不贪凉不贪酒、加强体育锻炼.多动少吃清淡平衡饮食,这才是正确的姿势。]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>运动营养与健康</category>
        <category>身体之道</category>
      </categories>
      <tags>
        <tag>湿气</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Python编程从入门到实践》-Django项目]]></title>
    <url>%2F2018%2F04%2F17%2F%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%2FPython%2Fdjango%E9%A1%B9%E7%9B%AE%2FPython-django%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[基础环境： Python3系列（针对环境变量做好软链接，将python3链接为python） sudo apt-get -y install python3 ln -s /usr/bin/python3 /usr/bin/python pip3(pip2不支持Python3.x，因此我们要安装pip来支持python3) sudo apt-get install python3-pip ln -s /usr/bin/pip3 /usr/bin/pip pip的升级：pip install –upgrade pip 依赖关系（python3-venv） sudo apt-get -y install python3-venv 环境准备创建激活虚拟环境要使用django，首先需要建立一个虚拟工作环境。虚拟环境是系统的一个位置，你可以在其中安装包，并将其与其他python包隔离。将项目的库与其他项目分离是有益的。 创建虚拟环境： wxh@wxh-virtual-machine:/opt$ python -m venv ll_env 激活虚拟环境 (ll_env) wxh@wxh-virtual-machine:/opt$ source ll_env/bin/activate 停止虚拟环境 (ll_env) wxh@wxh-virtual-machine:/opt$ deactivate ​ 安装django安装django(python3之后对应的django版本为1.8.1，因此在安装的时候需要额外注意)： (ll_env) wxh@wxh-virtual-machine:/opt$ pip install Django django项目创建项目：(ll_env) wxh@wxh-virtual-machine:/opt$ sudo django-admin.py startproject learning_log . 创建完毕之后的目录结构如下所示： 注意事项： 命令末尾有有一个句点的存在，如果遗忘，可能出现一些问题。 manage.py文件是一个简单的程序，它接受命令并将其交给django的相关部分去运行，我们将会使用这些命令来管理诸如使用数据库和运行服务器等任务 目录learning_log有4个文件，其中最重要的的是setting.py、urls.py、wsgi.py。 setting.py指定django如何与系统交互以及如何管理项目。在开发项目的过程中，我们将修改其中的一些设置，并添加一些设置。 urls.py告诉django应该创建哪些网页来响应浏览器请求。 wsgi.py帮助django提供它创建的文件。（web server gateway interface）web服务器网关接口的缩写 在一个目录下，只能创建一个django项目，因为一个目录下不允许存在2个manage.py 创建数据库django将大部分与项目有关的信息都存储在数据库中，因此我们需要创建一个供django使用的数据库。为给项目“学习笔记”创建数据库，在处于活动虚拟环境中的情况下执行下面的命令： (ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py migrate 启动/停止项目核实django项目是否正确的创建，执行下面的命令启动： python manage.py runserver [port] 创建应用程序django由一系列应用程序组成（也可以看成是一系列的功能组件），他们协同工作，让项目成为一个整体。现在我们暂时只创建一个应用程序，它将完成项目的大部分工作。在后面，我们还将再添加一个管理用户账户的应用程序 (ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py startapp learning_logs 命令startapp让django创建应用程序所需的基础设施。如果现在查看项目目录，将看到其中新增了一个文件夹learning_logs 其中最重要的文件是models、admin和views，我们将使用models来定义我们要在应用程序中管理的数据 注意：learning_logs是learning_log项目中的一个应用程序，这个概念要分清。 定义模型每位用户都需要在学习笔记中创建很多的主题（例如：数学、英语、语文等等）。用户输入的每个条目（文章，每篇笔记）都要与特定的主题相关联。这些条目将以文本的形式显示。我们还需要存储每个目录的时间戳，以便能够告诉用户每个条目都是什么时候创建的。 (ll_env) wxh@wxh-virtual-machine:/opt$ cat learning_logs/models.py from django.db import models # Create your models here. 我们可以看到这个文件的内容。django事先导入了模块models，让我们自己创建模型。 模型告诉django如何处理应用程序中存储的数据。在代码层面，模型就是一个类，就像前面讨论的每个类一样，包含属性和方法。 我们编写完毕之后的代码如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim models.py from django.db import models class Topic(models.Model): &quot;&quot;&quot;用户学习的主题&quot;&quot;&quot; text = models.CharField(max_length=200) date_added = models.DateTimeField(auto_now_add=True) def __str__(self): &quot;&quot;&quot;返回模型的字符串表示&quot;&quot;&quot; return self.text 我们创建了一个名为Topic的类，它继承了models模块中的类Model-django中一个定义了模型基本功能的类。新建的这个Topic类中，我们只定义了两个属性：text和data_added（也就是拿来保存主题和时间戳） 属性text是一个CharField——由字符或文本组成的数据（见）。需要存储少量的文本，如名称、标题或城市时，可使用CharField。定义CharField属性时，必须告诉Django该在数据库中预留多少空间。在这里，我们将max_length设置成了200（即200个字符），这对存储大多数主题名来说足够了。 属性date_added是一个DateTimeField——记录日期和时间的数据（见）。我们传递了实参auto_add_now=True，每当用户创建新主题时，这都让Django将这个属性自动设置成当前日期和时间 我们需要告诉django，默认应该使用哪个属性来显示有关主题的信息。django调用方法str()来显示模型的简单表示，在这里，我们编写了方法str(),它返回存储在属性text中的字符串。 激活模型要使用模型，必须让Django将应用程序包含到项目中。为此，打开settings.py（它位于项目learning_log目录下），你将看到一个这样的片段，这一段的配置告诉Django使用哪些应用程序安装在项目中： (ll_env) wxh@wxh-virtual-machine:/opt$ sudo vim learning_log/settings.py 33 INSTALLED_APPS = [ 34 &apos;django.contrib.admin&apos;, 35 &apos;django.contrib.auth&apos;, 36 &apos;django.contrib.contenttypes&apos;, 37 &apos;django.contrib.sessions&apos;, 38 &apos;django.contrib.messages&apos;, 39 &apos;django.contrib.staticfiles&apos;, 40 ] 我们将新建的应用程序加载进项目之中，修改之后的配置如下所示： 33 INSTALLED_APPS = [ 34 &apos;django.contrib.admin&apos;, 35 &apos;django.contrib.auth&apos;, 36 &apos;django.contrib.contenttypes&apos;, 37 &apos;django.contrib.sessions&apos;, 38 &apos;django.contrib.messages&apos;, 39 &apos;django.contrib.staticfiles&apos;, 40 # my appalication 41 &apos;learning_logs&apos; 42 ] 通过这种将应用程序编组的方式，在项目不断增大，包含更多的应用程序时，可以有效的对应用程序进行跟踪。 数据库配置： 接下来，需要让django修改数据库，使其能够存储与模型Topic相关的信息，执行以下命令： (ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py makemigrations learning_logs Migrations for &apos;learning_logs&apos;: learning_logs/migrations/0001_initial.py - Create model Topic (ll_env) wxh@wxh-virtual-machine:/opt$ 命令makemigrations让Django确定该如何修改数据库，使其能够存储与我们定义的新模型相关联的数据。 输出表明Django创建了一个名为0001_initial.py的迁移文件，这个文件将在数据库中为模型Topic创建一个表。 下面来应用这种迁移，让Django替我们修改数据库： (ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, learning_logs, sessions Running migrations: Applying learning_logs.0001_initial... OK 注意：每当需要修改该应用程序管理的数据时（在这里是learning_logs应用程序），都采取如下三个步骤： 修改models.py； 对learning_logs调用makemigrations; 让django迁移项目** django管理网站一个网站，需要有管理员来管理网站，django提供的管理网站（admin site）能够轻松的实现。 接下来，我们将建立管理网站，并通过它使用模型Topic来添加一些主题 创建超级用户创建具备所有权限的用户—超级用户，执行以下命令： (ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py createsuperuser Username (leave blank to use &apos;root&apos;): ll_admin Email address: Password: Password (again): Superuser created successfully. 注意：django并不存储实际输入的明文密码，而是存储该密码的散列值，每当你输入密码的时候，django都将计算其散列值，并将结果与存储的散列值进行比较。 向管理网站注册模型Django自动在管理网站中添加了一些模型，如User和Group，但对于我们创建的模型，必须手工进行注册。 我们创建应用程序learning_logs时， Django在models.py所在的目录中创建了一个名为admin.py的文件： (ll_env) wxh@wxh-virtual-machine:/opt$ cat learning_logs/admin.py from django.contrib import admin # Register your models here. 修改之后的文件为： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim admin.py from django.contrib import admin from learning_logs.models import Topic admin.site.register(Topic) 导入我们要注册的模型Topic，再使用admin.site.register方法让django通过管理网站管理我们的模型 接下来访问：http://127.0.0.1:8000/admin可以直接使用我们刚才创建的超级管理员用户的用户名和密码进行登录。 登录之后的页面如下所示： 这个网页能够让你添加和修改用户和用户组，还可以管理刚才定义的模型Topic相关的数据。 我们能够看到刚才定义的模型Topic及其相关的数据（当前没有数据） 添加主题向管理网站注册了topic之后，我们需要添加主题，这里添加Chess和Rock Climbing主题。添加完毕之后，如下图所示： 定义模型Entry当前的模型只是定义了2个属性（主题和时间戳），并不能实际的保存数据，因此我们需要添加模型Entry 关系：每个条目都会与特定的主题相关联，即多对一的关系。 修改之后的代码如下图所示： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim models.py from django.db import models class Topic(models.Model): &quot;&quot;&quot;用户学习的主题&quot;&quot;&quot; text = models.CharField(max_length=200) date_added = models.DateTimeField(auto_now_add=True) def __str__(self): &quot;&quot;&quot;返回模型的字符串表示&quot;&quot;&quot; return self.text ​ class Entry(models.Model): “””学到的有关某个主题的具体知识””” topic = models.ForeignKey(Topic,on_delete=models.CASCADE) text = models.TextField() date_added = models.DateTimeField(auto_now_add=True) class Meta: verbose_name_plural = &apos;entries&apos; ​ def str(self): “””返回模型的字符串表示””” return self.text[:50] + “…” 像Topic一样， Entry也继承了Django基类Model。 第一个属性topic是一个ForeignKey实例。外键是一个数据库术语，它引用了数据库中的另一条记录；这些代码将每个条目关联到特定的主题。每个主题创建时，都给它分配了一个键（或ID）。需要在两项数据之间建立联系时，Django使用与每项信息相关联的键。稍后我们将根据这些联系获取与特定主题相关联的所有条目。 接下来是属性text，它是一个TextField实例（见）。这种字段不需要长度限制，因为我们不想限制条目的长度。 属性date_added让我们能够按创建顺序呈现条目，并在每个条目旁边放置时间戳。 我们在Entry类中嵌套了Meta类。 Meta存储用于管理模型的额外信息，在这里，它让我们能够设置一个特殊属性，让Django在需要时使用Entries来表示多个条目。如果没有这个类，Django将使用Entrys来表示多个条目。 最后，方法str()告诉Django，呈现条目时应显示哪些信息。由于条目包含的文本可能很长，我们让Django只显示text的前50个字符（见）。我们还添加了一个省略号，指出显示的并非整个条目。 迁移模型Entry由于我们添加了一个新模型，因此需要再次迁移数据库 步骤： 修改models.py makemigrations参数 mkigrate参数 命令及输出如下所示： (ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py makemigrations learning_logs Migrations for &apos;learning_logs&apos;: learning_logs/migrations/0002_entry.py - Create model Entry (ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, learning_logs, sessions Running migrations: Applying learning_logs.0002_entry... OK 生成了一个新的迁移文件0002_entry.py，它告诉django如何修改数据库，使其能够存储与模型Entry相关的信息。 执行命令migrate，我们发现django应用了这种迁移且一切顺利。 向管理网站注册Entry首先需要修改admin.py (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim admin.py from django.contrib import admin from learning_logs.models import Topic,Entry admin.site.register(Topic) admin.site.register(Entry) 然后刷新页面，可以看到新的内容 接下来，我们添加条目 为当前两个主题都添加相应的条目： django shell输入一些数据后，就可通过交互式终端会话以编程方式查看这些数据了。这种交互式环境称。为Django shell，是测试项目和排除其故障的理想之地。下面是一个交互式shell会话示例： (ll_env) wxh@wxh-virtual-machine:/opt$ sudo python manage.py shell [sudo] password for wxh: Python 3.5.2 (default, Nov 23 2017, 16:37:01) [GCC 5.4.0 20160609] on linux Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. (InteractiveConsole) &gt;&gt;&gt; from learning_logs.models import Topic &gt; &gt;&gt;&gt; Topic.objects.all() &lt;QuerySet [&lt;Topic: Chess&gt;, &lt;Topic: Rock Climbing&gt;]&gt; &gt;&gt;&gt; topics = Topic.objects.all() &gt;&gt;&gt; for topic in topics: ... print (topic.id,topic) ... 8 Chess 9 Rock Climbing &gt;&gt;&gt; t = Topic.objects.get(id=8) &gt;&gt;&gt; t.text &apos;Chess&apos; &gt;&gt;&gt; t.date_added datetime.datetime(2018, 4, 23, 12, 51, 16, 430242, tzinfo=&lt;UTC&gt;) 命令python manage.py shell启动一个Python解释器，可使用它来探索存储在项目数据库中的数据 在这里，我们导入了模块learning_logs.models中的模型Topic，然后使用方法Topic.objects.all()来获取模型Topic的所有实例；它返回的是一个列表，称为查询集（queryset）。 我们可以像遍历列表一样遍历查询集。 我们将返回的查询集存储在topics中，然后打印每个主题的id属性和字符串表示。从输出可知，主题Chess的ID为2，而Rock Climbing的ID为9。 知道对象的ID后，就可获取该对象并查看其任何属性。 我们还可以查看与主题相关联的条目。前面我们给模型Entry定义了属性topic，这是一个ForeignKey，将条目与主题关联起来。利用这种关联， Django能够获取与特定主题相关联的所有条目，如下所示： &gt;&gt;&gt; t.entry_set.all() &lt;QuerySet [&lt;Entry: The opening is the first part of the game, roughly...&gt;]&gt; 为通过外键关系获取数据，可使用相关模型的小写名称、下划线和单词set。例如，假设你有模型Pizza和Topping，而Topping通过一个外键关联到Pizza；如果你有一个名为my_pizza的对象，表示一张比萨，就可使用代码my_pizza.topping_set.all()来获取这张比萨的所有配料。 编写用户可请求的网页时，我们将使用这种语法。确认代码能获取所需的数据时， shell很有帮助。如果代码在shell中的行为符合预期，那么它们在项目文件中也能正确地工作。如果代码引发了错误或获取的数据不符合预期，那么在简单的shell环境中排除 故障要比在生成网页的文件中排除故障容易得多。我们不会太多地使用shell，但应继续使用它来熟悉对存储在项目中的数据进行访问的Django语法。 注意：每次修改模型后，都需要重启shell,执行Ctr + D django APIOnce you’ve created your data models, Django automatically gives you a database-abstraction API that lets you create, retrieve, update and deleteobjects. Creating objects &gt;&gt;&gt; from learning_logs.models import Topic &gt;&gt;&gt; b = Topic(text=&apos;badminton&apos;) &gt;&gt;&gt; b.save() 注意： This performs an INSERT SQL statement behind the scenes. Django doesn’t hit the database until you explicitly call save() The save() method has no return value 其他操作，查看：官方资料 创建网页：学习笔记主页使用django创建网页的过程通常分为四个阶段： 定义模型 这里我们有Topic模型和Entry模型，模型我们可以理解为就是一个数据库，其中定义了几个字段以及其对应的数据类型，后续我们都是根据这些数据进行操作。 定义URL URL模式描述了URL是如何设计的，让Django知道如何将浏览器请求与网站URL匹配，以确定返回哪个网页 编写视图 每个URL都被映射到特定的视图——视图函数获取并处理网页所需的数据。【也就是URL与内容的映射关系】 编写模板 视图函数通常调用一个模板，后者生成浏览器能够理解的网页。【也就是内容数据的显示方式，视图前端显示模板】 接下来，我们来创建学习笔记的主页。我们将定义该主页的URL、编写其视图函数并创建一个简单的模板 逻辑关系： 项目中定义调用的应用程序的模块，然后在具体应用程序中配置URL和视图 映射URL用户通过在浏览器中输入URL以及单击链接来请求网页，因此我们需要确定项目需要哪些URL主 页 的 URL 最 重 要 ， 它 是 用 户 用 来 访 问 项 目 的 基 础 URL 。 当 前 ， 基 础 URL（http://localhost:8000）返回默认的Django网站，让我们知道正确地建立了项目。我们将修改这一点，将这个基础URL映射到“学习笔记”的主页。 打开项目主目录中的urls.py文件（该文件针对整个项目的url配置），默认的内容为： 前两行导入了为项目和管理网站管理URL的函数和模块，在这个针对整个项目的urls.py文件中，变量urlpatterns包含项目中的应用程序的URL。 admin.site.urls模块定义了可在管理网站中请求的所有URL。 修改之后的配置文件如下图所示： 现在，我们需要在learning_logs目录下创建urls.py文件文件内容如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim urls.py (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ cat urls.py &quot;&quot;&quot;定义learning_logs的URL模式&quot;&quot;&quot; from django.conf.urls import url from . import views app_name = &apos;learning_logs&apos; urlpatterns = [ #主页 url(r&apos;^$&apos;,views.index,name=&apos;index&apos;) ] 讲解： 实际的URL模式其实是对函数url()的调用，这个函数接受3个实参 这里的正则表达式让python查找开头和末尾之间没有任何东西的url。 python忽略项目基础的URL（在这里是:http://localhost:8000/），因此这个正则表达式与基础URL相匹配，其他的非基础URL都不与这个正则表达式匹配，如果请求的是其他的URL页面，django将会返回一个错误页面。 url()的第2个实参指定了要调用的视图函数。请求的URL与前面的正则表达式匹配时，django将会调用views.index（这个index视图函数稍后编写） 第3个实参，将这个url模式的名称指定为index(相当于是alias别名的形式)，让我们在代码的其他地方引用它。每当我们需要提供这个主页的链接时，我们可以直接使用这个名称，而不用编写URL。 编写视图每个URL都被映射到特定的视图函数——视图函数获取并处理网页所需的数据。【也就是URL与内容的映射关系】 视图函数接受请求中的信息，准备好生成网页所需的数据，再讲这些数据发送给浏览器—这通常还涉及到网页的模板 learning_logs中的文件views.py是执行命令python manage.py startapp时自动生成的，当前的文件内容如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ cat views.py from django.shortcuts import render # Create your views here. 现在，这个文件只导入了函数render()，它根据视图提供的数据渲染响应。修改之后的文件内容如下如所示： from django.shortcuts import render def index(request): &quot;&quot;&quot;学习笔记的主页&quot;&quot;&quot; return render(request,&apos;learning_logs/index.html&apos;) 当URL被刚才定义的模式匹配之后，django会在views.py文件中查找函数index()，再将请求对象传递给这个视图函数（也就是这里的request）。 接下来向函数render进行传2个实参，原始的请求对象以及一个用于创建网页的模板（模板目录下的learning_logs目录下的index.html文件） 下面我们来编写这个模板。 编写模板模板定义了网页的结构，也就是说模板指定了网页是什么样子的。 每当网页被请求时，django将会填入相关的数据。模板让你能够访问视图提供的任何数据。我们主页视图没有提供任何数据，因此相应的模板非常简单。 创建目录在目录learning_logs下创建templates目录，用户保存网页模板文件 然后创建子目录learninig_logs，并在该子目录下新建文件index.html 文件内容为： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo mkdir -p templates/learning_logs (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ cd templates/learning_logs (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs/templates/learning_logs$ sudo vim index.html &lt;p&gt;Learning Log&lt;/p&gt; &lt;p&gt;Learning Log helps you keep track of your learning, for any topic you&apos;re learning about.&lt;/p&gt; 现在重新访问网站，会发现显示的是刚才自定义的这个网页，不再显示django网页。 如下图所示： 总结创建网页的过程看起来会有点复杂，但是将URL、视图和模板分离，效果实际上会更好，这让我们可以分别考虑项目的不同方面。 例如：数据库专家可以专注于模型，程序员可以专注于视图代码，而web涉及人员可以专注于模板。 关系： 访问请求–&gt;url（入：定义url匹配规则，出：视图函数。同时还定义这个url的调用别名） –&gt;视图（入：url请求对象，出：创建网页的模板，包含路径和名称信息。动态内容在这里生成） –&gt;模板（html网页，其中包含具体的网页内容，这里只是静态内容，接受视图中的动态数据然后组装显示） 创建其他网页接下来，我们创建两个显示数据的网页。 其中一个列出所有的主题 另一个显示特定主题的所有条目 对于每一个网页，我们都将指定URL模式，编写一个视图函数，并编写一个模板。 为了效率，我们可以先编写一个父模板 模板继承父模板：base.html 我们在/opt/learning_logs/templates/learning_logs目录下创建base.html【在项目中，每个网页都将继承base.html】 内容如下： &lt;p&gt; &lt;a href=&quot;{ % url &apos;learning_logs:index&apos;% }&quot;&gt;Learning Log&lt;/a&gt; &lt;/p&gt; { % block content % }{ % endblock content % } 实际效果为： Learning Log { % block content % }{ % endblock content % } 说明： 在当前，所有页面都包含的元素只有顶端的标题。我们将在每个页面中包含这个模板，因此我们将这个标题设置到主页的链接。 模板标签是用大括号和百分号{ %% }表示的。模板标签是一小段代码，生成要在网页中显示的信息。 在这里，模板标签{ % url ‘learning_logs:index’% }生成一个URL，该URL与learning_logs/urls.py中定义的名为index的URL模式匹配，也就是说learning_logs是一个命名空间，而index是该命名空间中一个名称独特的URL模式。 在HTML页面中，链接是使用锚（mao）标签来定义了： 格式为： &lt;a href=&quot;link_url&quot;&gt;link text &lt;/a&gt; 这里也就是类似markdown的链接使用方式，也可以说是类似Linux中软链接的方式，可以隐藏后端真实的URL串，并且让对外的链接保持最新也要容易得多。 子模板现在我们需要重新编写index.html，使其继承base.html，修改之后的代码如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs/templates/learning_logs$ sudo vim index.html { % extends &quot;learning_logs/base.html&quot; % } { % block content % } &lt;p&gt;Learning Log helps you keep track of your learning, for any topic you&apos;re learning about.&lt;/p&gt; { % endblock content % } 子模板的第一行必须包含标签{ % extends % }，让Django知道它继承了哪个父模板。 注意：这时候虽然两个文件的目录结构都是一样，但是还是需要制定目录learning_logs。 这行代码导入了base.html页面的所有内容，让index.html能够指定要在content块中预留的空间中添加的内容。 在子模板中，只需要包含当前网页特有的内容，这不仅简化了每个模板，还使得网站修改起来容易得多，要修改很多网页都包含的元素，只需要在父模板中修改该元素。 在大型项目中，我们可以定义多级父模板，有一个用于整个网站的父模板，并且网站的每个主要部分都有一个父模板，每个部分中又去继承这个模板。 接下来，我们专注于另外两个网页： 显示全部所有主题的网页 显示特定主题中条目的网页 显示所有主题的页面URL模式首先定义显示所有主题页面的URL。在这里我们使用topics来表示 完整的URL应该是：http://localhost:8000/topics 我们修改urls.py &quot;&quot;&quot;定义learning_logs的URL模式&quot;&quot;&quot; from django.conf.urls import url from . import views app_name = &apos;learning_logs&apos; urlpatterns = [ #主页 url(r&apos;^$&apos;,views.index,name=&apos;index&apos;), url(r&apos;^topics/$&apos;,views.topics,name=&apos;topics&apos;) ] 视图函数修改views.py，添加上面指定的topics视图函数 from django.shortcuts import render from .models import Topic def index(request): &quot;&quot;&quot;学习笔记的主页&quot;&quot;&quot; return render(request,&apos;learning_logs/index.html&apos;) def topics(request): &quot;&quot;&quot;显示所有的主题&quot;&quot;&quot; topics = Topic.object.order_by(&apos;date_added&apos;) context = {&apos;topics&apos;:topics} return render(request,&apos;learning_logs/topics.html&apos;,context) 说明： 需要导入与所需数据相关联的模型，也就是导入Topic类 视图函数中包含一个形参（django从服务器收到的访问request对象） 第一行中，我们查询数据库，请求提供Topic对象，并且按照属性date_added进行排序，然后将返回的查询集存储在topics中 context定义了一个将要发送给模板的上下文。上下文是一个字典类型，其中的键是我们将在模板中用来访问数据的名称，而值是我们要发送给模板的数据。在这里，我们暂时只是定义了一个键值对，包含我们将要在网页中显示的主题。 创建使用数据的网页时，除了对象request和模板的路径之外，我们还将变量context传递给render() 模板在这里，我们需要定义上面指定的topics网页。页面接受字典context，以便能使用topics()提供的数据。 创建的topics.html页面内容如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs/templates/learning_logs$ sudo vim topics.html { % extends &quot;learning_logs/base.html&quot; % } { % block content % } &lt;p&gt;Topics&lt;/p&gt; &lt;ul&gt; { % for topic in topics % } &lt;li&gt;{{ topic }}&lt;/li&gt; { % empty % } &lt;li&gt; No topics have been added yet.&lt;/li&gt; { % endfor % } &lt;/ul&gt; ​ { % endblock content % } 说明： 就像index.html一样，我们首先使用标签{ % extends % }来继承base.html，再开始定义content块。这个网页的主体是一个项目列表，其中列出了用户输入的主题。在标准的HTML中，项目列表被称为无序列表，用标签&lt;ul&gt;&lt;/ul&gt;表示。 我们使用了一个for循环的模板标签【注意：pytho使用缩进来指出哪些代码是for循环的组成部分，而在模板中，每个for循环都必须使用{ % endfor %标签来显示地指出其结束位置}】 在这里topics这个变量是从视图函数中传递过来的，因此不需要我们再指定 在HTML中，for循环的格式为： { % for item in list % } do something with each item { % endfor % } 在循环中，我们要将每个主题转换为一个项目列表项。要在模板中打印变量，需要将变量名用双花括号括起来。每次循环时，代码都被替换为topic的当前值。这些花括号不会出现在网页中，它们只是用于告诉Django我们使用了一个模板变量。 HTML标签表示一个项目列表项，在标签对内部，位于标签和之间的内容都是一个项目列表项。 修改父模板 我们现在需要修改父模板(base.html)，使其包含到显示所有主题的页面的链接修改之后的内容如下所示： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs/templates/learning_logs$ cat base.html &lt;p&gt; &lt;a href=&quot;{%url 'learning_logs:index'%}&quot;&gt;Learning Log&lt;/a&gt; - &lt;a href=&quot;{%url 'learning_logs:topics'%}&quot;&gt;Topics&lt;/a&gt; &lt;/p&gt; {% block content%}{% endblock content%} 这个时候刷新页面，显示如下： ![topics](http://picture.watchmen.xin/python-django/alltopics.png) ### 显示特定主题主所有条目的页面 ### 接下来，我们需要创建一个专注于显示特定主题的页面-**`显示该主题的名称以及该主题的所有条目`** 同样，我们的顺序还是： 1. 定义URL模式 2. 编写视图函数 3. 创建网页模板 此外，我们还需要修改上一个网页（显示所有主题的网页），让每个项目列表都是一个链接，点击之后可以显示相应主题的所有条目 #### URL模式 #### (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim urls.py """定义learning_logs的URL模式""" from django.conf.urls import url from . import views app_name = 'learning_logs' urlpatterns = [ #主页 url(r'^$',views.index,name='index'), url(r'^topics/$',views.topics,name='topics'), url(r'^topics/(?P\d+)/$',views.topic,name='topic') ] **说明：** r让django将这个字符串视为原始字符串，并指出正则表达式包含在引号内。这个表达式的第二部分**`/(?P\d+)/`**与包含在两个//内的整数内容进行匹配，并将这个整数存储在一个名为topic_id的实参中，这部分表达式捕获URL中的值； ?P将匹配到的值存储到topic_id中，而表达式\d+与包含在两个斜杆内的任何数字都匹配，不管这个数字为多少位 当发现URL与这个模式匹配的时候，django将会调用视图函数topiic()，并将存储在topic_id中的值作为实参传递给它。在这个函数中，我们使用topic_id的值来获取相应的主题 #### 视图 #### 视图topic()需要从数据库中获取指定的主题以及与之相关联的所有条目。如下所示： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim views.py from django.shortcuts import render from .models import Topic def index(request): """学习笔记的主页""" return render(request,'learning_logs/index.html') def topics(request): """显示所有的主题""" topics = Topic.objects.order_by('date_added') context = {'topics':topics} return render(request,'learning_logs/topics.html',context) def topic(request,topic_id): """显示单个主题及其所有的条目""" topic = Topic.objects.get(id=topic_id) entries = topic.entry_set.order_by('-date_added') context = {'topic':topic,'entries':entries} return render(request,'learning_logs/topic.html',context) 在这个视图函数中，我们有两个形参。这个函数接受正则表达式(?P\d+)捕获的值，并将其存储到topic_id这个形参当中 接下来，我们使用get()来获取指定的主题 下一行中，我们获取与该主题相关联的条目并将它们按照date_add进行排序：date_added前面的减号（-）指定按照降序进行排序，也就是先显示最近的条目，我们将主题和条目都存储在字典context当中，再将这个字典发送给模板topic.html。 注意： > 第一行和第二行（get和order_by）的代码都被称之为查询，因为它们会向数据中查询特定的信息，在自己的项目中编写这样的查询时，可以现在django shell中先进行试验 > 相比于直接编写视图和网页模板，再在浏览器中检查结果，在shell中执行代码可以更加快速的获得反馈 #### 模板 #### 这个模板需要显示每个主题的名称和其对应条目的内容，如果当前主题不包含任何条目，我们还需要向用户指出这一点。 代码如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs/templates/learning_logs$ sudo vim topic.html {% extends "learning_logs/base.html" %} {% block content %} Topic:{{ topic }} Entries: {% for entry in entries%} {{ entry.date_added|date:'M d, Y H:i'}} {{ entry.text|linebreaks }} { % empty % } There are no entries for this topic yet. {% endfor %} {% endblock content %} 说明： 是一个模板变量，在这里变量都是这种表示方式，这里的变量topic，是存储在字典context中的 在&lt;ul&gt;&lt;/ul&gt;中我们利用for循环定义一个显示每个条目的项目列表（无序列表） 每个列表项目都将列出两项信息：条目的时间戳和完整的文本。 第一行时间戳：在django中的模板中，竖线（|）表示模板过滤器–【对模板变量的值进行修改的函数】。后面的部分我们称之为：过滤器 过滤之后的时间戳显示格式将是：’M d, Y H:i’以这样的格式显示时间戳： January 1, 2015 23:00 第二行显示text的完整值，而不仅仅是entry的前50个字符。过滤器linebreaks将包含换行符的长条目转换为浏览器能够理解的格式，避免显示一个不间断的文本块。 在最后，我们使用模板标签{ % empty % }打印一条消息，告诉用户当前主题还没有条目 注意：代码和说明中的{和%中其实是没有空格的，在这里故意加上空格是因为hexo博客框架无法正常处理。 将显示所有主题的页面中的每个主题都设置为链接在浏览器中查看显示特定主题的页面前，我们需要修改模板topics.html，让每个主题都链接到相应的网页 如下所示： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs/templates/learning_logs$ sudo vim topics.html 这个时候我们再次刷新页面，再单击其中的一个主题，将会看到类似于下图的页面： 用户账户在这一章节，我们将创建对用户友好而直观的网页，让用户无需通过管理网站就能添加新的主题和条目，以及编辑既有的条目。 我们还将添加一个用户注册系统，让用户能够创建账户和自己的学习笔记。让任意数量的用户都能与之交互，是Web应用程序的核心所在。 让用户能够输入数据当前，只有超级用户能够通过管理网站输入数据。我们不想让用户与管理网站进行交互，因此我们将使用django的表单创建工具来创建工具让用户能够输入数据的页面 这部分，主要会涉及以下几种数据 添加新主题 添加新条目 编辑条目 添加新主题在添加新主题时，需要使用到一个输入框【在这里是一个基于表单的页面】 用户添加主题的表单我们需要让用户输入并提交信息的页面是表单 并且在用户输入数据的时候，我们还需要进行验证，确认提供的信息是否是正确的数据类型 而且信息不是恶意的信息，例如终端服务器的代码。 然后，我们再对这些有效信息进行处理，并将其保存到数据库的合适地方，这些工作都是由django自动完成。 在django中，创建表单最简单的方式是使用ModeForm，它根据我们在第18章定义的模型中的信息自动创建表单。 创建一个forms.py文件，并存储到models.py所在目录中 代码如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim forms.py from django import forms from .models import Topic class TopicForm(forms.ModelForm): class Meta: model = Topic fields = [&apos;text&apos;] labels = {&apos;text&apos;:&apos;&apos;} 最简单的ModelForm版本只包含一个内嵌的Meta类，它告诉django根据哪个模型创建表单，以及在表单中包含哪些字段。 在这里，我们根据模型Topic创建一个表单，该表单只包含字段text，下面的代码让django不要为字段text生产标签。 URL定义在这里我们创建的url是：http://localhost:8000/new_topic/ 代码如下： &quot;&quot;&quot;定义learning_logs的URL模式&quot;&quot;&quot; from django.conf.urls import url from . import views app_name = &apos;learning_logs&apos; urlpatterns = [ #主页 url(r&apos;^$&apos;,views.index,name=&apos;index&apos;), url(r&apos;^topics/$&apos;,views.topics,name=&apos;topics&apos;), url(r&apos;^topics/(?P&lt;topic_id&gt;\d+)/$&apos;,views.topic,name=&apos;topic&apos;), # 用户添加新主题的网页 url(r&apos;^new_topic/$&apos;,views.&apos;new_topic&apos;,name=&apos;new_topic&apos;) ] 这个url模式将请求交给视图函数new_topic(),接下来我们将编写这个函数 视图函数new_topic()函数new_topic()需要处理两种情形 第一种情况是刚进入new_topic网页（在这种情况下，它应该显示一个空表单） 第二种情况是对提交的表单数据进行处理，并将用户重定向到网页topics 代码如下： from django.shortcuts import render from django.http import HttpResponseRedirect from django.urls import reverse from .models import Topic from .forms import TopicForm def index(request): &quot;&quot;&quot;学习笔记的主页&quot;&quot;&quot; return render(request,&apos;learning_logs/index.html&apos;) def topics(request): &quot;&quot;&quot;显示所有的主题&quot;&quot;&quot; topics = Topic.objects.order_by(&apos;date_added&apos;) context = {&apos;topics&apos;:topics} return render(request,&apos;learning_logs/topics.html&apos;,context) def topic(request,topic_id): &quot;&quot;&quot;显示单个主题及其所有的条目&quot;&quot;&quot; topic = Topic.objects.get(id=topic_id) entries = topic.entry_set.order_by(&apos;-date_added&apos;) context = {&apos;topic&apos;:topic,&apos;entries&apos;:entries} return render(request,&apos;learning_logs/topic.html&apos;,context) def new_topic(request): &quot;&quot;&quot;添加新主题&quot;&quot;&quot; if request.method != &apos;POST&apos;: # 未提交数据：创建一个新表单 form = TopicForm() else: # POST提交的数据，对数据进行处理 form = TopicForm(request.POST) if form.is_valid(): form.save() return HttpResponseRedirect(reverse(&apos;learning_logs:topics&apos;)) context = {&apos;form&apos;: form} return render(request,&apos;learning_logs/new_topic.html&apos;,context) 说明： 在这里，我们我们导入了HttpResponseRedirect类，用户提交主题后，我们会使用这个类将用户重定向到网页topics。 函数reverse()根据指定的URL模型确定URL，这意味着django将在页面被请求时生成URL。我们还导入了刚才创建的表单TopicFrom 补充信息：GET请求与POST创建Web应用程序时，将用到的两种主要请求类型是GET请求和POST请求。对于只是从服务器读取数据的页面，使用GET请求；在用户需要通过表单提交信息时，通常使用POST请求。 处理所有表单时，我们都将指定使用POST方法。还有一些其他类型的请求，但这个项目没有使用。 函数new_topic()将请求对象作为参数。 用户初次请求该网页时，其浏览器将发送GET请求； 用户填写并提交表单时，其浏览器将发送POST请求。 根据请求的类型，我们可以确定用户请求的是空表单（GET请求）还是要求对填写好的表单进行处理（POST请求）。 如果请求方法不是POST，请求就可能是GET，因此我们需要返回一个空表单（即便请求是其他类型的，返回一个空表单也不会有任何问题）。 我们创建一个TopicForm实例，将其存储在变量form中，再通过上下文字典将这个表单发送给模板。由于实例化TopicForm时我们没有指定任何实参， Django将创建一个可供用户填写的空表单。 如果请求方法为POST，将执行else代码块，对提交的表单数据进行处理。我们使用用户输入的数据（它们存储在request.POST中）创建一个TopicForm实例，这样对象form将包含用户提交的信息。 要将提交的信息保存到数据库，必须先通过检查确定它们是有效的。函数is_valid()核实用户填写了所有必不可少的字段（表单字段默认都是必不可少的），且输入的数据与要求的字段类型一致（例如，字段text少于200个字符，这是我们在第18章中的models.py中指定的）。 这种自动验证避免了我们去做大量的工作。如果所有字段都有效，我们就可调用save()，将表单中的数据写入数据库。保存数据后，就可离开这个页面了。 我们使用reverse()获取页面topics的URL，并将其传递给HttpResponseRedirect()，后者将用户的浏览器重定向到页面topics。在页面topics中，用户将在主题列表中看到他刚输入的主题。 模板new_topic下面来创建模板new_topic.html 代码如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs/templates/learning_logs$ sudo vim new_topic.html 链接到页面new_topic接下来，我们在页面topics中添加一个到页面new_topic的链接： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs/templates/learning_logs$ sudo vim topics.html 这个时候访问指定页面，可以看到有输入框出现 添加新条目现在用户可以添加新主题了，但是他们还想添加新的条目。 我们再次定义URL，编写视图函数和模板，并连接到添加新条目的网页，但在此之前，我们需要好在forms.py中再添加一个类 1. 用于添加新条目的表单 我们需要创建一个与模型Entry相关联的表单，但是这个表单的定制程度比TopicForm要高些 (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim forms.py from django import forms from .models import Topic,Entry class TopicForm(forms.ModelForm): class Meta: model = Topic fields = [&apos;text&apos;] labels = {&apos;text&apos;:&apos;&apos;} class EntryForm(forms.ModelForm): class Meta: model = Entry fields = [&apos;text&apos;] labels = {&apos;text&apos;:&apos;&apos;} widgets = {&apos;text&apos;:forms.Textarea(attrs={&apos;cols&apos;:80})} 说明： 在这里，再导入了Entry。我们定义了属性widgets。小部件（widgets）是一个HTML表单元素，例如单行文本框、多行文本区域或者下拉列表。 通过设置属性widgets，可覆盖Django选择的默认小部件。通过让Django使用forms.Textarea，我们定制了字段’text’的输入小部件，将文本区域的宽度设置为80列，而不是默认的40列。这给用户提供了足够的空间，可以编写有意义的条目。 2. URL模式new_entry 在用户添加新条目的页面的URL模式中，需要包含实参topic_id,因为条目必须与特定的主题相关联。该URL模式如下： (ll_env) wxh@wxh-virtual-machine:/opt/learning_logs$ sudo vim urls.py &quot;&quot;&quot;定义learning_logs的URL模式&quot;&quot;&quot; from django.conf.urls import url from . import views app_name = &apos;learning_logs&apos; urlpatterns = [ #主页 url(r&apos;^$&apos;,views.index,name=&apos;index&apos;), url(r&apos;^topics/$&apos;,views.topics,name=&apos;topics&apos;), url(r&apos;^topics/(?P&lt;topic_id&gt;\d+)/$&apos;,views.topic,name=&apos;topic&apos;), # 用户添加新主题的网页 url(r&apos;^new_topic/$&apos;,views.new_topic,name=&apos;new_topic&apos;), # 用户添加新条目的页面 url(r&apos;^new_entry/(?P&lt;topic_id&gt;\d+)/$&apos;,views.new_entry,name=&apos;new_entry&apos;) ] 3. 视图函数new_entry]]></content>
      <categories>
        <category>编程语言</category>
        <category>Python</category>
        <category>django项目</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VPC从入门到实践]]></title>
    <url>%2F2018%2F04%2F17%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E5%85%AC%E6%9C%89%E4%BA%91%E4%BA%A7%E5%93%81%2F%E9%98%BF%E9%87%8C%E4%BA%91%2FVPC%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[参考文献： 阿里云-VPC官方帮助文档 VPC基础知识VPC概述专有网络VPC（Virtual Private Cloud）是用户基于阿里云创建的自定义私有网络, 不同的专有网络之间二层逻辑隔离，用户可以在自己创建的专有网络内创建和管理云产品实例，比如ECS、负载均衡、RDS等。 特点 专有网络VPC（Virtual Private Cloud）是基于阿里云构建的一个隔离的网络环境。每个专有网络（也就是每个VPC）之间逻辑上彻底隔离。 专有网络是独有的的云上私有网络。用户可以完全掌控自己的专有网络，例如选择IP地址范围、配置路由表和网关等，可以在自己定义的专有网络中使用阿里云资源如ECS、RDS、SLB等。 可以将专有网络连接到其他专有网络，或本地网络（这里的本地网络包括IDC和公司内部机房），形成一个按需定制的网络环境，实现应用的平滑迁移上云和对数据中心的扩展。 【默认情况下，VPC内主机是无法与外网连接的。这里需要借助阿里云的公网介入产品，例如弹性公网IP、NAT网关、负载均衡等】 VPC重点内容小结： 不同用户的云服务器部署在不同的专有网络里。 不同专有网络之间通过隧道ID进行隔离。专有网络内部由于交换机和路由器的存在，所以可以像传统网络环境一样划分子网，每一个子网内部的不同云服务器使用同一个交换机互联，不同子网间使用路由器互联。 不同专有网络之间内部网络完全隔离，只能通过对外映射的IP（弹性公网IP和NAT IP）互联。 由于使用隧道封装技术对云服务器的IP报文进行封装，所以云服务器的数据链路层（二层MAC地址）信息不会进入物理网络，实现了不同云服务器间二层网络隔离，因此也实现了不同专有网络间二层网络隔离。 专有网络内的ECS使用安全组防火墙进行三层网络访问控制。 VPC中的路由器和交换机路由器（VRouter）是专有网络的枢纽。作为专有网络中重要的功能组件，它可以连接VPC内的各个交换机，同时也是连接VPC和其他网络的网关设备。每个专有网络创建成功后，系统会自动创建一个路由器。每个路由器关联一张路由表。更多信息，参见路由。 交换机（VSwitch）是组成专有网络的基础网络设备，用来连接不同的云产品实例。创建专有网络之后，您可以通过创建交换机为专有网络划分一个或多个子网。同一专有网络内的不同交换机之间内网互通。您可以将应用部署在不同可用区的交换机内，提高应用的可用性。 说明：交换机不支持组播和广播。您可以通过阿里云提供的组播代理工具实现组播代理。详情参见组播代理概述。 整体拓扑架构如下图所示： VPC可以使用的私网地址范围： 在创建专有网络和交换机时，您需要以CIDR地址块的形式指定专有网络使用的私网网段。关于CIDR的相关信息，参见维基百科上的Classless Inter-Domain Routing条目说明。 您可以使用下表中标准的私网网段及其子网作为VPC的私网地址。专有网络创建成功之后，无法修改网段。建议使用比较大的网段，尽量避免后续扩容。 网段 可用私网IP数量 （不包括系统保留） IP地址范围 192.168.0.0/16 65532 192.168.0.0-192.168.255.255 172.16.0.0/12 1048572 172.16.0.0-172.31.255.255 10.0.0.0/8 16777212 10.0.0.0-10.255.255.255 最终每个网段的可用IP数量要总数减去4（系统去掉了0以及保留了最后3个） 交换机的网段不能和所属的专有网络的网段重叠，可以是其子集或者相同，网段大小在16位网络掩码与29位网络掩码之间。 如果交换机的网段和专有网络的网段相同，您只能创建一个交换机。 更多网络规划的信息，参考VPC网络规划。 关系梳理： 一个VPC（专有网络）是一个大网段，例如：192.168.0.0/16 如果掩码是24位，那么这里一共可以划分出来2^8=256个子网 每一个可用区的可用主机数量为：2^8=256个（可用的为252个，剔除了0和255、254、253) 一个交换机在一个可用区中，一个交换机也就是一个子网，路由器连接的是每个交换机，对外的网段是VPC的网段。 基础架构及实现原理问题随着云计算的不断发展，对虚拟化网络的要求越来越高，比如弹性（scalability）、安全性（security）、可靠性（reliability）和私密性（privacy），并且还有极高的互联性能（performance）需求，因此催生了多种多样的网络虚拟化技术。 比较早的解决方案，是将虚拟机的网络和物理网络融合在一起，形成一个扁平的网络架构，例如大二层网络。随着虚拟化网络规模的扩大，这种方案中的ARP欺骗、广播风暴、主机扫描等问题会越来越严重。为了解决这些问题，出现了各种网络隔离技术，把物理网络和虚拟网络彻底隔开。其中一种技术是用户之间用VLAN进行隔离，但是VLAN的数量最大只能支持到4096个，无法支撑公共云的巨大用户量。 解决方案基于目前主流的隧道技术，专有网络（Virtual Private Cloud，简称VPC）隔离了虚拟网络。每个VPC都有一个独立的隧道号，一个隧道号对应着一个虚拟化网络。一个VPC内的ECS（Elastic Compute Service）实例之间的传输数据包都会加上隧道封装，带有唯一的隧道ID标识，然后送到物理网络上进行传输。不同VPC内的ECS实例因为所在的隧道ID不同，本身处于两个不同的路由平面，所以不同VPC内的ECS实例无法进行通信，天然地进行了隔离。 基于隧道技术和软件定义网络（Software Defined Network，简称SDN）技术，阿里云的研发在硬件网关和自研交换机设备的基础上实现了VPC产品。 逻辑架构如下图所示，VPC包含交换机、网关和控制器三个重要的组件。交换机和网关组成了数据通路的关键路径，控制器使用自研的协议下发转发表到网关和交换机，完成了配置通路的关键路径。整体架构里面，配置通路和数据通路互相分离。交换机是分布式的结点，网关和控制器都是集群部署并且是多机房互备的，并且所有链路上都有冗余容灾，提升了VPC产品的整体可用性。 交换机和网关性能在业界都是领先的。自研的SDN协议和控制器，能轻松管控公共云成千上万张虚拟网络。 VPC通信专有网络是完全隔离的网络环境。默认情况下，相同专有云网络内的ECS和云服务可以进行私网通信，但VPC与VPC之间、VPC与经典网络或公网不能互通。您可以使用弹性公网IP、高速通道、NAT、VPN网关或公网负载均衡等公网产品实现专有网络间的通信。 VPC与VPC通信 VPC与经典网络通信 VPC与Internet通信 VPC与本地IDC通信 VPC与VPC通信默认情况，不同专有网络间的ECS不能直接进行私网通信。 您可以使用高速通道的路由器接口，在两侧VPC的路由器上分别创建路由器接口，以及自有的骨干传输网络来搭建高速通道，轻松实现VPC之间安全可靠、方便快捷的通信。配置详情参考同账号下专有网络内网互通。 VPC与经典网络通信默认专有网络内的ECS不能访问经典网络的ECS或者云服务。 VPC访问经典网络 VPC与经典网络可以通过公网IP进行通信。只要VPC和经典网络中的ECS实例或云实例的公网IP符合下表中的任意一一条要求，专有网络就可以访问经典网络的云服务。 经典网络访问VPC 经典网络也可以通过公网IP访问VPC，只要VPC中的ECS实例或云服务也配置了公网IP。 VPC与Internel通信默认情况下，专有网络内的ECS不能与公网互通。您可以通过以下途径中的一种打通VPC与公网的通信： 为专有网络中的ECS实例分配公网IP，实现专有网络与公网的通信。详情参考分配公网IP。 您可以通过在ECS上绑定弹性公网IP（EIP），实现专有网络与公网的互通。详情参考弹性公网IP。 在专有网络的ECS上设置NAT网关，实现专有网络与公网的互通。详情参考端口映射和SNAT设置。 如果您有多台ECS需要和公网互通，您可以使用NAT网关的共享带宽包，一个带宽包内的所有ECS实例共享带宽，以节省您的费用。 专有网络的ECS实例添加到一个公网负载均衡实例中。详情参考配置公网负载均衡。 此情形下，专有网络中的ECS实例不能访问公网，只能接收负载均衡转发的公网请求。 VPC与本地IDC通信默认情况下，本地IDC网络中心和专有网络之间不能通信，您可以通过以下途径打通本地IDC与VPC之间的通信： 您可以使用高速通道的物理专线来连通本地IDC到阿里云的专线接入点，并建立虚拟边界路由器作为VPC到IDC的数据转发桥梁。详情参考专线接入。 您可以使用VPN网关来实现本地IDC网络中心与专有网络的互通，详情参考搭建VPN网关。 名词解释 注意： 路由条目包括系统路由和自定义路由两种类型。 使用限制 注意： 每个VPC只有一个路由器，也就只有一张路由表 每个VPC可以容纳的云产品数量最多为15000个 路由器不支持动态路由协议 交换机不支持二层的广播个组播 VPC应用场景此部分介绍了专有网络常用的使用场景和架构： 场景一：本地数据中心+云上业务的混合云模式 场景二：多租户的安全隔离 场景三：主动访问公网的抓取类业务 场景四：多个应用流量波动大——共享带宽包 场景一：本地数据中心+云上对外业务的混合云模式如果您有以下业务需求，建议您使用VPC+高速通道+ECS+RDS的配置架构。 将内部核心系统与核心数据放置在自建数据中心以确保核心数据的安全； 云上部署对外客户的应用系统，实时应对业务访问量激增。 架构解读： 使用VPC、RDS、ECS搭建云上业务系统，核心数据部署在云下自建数据中心，使用高速通道专线接入保证云上数据快速同步，实现云上云下数据互通，搭建一个混合云使用环境。 场景二：多租户的安全隔离如果您有以下业务需求，建议使用VPC+ECS+RDS+SLB的配置架构。 希望在云上构建一个完全隔离的业务环境，因为传统云架构的多租户共享机制不能保证数据安全； 自主定义私有网络配置。 架构解读：您可以在阿里云上创建一个专有网络，和其他租户的网络完全隔离。您可以完全掌控自己的虚拟网络，例如选择自己的IP地址范围、划分网段、配置路由表和网关等，从而实现安全而轻松的资源访问和应用程序访问。此外，您也可以通过专线或VPN等连接方式将您的专有网络与传统数据中心相连，形成一个按需定制的网络环境，实现应用的平滑迁移上云和对数据中心的扩展。 场景三：主动访问公网的抓取类业务如果您有以下业务需求，建议使用VPC+ECS+NAT网关的配置架构。 专有网络中的多个服务器可以主动访问互联网； 避免这些服务器的公网IP暴露在公网上。 架构解读： 您可以对专有网络中的同一虚拟交换机下的所有ECS做SNAT配置，多台ECS通过同一公网IP访问互联网，并可随时进行公网IP替换，避免被外界攻击。 场景四：多个应用流量波动大——共享带宽包如果您有以下需求，建设使用VPC+NAT网关+ECS的配置架构。 系统中同时存在多个面向互联网的应用； 各个应用都需要对外提供服务，并且其波峰时间点不一致。 架构解读：您可以购买多个专有网络类型的ECS，分别承载不同的应用业务，前端挂载NAT网关，通过配置DNAT IP转发规则实现多IP共享带宽功能，减轻波峰波谷效应，从而减少您的成本。 NAT网关SNAT：在NAT网关上操作，接受到后端ECS主机发送来的数据包时，将源IP地址，修改为自身的IP地址，堆外隐藏内部的信息，是内部主动对外的 DNAT：在NAT网关上操作，接受到internet发送过来的数据包时，将目的IP地址进行修改（这个时候是NAT网关的地址），修改成为内部ECS主机的IP地址。用于后端多套系统共享带宽。 S：源是NAT网关 D:目的地是NAT网关 入门实践搭建专有网络本教程将指引您搭建一个专有网络，并为专有网络中的ECS实例绑定一个弹性公网IP（EIP）进行公网访问。 参考文献: 官方帮助文档-搭建专有网络 步骤1 创建专有网络和交换机在专有网络中部署云资源，您必须至少创建一台交换机。完成以下操作步骤，创建专有网络和交换机： 登录专有网络管理控制台。 在顶部菜单栏，选择专有网络的地域。 注意：专有网络的地域和要部署的云资源的地域必须相同，本操作选择华北2（也就是北京地域）。 单击创建专有网络，根据以下信息配置专有网络和交换机，然后单击确定。 配置对照表： 创建如下图所示： 注意： 每个交换机的第一个和最后三个IP地址为系统保留地址。 例如/20的掩码，可以使用的IP范围应该是4094个（2^12-2=4096-2=4094），但是实际平台上显示可分配使用IP为4092个，因为有4个已经被系统占用（以172.16.0.0/20为例，172.176.0.0、172.31.255.253、172.31.255.254和172.31.255.255这些地址是系统保留地址。） 步骤二 创建ECS实例完成以下操作，在已创建的VPC中创建一个ECS实例： 在专有网络控制台的左侧导航栏，单击交换机。 选择交换机的地域，本操作选择华北1。 找到已创建的交换机，然后单击购买 &gt; ECS实例。 配置ECS实例后，单击立即购买。 本操作中ECS实例的网络配置如下： 网络：选择已创建的专有网络和交换机。 公网IP地址：选择不分配。 返回ECS管理控制台，查看已创建的ECS实例。 步骤三 创建EIP弹性公网IP（EIP）是可以独立购买和持有的公网IP地址资源。完成以下操作，创建EIP： 在专有网络控制台的左侧导航栏，单击弹性公网IP。 选择EIP的地域，然后单击申请弹性公网IP。本操作，选择华北1。 配置EIP，完成支付。 步骤四 绑定EIP完成以下操作，将EIP绑定到已创建的ECS实例上： 在专有网络控制台的左侧导航栏，单击弹性公网IP。 选择EIP的地域。 找到已创建的EIP，然后单击绑定。 在弹出的对话框中，实例类型选择ECS实例，然后选择已创建的ECS实例。 单击确定。 步骤五 公网访问测试以上4和步骤均省略，可以自行查看文档 ECS安全组配置这部分内容见官方文档： 官方文档1 官方文档2 交换机交换机（VSwitch）是组成专有网络的基础网络设备，用来连接不同的云产品实例。创建专有网络之后，您可以通过创建交换机为专有网络划分一个或多个子网，同一专有网络内的不同交换机之间内网互通。 您可以将应用部署在不同可用区的交换机内，提高应用的可用性。 交换机不支持组播和广播。您可以通过阿里云提供的组播代理工具实现组播代理。详情参见组播代理概述。 交换机的网段在创建交换机时，您需要以CIDR地址块的形式指定交换机的私网网段，交换机的网段限制如下： 交换机的网段可以和其所属的VPC网段相同或者是其VPC网段的子集。 例如，VPC的网段是192.168.0.0/16，那么该VPC内的交换机的网段可以是192.168.0.0/16，也可以是192.168.0.0/17，一直到192.168.0.0/29。 说明：如果您的交换机网段和所属VPC网段相同，您只能在该VPC下创建一台交换机。 交换机的网段的大小在16位网络掩码与29位网络掩码之间，可提供8-65536个地址。 每个交换机的第一个和最后三个IP地址为系统保留地址。 以192.168.1.0/24为例，192.168.1.0、 192.168.1.253、 192.168.1.254和192.168.1.255这些地址是系统保留地址。 交换机网段的确定还需要考虑该交换机下容纳的主机的数量。 如果该交换机有和其他专有网络的交换机，或本地数据中心通信的需求，确保交换机的网段和要通信的网段不冲突。 默认的专有网络和交换机当创建一个云产品实例时，如果您没有提前创建专有网络和交换机，您可以使用系统提供的默认专有网络配置。在实例创建后，一个默认的专有网络和交换机也会随之创建好。 说明：每个地域只有一个默认专有网络，但每个专有网络内的每个可用区都可创建一个默认交换机。 默认专有网和交换机的配置如下表所示。 路由表和路由条目创建专有网络时，系统会为该专有网络自动创建一个路由器和一张路由表。 路由表中的每一项是一条路由条目。路由条目指定了网络流量的导向目的地，由目标网段、下一跳类型、下一跳三部分组成。路由条目包括系统路由和自定义路由。 您不可以直接删除专有网络的路由器或路由表，但可以在路由表中添加自定义路由条目转发流量。删除VPC后，关联的路由器和路由表也会随之删除。 系统路由创建VPC时，系统会自动添加一条目标网段为100.64.0.0/10的系统路由用于VPC内的云产品通信。另外，阿里云也会为交换机自动添加一条以交换机网段为目标网段的系统路由。 我们不可以创建，也不能删除系统路由。 比如我创建了一个网段为192.168.0.0/16的专有网络，并在该专有网络下创建了两个网段为192.168.1.0/24和192.168.0.0/24的交换机，则该专有网络的路由表中会有如下三条系统路由： 目标网段 下一跳类型 下一跳 类型 100.64.0.0/10 - - 系统 192.168.1.0/24 - - 系统 192.168.0.0/24 - - 系统 自定义路由您可以根据需要，添加自定义路由。针对不同的功能，专有网络提供如下下一跳类型的路由： ECS实例：将指向目标网段的流量转发到专有网络内的一台ECS实例上。 当需要通过该ECS实例部署的应用访问互联网或其他应用时，配置此类型的路由。【一般是网关管理类应用服务器】 适用于将指定网络访问路由至ECS实例进行流量统一转发和管理的场景，例如将一台ECS实例配置为公网网关管理其他ECS实例访问公网。 VPN网关：将指向目标网段的流量转发到一个VPN网关上。 当需要通过VPN网关连接本地网络或者其他专有网络时，配置此类型的路由。 专有网络：将来指向标网段的流量转发到一个专有网络内。 当需要使用高速通道连接两个专有网络时，配置此类型的路由。 边界路由器：将指向目标网段的流量转发到一个边界路由器上。 当需要使用高速通道连接本地网络（物理专线接入）时，才需要配置此类型的路由。 选路规则路由表采用最长前缀匹配原则作为流量的路由选路规则。最长前缀匹配是指当路由表中有多条条目可以匹配目的IP时，采用掩码最长（最精确）的一条路由作为匹配项并确定下一跳。 路由实例VPC内网路由当您在VPC内的一台ECS实例（ECS01）自建了NAT网关或绑定了弹性公网IP，您需要专有网络内的云资源通过该ECS实例访问公网时（实际上是被外部访问），可以添加如下一条自定义路由： 目标网段 下一跳类型 下一跳 0.0.0.0/0 ECS实例 ECS01 VPC互连VPC之间的互连又可以分为两种情况，一种是直接使用高速通道进行连接，一种是使用VPN网关进行连接。 第一种：使用高速通道进行连接 当使用高速通道连接两个VPC（VPC1 172.16.0.0/12和VPC2 192.168.0.0/16）时，创建完两个互相连接的路由器接口后，您还需要在两个VPC中分别添加如下一条路由： VPC1的路由配置: 目标网段 下一跳类型 下一跳 192.168.0.0/16 路由器接口（专有网络方向） VPC2的路由配置: 目标网段 下一跳类型 下一跳 172.16.0.0/12 路由器接口（专有网络方向） 第二种：使用VPN网关进行连接 如下图所示，当使用VPN网关连接两个VPC（VPC1 172.16.0.0/12和VPC2 10.0.0.0/8）时，配置完VPN网关后，需要在VPC中分别添加如下路由： VPC1的路由配置 目标网段 下一跳类型 下一跳 10.0.0.0/8 VPN网关 VPN网关1 VPC2的路由配置 目标网段 下一跳类型 下一跳 172.16.0.0/12 VPN网关 VPN网关2 VPC连接本地网络-（自建机房或者IDC）VPC连接本地网络又可以分为两种情况，一种是直接使用高速通道进行连接，一种是使用VPN网关进行连接。 第一种：使用高速通道连接本地网络 如下图所示，当使用高速通道物理专线连接专有网络和本地网络时，配置完专线和边界路由器后，需要配置如下路由： VPC端的路由配置 目标网段 下一跳类型 下一跳 192.168.0.0/16 路由器接口（普通路由） RI1 边界路由器端的配置 目标网段 下一跳类型 下一跳 192.168.0.0/16 指向专线 RI3 172.16.0.0/12 指向VPC RI2 本地网络的路由配置 目标网段 下一跳类型 下一跳 172.16.0.0/12 — 本地网关设备 第二种：使用VPN网关连接本地网络 如下图所示，当使用VPN网关连接VPC（网段：172.16.0.0/12）和本地网络（网段：192.168.0.0/16）时，配置好VPN网关后，需要在VPC内添加如下一条路由： 目标网段 下一跳类型 下一跳 192.168.0.0/16 VPN网关 已创建的VPN网关 添加自定义路由步骤如下所示： 登录专有网络管理控制台。 在左侧导航栏，单击路由表。 选择路由表所属的VPC的地域，然后单击目标路由表的ID链接。 单击添加路由条目。 在弹出的对话框，配置路由条目： 最佳实践网络规划在进行网络规划的时候，有几个问题需要去解决： 问题1：应该使用几个VPC？ 问题2：应该使用几个交换机？ 问题3：应该选择什么网段？ 问题4：VPC与VPC互通或者与线下IDC互通时，如何规划网段？ 问题1：应该使用几个VPC？单个VPC： 如果没有多地域部署系统的要求且各系统之间也不需要通过VPC进行隔离，那么推荐使用一个VPC。 目前，单个VPC内运行的云产品实例可达15000个，这样的容量基本上可以满足需求。 ps：可用区是指在同一地域内，电力和网络互相独立的物理区域，在同一地域内可用区与可用区之间内网互通。 单个VPC的拓扑如下所示： 多个VPC： 有以下需求时，那么建议使用多个VPC 多地域部署系统 VPC是地域级别的资源，是不能跨地域部署的。当您有多地域部署系统的需求时，就必然需要使用多个VPC。基于阿里巴巴骨干网构建的高速通道产品能轻松实现跨地域，跨国VPC间的互通。详情参考高速通道VPC互通。 多业务系统隔离 如果在一个地域的多个业务系统需要通过VPC进行严格隔离，比如生产环境和测试环境，那么也需要使用多个VPC，如下图所示。 问题2：应该使用几个交换机？首先，即使只使用一个VPC，也尽量使用至少两个交换机，并且将两个交换机分布在不同可用区，这样可以实现跨可用区容灾。 同一地域不同可用区之间的网络通信延迟很小，但也需要经过业务系统的适配和验证。由于系统调用复杂加上系统处理时间、跨可用区调用等原因可能产生期望之外的网络延迟。建议您进行系统优化和适配，在高可用和低延迟之间找到平衡。 其次，使用多少个交换机还和系统规模、系统规划有关。如果前端系统可以被公网访问并且有主动访问公网的需求，考虑到容灾可以将不同的前端系统部署在不同的交换机下，将后端系统部署在另外的交换机下。 问题3：应该选择什么网段？在创建VPC和交换机时，您必须以无类域间路由块 (CIDR block) 的形式为您的专有网络划分私网网段。 VPC网段规划 网段范围 网段 可用IP地址数量 备注 192.168.0.0/16 65532 去除系统占用地址 172.16.0.0/12 1048572 去除系统占用地址 10.0.0.0/8 16777212 去除系统占用地址 注意：如果有除此之外的特殊网段要求，也可以提工单或者通过客户经理申请开通。 如果有多个VPC，或者有VPC和线下IDC构建混合云的需求，建议使用上面这些标准网段的子网作为VPC的网段，掩码建议不超过16位。 如果云上只有一个VPC并且不需要和本地IDC互通时，可以选择上表中的任何一个网段或其子网。 VPC网段的选择还需要考虑到是否使用了经典网络。如果您使用了经典网络，并且计划将经典网络的ECS实例和VPC网络连通，那么，建议您选择非10.0.0.0/8作为VPC的网段，因为经典网络的网段也是10.0.0.0/8。 交换机网段 可以根据以下建议规划交换机网段。同样，交换机创建成功后，网段无法再修改。 交换机的网段的大小在16位网络掩码与29位网络掩码之间，可提供8-65536个地址。16位掩码能支持65532个ECS实例，而小于29位掩码又太小，没有意义。 交换机的网段可以和其所属的VPC网段相同，或者是其VPC网段的子网。比如VPC的网段是192.168.0.0/16，那么该VPC下的虚拟交换机的网段可以是192.168.0.0/16，也可以是192.168.0.0/17一直到192.168.0.0/29。 如果交换机网段和所属VPC网段相同，您在该VPC下只能创建一台交换机。 每个交换机的第一个和最后三个IP地址为系统保留地址。以192.168.1.0/24为例，192.168.1.0、 192.168.1.253、192.168.1.254和192.168.1.255这些地址是系统保留地址。 ClassicLink功能允许经典网络的ECS和192.168.0.0/16，10.0.0.0/8，172.16.0.0/12这三个VPC网段的ECS通信。例如，如果要和经典网络通信的VPC网段是10.0.0.0/8，则要和经典网络ECS通信的交换机的网段必须是10.111.0.0/16。详情参考ClassicLink。 交换机网段的确定还需要考虑该交换机下容纳ECS的数量。 问题4：VPC与VPC互通或者与本地数据中心互通时，如何规划网段？如下图所示，比如您在华东1、华北2、华南1三个地域分别有VPC1、VPC2和VPC3三个VPC。VPC1和VPC2通过高速通道内网互通，VPC3目前没有和其他VPC通信的需求，将来可能需要和VPC2通信。另外，您在上海还有一个自建IDC，需要通过高速通道（专线功能）和华东1的VPC1私网互通。 此例中VPC1和VPC2使用了不同的网段，而VPC3暂时没有和其他VPC互通的需求，所以VPC3的网段和VPC2的网段相同。但考虑到将来VPC2和VPC3之间有私网互通的需求，所以两个VPC中的交换机的网段都不相同。VPC互通要求互通的交换机的网段不能一样，但VPC的网段可以一样。 在多VPC的情况下，建议遵循如下网段规划原则： 尽可能做到不同VPC的网段不同，不同VPC可以使用标准网段的子网来增加VPC可用的网段数。 如果不能做到不同VPC的网段不同，则尽量保证不同VPC的交换机网段不同。 如果也不能做到交换机网段不同，则保证要通信的交换机网段不同。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>公有云产品</category>
        <category>阿里云</category>
      </categories>
      <tags>
        <tag>VPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT常用英语记录]]></title>
    <url>%2F2018%2F04%2F16%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FIT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2FIT%E8%8B%B1%E8%AF%AD%2FIT%E5%B8%B8%E7%94%A8%E8%8B%B1%E8%AF%AD%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[术语对照表 单词短语 释义 CURD CRUD (创建：Create， 读取：Read，更新：Update，删除： Delete) 是对于存储的信息可以进行操作的同义词。是一个对四种操作持久化信息的基本操作的助记符。CRUD 通常是指适用于存于数据库或数据存储器上的信息的操作，不过也可以应用在高层级的应用操作，例如通过在设置状态字段并标记删除的而并非移除数据的伪删除。 SDK RDS Remote Data Services。远程数据服务。云数据库 ECS 云服务器 ECS（Elastic Compute Service）是一种弹性可伸缩的计算服务 VPC 专有网络VPC（Virtual Private Cloud）是基于阿里云构建的一个隔离的网络环境，专有网络之间逻辑上彻底隔离。 PM Product Manager，产品经理 RD Research and Development 研究与开发 QA Qualtiy Assurance 品质保证。QA的主要职责就是质量保证工作。 OP Operator，操作员，管理员。 href hypertext reference 超文本连接 DML 数据变更是指DML(包含insert/delete/update) DDL 结构变更是指DDL(例如：create/drop/alter table) pki 公钥基础设施（Public Key Infrastructure） PV page view TPS transactions per second 每秒传输的事物处理个数，即服务器每秒处理的事务数 QPS queries per second RPS requests per second RPS 并发数/平均响应时间]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>IT基础知识</category>
        <category>IT英语</category>
      </categories>
      <tags>
        <tag>IT常用英语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[listary常用操作]]></title>
    <url>%2F2018%2F04%2F04%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7%2FListary%2Flistary%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[参考资料官网 官网链接 网友文章 Listary——让文件在指尖流动 Listary Pro - 能极大幅度提高你 Windows 文件浏览与搜索速度效率的「超级神器」 实际操作常用快捷操作 ctrl敲2下 调出Listary窗口【可以在设置中设置第二种方式】 左键双击 在文件夹中双击会调出Listary的收藏，最近文档等。 在电脑页面输入e 即可定位到E盘，以此类推 目录页面输入名称一部分 定位到该子目录或者文件 ctrl+右键 针对选中内容进行动作【例如打开文件夹等】 智能匹配只要输入文件名的一部分就可以找到这个文件，支持中文与英文。 比如，我输入测试 md就可以搜索到测XX试OO.md这个文件。 自然，输入的越多，返回的结果越精确。随着使用记录的积累，常用的文件或程序会获得更高的优先级。 打开保存文件浏览对话框增强Ctrl+G 在打开框中切换到上一次打开的目录 Ctrl+O 直接打开上一次打开目录中的文件]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>Listary</category>
      </categories>
      <tags>
        <tag>Listary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win10添加指定程序到开机自启动]]></title>
    <url>%2F2018%2F04%2F03%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FIT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2FWindows%2FWin10%E6%B7%BB%E5%8A%A0%E6%8C%87%E5%AE%9A%E7%A8%8B%E5%BA%8F%E5%88%B0%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[打开运行对话框（win键+R），输入命令 shell:startup 会直接弹出启动项对应的目录，然后像把应用程序快捷方式(需要对该执行文件右键创建快捷方式)复制或者剪切到启动目录 注意：该方式的启动项对应的目录是个人目录，也就是说不是针对系统上的所有用户。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>IT基础知识</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Win10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http Server 网络处理模型的进化之路]]></title>
    <url>%2F2018%2F04%2F02%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%E5%8F%8A%E7%BD%91%E7%BB%9C%E6%9C%8D%E5%8A%A1%2F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86%2FHTTP%2FHttp-Server-%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%9B%E5%8C%96%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[缘起我刚毕业那会儿，国家还是包分配工作的，我的死党小明被分配到了一个叫数据库的大城市，天天都可以坐在高端大气上档次的机房里，在那里专门执行 SQL查询优化，工作稳定又舒适； 隔壁宿舍的小白被送到了编译器镇，在那里专门把 C 源文件编译成 EXE 程序，虽然累，但是技术含量非常高，工资高，假期多。 我成绩不太好，典型的差生，四级补考了两次才过，被发配到了一个不知道什么名字的村庄，据说要处理什么 HTTP请求，这个村庄其实就是一个破旧的电脑，令我欣慰的是可以上网，时不时能和死党们通个信什么的。 不过辅导员说了，我们都有光明的前途。 Http Server 1.0HTTP是个新鲜的事物，能够激起我一点点工作的兴趣，不至于沉沦下去。 一上班，操作系统老大扔给我一大堆文档： “这是 HTTP协议， 两天看完！” 我这样的英文水平，这几十页的英文 HTTP协议我不吃不喝不睡两天也看不完， 死猪不怕开水烫，慢慢磨吧。 两个星期以后，我终于大概明白了这 HTTP是怎么回事：无非是有些电脑上的浏览器向我这个破电脑发送一个预先定义好的文本（Http request）, 然后我这边处理一下（通常是从硬盘上取一个后缀名是 html的文件，然后再把这个文件通过文本方式发回去（http response），就这么简单。 唯一麻烦的实现，我得请操作系统给我建立 Http 层下面的 TCP 连接通道， 因为所有的文本数据都得通过这些 TCP通道接收和发送，这个通道是用 socket建立的。 弄明白了原理，我很快就搞出了第一版程序，这个程序长这个样子： 看看， 这些 socket, bind, listen , accept… 都是操作系统老大提供的接口， 我能做的也就是把他们组装起来：先在 80端口监听，然后进入无限循环，如果有连接请求来了，就接受 (accept)，创建新的 socket，最后才可以通过这个 socket来接收，发送 http 数据。 老大给我的程序起了个名称，Http Server 版本 1.0 。 这个名字听起来挺高端的，我喜欢。 我兴冲冲的拿来实验，程序启动了，在 80端口“蹲守”，过了一会儿就有连接请求了， 赶紧 Accept ,建立新的 socket ，成功 ！接下来就需要从 socket 中读取 Http Request 了。 可是这个 receive 调用好慢，我足足等了 100 毫秒还没有响应！我被阻塞 (block) 住了！ 操作系统老大说：“别急啊，我也在等着从网卡那里读数据，读完以后就会复制给你。” 我乐的清闲，可以休息一下。 可是操作系统老大说：“别介啊，后边还有很多浏览器要发起连接，你不能在这儿歇着啊。” 我说不歇着怎么办？receive调用在你这里阻塞着，我除了加入阻塞队列，让出 CPU 让别人用还能干什么？ 老大说： “唉，大学里没听说过多进程吗？你现在很明显是单进程，一旦阻塞就完蛋了，想办法用下多进程，每个进程处理一个请求！” 老大教训的是，我忘了多进程并发编程了。 Http Server 2.0 ：多进程多进程的思路非常简单，当 accept连接以后，对于这个新的 socket ，不在主进程里处理，而是新创建子进程来接管。这样主进程就不会阻塞在 receive 上，可以继续接受新的连接了。 我改写了代码，把 Http server 升级为 V2.0，这次运行顺畅了很多，能并发的处理很多连接了。 这个时候 Web 刚刚兴起，我这个 Http Server 访问的人还不多，每分钟也就那么几十个连接发过来，我轻松应对。 由于是新鲜事物，我还有资本给搞数据库的小明和做编译的小白吹吹牛，告诉他们我可是网络高手。 没过几年，Web迅速发展，我所在的破旧机器也不行了，换成了一个性能强悍的服务器，也搬到了四季如春的机房里。 现在每秒中都有上百个连接请求了，有些连接持续的时间还相当的长，所以我经常得创建成百上千的进程来处理他们，每个进程都得耗费大量的系统资源，很明显操作系统老大已经不堪重负了。 他说：“咱们不能这么干了，这么多进程，光是做进程切换就把我累死了。” “要不对每个 Socket 连接我不用进程了，使用线程？ ” “可能好一点，但我还是得切换线程啊，你想想办法限制一下数量吧。” 我怎么限制？我只能说同一时刻，我只能支持 x个连接，其他的连接只能排队等待了。 这肯定不是一个好的办法。 Http Server 3.0 : Select模型老大说：“我们仔细合计合计，对我来说，一个 Socket连接就是一个所谓的文件描述符（File Descriptor ,简称 fd , 是个整数），这个 fd 背后是一个简单的数据结构，但是我们用了一个非常重量级的东西 – 进程 –来表示对它的读写操作，有点浪费啊。” 我说：“要不咱们还切换回单进程模型？但是又会回到老路上去，一个 receive 的阻塞就什么事都干不了了。” “单进程也不是不可以，但是我们要改变一下工作方式。” “改成什么？” 我想不透老大在卖什么关子。 “你想想你阻塞的本质原因，还不是因为人家浏览器还没有把数据发过来，我自然也没法给你，而你又迫不及待的想去读，我只好把你阻塞。在单进程情况下，一阻塞，别的事儿都干不了。“ “对，就是这样” “所以你接受了客户端连接以后，不能那么着急的去读，咱们这么办，你的每个 socket fd 都有编号，你把这些编号告诉我，就可以阻塞休息了 。” 我问道：“这不和以前一样吗？原来是调用 receive 时阻塞，现在还是阻塞。” “听我说完，我会在后台检查这些编号的 socket，如果发现这些 socket 可以读写，我会把对应的 socket 做个标记，把你唤醒去处理这些 socket 的数据，你处理完了，再把你的那些 socket fd 告诉我，再次进入阻塞，如此循环往复。” 我有点明白了：“ 这是我们俩的一种通信方式，我告诉你我要等待什么东西，然后阻塞，如果事件发生了，你就把我唤醒，让我做事情。” “对，关键点是你等我的通知，我把你从阻塞状态唤醒后，你一定要去遍历一遍所有的 socket fd，看看谁有标记，有标记的做相应处理。我把这种方式叫做 select 。” 我用 select 的方式改写了 Http server，抛弃了一个 socket 请求对于一个进程的模式，现在我用一个进程就可以处理所有的 socket了。 Http Server4.0 : epoll这种称为 select 的方式运行了一段时间，效果还不错，我只管把 socket fd 告诉老大，然后等着他通知我就行了。 有一次我无意中问老大：“我每次最多可以告诉你多少个 socket fd？” “1024个。” “那就是说我一个进程最多只能监控 1024 个 socket 了？ ” “是的，你可以考虑多用几个进程啊！” 这倒是一个办法，不过”select”的方式用的多了，我就发现了弊端，最大的问题就是我从阻塞中恢复以后，需要遍历这 1000 多个 socket fd，看看有没有标志位需要处理。 实际的情况是， 很多 socket 并不活跃， 在一段时间内浏览器并没有数据发过来， 这 1000 多个 socket 可能只有那么几十个需要真正的处理，但是我不得不查看所有的 socket fd，这挺烦人的。 难道老大不能把那些发生了变化的 socket 告诉我吗？ 我把这个想法给老大说了下，他说：“嗯，现在访问量越来越大， select 方式已经不满足要求，我们需要与时俱进了，我想了一个新的方式，叫做 epoll。” “看到没有，使用 epoll 和 select 其实类似“ 老大接着说 ：”不同的地方是第 3 步和第 4 步，我只会告诉你那些可以读写的 socket , 你呢只需要处理这些 ‘ready’ 的 socket 就可以了“ “看来老大想的很周全， 这种方式对我来说就简单的多了。 ” 我用 epoll 把 Http Server 再次升级，由于不需要遍历全部集合，只需要处理哪些有变化的，活跃的 socket 文件描述符，系统的处理能力有了飞跃的提升。 我的 Http Server 受到了广泛的欢迎，全世界有无数人在使用，最后死党数据库小明也知道了，他问我：“ 大家都说你能轻松的支持好几万的并发连接， 真是这样吗？ ” 我谦虚的说：“过奖，其实还得做系统的优化啦。” 他说：“厉害啊，你小子走了狗屎运了啊。” 我回答： “毕业那会儿辅导员不是说过吗， 每个人都有光明的前途。”]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>网络知识及网络服务</category>
        <category>网络知识</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>epoll模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[终端常用快捷键]]></title>
    <url>%2F2018%2F04%2F01%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FLinux%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F%E7%BB%88%E7%AB%AF%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F%E7%BB%88%E7%AB%AF%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[常用快捷键Tab键： 命令、文件名等自动补全功能。 Ctrl+a： 光标回到命令行首。 （a：ahead） Ctrl+e： 光标回到命令行尾。 （e：end） Ctrl+b： 光标向行首移动一个字符。 （b：backwards） Ctrl+f： 光标向行尾移动一个字符。 （f：forwards） Ctrl+w： 删除光标处到行首的字符，也就是删除光标前面的所有内容。 Ctrl+k： 删除光标处到行尾的字符，也就是删除光标后面的所有内容。 Ctrl+u： 删除整个命令行文本字符，删除整行命令。 Ctrl+h： 向行首删除一个字符，向前删除一个字符，相当于Backspace。 Ctrl+d： 向行尾删除一个字符，向后删除一个字符，相当于Delete。 Ctrl+y： 粘贴Ctrl+u，Ctrl+k，Ctrl+w删除的文本。 Ctrl+p： 上一个使用的历史命令。 （p：previous） Ctrl+n： 下一个使用的历史命令。（n：next ） Ctrl+t： 交换光标所在字符和其前的字符。 Ctrl+i： 相当于Tab键。 Shift+Insert： 粘贴鼠标所复制的内容 Ctrl+d: 在空命令行的情况下可以退出终端。 Shift+c： 删除之后的所有内容并进入编辑模式 Ctrl+c： 中断终端中正在执行的任务。 Ctrl+z： 使正在运行在终端的任务，运行于后台。 （可用fg恢复到前台） 非常用快捷键Ctrl+s： 使终端发呆，静止，可以使快速输出的终端屏幕停下来。 Ctrl+q： 退出Ctrl+s引起的发呆。 Ctrl+[： 相当于Esc键。 Esc键： 连续按3次显示所有的支持的终端命令，相当于Tab键。 Ctrl+r： 快速检索历史命令。（r：retrieve）。 Ctrl+o： =Ctrl+m：相当Enter键。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>Linux基础知识</category>
        <category>终端常用快捷键</category>
      </categories>
      <tags>
        <tag>终端常用快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师面试常见问题]]></title>
    <url>%2F2018%2F03%2F28%2F%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F%E8%81%8C%E5%9C%BA%2FLinux%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[redhat、centos、suse、ubuntu等发行版本的区别这些发行版本本质上没有什么区别，都是类unix系统。redhat的系统本身是免费的，但是它的服务和一些特定的组件是收费的而centos是redhat社区版本，国内使用较多，社区相当活跃。SUSE也是分为两种，一种企业版本的SLES，一种是opensuse，sles主要是一些金融国企在使用，安全性较好，opensuse是社区版本，suse使用起来和centos相差不多，软件包形式使用源自redhat的rpm，但是管理工具使用的是zypper。ubuntu源自于debain，国外使用的较多，也是相当热门的一个发型版本，在桌面领域有绝对技术优势，适合开发人员使用。 OSI7层模型和TCP/IP模型的区别联系OSI7层模型OSI 7层模式主要是由国际标准化组织（ISO）创建的，是一个国际通用的标准，它被开发出作为一个参照标准，用于指导如何设计网络通信系统。说的简单一点就是统一网络设备商的协议标准，实现多网络设备商环境（主机，路由器，交换机等等都是网络设置，都要遵循同一套的通信标准）它一共分为7层，每一层在网络通信数据传输过程中都定义了不同的功能。 OSI7层模型主要分为(从下到上)：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。每一层说明： layer function Application data flow；离用户最近的一层，它使一个网络应用能和另一个网络应用相互通信 Presentation 定义数据格式；数据压缩、加解密等。 Session 定义如何建立和终止连接，是告诉4层怎么做，4层只管被动的接受然后去做。 Transport 数据段；将上层的数据流进行分段；建立和终止网络连接；常用于流量控制和数据恢复 Network 数据包；使用IP地址在Internet上唯一确定一台设备；定义设备路由，寻址 Data link 数据帧；将上层数据封装成数据帧，其中包含源目MAC地址以及帧校验字段（用于检测传输错误）；它包含2个子层（LLC和MAC） Physical 比特流；定义了比特流如何在两台设备之间流通；主要涉及线缆，网卡， 下面是每一层常见的对应协议 layer protocol Application HTTP,FTP,Telnet,SMTP,SNMP Presentation MIME,TIFF,GIF,JPEG,PICT,ASCII,EBCDIC,encryption,MPEG,MIDI,HTML Session SSl/TLS,NetBIOS,RPC Transport TCP,UDP Network IP,ICMP,ARP,RARP Data link PPP,HDLC,IEEE 802.3/802.2,FDDI,ATM,IEEE 802.5/802.2 Physical Ethernet TCP/IP协议族TCP/IP模型类似OSI模型，作用也是描述一套指导标准，实现网络设备之间的通信，它被设计成4层 Application Transport Internet Network Access 其对应关系为： TCP/IP model OSI model Application Application Presentation Session Transport Transport Internet Network Network Access Data link Physical 区别除了层数的区别之外，它们之间最大的区别就是： OSI模型规定了在一个网络上传输数据所需要的步骤，并且它是非常具体的，定义了每一层使用什么协议以及如何使用；而TCP/IP模型是不特定的。另外一个区别就是，目前TCP/IP是所有网络设备上既定的协议事实，一般分析问题使用OSI模型。 路由，交换技术的基本原理路由技术我们在这里说的路由技术一般是指，路由转发。主要涉及设备为路由器或者三层交换机。这些设备上会维护一张路由表，其中的信息可以是通过动态路由协议（例如OSPF，EIGRP，ISIS，RIP，BGP，静态路由，默认路由等）获取组成路由表的内容是：出口接口和对应网段 路由设备接收到一个数据包之后，会解封装，获取其中的目的IP地址信息（网段信息），然后查找路由表，选择最优路由去转发。路由设备上也会有一张ARP表，根据广播域 交换技术在一个局域网内，也就是一个广播域内使用的技术。通常会涉及到的设备就是交换机。交换机上会维护一张MAC地址转发表，其中的信息是MAC地址和端口的映射关系。交换机根据数据帧中的目的MAC地址进行数据包的转发 注意：在一个广播域内的数据流动是依靠二层MAC来实现的，因为在第一次会涉及到ARP，有了记录之后，交换机会记录他的MAC地址表，后续的速度就会非常快 PS：有关网络模型和路由技术可以结合一个小案例在白板上演示一下，效果会更好，也就是将上述两部分的内容有机的整合成为一个整体 脚本部分运维知识优化运维思想运维核心是什么稳定性-网站/平台不宕机【核心】集群 负载均衡 高可用 解耦，微服务 数据不丢失【核心】数据备份，异地容灾 避免人为错误 避免人为错误，主要分为两个方面，一个是开发不严谨产生的错误，这部分通过流程可以控制。【比如测试不严谨，开发人员的代码有问题，直接把服务器资源跑没了】 一个是自己操作产生的问题，这部分通过一些智能化的自动化工具来尽量避免【避免在执行命令的时候误操作等等】 解决：建立完善的流程制度，对运维来说，包括标准化，对开发测试来说，包括上线的流程化 运维效率管理平台运维脚本化，工具化，自动化，人工智能化 如何做好运维工作运维职业规划你为什么离职你对加班的看法个人最大的优点和缺点问题应答0. 自我介绍面试官 早上/下午好 我叫汪小华 大学就读于晋中学院 网络工程专业。目前一共有三年工作经验， 实习和第一份工作都是在亿阳信通在这期间从最基础的桌面运维干起，一直到最后独立接手负责了一个项目从0到1的这么一个整体过程，有很多的收获。这一期间对如何做好运维工作有了一些的感悟。 第二份工作是被内推到创世漫道，主要负责公司linux平台的调整，主要和我对接的是公司的架构师，因此在这个过程中对运维思想这方面有了很大的提升。 有关这两部分具体的内容我会在后面和您聊如何通过运维思想做好运维工作时谈及 我的优点是有一定的网络基础，平时喜欢问为什么，和同事交流谈论的时候喜欢拿纸笔写写画画。最强的技能部分应该是进程管理，这一点我觉得对运维工作来说，至关重要，关于这部分稍后我们可以一块交流探讨。 我的缺点目前是如何将所学知识有机的结合成为一个整体，构成一张知识之网这种能力还不够，这一点也是在后续的工作中需要去刻意修炼的。 以上是我的自我介绍，今天我要应聘的岗位是Linux运维工程师，谢谢！ 1. 发行版本区别及shell、python这些发行版本本质上没有什么区别，都是类unix系统。redhat的系统是免费的，但是他服务是收费的，并且有一些类似RHCS等服务只有收费版才支持。而centos是redhat社区版本，国内使用较多，社区相当活跃。SUSE也是分为两种，一种企业版本的SLES，一种是opensuse，sles主要是一些金融国企在使用，安全性较好，opensuse是社区版本，suse使用起来和centos相差不多，软件包形式使用源自redhat的rpm，但是管理工具使用的是zypper。ubuntu源自于debain，国外使用的较多，也是相当热门的一个发型版本，在桌面领域有绝对技术优势，适合开发人员使用。 1**有关shell的问题，做面试题，看abs【每天看一点】。** python目前正在学习，目前基础部分已经学完了，正在学习django项目，学完之后，要花钱买一套马哥或者老男孩的python视频来补充，预计下半年能够做项目。 2. OSI模型、TCP/IP部分；路由交换基本原理OSI7层模型OSI 7层模式主要是由国际标准化组织（ISO）创建的，是一个国际通用的标准，它被开发出作为一个参照标准，用于指导如何设计网络通信系统。说的简单一点就是统一网络设备商的协议标准，实现不同网络设备和谐共存的环境（主机，路由器，交换机等等都是网络设置，都要遵循同一套的通信标准）它一共分为7层，每一层在网络通信数据传输过程中都定义了不同的功能。 OSI7层模型主要分为(从下到上)：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。每一层说明： layer function Application data flow；离用户最近的一层，它使一个网络应用能和另一个网络应用相互通信 Presentation 定义数据格式；数据压缩、加解密等。 Session 定义如何建立和终止连接，是告诉4层怎么做，4层只管被动的接受然后去做。 Transport 数据段；将上层的数据流进行分段；建立和终止网络连接；常用于流量控制和数据恢复 Network 数据包；使用IP地址在Internet上唯一确定一台设备；定义设备路由，寻址 Data link 数据帧；将上层数据封装成数据帧，其中包含源目MAC地址以及帧校验字段（用于检测传输错误）；它包含2个子层（LLC和MAC） Physical 比特流；定义了比特流如何在两台设备之间流通；主要涉及线缆，网卡， 下面是每一层常见的对应协议 layer protocol Application HTTP,FTP,Telnet,SMTP,SNMP Presentation MIME,TIFF,GIF,JPEG,PICT,ASCII,EBCDIC,encryption,MPEG,MIDI,HTML Session SSl/TLS,NetBIOS,RPC Transport TCP,UDP Network IP,ICMP,ARP,RARP Data link PPP,HDLC,IEEE 802.3/802.2,FDDI,ATM,IEEE 802.5/802.2 Physical Ethernet TCP/IP协议族TCP/IP模型类似OSI模型，作用也是描述一套指导标准，实现网络设备之间的通信，它被设计成4层 1234ApplicationTransportInternetNetwork Access 其对应关系为： TCP/IP model OSI model Application Application Presentation Session Transport Transport Internet Network Network Access Data link Physical OSI和TCP/IP的区别除了层数的区别之外，它们之间最大的区别就是： OSI模型规定了在一个网络上传输数据所需要的步骤，并且它是非常具体的，定义了每一层使用什么协议以及如何使用；而TCP/IP模型是不特定的。另外一个区别就是，目前TCP/IP是所有网络设备上既定的协议事实，一般分析问题使用OSI模型。 路由技术我们在这里说的路由技术一般是指，路由转发。主要涉及设备为路由器或者三层交换机。这些设备上会维护一张路由表，其中的信息可以是通过动态路由协议（例如OSPF，EIGRP，ISIS，RIP，BGP，静态路由，默认路由等）获取组成路由表的内容是：出口接口和对应网段 路由设备接收到一个数据包之后，会解封装，获取其中的目的IP地址信息（网段信息），然后查找路由表，选择最优路由去转发。路由设备上也会有一张ARP表，根据广播域 交换技术在一个局域网内，也就是一个广播域内使用的技术。通常会涉及到的设备就是交换机。交换机上会维护一张MAC地址转发表，其中的信息是MAC地址和端口的映射关系。交换机根据数据帧中的目的MAC地址进行数据包的转发 注意：在一个广播域内的数据流动是依靠二层MAC来实现的，因为在第一次会涉及到ARP，有了记录之后，交换机会记录他的MAC地址表，后续的速度就会较快 这个时候可以在白板上进行讲解，大致的讲解百度页面打开的整个过程。 3. 高可用+负载均衡keepalived 2种角色：master和backup； 4种状态：stop,master,backup,fault 检测脚本2种触发机制 当VRRP检测脚本检测到自身所承载应用的返回值不为0的时候，就会触发角色变化，这个时候，VRRP脚本中如果没有设置weight权重值，那么直接进入fault状态，在vrrp组中发送组播通告，宣告自己进入异常状态，让出master角色并且不参与竞选如果脚本中设置了weight权重值，这个时候又会分为两种情况。 当weight权重值大于0时，master的优先级不变，backup的优先级为weight+现在优先级在wight权重值小于0时，master的优先级为目前的优先级减去weight的绝对值，backup的优先级保持不变。经过我多次的实验，目前保证最佳切换效果的配置是Vrrp检测脚本组中不配置weight，并且所有主机都设置为backup，设置不抢占参数，这种情况下，能有效避免优先级设置不当导致的切换不成功。 Nginx Nginx工作在应用层（使用location，通过正则表达表达式进行相关匹配），负载均衡是基于upstream模块实现的，因此配置比较简单。但是对后端服务器的健康检测只能支持端口Nginx的负载均衡算法可以分为两类：内置策略和扩展策略，内置的有轮询，ip_hash等。扩展的有fair，通用hash，一致性hash等。 Nginx的负载均衡目前支持5种调度算法： rr轮询【默认算法】；接受到请求之后，按照时间顺序逐一分配到后端不同的服务器上 wrr加权轮询；权重值越大，被分配访问的概率就越大，主要用于后端服务器性能不一致的情况 ip_hash；每个请求按访问IP的哈希结果分配，计算之后，nginx内部会维护一张哈希表，这样每个访客固定访问一个后端服务器，可以有效的解决动态网页存在的session共享问题。 fair;【第三方算法，需要通过额外安装upstream_fair模块实现】。更智能的一个负载均衡算法，此算法可以根据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。 url_hash；【第三方算法，需要通过额外安装hash模块实现】。也是哈希算法，只不过不是基于源IP，而是基于访问的URL来生成这张哈希表。每个URL定向到同一台后端服务器，可以进一步提高后端缓存服务器的效率。 注意：当算法是ip_hash的时候，后端服务器不能被添加weight和backup 我们在location中配置nginx负载均衡的时候，还需要添加proxy_next_upstream http_500 http_502 error timeout invalid_header; 这一行参数。用于定义故障转移策略。当后端服务器节点返回500、502和执行超时等错误时，自动将请求转发到upstream负载均衡器中的另一台服务器，实现故障转移。 Nginx负载均衡工作流： 当客户端访问 xxx 域名时请求会最先到达负载均衡器,负载均衡器就会去读取自己server标签段中的配置 到location里面一看,原来这是一个要往后端web节点抛的请求 而后,nginx通过 proxy_pass的配置项 在自己的主配置文件找到了事先定义好的后端web节点 最后,按照事先设置好的调度算法,把请求带上主机头和客户端原始ip一起抛给后端准备好的web服务器 nginx负载均衡较适合用于日pv 2000W以下的站点 HAProxy Haproxy能实现基于4层和7层的负载均衡， HAproxy的8中负载均衡算法1、roundrobin表示简单的轮询，每个服务器根据权重轮流使用，在服务器的处理时间平均分配的情况下这是最流畅和公平的算法。该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。 2、leastconn连接数最少的服务器优先接收连接。leastconn建议用于长会话服务，例如LDAP、SQL、TSE等，而不适合短会话协议。如HTTP.该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。 3、static-rr每个服务器根据权重轮流使用，类似roundrobin，但它是静态的，意味着运行时修改权限是无效的。另外，它对服务器的数量没有限制。 该算法一般不用； 4、source对请求源IP地址进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个客户端IP地址总是访问同一个服务器。如果哈希的结果随可用服务器数量而变化，那么客户端会定向到不同的服务器； 该算法一般用于不能插入cookie的Tcp模式。它还可以用于广域网上为拒绝使用会话cookie的客户端提供最有效的粘连； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 5、uri表示根据请求的URI左端（问号之前）进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个URI地址总是访问同一个服务器。一般用于代理缓存和反病毒代理，以最大限度的提高缓存的命中率。该算法只能用于HTTP后端； 该算法一般用于后端是缓存服务器； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 6、url_param在HTTP GET请求的查询串中查找中指定的URL参数，基本上可以锁定使用特制的URL到特定的负载均衡器节点的要求； 该算法一般用于将同一个用户的信息发送到同一个后端服务器； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 7、hdr(name)在每个HTTP请求中查找HTTP头，HTTP头将被看作在每个HTTP请求，并针对特定的节点； 如果缺少头或者头没有任何值，则用roundrobin代替； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 8、rdp-cookie（name）为每个进来的TCP请求查询并哈希RDP cookie； 该机制用于退化的持久模式，可以使同一个用户或者同一个会话ID总是发送给同一台服务器。如果没有cookie，则使用roundrobin算法代替； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 2种配置方式指的是在1.3版本之前，ha的负载均衡配置主要是在listen部分中进行配置在1.3版本之后，为了更好的维护和管理，将负载均衡的配置拆分成为了frotend和backend这两部分，为了保证兼容性，listen部分依然保留，目前主要使用listen部分配置HA的监控页面 HA通过ACL实现一些7层的功能例如通过path_end的ACl方法实现动静资源分离 通过hdr_dom(host)和hdr_reg(host)和hdr_beg(host)的方法实现虚拟主机 LVS关于LVS，它本身只是支持负载均衡，没有检测机制，因此要结合keepalived来使用【keepalived的诞生原因就是为了给LVS提供后端节点检测功能，到后面才添加了高可用的功能】。在这里需要明确一点，它只能转发4层数据包【IP+port】但是检测是能通过7层url进行监测的。LVS的8种算法：1.轮叫调度（Round Robin）调度器通过“轮叫”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载。大锅饭调度：rr - 纯轮询方式，比较垃圾。把每项请求按顺序在真正服务器中分派 2.加权轮叫（Weighted Round Robin）调度器通过“加权轮叫”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器能处理更多的访问流量。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。带权重的大锅饭调度：wrr -带权重轮询方式。把每项请求按顺序在真正服务器中循环分派，但是给能力较大的服务器分派较多的作业。 3.最少链接（Least Connections）调度器通过“最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用“最小连接”调度算法可以较好地均衡负载。谁不干活就给谁分配：lc - 根据最小连接数分派 4.加权最少链接（Weighted Least Connections）在集群系统中的服务器性能差异较大的情况下，调度器采用“加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。带权重的谁不干活就给谁分配：wlc - 带权重的。机器配置好的权重高 5.基于局部性的最少链接（Locality-Based Least Connections）“基于局部性的最少链接”调度算法是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用“最少链接” 的原则选出一个可用的服务器，将请求发送到该服务器。基于地区的最少连接调度：lblc - 缓存服务器集群。基于本地的最小连接。把请求传递到负载小的服务器上 6.带复制的基于局部性最少链接（Locality-Based Least Connections with Replication）“带复制的基于局部性最少链接”调度算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。它与LBLC算法的不同之处是它要维护从一个目标 IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。该算法根据请求的目标IP地址找出该目标IP地址对应的服务器组，按“最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。带有复制调度的基于地区的最少连接调度：lblcr - 带复制调度的缓存服务器集群。某页面缓存在服务器A上，被访问次数极高，而其他缓存服务器负载较低，监视是否访问同一页面，如果是访问同一页面则把请求分到其他服务器。 7.目标地址散列（Destination Hashing）“目标地址散列”调度算法根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。目标散列调度：realserver中绑定两个ip。ld判断来者的ISP商，将其转到相应的IP。 8.源地址散列（Source Hashing）“源地址散列”调度算法根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。了解这些算法原理能够在特定的应用场合选择最适合的调度算法，从而尽可能地保持Real Server的最佳利用性。当然也可以自行开发算法，不过这已超出本文范围，请参考有关算法原理的资料。源散列调度：源地址散列。基于client地址的来源区分。（用的很少） 补充：为什么4层性能比7层更好？在7层，因为负载均衡器要获取报文内部的内容，因此要先和客户端建立连接，才能收到客户发过来的报文内容，然后获取报文内容之后，再根据调度算法进行负载。也就是说7层负载会和客户端和后端服务器分别建立一个TCP连接，而4层负载均衡只需要一次，因此性能肯定比4层差。 三种负载均衡产品之间的对比HAProxy和LVS的4层负载对比因为LVS是基于Linux内核的，但是HAProxy是属于第三方应用，因此在性能上，LVS占据绝对优势。因此，如果只是做纯4层转发，则使用LVS HAProxy对比NginxHAProxy支持更为丰富的后端节点检测机制，并且性能比Nginx好，因此在并发量较大的情况下，使用HAproxy，日PV并发量较小的情况下可以使用Nginx，配置也较为简单。 4. Redis持久化策略数据持久化策略主要分为RDB和AOF两种 RDB方式：数据文件内记录的是实际的数据。因此在进行数据恢复的时候，速度较快。适合全量备份。在进行RDB持久化时，会fork出一个单独的进行，因此会CPU的开销较大。 AOF方式：数据文件内记录的是产生数据变化的命令。因此在进行数据恢复的时候，速度较慢，并且其中的内容可以编辑，因此适合在执行了一些类似flushall或者flushdb等命令时进行数据恢复 混合持久化：Redis4.0版本之后的持久化，结合了RDB和AOF的有点，当进行AOF重写的时候，将会把当前的数据转变成为RDB形式进行保存，重写之后的数据继续以AOF的格式保存 主从复制在Redis2.6版本之前，主从复制时，每次传输的都是全量数据，因此会非常占用网络带宽和相关资源。在这之后，在Redis master节点上可以设置复制缓存区，来实现差异的增量复制。但是当缓冲区满了之后，还是会执行全量复制。 淘汰策略淘汰策略是指当Redis进行即将使用到设置的最大内存量，执行的一个策略，避免出现内存溢出的问题，也就是一种内存回收机制。一般在使用到maxmemory的90%时触发，默认策略是不回收。 在redis中可以配置的策略主要有以下几种： noeviction policy 【默认策略，永不过期策略。】不会删除任何数据，拒绝任何写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时Redis只响应读操作volatile-lru 根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止，如果没有可以删除的键对象，则回退到noeviction策略 allkeys-lru 根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 volatile-lfu 根据LFU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止，如果没有可以删除的键对象，则回退到noeviction策略 allkeys-lfu 根据LFU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 volatile-random 随机删除设置了超时属性（expire）的键，直到腾出足够的空间 allkeys-random 随机删除所有键，知道腾出足够空间为止 volatile-ttl 根据键值对象的ttl属性，删除最近将要过期的数据，如果没有，则回退到noeviction策略 常见性能问题 常见性能问题主要为： 内存设置不合理 大量的慢查询 key值（名称）设置过大 单个key的value过大 没有使用Redis的流水线功能 命令使用不合理，例如可以使用mset等或者禁止使用monitor等命令 客户端最大连接数设置【需要设置最大描述符，Redis默认会占用32个fd，因此可用的是1024-32】 TCP积压队列 定义AOF重写大小 客户端输出缓冲区 复制积压缓冲区 swap优化等等 哨兵模式 哨兵模式也就是Redis的高可用模式。一般的配置模式为一对主从，然后配置3个哨兵实例哨兵实例的设置原则：当有(n/2)+1个哨兵宣告需要进行切换时，才进行切换，这一点同样适用于zk等集群选举。因此最好3个以上的奇数个实例，偶数个会浪费一个。【这在5个以上节点时能看出明显的效果】 分布式集群 集群采用哈希槽的分配方式，一共有0-16383个槽最小建议配置为3主3从。Redis集群使用的是gossip协议。 cachecloud云平台 这是我从github上引入的Redis运维项目 5. Mysql+OracleMysql基础知识 Mysql主从复制原理 整体上来说，复制有3个步骤： A.master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； B.slave将master的binary log events拷贝到它的中继日志(relay log)； C.slave重做中继日志中的事件，将改变反映它自己的数据。 Mysql读写分离 Mysql高可用和集群有几种高可用方案：Mysql双主+keepalived【优点：架构简单，】 Mysql备份与恢复 逻辑备份：备份的是产生数据变化的sql语句。mysqldump能直接进行这个操作，但是因为它在备份过程中会锁表，并且备份的速度也非常的慢因此我们需要选择第三方工具。 物理备份：备份的是实际的数据，直接拷贝mysql的数据目录。 直接拷贝只适用于myisam类型的表。这种类型的表是与机器独立的。【这种备份的粒度较粗，不能实现更细粒度的数据恢复，特别是对于更新较为频繁的系统。】 实际生产环境中一般使用完整备份+增量备份每周日凌晨2点进行一次全量备份，之后的每天凌晨2点进行一次增量备份 然后再每天备份binlog日志【为了粒度更细致的数据恢复】 Mysql优化 mysql优化包括其他所有的网络服务优化，思路都是一致的。 分层次的来进行。【普遍规律+应用需求】 普遍规律： 首先是硬件层面 再次是操作系统层面的基础优化，例如文件描述符的数量，swap使用限制，文件系统（目前主流xfs） 再次是c/s架构方面的优化，例如TCP的连接队列大小，队列的缓存大小。tcp连接超时时间，tcp滑动窗口（发送和接受） 应用需求：数据库通用：最大连接数，索引（优先在where,order group等涉及的列上创建索引），sort，group等排序结果的缓冲区大小，慢查询，sql语句优化（减少使用like等开销大的语句），命令规范等Mysql：存储引擎 JAVA类：JVM设置，是否设置锁内存策略，堆内还是堆外内存，线程数量等。web类：压缩，静态文件缓存，CDN加速等 Mysql特殊：存储引擎等 Mysql常见问题 慢查询，sql写的有问题 mha的时候VIP漂移有问题 连接数问题 版本不一致问题 Oracle oracle没什么数据库概念上，oracle是只有一个数据库，然后里面有多用户，每个用户多表mysql是多个数据库，多个用户，采取授权的形式来访问 6. Ansible等自动化工具Ad-Hoc Ad-Hoc指的是一般性的临时操作 日常运维中主要使用的模块有： shell模块 yum模块 copy模块 service模块 PlaybookAnsible使用YAML语法描述配置文件，这个配置文件就被成为playbook，剧本 Ansible的核心理念是：极致的简单高效并且Ansbile是使用python编写的，因此在后续的二次开发上更占据优势。另一个趋势是python的运行方式，它和区块链一致，采用的是去中心化的部署方式，不需要安装客户端即可，通过SSH来实现，并且目前还提供了SSH的加速模式，适用于大规模的环境中，可以说，Ansible绝对是未来的趋势主流。 puppet、chef、slatstackpuppet和chef都是使用ruby编写的，并且配置繁琐，都需要配置客户端目前不适合 slatstack也是通过python编写，但是slatstack适用于更大的规模，因为ansible使用ssh来传输命令，而它使用zeroMQ来传输数据在1000台主机的情况下，MQ用时2秒左右，而ansible的SSH则用时85秒。 对比ansible默认情况下适用于200台以内的主机，适合中小型企业，如果数量再多可以使用Ansible的加速模式去实现 选型标准：选择最合适，如果当前的运维环境主机在百台，则ansible是最好的选择，如果上千台，那么无疑使用slatstack。 cobbler和kickstartkickstart是传统的批量装机方式，配置比较繁琐 cobbler是较早前的kickstart的升级版本，有点是容易配置 并且cobbler具有高级功能，可以根据不同机器的MAC地址来进行设置装机 关闭自动装机这里之前还发生过一个问题，就是有一次在装机的时候使用的是百兆交换机，导致老是有几台装不上，后来都换成千兆之后，就解决了这个问题。 关闭这个批量装机，因此centos的网卡名称不再是ethx的形式，因此在安装的时候，我们需要再ks文件中添加命令，来调整网卡的命令规则 7. Nginx，Httpd，tomcat，weblogic，php，gitlab，Jenkins这部分和web相关，主要是和电商，互联网公司等核心为web的紧密相关，也就是主要是LNMP这一套 Nginx基础知识基础知识 Nginx主要分为几个模块 全局配置【worker数量，worker的最大打开数量，CPU指定等】 Event模块配置【worker的最大连接数等，网络IO处理模型等】 Http模块【其中包括upstream段,server段,server中的location段等】 主要配置的地方就是HTTP模块中的upstream，server中的location段【动静分离等都是在这里进行配置】 注意：nginx的模块是静态的，在编译时就已经完全编译进去，而不是像Httpd是动态链接的形式 Nginx常见问题日志文件将磁盘存储空间占满了。 Nginx常见应用场景web服务器【一般会做动静分离，rewrite功能（重定向302是临时，301是永久，地址栏都改变，主要看爬虫变不变），防盗链】 负载均衡服务器 Nginx优化全局优化 工作进程数量（worker_processes数量）一般等于CPU的核数，因为每个进程是单线程的模式，使用epoll网络IO模型来进行处理。 worker_rlimit_nofile 60000；每个work进程最大打开文件数量。【这里需要跟操作系统的文件描述符相对应】 Event模块优化 worker进程最大连接优化，官方数据是能支持到5W【那么所有的连接数=5W*几个worker】 网络模型【通常使用epoll模型】 HTTP模块优化 不显示版本 关闭TCP延迟发送数据 keepalive的超时时间等 压缩传输的设置【压缩级别，压缩的触发大小】 Nginx和Httpd在这里主要说web，不说nginx的负载均衡，这部分已经在第3条说了。 tomcat常见问题**数据库连接问题，后端数据库异常，没有连接到tomcat乱码tomcat日志大小问题，权限问题JAVA_HOME没有设置正确 tomcat优化**主要分为2块，tomcat的JVM内存优化和tomcat的并发优化 内存优化：Tomcat内存优化主要是对 tomcat 启动参数优化，我们可以在 tomcat 的启动脚本 catalina.sh 中设置 java_OPTS 参数 JAVA_OPTS参数说明 -server 启用jdk 的 server 版； -Xms Java虚拟机初始化时的最小堆内存； -Xmx java虚拟机可使用的最大堆内存； 【堆内存建议设置一致，避免GC回收后再次动态分配，增大系统的开销】 -XX: PermSize 内存永久保留区域 -XX:MaxPermSize 内存最大永久保留区域 【这部分，默认64位的是256M】 JAVA_OPTS=’-Xms1024m -Xmx2048m -XX: PermSize=256M -XX:MaxNewSize=256m -XX:MaxPermSize=256m’ 并发优化/线程优化+缓存优化： 在Tomcat 配置文件 server.xml 中的 参数说明 1234567891011121314 maxThreads 客户请求最大线程数 表示最多同时处理多少个连接 minSpareThreads **Tomcat初始化时创建的 socket 线程数** maxSpareThreads **Tomcat连接器的最大空闲 socket 线程数 ** enableLookups 若设为true, 则支持域名解析，可把 ip 地址解析为主机名 redirectPort 在需要基于安全通道的场合，把客户请求转发到基于SSL 的 redirectPort 端口 acceptAccount 监听端口队列最大数，满了之后客户请求会被拒绝（不能小于maxSpareThreads ） connectionTimeout 连接超时 minProcessors 服务器创建时的最小处理线程数 maxProcessors 服务器同时最大处理线程数 URIEncoding URL统一编码 compression 打开压缩功能 compressionMinSize 启用压缩的输出内容大小，这里面默认为2KB compressableMimeType 压缩类型 connectionTimeout 定义建立客户连接超时的时间. 如果为 -1, 表示不限制建立客户连接的时间 参考配置： tomcat多实例部署http://blog.51cto.com/watchmen/1955972 传统方式复制目录的话，会造成资源浪费，因为lib和bin等公共资源会被多次加载，造成在内存中不必要的重复 思路：将bin下的文件和lib文件单独拆分出来 weblogicweblogic最开始bea公司的一个JAVA中间件产品，现在归属于oracle功能非常的强大，支持EJB比如在配置程序连接数据库时，不需要再代码中通过jdbc的方式去人工手动指定，而是通过后台管理页面的数据源配置中，进行配置。所以说，在一般的环境中，使用tomcat即可，如果涉及到大型的java应用开发，就要使用weblogic PHPPHP主要对接Nginx，处理php文件【通过php-fpm来处理】PHP-CGI 解释器每进程消耗 7 至 25 兆内存所以它的优化是进程数量的设置【包括启动时分配的，最小空闲的，最大空闲的，最大值】一般启动时分配5个，最小空闲为5个，最大空闲为32个，最大值为32个 GitlabJenkinsJDK支持tomcat支持maven支持Jenkins支持 Jenkins的安装一共有3个步骤 首先是下载war包到tomcat的webapps目录并将其重命名为ROOT.war，之后就是对其环境变量进行配置。 设定jenkins的目录及管理用户及编码修改tomcat目录下./conf/context.xml：增加jenkins环境变量 修改tomcat目录下的./conf/server.xml,是编码符合jenkins 步骤四：在第一次登陆jenkins页面时，需要输入一串加密数据这串数据位于其家目录下的./secrets/initialAdminPassword之中。 流程：JDK+tomcat部署Jenkins添加git 源码仓库使用maven进行构建【需要编写触发脚本，当有源码发生变化时，在2分钟后进行构建部署等操作】 8. 消息队列MQ产品使用MQ产品的原因 程序异步解耦 数据冗余 扩展性，不需要改变程序的代码，就可以扩展性能。 灵活性，峰值处理能力。 消息的顺序保证 异步通信，允许用户把消息放入队列中，但是并不立即处理它 ActiveMQ；老牌的MQ产品，完全遵守JMS规范。是apache开源的一个MQ产品，比较重量级，没有什么特殊的亮点 ActiveMQ的高可用集群模式通过ZK来实现，为了保证数据的一致性，因此会严重影响性能。从ActiveMQ 5.9开始，它实现了通过ZooKeeper + LevelDB实现高可用集群的部署方式。这种方式，对外只有Master提供服务这种方式实现了可以称之为半事务特性的机制，Master 将会存储并更新然后等待 (2-1)=1 个Slave存储和更新完成，才汇报 success RabbitMQ；遵循AMQP协议，借助erlang的特性在可靠性、稳定性和实时性上比别的MQ做得更好，非常重量级，性能比较好，适合企业级的开发。但是不利于做二次开发和维护 由于 rabbitmq 是使用 erlang 开发的，而 erlang 就是为分布式而生的。所以 rabbitmq 便于集群。rabbitmq 集群有两种模式：普通模式、镜像模式。 普通模式：也是默认模式，对于 queue 来说，消息实体只存在与其中的一个节点，A、B 两个节点只有相同的元数据，即队列的结构。当消息在A时，消费中从B中取消息时，消息会从A中传递到B中。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。 镜像模式：镜像模式是 rabbitmq 的 HA 方案。其与普通模式的唯一不同之处在于消息会在 A，B 两个节点中同步。当然这种模式带来的副作用也是显而易见的。除了降低系统性能以外，如果队列数量过多，网络带宽将会受到影响。所以这种情况只运用到对高可靠性要求的场合上。 集群配置方式：安装erlang,然后同步三台机器上的.erlang.cookie文件内容因为RabbitMQ的集群是依赖erlang集群，而erlang集群是通过这个cookie进行通信认证的，因此我们做集群的第一步就是干cookie。注意：erlang.cookie文件中cookie值一致，且权限为owner只读。因此需要设置为600 注意： RabbitMQ单节点环境只允许是磁盘节点，防止重启RabbitMQ时丢失系统的配置信息。RabbitMQ集群环境至少要有一个磁盘节点，因为当节点加入或者离开集群时，必须要将该变更通知到至少一个磁盘节点。 kafka；也是apache基金会的一个MQ产品。高吞吐量，消息的接受和消费都是落地到磁盘，因此适用于大数据环境流处理，对实时性要求不是太高的环境，可以积压非常庞大的数据量（瓶颈在磁盘） kafka是一种分布式的，基于发布/订阅的消息系统。有主分区和副本分区的概念。并且kafka中的数据是追加的形式，保证了消息的有序性 rocketmq；阿里开发并开发的一个MQ产品，纯JAVA开发。具有高吞吐量、高可用性、适合大规模分布式系统应用的特点。RocketMQ思路起源于Kafka，但并不是Kafka的一个Copy，它对消息的可靠传输及事务性做了优化，目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binglog分发等场景。 9. flume，zk，es，logstash，kibana系列flume flume：是一个日志收集软件。flume的agent设计实现这一系列的操作，一个agent就是一个java进程，运行在日志收集节点-也就是日志收集服务器节点。 agent里面包含3个核心的组件：source—-&gt;channel—–&gt;sink,类似生产者、仓库、消费者的架构。source:收集数据，可以处理各种类型sink：该组件是用于把数据发送到目的地的组件，目的地包括有：hdfs，kafka等等文件系统 工作流：flume的核心是把数据从数据源(source)收集过来，在将收集到的数据送到指定的目的地(sink)。为了保证输送的过程一定成功，在送到目的地(sink)之前，会先缓存数据(channel),待数据真正到达目的地(sink)后，flume在删除自己缓存的数据。 也就是说flume提供了一种类似事务机制。 flume的2种工作模式：主动模式和被动模式【主要是针对客户端来说】。这两种模式和zabbix的两种模式一样 在进行配置的时候，每个agent实例是通过别名来进行区分的。 kafka流式消息队列产品，接受flume发送过来的消息，或者日常产生端直接将JSON格式的数据发送到Kafka中。详见上方MQ产品 zookeeperzk:是一个分布式应用程序协调组件，用于为哪些原生没有提供集群功能的服务实现分布式集群。提供的功能包括：配置维护、域名服务、分布式同步、组服务等。zk的工作流：1、选举Leader。（选举zk集群中的leader）2、同步数据。3、选举Leader过程中算法有很多，但要达到的选举标准是一致的。4、Leader要具有最高的执行ID，类似root权限。5、集群中大多数的机器得到响应并接受选出的Leader。 注意：zk在3.5.0以上的版本会有一个内嵌的web服务，通过访问http://localhost:8080/commands来访问以上的命令列表。 一旦Zk集群启动之后，它将等待客户端的连接 esEs的主要功能是将收集的数据建立索引，方便日后数据的存储于检索。ES不止是一个全文本引擎，他还是一个分布式实时文档存储系统。这里，KCE的数据目的地和ES的数据来源设置成了一个分区，因此避免了磁盘IO的二次开销 logstash日志收集，需要在日志产生端配置，收集日志，再进行发送，目前使用flume来代替了。 kibanakibana不多说了，主要是提供了一个连接ES的入口 10. dockerdocker的核心三大组件是 镜像 容器 仓库 镜像主要分为几种，一个是官方的或者别人已经写好的镜像文件另一个可以自己产生镜像文件。 自己产生的镜像文件可以分为两种 在现有镜像的基础之上commit出来一个新的镜像 编写dockerfile文件，然后build出来一个镜像 建议通过dockerfile的形式产生镜像，因为使用commit出来的镜像会存在很多的缓存文件等。 容器是镜像的运行态，和程序及进程的概念比较像。 仓库主要分为两种，一个是存储镜像的仓库【里面的 镜像通过tag标签来尽心区分，默认是latest】，另一个是存储仓库名称的注册仓库 公网上的仓库可以是docker hub，也可以通过官方提供的registry镜像来简单搭建一套本地私有仓库环境: dockerfile编写dockerfile主要分为4个部分 基础镜像信息 from字段，也就是这个应用是以那个镜像为基础的 维护者信息，maintainer，也就是作者信息 镜像的操作指令，也就是在制作镜像是要执行的一系列操作，add加入一系列的文件，例如JDK，war包等 容器启动时执行指令-CMD，在启动时要执行的操作，例如启动项目等 在cachecloud中，基础镜像是使用的centos7.4-内核基础3.0-1811系统维护者是我，镜像的操作指令是JDK环境等等；容器启动时执行的命令是启动cachecloud项目 k8s k8s是谷歌开源的一个容器集群管理项目k8s对集群中的资源进行了不同级别的抽象，每个资源都是一个rest对象，通过API进行操作，通过JSON/YAML格式的模板文件进行定义要注意的是，k8s并不是直接对容器操作，它的操作最小单位是容器组。容器组由一个或多个容器组成。k8s围绕着容器组进行创建，调度，停止等生命周期管理。 ESXI,vsphere,xen,kvm 这些是第一家公司所使用的产品exsi和vsphere是vmware公司的企业虚拟化产品，相比于kvm，它有更好的性能，因此它是直接在物理上安装虚拟化操作系统，不需要第三方软件的实现。esxi是单机版本，vsphere是集中管理版本，支持在线迁移等高级功能。xenserver是思杰公司的一个虚拟化产品，单机的操作比vmware的esxi好，但是在涉及到多机环境时不是太好kvm需要linux系统的支持，然后还要安装一系列的组件，相对来说，更方便，但是不够专业，一般企业使用的相对较少。 11. 监控软件及JMX，JVMzabbix 我们的生产是怎么监控的 首先是监控模板，监控一些基础指标，例如CPU，内存，磁盘等 一些类似HAproxy，activemq等有web页面的应用我们通过web监控来实现【创建web场景，60秒内，尝试连接3次，如果3次都失败，则报警，这里还会涉及到一些有认证的页面，也是可以实现的。】 更高级一点的例如redis等应用，需要监控一些特定的指标，我们通过自定义监控项来实现。 JAVA类的应用，在后期慢慢的开放了JMX端口的情况下，陆续加入了JMX的监控。 自定义监控项为了简单高效，我们自己编写的脚本，判断引用的状态，将采用所能想到的一切来判断，然后再最后只输出一个0,如果服务不正常的话，则输出为1。 zabbix的一些优化操作采取zabbix的主动模式来进行监控使用自动发现的功能。 自动发现等操作 各监控产品的区别zabbix是一款商业的开源软件，涉及到的东西非常之多，因此官方能够靠咨询，技术服务等来收费运作。而cacti，nagios等是普通的开源软件，自然没有zabbix这么强大。 nagios的可视化功能非常弱，zabbix是有自己的可视化界面的【一般我们都是通过最新数据哪里查看，为了给zabbix减负，不是非必要的情况下，一般不会给监控项添加图形】它不支持自动发现，并且缺少图形展示工具，也没有历史数据，追查起来非常困难。 cacti是一个PHP程序它通过使用SNMP 协议获取远端网络设备和相关信息，（其实就是使用Net-SNMP 软件包的snmpget 和snmpwalk 命令获取）并通过RRDTOOL 工具绘图， 通过SNMP采集数据，并且自定义监控项等非常繁琐，报警方式需要添加插件等。 JMX监控 前提条件：需要JAVA类程序开放JMX端口【也就是开放API接口】 工作流：（1）zabbix_server需要知道一台主机上的特定端口的JMX值时，它会向Zabbix-Java-gateway进程去询问。这个连接进程叫做StartJavaPollers （2）Zabbix-Java-gateway使用JMXmanagementAPI这个API去查询特定的应用程序 注意：在配置的时候，StartJavaPollers线程数量要小于等于START_POLLERS设置的线程数量 这些操作操作完毕之后，在web页面上进行操作，添加JMX监控模板即可。 JVM调优 提到虚拟机的内存结构，可能首先想起来的就是堆栈。对象分配到堆上，栈上用来分配对象的引用以及一些基本数据类型相关的值。 JAVA虚拟机的内存结构是分了好几个区域的。分区域的好处是： 便于查找 便于内存回收【如果不分，回收内存就要全部内存扫描】 JVM内存分区（5部分）： 方法区 线程共享【这部分常被成为永久代，除了编译后的字节码之外，方法区中还会存放常量，静态变量以及及时编译器编译后的代码等数据。】 堆 线程共享【这部分一般是Java虚拟机中最大的一块内存区域，这块存储对象的实例。堆内存是垃圾收集器主要光顾的区域，一般来讲根据使用的垃圾收集器的不同，堆中还会划分为一些区域，比如新生代和老年代。新生代还可以再划分为Eden，Survivor等区域。另外为了性能和安全性的角度，在堆中还会为线程划分单独的区域，称之为线程分配缓冲区。更细致的划分是为了让垃圾收集器能够更高效的工作，提高垃圾收集的效率。】 Java栈 线程独享【每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。在Java虚拟机规范中，对于此区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。】 本地方法栈 线程独享【本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。】 程序计数器 线程独享【这部分内存不会内存溢出，字节码行号提示器】 堆（新生代和老年代等）： Xms256m 代表堆内存初始值为256MB Xmx1024m 代表堆内存最大值为1024MB如果-Xmx不指定或者指定偏小，应用可能会导致java.lang.OutOfMemory错误 方法区（永久代） PermSize和MaxPermSize指明虚拟机为java永久生成对象（Permanate generation）例如：class对象、方法对象这些可反射（reflective）对象分配内存限制，这些内存不包括在Heap（堆内存）区之中。-XX:PermSize=64MB 最小尺寸，初始分配XX:MaxPermSize=256MB 最大允许分配尺寸，按需分配这部分设置过小会导致：java.lang.OutOfMemoryError: PermGen space MaxPermSize缺省值和-server -client选项相关。-server选项下默认MaxPermSize为64m。 -client选项下默认MaxPermSize为32m 设置-Xms、-Xmx 相等以避免在每次GC 后调整堆的大小 在jdk1.8之前之前我们将储存类信息、常量、静态变量的方法区称为持久代(Permanent Generation)，PermSize和MaxPermSize是设置持久代大小的参数，在jdk1.8中持久代被完全移除了，所以这两个参数也被移除了，多了一个元数据区(Metadata Space)，所以设置元数据区大小的参数也变成对应的MetaspaceSize和MaxMetaspaceSize了 -XX:PermSize和-XX:MaxPermSize在jdk1.8中使用-XX:MetaspaceSize和-XX:MaxMetaspaceSize替代了现在能兼容正常启动，没有产生影响，知悉。 云产品说起阿里云，这期间还发生了一个人为事故。当初京东金融本来是通过我们的平台发送的，但是它要我们给他拉专线直接连接运营商。但是这边没有给他拉，而是买了一台阿里云服务器，暴露出一个公网IP地址让它连接，在这台服务器上面部署HAproxy，还是调整到我们的平台。【上边领导们的决定，我就不评论是非对错了 哈哈】 然后有一天，突然HAProxy的web监测报警，页面打不开。马上上服务器看，CPU爆了【买的服务器配置一般】检查进程。内存正常，磁盘正常，CPU爆了，然后再查看网络连接，发现有大量的CLOSE_WAIT（400个close_wait;100多个establish） 在TCP关闭时，主动关闭的一方发出 FIN 包，被动关闭的一方响应 ACK 包，此时，被动关闭的一方就进入了 CLOSE_WAIT 状态。如果一切正常，稍后被动关闭的一方也会发出 FIN 包，然后迁移到 LAST_ACK 状态。 导致产生大量close_wait的原因是突然遭遇大量的请求，即便响应速度不慢，但是也来不及消费，导致多余的请求还在队列里就被对方关闭了。（因为对方设置了超时时间）。但是linux没有对close_wait做类似超时控制的设置，如果不重启进程，这个状态很可能会永远的持续下去， AWS主要是当初想搭VPN，但是一大堆的限制，最终没成功，所以现在是直接买的商业的，稳定，速度也有保证。七牛云，产品主要是数据存储和CDN加速，我自己的博客目前也是在用七牛云。瑞江云，是公司在做什么业务时和人家合作时，人家送的，具体什么我就不知道了 13 自身素质关于这三个人的管理经验，是在第一家公司公司的时候。亿阳分为很多个部门，其中就有一个对外产品部门，当时是准备和人保合作，进入金融行业。因此拿下了一个标，但是招运维主管的时候的比较难招，差不不行，好的知道是外包驻场的形式一般也不愿意来，到最后实在没办法只能从公司内部要人了，然后就把我派过去了。在那边呆了有7个月左右。当时工作非常艰辛【上一家被换掉是因为政治原因，具体是谁就不知道了】，因此过去需要接受上一家的工作，然后开发二代新产品，中间不能停，也就是起承上启下的作用。当时1个月直接就瘦了10斤，天天加班。 高效办公系列软件TC:资源管理器Autohotey：热键管理器Listary：文件搜索浏览增强工具evernote:云笔记Fences:桌面管理工具Ditto：剪切板增强工具Snipaste：截图工具Everything:文件搜索工具 运维职业规划-如何通过运维思想做好运维工作运维思想-运维核心稳定性-网站/平台不宕机【这是运维的核心】一般通过以下方式来实现 架构使用集群+负载均衡+高可用+应用解耦，微服务等部署方式来保证性能 安全【】 运营推广不能在白天高峰期推广，需要和运维打招呼 前端图片的优化，不能使用大图等，尽量使用缩略图 数据库优化【加入Redis数据缓存层，sql语句优化等】 避免随时上线的操作【减少次数】 测试生产等环境保持一致【系统，软件版本，路径等等】 流程操作【运维标准和流程】 等等等等 数据不丢失 应用配置数据管理-【考虑使用CMDB等平台】 数据库数据 避免人为问题避免人为错误，主要分为两个方面， 一个是他人(主要是开发不严谨)产生的错误，这部分通过运维流程并结合工具控制。【比如测试不严谨，或者开发人员的代码有问题，直接把服务器资源跑没了】 一个是自己操作产生的问题，这部分通过一些智能化的自动化工具来尽量避免【避免在执行命令的时候误操作等等，常见的有】 解决：建立完善的流程制度，对运维来说，包括标准化，对开发测试来说，包括上线的流程化【通过运维制度和一些工具来实现】 提升运维效率这一点是放在最后的，是在上面都做好的前提下，然后再有这么一层，什么自动化，CICD，devops，不是说招几个运维开发就能解决的。一定是需要一个过程的。运维效率很重要，但是不能盲目的只盯住这个上面 个人如何做好运维工作主动性很多东西如果不主动去找系统负责人去推进，进度根本没法完成。 划重点的能力写文档，研究技术，培训讲解等，需要将其中最重要的东西给讲述出来。就比如在看书的时候，有时候一些大部头的书，可能一句话非常长，你要从中快速挑出这句话的重点。然后建立知识体系。【这就需要能快速的找出重点，快速浏览说明性的内容，因为有可能这些说明性内容对你目前的水平来说完全来说可以忽略】 全局观 比如像我当初对接那么多的系统，在出问题的时候，可能是后面某一个系统出问题，但是导致你直接无法使用，所以你需要根据症状， 态度某一项技术不会非常正常，要摆正心态，虚心向人学习，比如像开发学习，像DBA学习，等等。构建完善的知识体系。一个技术不会到会其实有时候就是一个月的事，根本没有大家想的那么恐怖，不要怕，大胆的去问。 换位思考，自身作则 上面的任务怎么说话去分派下去。怎么安排任务， 流程制度 流程化，制度化为了便于管理，减少出错的概率。因此要有流程和制度 新员工刚进来，可以适当的较少压力，因为有 分配任务的时候，要求下面的人去重复描述下，确保正确无误 优秀的思维去分享给团队，让团队一起成长 比如烧开水理论， 优秀的团队应该是一列高铁 个人职业规划个人现阶段的努力方向是能够快速解决问题这个要求就非常高，需要具备一定的开发能力。比如开发开发出来的程序，在测试上正常，但是一到生产上，服务器的负载就持续飙升，CPU资源被消耗殆尽，这个时候要能够快速的定位到进程。然后要能分析进程内部的资源消耗情况，比如调用内核的哪些系统调用的情况引起的异常等等，找到之后能不能定位到相应的程序代码，这样才能解决问题，而不是找到进程之后，简单的重启。【这一阶段基本上就是资深运维开发工程师级别，预计3年时间】 在这之后下一个阶段目标是未雨绸缪，在源头将问题遏制住因此需要具备开发能力，在软件需求评审和软件设计阶段就要参与进来。【在这一阶段基本上就达到了架构师的水平】 补充HTTP协议POST与GET的区别 GET是从服务器上获取数据，POST是向服务器传送数据 GET是通过发送HTTP协议通过URl参数传递进行接收，而POST是实体数据，通过表单提交 GET传送的数据量较小，不能大于2KB。POST传送的数据量较大，一般被默认为不受限制。 GET安全性非常低，POST安全性较高]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>职场</category>
        <category>Linux运维面试问题</category>
      </categories>
      <tags>
        <tag>Linux运维面试问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix的历史数据与趋势数据]]></title>
    <url>%2F2018%2F02%2F06%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2F%E8%BF%90%E7%BB%B4%E7%9B%91%E6%8E%A7%E4%BD%93%E7%B3%BB%2Fzabbix%2Fzabbix%E7%9A%84%E5%8E%86%E5%8F%B2%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%B6%8B%E5%8A%BF%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[参考链接官方文档 zabbix history trends历史与趋势数据详解 zabbix配置操作详解（三） Zabbix系统中的历史数据和趋势数据 正文历史与趋势历史数据和趋势数据是Zabbix系统中对采集到的监控项数据进行存储的两种方式。 历史根据设定的时间间隔保持每个收集的值， 而趋势是每个小时产生一个值（一条信息），内容为历史数据在一个小时内的平均值、最大值、最小值以及这一个小时内该监控项目所采集到的数据的个数。 在zabbix中的配置在监控项配置页面进行定义，在这里，我的配置是历史数据保留15天，趋势数据保留90天。如下图所示： 区别联系详解历史和趋势数据它们既有区别又有联系。 历史数据： Zabbix系统针对每个监控项目在每次采集时所收集到的数据，这个数据保存Zabbix系统数据库的历史表中，这就是所谓的历史数据。 因为每次所采集到的数据都保存在历史表中，所以如果监控项目的更新间隔越小，则在固定时间内所保存到历史表中的数据就越多。如果每个监控项目的更新间隔是30秒的话，则两个小时，该监控项目在Zabbix数据库的历史表中就会产生240条记录，一天就会产生2880条记录。 如果我们的Zabbix系统只监控一台被监控主机，且这台被监控主机只有一个被监控项目，那么每天产生2880条记录确实不值得一提的。但是，当我们监控系统所监控的项目比较多时，则这个数据量是非常大的。 比如说，如果我们监控系统监控1000个监控项目，且每个监控项目的更新间隔都是30秒，则每天历史表中就会产生2880*1000=2880000条记录，也即近300万条记录。而1000个监控项目可以监控多少主机呢？我们以48口的交换机为例，单监控每台交换机的每个端口的流量，则一台48口的交换机就有96个监控项目。所以，如果我们仅监控这样的48口的交换机，1000个监控项目只差不多只够监控10台这样交换机。由此可见，如果我们所监控主机的数量稍微多一点，或者更确切的来说，我们所监控的项目稍微多点，则Zabbix系统每天在其数据库中所产生的记录是非常大的。 因此，我们建议，如非必须的，我们在配置监控项目时，应尽量减小历史数据的保留天数，以免给数据库系统带来很大的压力。 趋势数据： 而趋势数据则不同，对于相同的更新间隔，系统所产生的趋势数据的数量远远没有历史数据那么庞大。对同一个监控项目，之所以趋势数据的数据量要远远小于历史数据的数据量，是由趋势数据的取值方式决定的。 趋势数据取值方式是，它取对应监控项目的历史数据在一个小时内的平均值、最大值、最小值以及这一个小时内该监控项目所采集到的数据的个数。 因此，不管一个监控项目的更新间隔是多少，它所对应的趋势数据在数据库中的记录都只有一条。更新间隔越小，仅可能导致数据个数增大，而不会影响该监控项目在趋势表里的记录条数的。 由此，或许你觉得趋势数据很不准确，你还是愿意保留更长时间的历史数据，以便查看较长时间的数据图。其实不是这样的，因为在Zabbix系统数据库的趋势表里不但保留一个小时内历史数据的最大值、最小值和平均值，而还保存这一个小时内所采集到的数据个数。因此，在要求并不是很高的场合，使用趋势数据绘出的监控项目的数据图的走势与用历史数据绘出的数据图的走势差别不会很大的。 不管是历史数据还是趋势数据，都会周期性被Zabbix服务器端一种称之为“主妇（housekeeper）”进程进行清理，它会周期性的删除过期的历史数据和趋势数据。 也正是因为这个进程的存在，才会使Zabbix系统数据的数据量不会一直的彭胀下去。而实际上，如果我们在保持Zabbix系统的被监控主机和被监控项目不变，且不更改监控项目的更新间隔的情况下，Zabbix系统的数据库的数据量会在增长到一定的数据量后不再增长，而是基本维持在这个数据量上不变。 “主妇”进程清理历史数据和趋势数据的频率可以在Zabbix服务器端组件(或服务器代理组件)的配置文件zabbix_server.conf中进行配置，它的配置项是HousekeepingFrequency。 特别注意： 1、 如果监控项目的“保留历史数据(天)”配置项被设置成0时，则数据库历史表中仅保留该监控项目所采集的最后一条数据，其它历史数据将不会被会保留。而且，引用该监控项目的触发器也只能使用该项目所采集的最后数据。因此，此时如果在触发器里引用该项目时使用max、avg、min等函数，其将没有意义。 2、 如果监控项目的“保留趋势数据(天)”配置项被设置成0时，则该项目在系统数据库的趋势表里将不保留任何数据。 配置建议具体该配置成什么样的周期，需要根据监控项以及数据库的配置以及对数据查看的要求程度来决定。这里只给出相关建议。 历史数据配置首先我们需要知道当前mysql的存储情况。在zabbix的前端页面上，我们可以看到如下图所示信息： 这个数值就是NVPS，也就是每秒处理平均数量（Number of processed values per second) 计算公式如下： 历史数据大小=NVPSx3600x24x365(天数)x50B 每个监控项大小约为50B，每秒条数为NVPS，一小时3600秒，一天24小时，一年365年。 具体单个监控项大小取决于数据库引擎，通常为50B 例如： 假设有6W个监控项，刷新周期都为60秒（我这里为30秒），那么每秒将会产生1000条数据，也就是每秒会向数据库写入1000条数据。如果我的历史数据保留天数为90天，那么需要的空间大小如下： 1000x3600x24x90x50=388 800 000 000(B) (约为362G，如果保存一年则为：362x4=1448G) 趋势数据配置因为趋势数据是每小时每个监控项一条记录，因此可以计算出大致所占的空间，其计算公式如下： 趋势数据大小=监控项个数x24x365(天数)x128B 每一个监控项的大小约为128B，每小时产生一条记录，一天24小时，一年365天 具体单个监控项大小取决于数据库引擎，通常为128B 例如： 假设有6W个监控项，保存一年的趋势数据，那么需要的空间如下： 60000x24x265x128=67 276 800 000(B) （约为67GB） 总结通过上面的计算对比，相信可以很直观的看到差别，在同样一年的情况下，历史与趋势所占存储空间的比例为：1448/67。 所以，具体选择什么周期需要根据公司的业务及实际情况（硬件配置等）来决定，并没有一个统一的标准，遵循这个公式，都可以很明确的计算预估出数据量情况。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>运维监控体系</category>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[autohotkeye常用操作]]></title>
    <url>%2F2018%2F02%2F06%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7%2FAutoHotKey%2Fautohotkeye%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言AutoHotkey是一个windows下的开源、免费、自动化软件工具。它由最初旨在提供键盘快捷键的脚本语言驱动(称为：热键)，随着时间的推移演变成一个完整的脚本语言。但你不需要把它想得太深，你只需要知道它可以简化你的重复性工作，一键自动化启动或运行程序等等；以此提高我们的工作效率，改善生活品质；通过按键映射，鼠标模拟，定义宏等。 参考资料官方https://autohotkey.com/docs/AutoHotkey.htm 民间https://jeffjade.com/2016/03/11/2016-03-11-autohotkey/https://ahkcn.github.io/docs/AutoHotkey.htm 下载安装下载地址autohotkey下载地址 使用说明 AutoHotkey doesn’t do anything on its own; it needs a script to tell it what to do. A script is simply a plain text file with the .ahk filename extension containing instructions for the program, like a configuration file, but much more powerful. A script can do as little as performing a single action and then exiting, but most scripts define a number of hotkeys, with each hotkey followed by one or more actions to take when the hotkey is pressed. 也就是说，在实际使用的时候，是通过autohotkey去调用脚本，然后再去执行一系列的操作 脚本是自己定义个一个后缀为.ahk的文件 然后双击启动Ahk2Exe.exe，选择自己编写的这个ahk文件，执行convert，之后会生成一个ahk.exe的可执行文件。启动这个ahk.exe文件，就将配置加载，之后就可以使用这些热键进行一系列的操作 一个脚本中对应一系列热键 脚本符号这里简单说明下脚本中常用符号代表的含义： # 号 代表 Win 键； ! 号 代表 Alt 键； ^ 号 代表 Ctrl 键； + 号 代表 shift 键； :: 号(两个英文冒号)起分隔作用； run， 非常常用 的 AHK 命令之一; ; 号 代表注释后面一行内容； *通配符 即使附加的修饰键被按住也能激发热键. 这常与 重映射 按键或按钮组合使用. 例如: *#c::Run Calc.exe 表示：Win+C、Shift+Win+C、Ctrl+Win+C 等都会触发此热键。 run它的后面是要运行的程序完整路径（比如我的Sublime的完整路径是：D:\Program Files (x86)\Sublime Text 3\sublime_text.exe）或网址。为什么第一行代码只是写着“notepad”，没有写上完整路径？因为“notepad”是“运行”对话框中的命令之一。 如果你想按下“Ctrl + Alt + Shift + Win + Q”（这个快捷键真拉风啊。(￣▽￣)）来启动 QQ 的话，可以这样写： ^!+#q::run QQ所在完整路径地址。 AutoHotKey的强大，有类似Mac下的Alfred2之风，可以自我定制(当然啦，后者还是强大太多)。所以可以说，它强大与否，在于使用者的你爱或者不爱折腾。学以致用，如果简单的折腾下，可以使得我们工作效率大幅提升，何乐不为？况且，在见识的增长中，这可以给我们思维带来极大的营养。以下是笔者常用功能的脚本配置： 温馨提示： 以下几个系统默认的 Win 快捷键，请自行确认是否覆盖 Win + E：打开资源管理器； Win + D：显示桌面； Win + F：打开查找对话框； Win + R：打开运行对话框； Win + L：锁定电脑； Win + PauseBreak：打开系统属性对话框; Win + Q: 本地文件/网页等搜索; Win + U: 打开控制面板－轻松使用设置中心; 配置使用这是我自行编写的脚本的内容 #q::Run https://wx.qq.com/ #w::Run http://watchmen.xin/ #e::Run E:\software\tcmd\totalcmd\TOTALCMD64.EXE #r::Run, E:\software\ss\Shadowsocks.exe #t::Run, E:\software\Snipaste\Snipaste.exe #y::Run, E:\software\TIMqq\Bin\QQScLauncher.exe #u::Run, E:\software\foxmail\Foxmail.exe #i::Run, E:\software\xmanager\Xshell.exe 进阶单热键多命令类似下面的这种设置被称为单行热键, 因为它们只包含单个命令. #n::Run Notepad ^!c::Run calc.exe 要在一个热键中执行多个命令，请把首行放在热键定义的下面，且在最后行命令的下一行添加 return。例如： #n:: Run http://www.google.com Run Notepad.exe return 如果要运行的程序或文档没有在环境变量中, 那么需要指定它的完整路径才能运行: Run %A_ProgramFiles%\Winamp\Winamp.exe 在上面的例子中, %A_ProgramFiles% 是 内置变量. 使用它而不使用像 C:\Program Files 这样的, 脚本可以有更好的移植性, 这表示它在其他电脑上能执行的可能性更大. 注意: 命令和变量的名称是不区分大小写的. 例如, “Run” 等同于 “run”, 而 “A_ProgramFiles” 等同于 “a_programfiles”. 要让脚本等到程序或文档关闭后才继续执行, 请使用 RunWait 代替 Run. 在下面的例子中, 一直到用户关闭记事本后 MsgBox 命令才会继续执行. RunWait Notepad MsgBox The user has finished (Notepad has been closed).]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>AutoHotKey</category>
      </categories>
      <tags>
        <tag>autohotkey</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛云-qshell工具常用命令]]></title>
    <url>%2F2018%2F02%2F05%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7%2F%E4%B8%83%E7%89%9B%E4%BA%91-qshell%2F%E4%B8%83%E7%89%9B%E4%BA%91-qshell%E5%B7%A5%E5%85%B7%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[前言/简介qshell是利用七牛文档上公开的API实现的一个方便开发者测试和使用七牛API服务的命令行工具。 该工具设计和开发的主要目的就是帮助开发者快速解决问题。 目前该工具融合了七牛存储，CDN，以及其他的一些七牛服务中经常使用到的方法对应的便捷命令，比如b64decode，就是用来解码七牛的URL安全的Base64编码用的，所以这是一个面向开发者的工具。 官方资料文档https://developer.qiniu.com/kodo/tools/1302/qshell 视频教程http://notdelete.echohu.top/spjc/qshell-win.mp4 安装/环境准备目前在windows上使用qshell需要执行以下几个步骤添加命令到系统 下载qshell，存储到指定文件夹，例如我这里是：E:\software\qshell 重命名，将qshell_windows_x64.exe重命名为qshell.exe 添加系统环境变量，将E:\software\qshell追加到环境变量中 命令选项参数 描述 -d 设置是否输出DEBUG日志，如果指定这个选项，则输出DEBUG级别的日志 -m 切换到多用户模式，这样所有的临时文件写入都在命令运行的目录下 -h 打印命令列表帮助信息，遇到参数忘记的情况下，可以使用该命令 -v 打印工具版本，反馈问题的时候，请提前告知工具对应版本号 命令列表 实际操作我们使用qupload来进行文件的管理 官方文档 命令参数展示 命令语法： 1qshell qupload [&lt;ThreadCount&gt;] &lt;LocalUploadConfig&gt; 命令参数： 配置参数展示qupload 功能需要配置文件的支持，配置文件支持的全部参数如下： { &quot;src_dir&quot; : &quot;&lt;LocalPath&gt;&quot;, &quot;bucket&quot; : &quot;&lt;Bucket&gt;&quot;, &quot;file_list&quot; : &quot;&lt;FileList&gt;&quot;, &quot;key_prefix&quot; : &quot;&lt;Key Prefix&gt;&quot;, &quot;up_host&quot; : &quot;&lt;Upload Host&gt;&quot;, &quot;ignore_dir&quot; : false, &quot;overwrite&quot; : false, &quot;check_exists&quot; : false, &quot;check_hash&quot; : false, &quot;check_size&quot; : false, &quot;rescan_local&quot; : true, &quot;skip_file_prefixes&quot; : &quot;test,demo,&quot;, &quot;skip_path_prefixes&quot; : &quot;hello/,temp/&quot;, &quot;skip_fixed_strings&quot; : &quot;.svn,.git&quot;, &quot;skip_suffixes&quot; : &quot;.DS_Store,.exe&quot;, &quot;log_file&quot; : &quot;upload.log&quot;, &quot;log_level&quot; : &quot;info&quot;, &quot;log_rotate&quot; : 1, &quot;log_stdout&quot; : false, &quot;file_type&quot; : 0 } 参数具体含义如下： 密钥设置单用户 1qshell account ak sk 多用户 1qshell -m account ak sk 这里的ak、sk在个人面板中的密钥管理中查看，点击显示，然后进行复制粘贴 如下图所示： 上传图片这里我们选择qupload方式来进行图片的上传，在windows本地创建一个文件夹用户放置图片数据，每次同步该文件夹即可，不用再单独每张上传 步骤1：创建本地图片文件夹如下图所示，在指定位置下创建一个文件夹用于存放图片，在这里，我把它和我的博客文件夹放在同级 步骤2：创建配置文件如下图所示，在指定目录下创建配置文件，注意，这里需要使用编辑打开，不要用notpad++这些编辑器 步骤3：执行命令进行上传准备工作都做好后，执行如下命令直接上传： qshell qupload 1 c:\Users\56810\blog\config.txt qshell qupload 1 C:\Users\Administrator\blog\config.txt 如下图所示 其他配置刷新缓存官方资料 使用七牛云提供的 qshell 命令行工具，参考使用文档，先设置密钥，然后执行 cdnrefresh 命令来刷新缓存。]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>七牛云-qshell</category>
      </categories>
      <tags>
        <tag>qshell</tag>
        <tag>七牛云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RSS介绍及使用]]></title>
    <url>%2F2018%2F02%2F04%2FIT%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-Linux%E8%BF%90%E7%BB%B4%E6%96%B9%E5%90%91%2FIT%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2FIT%E7%A7%91%E6%99%AE%E7%9F%A5%E8%AF%86%2FRSS%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[转载来源：http://www.ruanyifeng.com/blog/2006/01/rss.html RSS定义在解释RSS是什么之前，让我先来打一个比方。 读大学的时候，我有个习惯，就是每天要去看食堂后面的海报栏。在那里，会贴出各种各样最新的消息，比如哪个系要开讲座了、星期二晚上的电影放什么、二手货转让等等。只要看一下海报栏，就会对学校的各种活动心中有数。 如果没有海报栏的话，要想知道这些消息就会很麻烦。讲座消息会贴在各个系自己的公告栏里，电影排片表是贴在电影院里的，二手货消息则会贴在各幢宿舍的楼道里。我所在的大学有20几个系，一万多人，要想知道所有这些消息的话，即使是可能的话，也会相当的麻烦。 从这个例子出发，让我们来考虑一下互联网。 互联网是什么？最直观的说，就是一个杂乱无章的巨大信息源，其丰富和杂乱的程度，不仅是巨大的，而且几乎是无限的。 一个使用者，要想及时掌握的互联网上出现的最新信息，有办法吗？ 答案是没有办法，他只有一个网站一个网站的打开，去看有什么最新内容，就好比每天都必须去每一个系里走一遍，看有什么最新讲座。如果是几个网站，哪倒也不难，都去看一遍也花不了多少时间。但是随着你关注的网站数量上升，这项工作会迅速的变为”Mission Impossible”。想象一下，如果你每天关注几十个、甚至几百个网站，会是怎样的情景。光是打开它们的首页，就要花费多少时间啊，更别说浏览花去的时间了。 也许有人会说，普通人的话，谁会关心那么多网站啊？ 我要说，哪怕你只是一个网络的初级或最单纯的使用者，与你发生关系的网站数量也在急剧增加，因为Blog出现了。越来越多的人开始写作网络日志（Blog），把自己的想法和生活在网上展示，其中也必然包括你的朋友，或者其他你感兴趣的人。你想知道他/她的最新动向，就势必要留心他/她的Blog。所以，你的网站浏览清单总有一天会和你的电话本、MSN Message好友列表一样多，甚至更多。 那时，你会发现浏览网站会变成一种困难和低效率的行为。 有没有办法找到互联网上的”海报栏”，只去一个地方就知道你所想知道的所有最新内容？ 有，那就是RSS。 RSS内容和阅读器准确的说，RSS就像一个网站的海报，里面包括这个网站的最新内容，会自动更新。所以，我们只要订阅了RSS，就不会错过自己喜欢的网站的更新了。 但是光有海报还不行，还必须有海报栏，也就是说必须有RSS阅读器才行。因为RSS只是数据源，它本身是写给程序看的，必须经过阅读器转换，才能成为可以浏览的格式。 RSS阅读器多种多样，大致分为两种，一种是桌面型的，需要安装；另一种是在线型，直接使用浏览器进行阅读。 使用/订阅RSS在浏览器中订阅RSS，就必须先知道RSS的地址。一般来说，各个网站的首页都会用显著位置标明。名称可能会有些不同，比如RSS、XML、FEED，大家知道它们指的都是同样的东西就可以了。有时RSS后面还会带有版本号，比如2.0、1.0，甚至0.92，这个不必理会，它们只是内部格式不同，内容都是一样。 将RSS地址复制下来以后，你就可以在在线阅读器中添加。 以后，只用打开这一个网页，就可以看到所有你喜欢的网站的最新内容了。 推荐RSS阅读器个人目前在使用的RSS阅读器为：inoreader]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>IT基础知识</category>
        <category>IT科普知识</category>
      </categories>
      <tags>
        <tag>RSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown从入门到实践]]></title>
    <url>%2F2018%2F01%2F25%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7%2FMarkdown%2FMarkdown%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Markdown介绍Markdown 是一种轻量级标记语言，它以纯文本形式(易读、易写、易更改)编写文档，常用的标记符号也不超过十个，并最终以HTML格式发布,让写作者专注于写作而不用关注样式。 划重点： 轻量级 标记语言 纯文本，所以兼容性极强，可以用所有文本编辑器打开。 让你专注于文字而不是排版。 格式式转换方便，Markdown 的文本你可以轻松转换为 html、电子书等。 Markdown 的标记语法有极好的可读性，常用的标记符号不过十来个 参考资料看完我这篇文章，再看完我下面推荐的这些内容，然后对比归纳总结，认真实践后，可以说在平常工作学习中完全够用。 官方资料 Markdown 语法说明 (简体中文版) Markdown 语法介绍 易读易写!-MarkDown语法说明 个人文章 献给写作者的 Markdown 新手指南 Markdown——入门指南 Markdown 基本语法 编辑器 个人在用的编辑器是MarkdownPad 2。各个工具之间相差不会很大，熟练掌握快捷键是提高效率的好方法 核心理念Markdown 的目标是实现「易读易写」，成为一种适用于网络的书写语言。。不管从任何角度来说，可读性，都是最重要的。Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像强调。 划重点： 语法是非常简单的符号 即写即读 兼容HTMLMarkdown 的构想不是要使得 HTML文档更容易书写。HTML 已经很容易写了。Markdown 的理念是，能让文档更容易读、写和随意改。 HTML是一种发布的格式，而Markdown 是一种书写的格式。也因此，Markdown 的格式语法只涵盖纯文本可以涵盖的范围。 常用操作标题（MarkdownPad中快捷键为Ctrl+1/2/3/4）：Markdown 支持两种标题的语法，类 Setext 和类 atx 形式。类 Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），例如： This is an H1 ============= This is an H2 ------------- 任何数量的 = 和 - 都可以有效果。但是这种形式只支持2层标题。 类 Atx 形式则是在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶，例如： # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 强调在Markdown中，可以使用 和 _ 来表示斜体和加粗。*单个为斜体，2个为加粗 加粗（MarkdownPad中快捷键为Ctrl+b）：加粗部分使用方式如下： **Coding，让开发更简单** __Coding，让开发更简单__ 实际展示效果如下： Coding，让开发更简单 Coding，让开发更简单 斜体（MarkdownPad中快捷键为Ctrl+l）：斜体部分的使用如下： *Coding，让开发更简单* _Coding，让开发更简单_ 实际展示效果展示如下： Coding，让开发更简单 Coding，让开发更简单 列表无序列表（MarkdownPad中快捷键为Ctrl+u）：* list1 前面使用*号 - list2 前面使用-号 + list3 前面使用+号 效果如下： list1 list2 list3 有序列表(MarkdownPad中快捷键为Ctrl+shift+o）：1. list1 使用数字+英文的点号，空格后接数据 2. list2 效果如下： list1 list2 区块引用（MarkdownPad中快捷键为Ctrl+q）在我们写作的时候经常需要引用他人的文字，这个时候引用这个格式就很有必要了，在 Markdown 中，你只需要在你希望引用的文字前面加上 &gt; 就好了。注意&gt;和文本之间要保留一个字符的空格。 &gt; 数据1 使用&gt;号 &gt; 数据2 &gt; &gt; 二级引用 注意区块引用可以包含多级引用 &gt; 实际效果展示： 数据1 数据2 这是二级引用 三级引用 代码区块（MarkdownPad中快捷键为Ctrl+k）：代码区块包括3种，文字内和单独一行以及指定代码格式的区块行 文字内加区块，不会加空白处底纹使用``（数字1左边，ESC下面的按键） 实际效果展示：在文件中含有代码区块是什么样子 整行的代码区块行，会加空白处底纹（快捷操作：全部选中然后敲Tab）缩进4个空格或者一个制表符（tab键）或者将代码块包裹在代码块包裹在 “/` 之间（避免无休止的缩进）。 实际效果展示 123require 'redcarpet'markdown = Redcarpet.new("Hello World!")puts markdown.to_html 实际效果展示： 现在的效果就是整整一个的区块行，如果这段代码比较长的话，那么markdown就会在下面生成一个查看条，供用户左右拉取调整，就是如现在所示。 指定代码格式的区块行 实际效果展示： 12$ line1-test1$ line2-test2 分割线/分隔线（MarkdownPad中快捷键为Ctrl+r）：一行中用三个以上的星号、减号、底线来建立一个分隔线，可以在字符之间加入空格，也可以不加空格 * * * *** ***** --- - - - 实际效果展示如下： 网页链接网页链接有2种方式，一种是直接显示链接，一种是通过文字进行跳转 直接显示&lt;https://www.baidu.com&gt; 用&lt;&gt;尖括号将内容包起来，markdown就会自动把它转成链接。网页链接、邮箱链接等都采用这种方式 实际效果展示如下：这段话中将要插入百度https://www.baidu.com的链接 文字跳转More info: [Server](https://hexo.io/docs/server.html) 前面是解释性说明，[]内是可以跳转的文字，()内是真正访问的地址。 实际效果展示如下： 请点击百度调整到百度页面 图片链接图片链接分为2部分，一种是在文字中，通过文字来链接到图片位置，用户需要点击这个文字链接去查看图片，优点是使文字更简约，缺点是无法直观的看到图。因此，第二种方式是直接在文章中显示图片。 我们把这两种方式分别称之为：行内式和参考式 行内式行内式的图片语法看起来像是： ![Alt text](/path/to/img.jpg) 参考案例：![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 详细叙述如下： 一个惊叹号 ! 接着一个方括号，里面放上图片的替代文字 接着一个普通括号，里面放上图片的网址， 最后还可以用引号包住并加上 选择性的 ‘title’ 文字。 参考式参考式的图片语法则长得像这样： ![Alt text][id] 「id」是图片参考的名称，图片参考的定义方式则和连结参考一样： 参考案例：[id]: url/to/image &quot;Optional title attribute&quot; 参考式超链接一般用在学术论文上面，或者另一种情况，如果某一个链接在文章中多处使用，那么使用引用 的方式创建链接将非常好，它可以让你对链接进行统一的管理。 参考式同样适用于网页链接的使用 表格普通表格： First Header | Second Header | Third Header ------------ | ------------- | ------------ Content Cell | Content Cell | Content Cell Content Cell | Content Cell | Content Cell 设置表格两边内容对齐，中间内容居中，例如： First Header | Second Header | Third Header :----------- | :-----------: | -----------: Left | Center | Right Left | Center | Right 实际效果展示： First Header Second Header Third Header Left Center Right Left Center Right 文本居中居中使用html方式添加，格式如下： 1&lt;center&gt;这一行需要居中&lt;/center&gt; 文本居中的引用先看下实际效果： 主要用于主页等显示，和上面的文本场景有点不一样。 具体实现： &lt;!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --&gt; &lt;!-- 其中 class=&quot;blockquote-center&quot; 是必须的 --&gt; &lt;blockquote class=&quot;blockquote-center&quot;&gt;blah blah blah&lt;/blockquote&gt; &lt;!-- 标签 方式，要求NexT版本在0.4.5或以上 --&gt; {% centerquote %} content {% endcenterquote %} &lt;!-- 标签别名 --&gt; {% cq %} content {% endcq %} 添加空行&lt;br /&gt; 使用该方法进行插入 反斜杠转义\*literal asterisks\* 使用这种方式来输出*号 实际效果展示： *literal asterisks* 字体与字号字体，字号和颜色编辑如下代码 &lt;font face=&quot;黑体&quot;&gt;我是黑体字&lt;/font&gt; &lt;font face=&quot;微软雅黑&quot;&gt;我是微软雅黑&lt;/font&gt; &lt;font face=&quot;STCAIYUN&quot;&gt;我是华文彩云&lt;/font&gt; &lt;font color=#0099ff size=7 face=&quot;黑体&quot;&gt;color=#0099ff size=72 face=&quot;黑体&quot;&lt;/font&gt; &lt;font color=#00ffff size=72&gt;color=#00ffff&lt;/font&gt; &lt;font color=gray size=72&gt;color=gray&lt;/font&gt; Size：规定文本的尺寸大小。可能的值：从 1 到 7 的数字。浏览器默认值是 3 效果如下： 我是黑体字我是微软雅黑我是华文彩云color=#0099ff size=72 face=”黑体”color=#00ffffcolor=gray 字体颜色语法格式：&lt;font color=指定颜色的英文单词&gt;内容&lt;/font&gt;，例如 例如将字体颜色修改为红色： 代码为：&lt;font color=red&gt;内容&lt;/font&gt; 内容 背景色&lt;table&gt;&lt;tr&gt;&lt;td bgcolor=orange&gt;背景色是：orange&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 实际效果如下： 背景色是：orange 删除线文本两端加上两个~~即可 删除我 复选框列表在列表符号后面加上[]或者[x]代表选中或者未选中情况 - [x] C - [x] C++ - [x] Java - [x] Qt - [x] Android - [ ] C# - [ ] .NET 实际效果为 C C++ Java Qt Android C# .NET 生成目录-TOC插件首先下载和安装 Visual Studio Code 锚点网页中，锚点其实就是页内超链接，也就是链接本文档内部的某些元素，实现当前页面中的跳转。比如我这里写下一个锚点，点击回到目录，就能跳转到目录。 在目录中点击这一节，就能跳过来。还有下一节的注脚。这些根本上都是用锚点来实现的。 语法描述： 代码： 这里使用截图的方式展示，因为直接编写的话，hexo会检测报错(因为%没有对应的%结尾) emoji表情Github的Markdown语法支持添加emoji表情，输入不同的符号码（两个冒号包围的字符）可以显示出不同的表情。 比如:blush:，可以显示: :blush: 注释注释是写作者自己的标注记录，不被浏览器解析渲染。HTML 以 结尾的闭包定义注释（支持跨行），不在正文中显示。 Markdown 沿用 HTML Comment 注释格式： &lt;!-- This text will not appear in the browser window. --&gt; 折叠块代码如下： &lt;details&gt; &lt;summary&gt;点击展开答案&lt;/summary&gt; &lt;p&gt; 象&lt;/p&gt; &lt;/details&gt; 效果如下： 你和猪，打一种动物 点击展开答案 象 代码高亮与原来使用缩进来添加代码块的语法不同，这里使用 来包含多行代码： 三个 ``` 要独占一行。 指定图片大小Markdown 不支持指定图片的显示大小，不过可以通过直接插入&lt;img /&gt;标签来指定相关属性： &lt;img src=&quot;https://avatars2.githubusercontent.com/u/3265208?v=3&amp;s=100&quot; alt=&quot;GitHub&quot; title=&quot;GitHub,Social Coding&quot; width=&quot;50&quot; height=&quot;50&quot; /&gt; 效果如下： 在单元格里换行借助于 HTML 里的 实现。 示例代码： | Header1 | Header2 | |---------|----------------------------------| | item 1 | 1. one&lt;br /&gt;2. two&lt;br /&gt;3. three | 示例效果： Header1 Header2 item 1 1. one2. two3. three]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TotalCommander常用快捷键]]></title>
    <url>%2F2018%2F01%2F25%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%B7%A5%E5%85%B7%2FTotalCommander%2FTotalCommander%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[基础知识参考资料可以先看下相关资料，这些资料对概念介绍等做的非常详细也写的非常好，因此这里不再赘述，本文主要是针对实际的运用。 官方资料 https://www.ghisler.com/官网上没有相对应的文档，需要额外去搜寻 优秀个人文章 TC学堂——最易读的Total Commander教程-强烈推荐通过该网站进行学习 Total Commander快捷键 实际操作常用目录这部分设置可以说是TC操作的精华，效率直接甩开windows资源管理器几条街。 快速添加ctrl+d，添加，然后a直接添加 常用目录高级配置通过自定义配置，可以自定义调整常用目录的名称、顺序等，后续的增删改查也在此页面进行。 ctrl+d，添加，进去之后按c进入常用目录配置对话框。在里面配置的时候，需要再最前面人为添加&amp;。 名称设置： &amp;1 test $b blog 命令参考设置： cd C:\Users\56810\blog\blog 直达组合键通过直达组合键，可以直接切换到指定目录下。 设置：alt+s 调出窗口，再按s进行配置。一共可以使用的个数是一般都是类似ctrl+alt+F1/F2..F11这么11个组合键 名称设置： &amp;1 desktop $b blog 命令参考设置： cd C:\Users\56810\blog\blog 配置完成之后，切换到桌面只需要：alt+s+1 切换磁盘分区Alt+F1调出分区选项之后，按D则进入D盘，E则进入E盘。 目录内容查看Alt+1 详细的列表信息 Alt+2 图形信息显示 Alt+3 目录树显示 多Tab标签操作ctrl+t 新建tab ctrl+上箭头 新建父目录tab ctrl+w 关闭标签 ctrl+shift+w 关闭所有非活动标签 ctrl+tab, ctrl+shift+tab 在同侧的tab间切换 改变tab排列顺序（包括在两个窗口间移动）：鼠标左键拖动。 自定义快捷键，直接切换到第N个标签可以在 wincmd.ini 中 [Shortcuts] 段，增加如下内容， C+1=cm_SrcActivateTab1 C+2=cm_SrcActivateTab2 C+3=cm_SrcActivateTab3 效果： ctrl+1～3 激活第 1～3 个标签，依次类推 压缩操作压缩： 选中文件之后，执行Alt+F5 查看压缩文件内容（不解压缩）： ctrl+右箭头或者直接回车 解压缩：Alt+F9 文件搜索Alt+F7 创建操作F7/Shift+F7 新建一个或多层文件夹。可以像DOS那样新建多层的目录，比如c:\file\a\b\c Shift+F4 新建文本文件，调用记事本编辑（自定义编辑器） 其他快捷键ctrl +e 进入资源管理器 alt + f1 选择第一个窗口的磁盘 +f2就是选择第二个窗口的磁盘 alt+下箭头 历史记录 alt+左箭头 返回上一个操作目录（历史目录） alt+右箭头 返回下一个操作目录（历史目录） ctrl+\ 返回到当前目录的根目录 Ctrl+Shift+Enter 查看当前的路径 shift+F10 右键 F3 文件内容预览 ctrl+M 批量重命名 Shift+F4 新建文本文件，调用记事本编辑（自定义编辑器） Ctrl+加号 全部选择同一类型的文件（例如压缩文件，目录文件） Ctrl+减号 全部取消同一类型的文件（例如压缩文件，目录文件）]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>TotalCommander</category>
      </categories>
      <tags>
        <tag>TC操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F01%2F23%2F%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%2F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%2FHexo%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is my first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask author on GitHub. 前言之前使用阿里云结合wordpress的方式搭博客，但是自己维护起来不是太方便，云服务器一旦攻击，数据是个问题。之后在51cto和csdn上写，但是要受到平台的限制。最近发现github有博客功能(几年前就推出了，竟然现在才发现)，完美解决这些问题。github提供空间，用户自行选择博客框架，专注于内容，大部分人应该还是喜欢这种简约风主题。目前这个博客使用github-pages+Hexo来实现。 参考资料搭建 https://zhuanlan.zhihu.com/p/26625249 http://eleveneat.com/2015/04/24/Hexo-a-blog/ 进阶 主要参考官方资料 Hexo文档 https://hexo.io/zh-cn/docs/ Next主题使用手册 http://theme-next.iissnan.com/ 根据官方资料，按图索骥，基本上都能很好的把所有功能实现出来。使用问题可以随时沟通交流 markdown语法 关于markdown的使用，可以看我的这篇博文 Markdown语法 Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy Generate static files + Deploy to remote sites1$ hexo g -d More info: Deployment]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>个人博客</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
