<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ELK架构之Filebeat+kafka+logstash+Elasticsearch]]></title>
    <url>%2F2018%2F04%2F17%2FELK%E6%9E%B6%E6%9E%84%E4%B9%8BFilebeat-kafka-logstash-Elasticsearch%2F</url>
    <content type="text"><![CDATA[整体架构 组件关系说明： logstash 和filebeat都具有日志收集功能，filebeat更轻量，占用资源更少，但logstash 具有filter功能，能过滤分析日志。一般结构都是filebeat采集日志，然后发送到消息队列，redis，kafaka。然后logstash去获取，利用filter功能过滤分析，然后存储到elasticsearch中 filebeat–&gt;kafka集群–&gt;logstash–&gt;(file server文件系统|kafka集群|ES集群) Filebeat 日志收集 kafka 日志接受消息队列 logstash 将日志进行过滤分析后存储到ES ES 存储，检索，分析 Filebeat1. filebeat基础知识 Filebeat consists of two main components: prospectors and harvesters. These components work together to tail files and send event data to the output that you specify. prospectors:勘探者；探矿者【也就是数据变化的探测者，也就是入向配置】 harvesters：收割机；收获者【也就是数据的下游接收端，也就是出向配置】 spooler：处理程序；【处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。】 Filebeat工作流程： 当你开启filebeat程序的时候，它会启动一个或多个探测器（prospectors）去检测你指定的日志目录或文件，对于探测器找出的每一个日志文件，filebeat启动收割进程（harvester），每一个收割进程读取一个日志文件的新内容，并发送这些新的日志数据到处理程序（spooler），处理程序会集合这些事件，最后filebeat会发送集合的数据到你指定的地点。 流程图如下： 1.1 What is harvester? A harvester is responsible for reading the content of a single file. The harvester reads each file, line by line, and sends the content to the output. One harvester is started for each file. The harvester is responsible for opening and closing the file, which means that the file descriptor remains open while the harvester is running. If a file is removed or renamed while it’s being harvested, Filebeat continues to read the file. This has the side effect that the space on your disk is reserved until the harvester closes. By default, Filebeat keeps the file open until close_inactive is reached. Closing a harvester has the following consequences:【关闭时按以下顺序依`次执行，也就是关闭顺序】 The file handler is closed, freeing up the underlying resources if the file was deleted while the harvester was still reading the file.The harvesting of the file will only be started again after scan_frequency has elapsed. If the file is moved or removed while the harvester is closed, harvesting of the file will not continue. To control when a harvester is closed, use the close_* configuration options. harvester负责打开和关闭文件 当harvester捕获到一个文件之后，这个文件被删除或者重命名，它将继续读取这个文件。【副作用是占用磁盘空间直到harvester进程关闭】 1.2 What is prospector? A prospector is responsible for managing the harvesters and finding all sources to read from. If the input type is log, the prospector finds all files on the drive that match the defined glob paths and starts a harvester for each file. Each prospector runs in its own Go routine. The following example configures Filebeat to harvest lines from all log files that match the specified glob patterns: filebeat.prospectors: - type: log paths: - /var/log/*.log - /var/path2/*.log prospector负责管理harvesters进程以及寻找需要去读取的资源（input设置） Filebeat的input type当前有两种设置：log和stdin The log prospector checks each file to see whether a harvester needs to be started, whether one is already running, or whether the file can be ignored (see ignore_older).New lines are only picked up if the size of the file has changed since the harvester was closed. 注意，Filebeat只能读取本地的文件，也就是需要在每个日志产生端都安装：Filebeat prospectors can only read local files. There is no functionality to connect to remote hosts to read stored files or logs. 1.3 How does Filebeat keep the state of filesfilebeat通过定期去刷新，将状态落地到磁盘的注册文件中，以这种形式来保持文件检测状态 Filebeat keeps the state of each file and frequently flushes the state to disk in the registry file The state is used to remember the last offset a harvester was reading from and to ensure all log lines are sent filebeat的状态信息记录的是最新的读取偏移量，如果下游的接受者（ES、kafka、logstash等不可达），filebeat将会保持这种状态，当检测后可达之后将会重新发送 当filebeat重启时，将会重新构建这个注册文件 每个prospector针对每个文件都会保持一个状态，也就是一个注册文件，因为文件可能会被删除或者重命名 针对每个文件，filebeat存储一个唯一的标识符去发现该文件之前是否有被收集过 For each file, Filebeat stores unique identifiers to detect whether a file was harvested previously. 1.4 how does Filebeat ensure at-least-once delivery?Filebeat保证一个事件的完整及正确性，它将发送最少一次给设置的下游输出，以保证没有数据丢失。 Filebeat guarantees that events will be delivered to the configured output at least once and with no data loss. Filebeat is able to achieve this behavior because it stores the delivery state of each event in the registry file. Filebeat能够保证这种特性的原因是因为它将分发状态也存储在这个注册文件中。 当下游因为阻塞或者其他原因，没有对某一个事件进行确认的时候，filebeat将一直尝试去发送这个事件，直到收到ACK If Filebeat shuts down while it’s in the process of sending events, it does not wait for the output to acknowledge all events before shutting down. Any events that are sent to the output, but not acknowledged before Filebeat shuts down, are sent again when Filebeat is restarted. This ensures that each event is sent at least once, but you can end up with duplicate events being sent to the output. You can configure Filebeat to wait a specific amount of time before shutting down by setting theshutdown_timeout option. 当Filebeat异常关闭，再次启动的时候，它将会重新发送没有接受到ACk的事件。通过这种机制来保证每个事件至少发送一次。 因此，为了减少重新发送event事件的次数，可以通过设置shutdown_timeout参数来设置当filebeat关闭时，等待多少时间之后再关闭进程，以保证收到尽量多的ACK 注意：虽然拥有这种机制来保证数据的不丢失，但还是存在一些可能的情况导致数据的丢失（日志轮转和删除文件时） 例如： If log files are written to disk and rotated faster than they can be processed by Filebeat 【当日志刚好触发到日志轮转条件时，并且此时filebeat还没有来得及收集的时候，原因是inode节点发生变化】 if files are deleted while the output is unavailable 【当该文件被删除时，并且输出不可用时】 总结：filebeat会维护一个注册文件【是落地到磁盘中的】，该注册文件中包含2个信息 所发送事件的偏移量，精确记录当前的发送情况。 下游断开时，将保持直到连接后再发送 发送事件的ACk，记录发送事件的接受情况。 没有收到，将一直持续发送。 2. Filebeat安装部署配置启动2.1 安装curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.3-x86_64.rpm rpm -vih filebeat-6.2.3-x86_64.rpm 2.2 编辑配置文件配置文件生成规则 安装完毕之后，配置文件路径：/etc/filebeat/filebeat.yml参考配置文件为：filebeat.reference.yml 这里采用的是rpm包方式安装，因此生成规则如下： filebeat.yml整个配置文件分为几个部分，分别是： Modules configuration Filebeat prospectors【上游输入设置。这部分包含内容为：type设置|path路径设置，】 Filebeat autodiscover Filebeat global options General Elastic Cloud Outputs【下游输出设置。这部分内容为：ES|kafka|logstash|】 Paths Dashboards Template Logging Xpack Monitoring【xpack监控】 HTTP Endpoint 让我们来配置filebeat： 1、定义你的日志文件的路径（一个或多个） 对于大多数的基本filebeat配置，你可以定义一个单一探测器针对一个单一的路径，例如： filebeat.prospectors: - input_type: log paths: - /var/log/*.log 在这个例子中，探测器会收集/var/log/*.log的所有匹配文件，这意味这filebeat会手机所有的/var/log下以.log结尾的文件，此处还支持Golang Glob支持的所有模式。 在预定义级别的子目录中获取所有文件，可以使用这个配置：/var/log//.log，这会找到/var/log下所有子目录中所有的以.log结尾的文件。但它并不会找到/var/log文件夹下的以.log结尾的文件。现在它还不能递归的在所有子目录中获取所有的日志文件。 如果你设置输出到elasticsearch中，那么你需要在filebeat的配置文件中设置elasticsearch的IP地址与端口。 output.elasticsearch: hosts: [&quot;192.168.1.42:9200&quot;] 如果你设置输出到logstash|kafka等其他程序，那么请参考配置。例如下方 output.logstash: hosts: [&quot;127.0.0.1:5044&quot;] 完整的一个参考案例： filebeat.prospectors: - input_type: log #类型选择log|stdin中的log，在filebeat最新版本中input_type写成type paths: - /home/appdeploy/deploy/logs/pinpoint/*-pinpoint.log document_type: tools.pinpoint.data scan_frequency: 5s #prospector每隔5秒去检测日志的生成情况 tail_files: true #设置之后，filebeat读取新文件时从文件末尾开始读取，而不是开头，如果设置了日志轮转，那么新文件的第一行将会被忽略 output.kafka: #输出策略采用kafka hosts: [&quot;10.10.10.92:9092&quot;, &quot;10.10.10.93:9092&quot;, &quot;10.10.10.94:9092&quot;] #kafka集群的配置信息 topic: &apos;%{[type]}&apos; #设置topic使用文件类型 partition.round_robin: #Topic的分区算法 reachable_only: false # 如果设置为true，那么event将只会推送到leader上，默认设置就是false required_acks: 1 #ACk可靠性级别，0表示不响应，1表示本地commit，-1表示所有的副本commit。默认为1 compression: gzip # 设置输出压缩编解码器，可选snappy and gzip。默认就是gzip max_message_bytes: 1000000 # JSON格式的信息一个传输允许的最大大小上限 codec.format: string: &apos;%{[message]}&apos; 2.3 启动service filebeat start kafka在这里，kafka的作用是将 kafka的配置【其中一台，除了id不同之外，其他均类似】 [root@qa-bigdata002 config]# egrep -v ‘^#|^$’ server.properties broker.id=0 # The id of the broker. This must be set to a unique integer for each broker，在一个kafka集群中，每个broker的ID必须不同 port=9092 host.name=172.24.80.87 num.network.threads=3 #The number of threads handling network requests num.io.threads=8 # The number of threads doing disk I/O，将数据落地到磁盘的线程数量，一般为CPU核数的倍数 socket.send.buffer.bytes=102400 #发送缓冲区的大小，单位是字节，这里是1M socket.receive.buffer.bytes=102400 #接受缓冲区大小，这里是1M socket.request.max.bytes=104857600 #最大接受的请求数量，防止OOM的出现，out of memory,这里设置为104M log.dirs=/home/kafka/kafka-logs # 落地到磁盘的文件的存储路径 num.partitions=2 # 每个Topic的分区数量 num.recovery.threads.per.data.dir=1 #在日志数据恢复时， log.retention.hours=168 #日志保留小时数，这里的168小时，也就是保留7天。 log.segment.bytes=1073741824 #单个日志的文件的最大大小，现在配置为1G log.retention.check.interval.ms=300000 #每隔5分钟检测日志文件是否可以被删除 log.cleaner.enable=false #设置flase之后，日志保留策略将会采用上面的分段及超时设置，如果为true， zookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181 #ZK的配置 zookeeper.connection.timeout.ms=600000 #连接ZK的超时时间 consumer.properties # Zookeeper connection string # comma separated host:port pairs, each corresponding to a zk # server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot; zookeeper.connect=172.24.80.87:2181,172.24.80.88:2181,172.24.80.89:2181 # timeout in ms for connecting to zookeeper zookeeper.connection.timeout.ms=6000 #consumer group id group.id=test-consumer-group producer.properties # list of brokers used for bootstrapping knowledge about the rest of the cluster # format: host1:port1,host2:port2 ... metadata.broker.list=172.24.80.87:9092,172.24.80.88:9092,172.24.80.89:9092 zookeeper.properties # the directory where the snapshot is stored. dataDir=/tmp/zookeeper # the port at which the clients will connect clientPort=2181 # disable the per-ip limit on the number of connections since this is a non-production config maxClientCnxns=0 logstashElasticsearchES模板设置通过使用ES模板，可以有效的减轻存储压力ES模板：通过对索引中的每个字段做事先的预定义数据类型（例如ID，name等分别使用存储空间最小的数据类型）]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>大数据</category>
        <category>ELk日志处理平台</category>
        <category>Filebeat+kafka+logstash+Elasticsearch</category>
      </categories>
      <tags>
        <tag>ELK架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[异地多活机房建设]]></title>
    <url>%2F2018%2F04%2F17%2F%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9C%BA%E6%88%BF%E5%BB%BA%E8%AE%BE%2F</url>
    <content type="text"><![CDATA[1. 前言概述当前公司的核心应用都是运行在阿里云上，这种方式存在以下几个缺点： 星型拓扑结构，所有压力都集中在一套系统之上，整体系统的高可用性还不够充分。新增IDC机房之后，可以将一部分流量引入到就近的云下机房。为核心系统减负，也就是说，同一个应用对应有多个生产环境。 的 1.1 思路整体思路： 为什么？ 是什么？ 怎么做？ 1.2 为什么？为什么需要异地机房？1.3 是什么？ 异地机房应该是什么样子，能实现什么功能，对当前架构有什么影响？1.4 怎么做？ 如何实现？这部分内容将会在下面的章节进行具体的阐述。 2. 具体实施]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>运维架构</category>
        <category>异地多活</category>
      </categories>
      <tags>
        <tag>异地多活机房建设</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用软件激活密钥]]></title>
    <url>%2F2018%2F04%2F16%2F%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%BF%80%E6%B4%BB%E5%AF%86%E9%92%A5%2F</url>
    <content type="text"><![CDATA[vmware workstations 14 pro CG54H-D8D0H-H8DHY-C6X7X-N2KG6 【亲测可用】 ZC3WK-AFXEK-488JP-A7MQX-XL8YF AC5XK-0ZD4H-088HP-9NQZV-ZG2R4 ZC5XK-A6E0M-080XQ-04ZZG-YF08D ZY5H0-D3Y8K-M89EZ-AYPEG-MYUA8]]></content>
      <categories>
        <category>常用软件工具</category>
      </categories>
      <tags>
        <tag>软件激活密钥</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令之curl命令]]></title>
    <url>%2F2018%2F04%2F16%2FLinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"></content>
      <categories>
        <category>Linux常用命令</category>
        <category>curl</category>
      </categories>
      <tags>
        <tag>curl命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IT常用英语记录]]></title>
    <url>%2F2018%2F04%2F16%2F%E5%B8%B8%E7%94%A8%E8%8B%B1%E8%AF%AD%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[英语 释义 side effect 副作用 properties 性能，属性，性质，特性，财产 involves 包含，牵涉 at-least-once 至少一次 deprecated 弃用，废弃，不赞成的 shipper 托运人；发货人；货主 prospectors 勘探者；探矿者 harvesters 收割机；收获者 layout 布局；设计；安排；陈列 keystore 密钥库;文件;密码;签名文件 permitted 被允许的；允许 individual 个人的；个别的；独特的；个体]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>英语</category>
      </categories>
      <tags>
        <tag>IT常用英语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jumpserver安装部署及使用]]></title>
    <url>%2F2018%2F04%2F13%2Fjumpserver%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[1. 安装部署【注意：务必保证版本及操作一致】 参考链接：一步一步安装文档 1.1 环境准备1.1.1 安装依赖关系yum -y install wget sqlite-devel xz gcc automake zlib-devel openssl-devel epel-release git libffi-devel python-devel 注意：python-deve需要安装对应的版本，我这里安装的是python36-devel 1.1.2 建立python虚拟环境使用原因：因为 CentOS 6/7 自带的是 Python2，而 Yum 等工具依赖原来的 Python，为了不扰乱原来的环境我们来使用 Python 虚拟环境 如果服务器上没有python3.6.1+环境，则需要手动安装 $ wget https://www.python.org/ftp/python/3.6.1/Python-3.6.1.tar.xz $ tar xvf Python-3.6.1.tar.xz &amp;&amp; cd Python-3.6.1 $ ./configure &amp;&amp; make &amp;&amp; make install $ cd /opt $ python3 -m venv py3 $ source /opt/py3/bin/activate 看到下面的提示符代表成功，以后运行 Jumpserver 都要先运行以上 source 命令，以下所有命令均在该虚拟环境中运行 (py3) [root@localhost py3] 在源码安装python3时可能会出现报错，关键字：“ake: * [Objects/unicodeobject.o] Error 4”。这个时候，修改Makefile文件，把‘-DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes’中的‘03’改为‘02’，然后再重新编译安装即可。 1.2 安装启动 jumpserver1.2.1 下载jumpservercd /opt git clone --depth=1 https://github.com/jumpserver/jumpserver.git &amp;&amp; cd jumpserver &amp;&amp; git checkout master 注意：不要安装在/root、/home 等目录下，以免权限问题 1.2.2 安装RPM依赖包cd requirements yum -y install $(cat rpm_requirements.txt) 1.2.3 安装python库依赖pip install -r requirements.txt # 不要指定-i参数，因为镜像上可能没有最新的包，如果没有任何报错请继续 1.2.4 安装 Redis, Jumpserver 使用 Redis 做 cache 和 celery broke$ yum -y install redis $ service redis start 1.2.5 安装配置MySQLcreate database jumpserver default charset &apos;utf8&apos;; grant all on jumpserver.* to &apos;jumpserver&apos;@&apos;127.0.0.1&apos; identified by &apos;Jumpserver_password_123&apos;; 1.2.6 修改jumpserver配置文件$ cd /opt/jumpserver $ cp config_example.py config.py $ vi config.py # 我们计划修改 DevelopmentConfig中的配置，因为默认jumpserver是使用该配置，它继承自Config 注意: 配置文件是 Python 格式，不要用 TAB，而要用空格 在该文件中新添加一个类 class DevelopmentConfig(Config): DEBUG = True DB_ENGINE = &apos;mysql&apos; DB_HOST = &apos;127.0.0.1&apos; DB_PORT = 3306 DB_USER = &apos;jumpserver&apos; DB_PASSWORD = &apos;somepassword&apos; DB_NAME = &apos;jumpserver&apos; config = DevelopmentConfig() # 确保使用的是刚才设置的配置文件，该行默认在文件末尾就存在。 1.2.7 生成数据库表结构和初始化结构$ cd /opt/jumpserver/utils $ bash make_migrations.sh 1.2.8 运行jumpserver$ cd /opt/jumpserver $ python3 run_server.py all 运行不报错，请浏览器访问 http://192.168.244.144:8080/ (这里只是 Jumpserver, 没有 Web Terminal，所以访问 Web Terminal 会报错) 账号: admin 密码: admin 2. jumpserver配置2.1 安装 SSH Server 和 WebSocket Server: Coco【此时还是在虚拟环境下】 $ cd /opt $ git clone https://github.com/jumpserver/coco.git &amp;&amp; cd coco &amp;&amp; git checkout master 2.2 安装 Web Terminal 前端: Luna3. 常用命令启动 jumpserver /opt/jumpserver/service.sh start 停止 jumpserver /opt/jumpserver/service.sh stop 重启 jumpserver /opt/jumpserver/service.sh restart 查看 jumpserver 状态 /opt/jumpserver/service.sh status 4. 配置优化/注意事项配置文件路径：/opt/jumpserver/ jumpserver.conf、 配置如下： \[base] url = access_url（安装时配置） key = o57ev5oc1nwe44r4 ip = 0.0.0.0 port = 8000 log = debug \[db] engine = mysql host = mysql_addr（安装时配置） port = 3306 user = jumpserver password = password（安装时配置） database = jumpserver \[mail] mail_enable = 1 email_host = smtp.163.com email_port = 25 email_host_user = name@163.com（安装时配置） email_host_password = password（安装时配置） email_use_tls = False email_use_ssl = False \[connect] nav_sort_by = ip 问题/总结日志压缩删除 访问服务器记录日志生成路径：/opt/jumpserver/logs/tty 需要定时压缩文件夹，并保留一段时间的历史日志 压缩文件夹命令： for i in `ls -d 201802*`; do tar czvf ${i}.tar.gz ${i}; done 使用连接之后的终端页面如下所示：]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>运维安全</category>
        <category>堡垒机</category>
      </categories>
      <tags>
        <tag>jumpserver</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix结合Grafana实现炫酷动态可视化监控]]></title>
    <url>%2F2018%2F04%2F04%2FZabbix%E7%BB%93%E5%90%88Grafana%E5%AE%9E%E7%8E%B0%E7%82%AB%E9%85%B7%E5%8A%A8%E6%80%81%E5%8F%AF%E8%A7%86%E5%8C%96%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[来源：公众号-运维军团-《10分钟打造炫酷的监控大屏》 说明Grafana是一个开源的数据展示工具，是一个开箱即用的可视化工具，具有功能齐全的度量仪表盘和图形编辑器，有灵活丰富的图形化选项，可以混合多种风格，支持多个数据源，例如Graphite、InfluxDB、Mysql、Zabbix等等。虽然zabbix监控性能毋庸置疑，但zabbix图形显示过于简单、丑，因此利用zabbix作为数据源，结合Grafana作前端展示再好不过了。 重要的是Grafana的使用也超级简单，安装完成后登陆添加数据源即可，后面的事情就是添加图表等工作了。 实操未更新完，待续]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>运维监控体系</category>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>Grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ditto常用操作]]></title>
    <url>%2F2018%2F04%2F04%2Fditto%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[概述Ditto 是一款开源、免费、强大的剪贴板增强工具。可以把复制过的所有内容保存起来（可以设定保存日期或条目总数），快捷地供后续调用。还可以合并粘贴，纯文本粘贴，支持分组、置顶、快速搜索、热键粘贴功能。并且，还可以通过网络共享剪贴板内容。 主页：http://ditto-cp.sourceforge.net/ 教程：http://xbeta.info/ditto.htm 操作平常情况下，Ditto只是系统托盘中的图标。按下热键（默认 ctrl+`）后，会出现的粘贴主界面；再点击右键会弹出功能丰富的菜单。 详细请参看教程]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>Ditto</category>
      </categories>
      <tags>
        <tag>Ditto</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fences桌面]]></title>
    <url>%2F2018%2F04%2F04%2Ffences%E6%A1%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[下载安装目前的fences版本都是收费版本，可以下载免费版使用30天之后才酌情是否购买。官网 早期Fences免费版本连接：下载链接【该版本不是太好用】 使用fences的使用比较简单，这里介绍3点吧。 1、右键框选桌面空白处，即可出现桌面小区域。 这个应该大家都懂吧，基本功能。 2、桌面空白处双击鼠标左键，隐藏全部桌面图标 对桌面有洁癖的同学来说，这是个好福音。 3、设置好你的桌面区域后，可以锁定它们 当我们已经设置好桌面的区域后，可以将这些区域锁定，这样就无法再调整它们。 在桌面空白处右键鼠标，“查看”里选择“锁定fences”即可，这样你在桌面设置的这些fences小区域，就跟桌面“结合”在一起了，如果想要调整，取消勾选即可。]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>Fences</category>
      </categories>
      <tags>
        <tag>fences</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[listary常用操作]]></title>
    <url>%2F2018%2F04%2F04%2Flistary%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[参考资料官网 官网链接 网友文章 Listary——让文件在指尖流动 Listary Pro - 能极大幅度提高你 Windows 文件浏览与搜索速度效率的「超级神器」 实际操作常用快捷操作 ctrl敲2下 调出Listary窗口【可以在设置中设置第二种方式】 左键双击 在文件夹中双击会调出Listary的收藏，最近文档等。 在电脑页面输入e 即可定位到E盘，以此类推 目录页面输入名称一部分 定位到该子目录或者文件 ctrl+右键 针对选中内容进行动作【例如打开文件夹等】 智能匹配只要输入文件名的一部分就可以找到这个文件，支持中文与英文。 比如，我输入测试 md就可以搜索到测XX试OO.md这个文件。 自然，输入的越多，返回的结果越精确。随着使用记录的积累，常用的文件或程序会获得更高的优先级。 打开保存文件浏览对话框增强Ctrl+G 在打开框中切换到上一次打开的目录 Ctrl+O 直接打开上一次打开目录中的文件]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>Listary</category>
      </categories>
      <tags>
        <tag>Listary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简历内容应答]]></title>
    <url>%2F2018%2F04%2F04%2F%E7%AE%80%E5%8E%86%E5%86%85%E5%AE%B9%E5%BA%94%E7%AD%94%2F</url>
    <content type="text"><![CDATA[0. 自我介绍面试官 早上/下午好 我叫汪小华 大学就读于晋中学院 网络工程专业。目前一共有三年工作经验， 实习和第一份工作都是在亿阳信通在这期间从最基础的桌面运维干起，一直到最后独立接手负责了一个项目从0到1的这么一个整体过程，有很多的收获。这一期间对如何做好运维工作有了一些的感悟。 第二份工作是被内推到创世漫道，主要负责公司linux平台的调整，主要和我对接的是公司的架构师，因此在这个过程中对运维思想这方面有了很大的提升。 有关这两部分具体的内容我会在后面和您聊如何通过运维思想做好运维工作时谈及 我的优点是有一定的网络基础，平时喜欢问为什么，和同事交流谈论的时候喜欢拿纸笔写写画画。最强的技能部分应该是进程管理，这一点我觉得对运维工作来说，至关重要，关于这部分稍后我们可以一块交流探讨。 我的缺点目前是如何将所学知识有机的结合成为一个整体，构成一张知识之网这种能力还不够，这一点也是在后续的工作中需要去刻意修炼的。 以上是我的自我介绍，今天我要应聘的岗位是Linux运维工程师，谢谢！ 1. 发行版本区别及shell、python这些发行版本本质上没有什么区别，都是类unix系统。redhat的系统是免费的，但是他服务是收费的，并且有一些类似RHCS等服务只有收费版才支持。而centos是redhat社区版本，国内使用较多，社区相当活跃。SUSE也是分为两种，一种企业版本的SLES，一种是opensuse，sles主要是一些金融国企在使用，安全性较好，opensuse是社区版本，suse使用起来和centos相差不多，软件包形式使用源自redhat的rpm，但是管理工具使用的是zypper。ubuntu源自于debain，国外使用的较多，也是相当热门的一个发型版本，在桌面领域有绝对技术优势，适合开发人员使用。 **有关shell的问题，做面试题，看abs【每天看一点】。** python目前正在学习，目前基础部分已经学完了，正在学习django项目，学完之后，要花钱买一套马哥或者老男孩的python视频来补充，预计下半年能够做项目。 2. OSI模型、TCP/IP部分；路由交换基本原理OSI7层模型OSI 7层模式主要是由国际标准化组织（ISO）创建的，是一个国际通用的标准，它被开发出作为一个参照标准，用于指导如何设计网络通信系统。说的简单一点就是统一网络设备商的协议标准，实现不同网络设备和谐共存的环境（主机，路由器，交换机等等都是网络设置，都要遵循同一套的通信标准）它一共分为7层，每一层在网络通信数据传输过程中都定义了不同的功能。 OSI7层模型主要分为(从下到上)：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。每一层说明： layer function Application data flow；离用户最近的一层，它使一个网络应用能和另一个网络应用相互通信 Presentation 定义数据格式；数据压缩、加解密等。 Session 定义如何建立和终止连接，是告诉4层怎么做，4层只管被动的接受然后去做。 Transport 数据段；将上层的数据流进行分段；建立和终止网络连接；常用于流量控制和数据恢复 Network 数据包；使用IP地址在Internet上唯一确定一台设备；定义设备路由，寻址 Data link 数据帧；将上层数据封装成数据帧，其中包含源目MAC地址以及帧校验字段（用于检测传输错误）；它包含2个子层（LLC和MAC） Physical 比特流；定义了比特流如何在两台设备之间流通；主要涉及线缆，网卡， 下面是每一层常见的对应协议 layer protocol Application HTTP,FTP,Telnet,SMTP,SNMP Presentation MIME,TIFF,GIF,JPEG,PICT,ASCII,EBCDIC,encryption,MPEG,MIDI,HTML Session SSl/TLS,NetBIOS,RPC Transport TCP,UDP Network IP,ICMP,ARP,RARP Data link PPP,HDLC,IEEE 802.3/802.2,FDDI,ATM,IEEE 802.5/802.2 Physical Ethernet TCP/IP协议族TCP/IP模型类似OSI模型，作用也是描述一套指导标准，实现网络设备之间的通信，它被设计成4层 Application Transport Internet Network Access 其对应关系为： TCP/IP model OSI model Application Application Presentation Session Transport Transport Internet Network Network Access Data link Physical OSI和TCP/IP的区别除了层数的区别之外，它们之间最大的区别就是： OSI模型规定了在一个网络上传输数据所需要的步骤，并且它是非常具体的，定义了每一层使用什么协议以及如何使用；而TCP/IP模型是不特定的。另外一个区别就是，目前TCP/IP是所有网络设备上既定的协议事实，一般分析问题使用OSI模型。 路由技术我们在这里说的路由技术一般是指，路由转发。主要涉及设备为路由器或者三层交换机。这些设备上会维护一张路由表，其中的信息可以是通过动态路由协议（例如OSPF，EIGRP，ISIS，RIP，BGP，静态路由，默认路由等）获取组成路由表的内容是：出口接口和对应网段 路由设备接收到一个数据包之后，会解封装，获取其中的目的IP地址信息（网段信息），然后查找路由表，选择最优路由去转发。路由设备上也会有一张ARP表，根据广播域 交换技术在一个局域网内，也就是一个广播域内使用的技术。通常会涉及到的设备就是交换机。交换机上会维护一张MAC地址转发表，其中的信息是MAC地址和端口的映射关系。交换机根据数据帧中的目的MAC地址进行数据包的转发 注意：在一个广播域内的数据流动是依靠二层MAC来实现的，因为在第一次会涉及到ARP，有了记录之后，交换机会记录他的MAC地址表，后续的速度就会较快 这个时候可以在白板上进行讲解，大致的讲解百度页面打开的整个过程。 3. 高可用+负载均衡keepalived 2种角色：master和backup； 4种状态：stop,master,backup,fault 检测脚本2种触发机制 当VRRP检测脚本检测到自身所承载应用的返回值不为0的时候，就会触发角色变化，这个时候，VRRP脚本中如果没有设置weight权重值，那么直接进入fault状态，在vrrp组中发送组播通告，宣告自己进入异常状态，让出master角色并且不参与竞选如果脚本中设置了weight权重值，这个时候又会分为两种情况。 当weight权重值大于0时，master的优先级不变，backup的优先级为weight+现在优先级在wight权重值小于0时，master的优先级为目前的优先级减去weight的绝对值，backup的优先级保持不变。经过我多次的实验，目前保证最佳切换效果的配置是Vrrp检测脚本组中不配置weight，并且所有主机都设置为backup，设置不抢占参数，这种情况下，能有效避免优先级设置不当导致的切换不成功。 Nginx Nginx工作在应用层（使用location，通过正则表达表达式进行相关匹配），负载均衡是基于upstream模块实现的，因此配置比较简单。但是对后端服务器的健康检测只能支持端口Nginx的负载均衡算法可以分为两类：内置策略和扩展策略，内置的有轮询，ip_hash等。扩展的有fair，通用hash，一致性hash等。 Nginx的负载均衡目前支持5种调度算法： rr轮询【默认算法】；接受到请求之后，按照时间顺序逐一分配到后端不同的服务器上 wrr加权轮询；权重值越大，被分配访问的概率就越大，主要用于后端服务器性能不一致的情况 ip_hash；每个请求按访问IP的哈希结果分配，计算之后，nginx内部会维护一张哈希表，这样每个访客固定访问一个后端服务器，可以有效的解决动态网页存在的session共享问题。 fair;【第三方算法，需要通过额外安装upstream_fair模块实现】。更智能的一个负载均衡算法，此算法可以根据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。这种策略具有很强的自适应性，但是实际的网络环境往往不是那么简单，因此要慎用。 url_hash；【第三方算法，需要通过额外安装hash模块实现】。也是哈希算法，只不过不是基于源IP，而是基于访问的URL来生成这张哈希表。每个URL定向到同一台后端服务器，可以进一步提高后端缓存服务器的效率。 注意：当算法是ip_hash的时候，后端服务器不能被添加weight和backup 我们在location中配置nginx负载均衡的时候，还需要添加proxy_next_upstream http_500 http_502 error timeout invalid_header; 这一行参数。用于定义故障转移策略。当后端服务器节点返回500、502和执行超时等错误时，自动将请求转发到upstream负载均衡器中的另一台服务器，实现故障转移。 Nginx负载均衡工作流： 当客户端访问 xxx 域名时请求会最先到达负载均衡器,负载均衡器就会去读取自己server标签段中的配置 到location里面一看,原来这是一个要往后端web节点抛的请求 而后,nginx通过 proxy_pass的配置项 在自己的主配置文件找到了事先定义好的后端web节点 最后,按照事先设置好的调度算法,把请求带上主机头和客户端原始ip一起抛给后端准备好的web服务器 nginx负载均衡较适合用于日pv 2000W以下的站点 HAProxy Haproxy能实现基于4层和7层的负载均衡， HAproxy的8中负载均衡算法1、roundrobin表示简单的轮询，每个服务器根据权重轮流使用，在服务器的处理时间平均分配的情况下这是最流畅和公平的算法。该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。 2、leastconn连接数最少的服务器优先接收连接。leastconn建议用于长会话服务，例如LDAP、SQL、TSE等，而不适合短会话协议。如HTTP.该算法是动态的，对于实例启动慢的服务器权重会在运行中调整。 3、static-rr每个服务器根据权重轮流使用，类似roundrobin，但它是静态的，意味着运行时修改权限是无效的。另外，它对服务器的数量没有限制。 该算法一般不用； 4、source对请求源IP地址进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个客户端IP地址总是访问同一个服务器。如果哈希的结果随可用服务器数量而变化，那么客户端会定向到不同的服务器； 该算法一般用于不能插入cookie的Tcp模式。它还可以用于广域网上为拒绝使用会话cookie的客户端提供最有效的粘连； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 5、uri表示根据请求的URI左端（问号之前）进行哈希，用可用服务器的权重总数除以哈希值，根据结果进行分配。只要服务器正常，同一个URI地址总是访问同一个服务器。一般用于代理缓存和反病毒代理，以最大限度的提高缓存的命中率。该算法只能用于HTTP后端； 该算法一般用于后端是缓存服务器； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 6、url_param在HTTP GET请求的查询串中查找中指定的URL参数，基本上可以锁定使用特制的URL到特定的负载均衡器节点的要求； 该算法一般用于将同一个用户的信息发送到同一个后端服务器； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 7、hdr(name)在每个HTTP请求中查找HTTP头，HTTP头将被看作在每个HTTP请求，并针对特定的节点； 如果缺少头或者头没有任何值，则用roundrobin代替； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 8、rdp-cookie（name）为每个进来的TCP请求查询并哈希RDP cookie； 该机制用于退化的持久模式，可以使同一个用户或者同一个会话ID总是发送给同一台服务器。如果没有cookie，则使用roundrobin算法代替； 该算法默认是静态的，所以运行时修改服务器的权重是无效的，但是算法会根据“hash-type”的变化做调整。 2种配置方式指的是在1.3版本之前，ha的负载均衡配置主要是在listen部分中进行配置在1.3版本之后，为了更好的维护和管理，将负载均衡的配置拆分成为了frotend和backend这两部分，为了保证兼容性，listen部分依然保留，目前主要使用listen部分配置HA的监控页面 HA通过ACL实现一些7层的功能例如通过path_end的ACl方法实现动静资源分离 通过hdr_dom(host)和hdr_reg(host)和hdr_beg(host)的方法实现虚拟主机 LVS关于LVS，它本身只是支持负载均衡，没有检测机制，因此要结合keepalived来使用【keepalived的诞生原因就是为了给LVS提供后端节点检测功能，到后面才添加了高可用的功能】。在这里需要明确一点，它只能转发4层数据包【IP+port】但是检测是能通过7层url进行监测的。LVS的8种算法：1.轮叫调度（Round Robin）调度器通过“轮叫”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载。大锅饭调度：rr - 纯轮询方式，比较垃圾。把每项请求按顺序在真正服务器中分派 2.加权轮叫（Weighted Round Robin）调度器通过“加权轮叫”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器能处理更多的访问流量。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。带权重的大锅饭调度：wrr -带权重轮询方式。把每项请求按顺序在真正服务器中循环分派，但是给能力较大的服务器分派较多的作业。 3.最少链接（Least Connections）调度器通过“最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用“最小连接”调度算法可以较好地均衡负载。谁不干活就给谁分配：lc - 根据最小连接数分派 4.加权最少链接（Weighted Least Connections）在集群系统中的服务器性能差异较大的情况下，调度器采用“加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。带权重的谁不干活就给谁分配：wlc - 带权重的。机器配置好的权重高 5.基于局部性的最少链接（Locality-Based Least Connections）“基于局部性的最少链接”调度算法是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用“最少链接” 的原则选出一个可用的服务器，将请求发送到该服务器。基于地区的最少连接调度：lblc - 缓存服务器集群。基于本地的最小连接。把请求传递到负载小的服务器上 6.带复制的基于局部性最少链接（Locality-Based Least Connections with Replication）“带复制的基于局部性最少链接”调度算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。它与LBLC算法的不同之处是它要维护从一个目标 IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。该算法根据请求的目标IP地址找出该目标IP地址对应的服务器组，按“最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。带有复制调度的基于地区的最少连接调度：lblcr - 带复制调度的缓存服务器集群。某页面缓存在服务器A上，被访问次数极高，而其他缓存服务器负载较低，监视是否访问同一页面，如果是访问同一页面则把请求分到其他服务器。 7.目标地址散列（Destination Hashing）“目标地址散列”调度算法根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。目标散列调度：realserver中绑定两个ip。ld判断来者的ISP商，将其转到相应的IP。 8.源地址散列（Source Hashing）“源地址散列”调度算法根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。了解这些算法原理能够在特定的应用场合选择最适合的调度算法，从而尽可能地保持Real Server的最佳利用性。当然也可以自行开发算法，不过这已超出本文范围，请参考有关算法原理的资料。源散列调度：源地址散列。基于client地址的来源区分。（用的很少） 补充：为什么4层性能比7层更好？在7层，因为负载均衡器要获取报文内部的内容，因此要先和客户端建立连接，才能收到客户发过来的报文内容，然后获取报文内容之后，再根据调度算法进行负载。也就是说7层负载会和客户端和后端服务器分别建立一个TCP连接，而4层负载均衡只需要一次，因此性能肯定比4层差。 三种负载均衡产品之间的对比HAProxy和LVS的4层负载对比因为LVS是基于Linux内核的，但是HAProxy是属于第三方应用，因此在性能上，LVS占据绝对优势。因此，如果只是做纯4层转发，则使用LVS HAProxy对比NginxHAProxy支持更为丰富的后端节点检测机制，并且性能比Nginx好，因此在并发量较大的情况下，使用HAproxy，日PV并发量较小的情况下可以使用Nginx，配置也较为简单。 4. Redis持久化策略数据持久化策略主要分为RDB和AOF两种 RDB方式：数据文件内记录的是实际的数据。因此在进行数据恢复的时候，速度较快。适合全量备份。在进行RDB持久化时，会fork出一个单独的进行，因此会CPU的开销较大。 AOF方式：数据文件内记录的是产生数据变化的命令。因此在进行数据恢复的时候，速度较慢，并且其中的内容可以编辑，因此适合在执行了一些类似flushall或者flushdb等命令时进行数据恢复 混合持久化：Redis4.0版本之后的持久化，结合了RDB和AOF的有点，当进行AOF重写的时候，将会把当前的数据转变成为RDB形式进行保存，重写之后的数据继续以AOF的格式保存 主从复制在Redis2.6版本之前，主从复制时，每次传输的都是全量数据，因此会非常占用网络带宽和相关资源。在这之后，在Redis master节点上可以设置复制缓存区，来实现差异的增量复制。但是当缓冲区满了之后，还是会执行全量复制。 淘汰策略淘汰策略是指当Redis进行即将使用到设置的最大内存量，执行的一个策略，避免出现内存溢出的问题，也就是一种内存回收机制。一般在使用到maxmemory的90%时触发，默认策略是不回收。 在redis中可以配置的策略主要有以下几种： noeviction policy 【默认策略，永不过期策略。】不会删除任何数据，拒绝任何写入操作并返回客户端错误信息（error）OOM command not allowed when used memory，此时Redis只响应读操作 volatile-lru 根据LRU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止，如果没有可以删除的键对象，则回退到noeviction策略 allkeys-lru 根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 volatile-lfu 根据LFU算法删除设置了超时属性（expire）的键，直到腾出足够空间为止，如果没有可以删除的键对象，则回退到noeviction策略 allkeys-lfu 根据LFU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 volatile-random 随机删除设置了超时属性（expire）的键，直到腾出足够的空间 allkeys-random 随机删除所有键，知道腾出足够空间为止 volatile-ttl 根据键值对象的ttl属性，删除最近将要过期的数据，如果没有，则回退到noeviction策略 常见性能问题 常见性能问题主要为： 内存设置不合理 大量的慢查询 key值（名称）设置过大 单个key的value过大 没有使用Redis的流水线功能 命令使用不合理，例如可以使用mset等或者禁止使用monitor等命令 客户端最大连接数设置【需要设置最大描述符，Redis默认会占用32个fd，因此可用的是1024-32】 TCP积压队列 定义AOF重写大小 客户端输出缓冲区 复制积压缓冲区 swap优化等等 哨兵模式 哨兵模式也就是Redis的高可用模式。一般的配置模式为一对主从，然后配置3个哨兵实例哨兵实例的设置原则：当有(n/2)+1个哨兵宣告需要进行切换时，才进行切换，这一点同样适用于zk等集群选举。因此最好3个以上的奇数个实例，偶数个会浪费一个。【这在5个以上节点时能看出明显的效果】 分布式集群 集群采用哈希槽的分配方式，一共有0-16383个槽最小建议配置为3主3从。Redis集群使用的是gossip协议。 cachecloud云平台 这是我从github上引入的Redis运维项目 5. Mysql+OracleMysql基础知识 Mysql主从复制原理 整体上来说，复制有3个步骤： A.master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； B.slave将master的binary log events拷贝到它的中继日志(relay log)； C.slave重做中继日志中的事件，将改变反映它自己的数据。 Mysql读写分离 Mysql高可用和集群有几种高可用方案：Mysql双主+keepalived【优点：架构简单，】 Mysql备份与恢复 逻辑备份：备份的是产生数据变化的sql语句。mysqldump能直接进行这个操作，但是因为它在备份过程中会锁表，并且备份的速度也非常的慢因此我们需要选择第三方工具。 物理备份：备份的是实际的数据，直接拷贝mysql的数据目录。 直接拷贝只适用于myisam类型的表。这种类型的表是与机器独立的。【这种备份的粒度较粗，不能实现更细粒度的数据恢复，特别是对于更新较为频繁的系统。】 实际生产环境中一般使用完整备份+增量备份每周日凌晨2点进行一次全量备份，之后的每天凌晨2点进行一次增量备份 然后再每天备份binlog日志【为了粒度更细致的数据恢复】 Mysql优化 mysql优化包括其他所有的网络服务优化，思路都是一致的。 分层次的来进行。【普遍规律+应用需求】 普遍规律： 首先是硬件层面 再次是操作系统层面的基础优化，例如文件描述符的数量，swap使用限制，文件系统（目前主流xfs） 再次是c/s架构方面的优化，例如TCP的连接队列大小，队列的缓存大小。tcp连接超时时间，tcp滑动窗口（发送和接受） 应用需求：数据库通用：最大连接数，索引（优先在where,order group等涉及的列上创建索引），sort，group等排序结果的缓冲区大小，慢查询，sql语句优化（减少使用like等开销大的语句），命令规范等Mysql：存储引擎 JAVA类：JVM设置，是否设置锁内存策略，堆内还是堆外内存，线程数量等。web类：压缩，静态文件缓存，CDN加速等 Mysql特殊：存储引擎等 Mysql常见问题 慢查询，sql写的有问题 mha的时候VIP漂移有问题 连接数问题 版本不一致问题 Oracle oracle没什么数据库概念上，oracle是只有一个数据库，然后里面有多用户，每个用户多表mysql是多个数据库，多个用户，采取授权的形式来访问 6. Ansible等自动化工具Ad-Hoc Ad-Hoc指的是一般性的临时操作 日常运维中主要使用的模块有： shell模块 yum模块 copy模块 service模块 PlaybookAnsible使用YAML语法描述配置文件，这个配置文件就被成为playbook，剧本 Ansible的核心理念是：极致的简单高效并且Ansbile是使用python编写的，因此在后续的二次开发上更占据优势。另一个趋势是python的运行方式，它和区块链一致，采用的是去中心化的部署方式，不需要安装客户端即可，通过SSH来实现，并且目前还提供了SSH的加速模式，适用于大规模的环境中，可以说，Ansible绝对是未来的趋势主流。 puppet、chef、slatstackpuppet和chef都是使用ruby编写的，并且配置繁琐，都需要配置客户端目前不适合 slatstack也是通过python编写，但是slatstack适用于更大的规模，因为ansible使用ssh来传输命令，而它使用zeroMQ来传输数据在1000台主机的情况下，MQ用时2秒左右，而ansible的SSH则用时85秒。 对比ansible默认情况下适用于200台以内的主机，适合中小型企业，如果数量再多可以使用Ansible的加速模式去实现 选型标准：选择最合适，如果当前的运维环境主机在百台，则ansible是最好的选择，如果上千台，那么无疑使用slatstack。 cobbler和kickstartkickstart是传统的批量装机方式，配置比较繁琐 cobbler是较早前的kickstart的升级版本，有点是容易配置 并且cobbler具有高级功能，可以根据不同机器的MAC地址来进行设置装机 关闭自动装机这里之前还发生过一个问题，就是有一次在装机的时候使用的是百兆交换机，导致老是有几台装不上，后来都换成千兆之后，就解决了这个问题。 关闭这个批量装机，因此centos的网卡名称不再是ethx的形式，因此在安装的时候，我们需要再ks文件中添加命令，来调整网卡的命令规则 7. Nginx，Httpd，tomcat，weblogic，php，gitlab，Jenkins这部分和web相关，主要是和电商，互联网公司等核心为web的紧密相关，也就是主要是LNMP这一套 Nginx基础知识基础知识 Nginx主要分为几个模块 全局配置【worker数量，worker的最大打开数量，CPU指定等】 Event模块配置【worker的最大连接数等，网络IO处理模型等】 Http模块【其中包括upstream段,server段,server中的location段等】 主要配置的地方就是HTTP模块中的upstream，server中的location段【动静分离等都是在这里进行配置】 注意：nginx的模块是静态的，在编译时就已经完全编译进去，而不是像Httpd是动态链接的形式 Nginx常见问题日志文件将磁盘存储空间占满了。 Nginx常见应用场景web服务器【一般会做动静分离，rewrite功能（重定向302是临时，301是永久，地址栏都改变，主要看爬虫变不变），防盗链】 负载均衡服务器 Nginx优化全局优化 工作进程数量（worker_processes数量）一般等于CPU的核数，因为每个进程是单线程的模式，使用epoll网络IO模型来进行处理。 worker_rlimit_nofile 60000；每个work进程最大打开文件数量。【这里需要跟操作系统的文件描述符相对应】 Event模块优化 worker进程最大连接优化，官方数据是能支持到5W【那么所有的连接数=5W*几个worker】 网络模型【通常使用epoll模型】 HTTP模块优化 不显示版本 关闭TCP延迟发送数据 keepalive的超时时间等 压缩传输的设置【压缩级别，压缩的触发大小】 Nginx和Httpd在这里主要说web，不说nginx的负载均衡，这部分已经在第3条说了。 tomcat常见问题**数据库连接问题，后端数据库异常，没有连接到tomcat乱码tomcat日志大小问题，权限问题JAVA_HOME没有设置正确 tomcat优化**主要分为2块，tomcat的JVM内存优化和tomcat的并发优化 内存优化：Tomcat内存优化主要是对 tomcat 启动参数优化，我们可以在 tomcat 的启动脚本 catalina.sh 中设置 java_OPTS 参数 JAVA_OPTS参数说明 -server 启用jdk 的 server 版； -Xms Java虚拟机初始化时的最小堆内存； -Xmx java虚拟机可使用的最大堆内存； 【堆内存建议设置一致，避免GC回收后再次动态分配，增大系统的开销】 -XX: PermSize 内存永久保留区域 -XX:MaxPermSize 内存最大永久保留区域 【这部分，默认64位的是256M】 JAVA_OPTS=’-Xms1024m -Xmx2048m -XX: PermSize=256M -XX:MaxNewSize=256m -XX:MaxPermSize=256m’ 并发优化/线程优化+缓存优化： 在Tomcat 配置文件 server.xml 中的 参数说明 maxThreads 客户请求最大线程数 表示最多同时处理多少个连接 minSpareThreads **Tomcat初始化时创建的 socket 线程数** maxSpareThreads **Tomcat连接器的最大空闲 socket 线程数 ** enableLookups 若设为true, 则支持域名解析，可把 ip 地址解析为主机名 redirectPort 在需要基于安全通道的场合，把客户请求转发到基于SSL 的 redirectPort 端口 acceptAccount 监听端口队列最大数，满了之后客户请求会被拒绝（不能小于maxSpareThreads ） connectionTimeout 连接超时 minProcessors 服务器创建时的最小处理线程数 maxProcessors 服务器同时最大处理线程数 URIEncoding URL统一编码 compression 打开压缩功能 compressionMinSize 启用压缩的输出内容大小，这里面默认为2KB compressableMimeType 压缩类型 connectionTimeout 定义建立客户连接超时的时间. 如果为 -1, 表示不限制建立客户连接的时间 参考配置： tomcat多实例部署http://blog.51cto.com/watchmen/1955972 传统方式复制目录的话，会造成资源浪费，因为lib和bin等公共资源会被多次加载，造成在内存中不必要的重复 思路：将bin下的文件和lib文件单独拆分出来 weblogicweblogic最开始bea公司的一个JAVA中间件产品，现在归属于oracle功能非常的强大，支持EJB比如在配置程序连接数据库时，不需要再代码中通过jdbc的方式去人工手动指定，而是通过后台管理页面的数据源配置中，进行配置。所以说，在一般的环境中，使用tomcat即可，如果涉及到大型的java应用开发，就要使用weblogic PHPPHP主要对接Nginx，处理php文件【通过php-fpm来处理】PHP-CGI 解释器每进程消耗 7 至 25 兆内存所以它的优化是进程数量的设置【包括启动时分配的，最小空闲的，最大空闲的，最大值】一般启动时分配5个，最小空闲为5个，最大空闲为32个，最大值为32个 GitlabJenkinsJDK支持tomcat支持maven支持Jenkins支持 Jenkins的安装一共有3个步骤 首先是下载war包到tomcat的webapps目录并将其重命名为ROOT.war，之后就是对其环境变量进行配置。 设定jenkins的目录及管理用户及编码修改tomcat目录下./conf/context.xml：增加jenkins环境变量 修改tomcat目录下的./conf/server.xml,是编码符合jenkins 步骤四：在第一次登陆jenkins页面时，需要输入一串加密数据这串数据位于其家目录下的./secrets/initialAdminPassword之中。 流程：JDK+tomcat部署Jenkins添加git 源码仓库使用maven进行构建【需要编写触发脚本，当有源码发生变化时，在2分钟后进行构建部署等操作】 8. 消息队列MQ产品使用MQ产品的原因 程序异步解耦 数据冗余 扩展性，不需要改变程序的代码，就可以扩展性能。 灵活性，峰值处理能力。 消息的顺序保证 异步通信，允许用户把消息放入队列中，但是并不立即处理它 ActiveMQ；老牌的MQ产品，完全遵守JMS规范。是apache开源的一个MQ产品，比较重量级，没有什么特殊的亮点 ActiveMQ的高可用集群模式通过ZK来实现，为了保证数据的一致性，因此会严重影响性能。从ActiveMQ 5.9开始，它实现了通过ZooKeeper + LevelDB实现高可用集群的部署方式。这种方式，对外只有Master提供服务这种方式实现了可以称之为半事务特性的机制，Master 将会存储并更新然后等待 (2-1)=1 个Slave存储和更新完成，才汇报 success RabbitMQ；遵循AMQP协议，借助erlang的特性在可靠性、稳定性和实时性上比别的MQ做得更好，非常重量级，性能比较好，适合企业级的开发。但是不利于做二次开发和维护 由于 rabbitmq 是使用 erlang 开发的，而 erlang 就是为分布式而生的。所以 rabbitmq 便于集群。rabbitmq 集群有两种模式：普通模式、镜像模式。 普通模式：也是默认模式，对于 queue 来说，消息实体只存在与其中的一个节点，A、B 两个节点只有相同的元数据，即队列的结构。当消息在A时，消费中从B中取消息时，消息会从A中传递到B中。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。 镜像模式：镜像模式是 rabbitmq 的 HA 方案。其与普通模式的唯一不同之处在于消息会在 A，B 两个节点中同步。当然这种模式带来的副作用也是显而易见的。除了降低系统性能以外，如果队列数量过多，网络带宽将会受到影响。所以这种情况只运用到对高可靠性要求的场合上。 集群配置方式：安装erlang,然后同步三台机器上的.erlang.cookie文件内容因为RabbitMQ的集群是依赖erlang集群，而erlang集群是通过这个cookie进行通信认证的，因此我们做集群的第一步就是干cookie。注意：erlang.cookie文件中cookie值一致，且权限为owner只读。因此需要设置为600 注意： RabbitMQ单节点环境只允许是磁盘节点，防止重启RabbitMQ时丢失系统的配置信息。RabbitMQ集群环境至少要有一个磁盘节点，因为当节点加入或者离开集群时，必须要将该变更通知到至少一个磁盘节点。 kafka；也是apache基金会的一个MQ产品。高吞吐量，消息的接受和消费都是落地到磁盘，因此适用于大数据环境流处理，对实时性要求不是太高的环境，可以积压非常庞大的数据量（瓶颈在磁盘） kafka是一种分布式的，基于发布/订阅的消息系统。有主分区和副本分区的概念。并且kafka中的数据是追加的形式，保证了消息的有序性 rocketmq；阿里开发并开发的一个MQ产品，纯JAVA开发。具有高吞吐量、高可用性、适合大规模分布式系统应用的特点。RocketMQ思路起源于Kafka，但并不是Kafka的一个Copy，它对消息的可靠传输及事务性做了优化，目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binglog分发等场景。 9. flume，zk，es，logstash，kibana系列flume flume：是一个日志收集软件。flume的agent设计实现这一系列的操作，一个agent就是一个java进程，运行在日志收集节点-也就是日志收集服务器节点。 agent里面包含3个核心的组件：source—-&gt;channel—–&gt;sink,类似生产者、仓库、消费者的架构。source:收集数据，可以处理各种类型sink：该组件是用于把数据发送到目的地的组件，目的地包括有：hdfs，kafka等等文件系统 工作流：flume的核心是把数据从数据源(source)收集过来，在将收集到的数据送到指定的目的地(sink)。为了保证输送的过程一定成功，在送到目的地(sink)之前，会先缓存数据(channel),待数据真正到达目的地(sink)后，flume在删除自己缓存的数据。 也就是说flume提供了一种类似事务机制。 flume的2种工作模式：主动模式和被动模式【主要是针对客户端来说】。这两种模式和zabbix的两种模式一样 在进行配置的时候，每个agent实例是通过别名来进行区分的。 kafka流式消息队列产品，接受flume发送过来的消息，或者日常产生端直接将JSON格式的数据发送到Kafka中。详见上方MQ产品 zookeeperzk:是一个分布式应用程序协调组件，用于为哪些原生没有提供集群功能的服务实现分布式集群。提供的功能包括：配置维护、域名服务、分布式同步、组服务等。zk的工作流：1、选举Leader。（选举zk集群中的leader）2、同步数据。3、选举Leader过程中算法有很多，但要达到的选举标准是一致的。4、Leader要具有最高的执行ID，类似root权限。5、集群中大多数的机器得到响应并接受选出的Leader。 注意：zk在3.5.0以上的版本会有一个内嵌的web服务，通过访问http://localhost:8080/commands来访问以上的命令列表。 一旦Zk集群启动之后，它将等待客户端的连接 esEs的主要功能是将收集的数据建立索引，方便日后数据的存储于检索。ES不止是一个全文本引擎，他还是一个分布式实时文档存储系统。这里，KCE的数据目的地和ES的数据来源设置成了一个分区，因此避免了磁盘IO的二次开销 logstash日志收集，需要在日志产生端配置，收集日志，再进行发送，目前使用flume来代替了。 kibanakibana不多说了，主要是提供了一个连接ES的入口 10. dockerdocker的核心三大组件是 镜像 容器 仓库 镜像主要分为几种，一个是官方的或者别人已经写好的镜像文件另一个可以自己产生镜像文件。 自己产生的镜像文件可以分为两种 在现有镜像的基础之上commit出来一个新的镜像 编写dockerfile文件，然后build出来一个镜像 建议通过dockerfile的形式产生镜像，因为使用commit出来的镜像会存在很多的缓存文件等。 容器是镜像的运行态，和程序及进程的概念比较像。 仓库主要分为两种，一个是存储镜像的仓库【里面的 镜像通过tag标签来尽心区分，默认是latest】，另一个是存储仓库名称的注册仓库 公网上的仓库可以是docker hub，也可以通过官方提供的registry镜像来简单搭建一套本地私有仓库环境: dockerfile编写dockerfile主要分为4个部分 基础镜像信息 from字段，也就是这个应用是以那个镜像为基础的 维护者信息，maintainer，也就是作者信息 镜像的操作指令，也就是在制作镜像是要执行的一系列操作，add加入一系列的文件，例如JDK，war包等 容器启动时执行指令-CMD，在启动时要执行的操作，例如启动项目等 在cachecloud中，基础镜像是使用的centos7.4-内核基础3.0-1811系统维护者是我，镜像的操作指令是JDK环境等等；容器启动时执行的命令是启动cachecloud项目 k8s k8s是谷歌开源的一个容器集群管理项目k8s对集群中的资源进行了不同级别的抽象，每个资源都是一个rest对象，通过API进行操作，通过JSON/YAML格式的模板文件进行定义要注意的是，k8s并不是直接对容器操作，它的操作最小单位是容器组。容器组由一个或多个容器组成。k8s围绕着容器组进行创建，调度，停止等生命周期管理。 ESXI,vsphere,xen,kvm 这些是第一家公司所使用的产品exsi和vsphere是vmware公司的企业虚拟化产品，相比于kvm，它有更好的性能，因此它是直接在物理上安装虚拟化操作系统，不需要第三方软件的实现。esxi是单机版本，vsphere是集中管理版本，支持在线迁移等高级功能。xenserver是思杰公司的一个虚拟化产品，单机的操作比vmware的esxi好，但是在涉及到多机环境时不是太好kvm需要linux系统的支持，然后还要安装一系列的组件，相对来说，更方便，但是不够专业，一般企业使用的相对较少。 11. 监控软件及JMX，JVMzabbix 我们的生产是怎么监控的 首先是监控模板，监控一些基础指标，例如CPU，内存，磁盘等 一些类似HAproxy，activemq等有web页面的应用我们通过web监控来实现【创建web场景，60秒内，尝试连接3次，如果3次都失败，则报警，这里还会涉及到一些有认证的页面，也是可以实现的。】 更高级一点的例如redis等应用，需要监控一些特定的指标，我们通过自定义监控项来实现。 JAVA类的应用，在后期慢慢的开放了JMX端口的情况下，陆续加入了JMX的监控。 自定义监控项为了简单高效，我们自己编写的脚本，判断引用的状态，将采用所能想到的一切来判断，然后再最后只输出一个0,如果服务不正常的话，则输出为1。 zabbix的一些优化操作采取zabbix的主动模式来进行监控使用自动发现的功能。 自动发现等操作 各监控产品的区别zabbix是一款商业的开源软件，涉及到的东西非常之多，因此官方能够靠咨询，技术服务等来收费运作。而cacti，nagios等是普通的开源软件，自然没有zabbix这么强大。 nagios的可视化功能非常弱，zabbix是有自己的可视化界面的【一般我们都是通过最新数据哪里查看，为了给zabbix减负，不是非必要的情况下，一般不会给监控项添加图形】它不支持自动发现，并且缺少图形展示工具，也没有历史数据，追查起来非常困难。 cacti是一个PHP程序它通过使用SNMP 协议获取远端网络设备和相关信息，（其实就是使用Net-SNMP 软件包的snmpget 和snmpwalk 命令获取）并通过RRDTOOL 工具绘图， 通过SNMP采集数据，并且自定义监控项等非常繁琐，报警方式需要添加插件等。 JMX监控 前提条件：需要JAVA类程序开放JMX端口【也就是开放API接口】 工作流：（1）zabbix_server需要知道一台主机上的特定端口的JMX值时，它会向Zabbix-Java-gateway进程去询问。这个连接进程叫做StartJavaPollers （2）Zabbix-Java-gateway使用JMXmanagementAPI这个API去查询特定的应用程序 注意：在配置的时候，StartJavaPollers线程数量要小于等于START_POLLERS设置的线程数量 这些操作操作完毕之后，在web页面上进行操作，添加JMX监控模板即可。 JVM调优 提到虚拟机的内存结构，可能首先想起来的就是堆栈。对象分配到堆上，栈上用来分配对象的引用以及一些基本数据类型相关的值。 JAVA虚拟机的内存结构是分了好几个区域的。分区域的好处是： 便于查找 便于内存回收【如果不分，回收内存就要全部内存扫描】 JVM内存分区（5部分）： 方法区 线程共享【这部分常被成为永久代，除了编译后的字节码之外，方法区中还会存放常量，静态变量以及及时编译器编译后的代码等数据。】 堆 线程共享【这部分一般是Java虚拟机中最大的一块内存区域，这块存储对象的实例。堆内存是垃圾收集器主要光顾的区域，一般来讲根据使用的垃圾收集器的不同，堆中还会划分为一些区域，比如新生代和老年代。新生代还可以再划分为Eden，Survivor等区域。另外为了性能和安全性的角度，在堆中还会为线程划分单独的区域，称之为线程分配缓冲区。更细致的划分是为了让垃圾收集器能够更高效的工作，提高垃圾收集的效率。】 Java栈 线程独享【每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。在Java虚拟机规范中，对于此区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展，当扩展时无法申请到足够的内存时会抛出OutOfMemoryError异常。】 本地方法栈 线程独享【本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。】 程序计数器 线程独享【这部分内存不会内存溢出，字节码行号提示器】 堆（新生代和老年代等）： Xms256m 代表堆内存初始值为256MB Xmx1024m 代表堆内存最大值为1024MB如果-Xmx不指定或者指定偏小，应用可能会导致java.lang.OutOfMemory错误 方法区（永久代） PermSize和MaxPermSize指明虚拟机为java永久生成对象（Permanate generation）例如：class对象、方法对象这些可反射（reflective）对象分配内存限制，这些内存不包括在Heap（堆内存）区之中。-XX:PermSize=64MB 最小尺寸，初始分配XX:MaxPermSize=256MB 最大允许分配尺寸，按需分配这部分设置过小会导致：java.lang.OutOfMemoryError: PermGen space MaxPermSize缺省值和-server -client选项相关。-server选项下默认MaxPermSize为64m。 -client选项下默认MaxPermSize为32m 设置-Xms、-Xmx 相等以避免在每次GC 后调整堆的大小 云产品说起阿里云，这期间还发生了一个人为事故。当初京东金融本来是通过我们的平台发送的，但是它要我们给他拉专线直接连接运营商。但是这边没有给他拉，而是买了一台阿里云服务器，暴露出一个公网IP地址让它连接，在这台服务器上面部署HAproxy，还是调整到我们的平台。【上边领导们的决定，我就不评论是非对错了 哈哈】 然后有一天，突然HAProxy的web监测报警，页面打不开。马上上服务器看，CPU爆了【买的服务器配置一般】检查进程。内存正常，磁盘正常，CPU爆了，然后再查看网络连接，发现有大量的CLOSE_WAIT（400个close_wait;100多个establish） 在TCP关闭时，主动关闭的一方发出 FIN 包，被动关闭的一方响应 ACK 包，此时，被动关闭的一方就进入了 CLOSE_WAIT 状态。如果一切正常，稍后被动关闭的一方也会发出 FIN 包，然后迁移到 LAST_ACK 状态。 导致产生大量close_wait的原因是突然遭遇大量的请求，即便响应速度不慢，但是也来不及消费，导致多余的请求还在队列里就被对方关闭了。（因为对方设置了超时时间）。但是linux没有对close_wait做类似超时控制的设置，如果不重启进程，这个状态很可能会永远的持续下去， AWS主要是当初想搭VPN，但是一大堆的限制，最终没成功，所以现在是直接买的商业的，稳定，速度也有保证。七牛云，产品主要是数据存储和CDN加速，我自己的博客目前也是在用七牛云。瑞江云，是公司在做什么业务时和人家合作时，人家送的，具体什么我就不知道了 13 自身素质关于这三个人的管理经验，是在第一家公司公司的时候。亿阳分为很多个部门，其中就有一个对外产品部门，当时是准备和人保合作，进入金融行业。因此拿下了一个标，但是招运维主管的时候的比较难招，差不不行，好的知道是外包驻场的形式一般也不愿意来，到最后实在没办法只能从公司内部要人了，然后就把我派过去了。在那边呆了有7个月左右。当时工作非常艰辛【上一家被换掉是因为政治原因，具体是谁就不知道了】，因此过去需要接受上一家的工作，然后开发二代新产品，中间不能停，也就是起承上启下的作用。当时1个月直接就瘦了10斤，天天加班。 高效办公系列软件TC:资源管理器Autohotey：热键管理器Listary：文件搜索浏览增强工具evernote:云笔记Fences:桌面管理工具Ditto：剪切板增强工具Snipaste：截图工具Everything:文件搜索工具 运维职业规划-如何通过运维思想做好运维工作运维思想-运维核心稳定性-网站/平台不宕机【这是运维的核心】一般通过以下方式来实现 架构使用集群+负载均衡+高可用+应用解耦，微服务等部署方式来保证性能 安全【】 运营推广不能在白天高峰期推广，需要和运维打招呼 前端图片的优化，不能使用大图等，尽量使用缩略图 数据库优化【加入Redis数据缓存层，sql语句优化等】 避免随时上线的操作【减少次数】 测试生产等环境保持一致【系统，软件版本，路径等等】 流程操作【运维标准和流程】 等等等等 数据不丢失 应用配置数据管理-【考虑使用CMDB等平台】 数据库数据 避免人为问题避免人为错误，主要分为两个方面， 一个是他人(主要是开发不严谨)产生的错误，这部分通过运维流程并结合工具控制。【比如测试不严谨，或者开发人员的代码有问题，直接把服务器资源跑没了】 一个是自己操作产生的问题，这部分通过一些智能化的自动化工具来尽量避免【避免在执行命令的时候误操作等等，常见的有】 解决：建立完善的流程制度，对运维来说，包括标准化，对开发测试来说，包括上线的流程化【通过运维制度和一些工具来实现】 提升运维效率这一点是放在最后的，是在上面都做好的前提下，然后再有这么一层，什么自动化，CICD，devops，不是说招几个运维开发就能解决的。一定是需要一个过程的。运维效率很重要，但是不能盲目的只盯住这个上面 个人如何做好运维工作主动性很多东西如果不主动去找系统负责人去推进，进度根本没法完成。 划重点的能力写文档，研究技术，培训讲解等，需要将其中最重要的东西给讲述出来。就比如在看书的时候，有时候一些大部头的书，可能一句话非常长，你要从中快速挑出这句话的重点。然后建立知识体系。【这就需要能快速的找出重点，快速浏览说明性的内容，因为有可能这些说明性内容对你目前的水平来说完全来说可以忽略】 全局观 比如像我当初对接那么多的系统，在出问题的时候，可能是后面某一个系统出问题，但是导致你直接无法使用，所以你需要根据症状， 态度某一项技术不会非常正常，要摆正心态，虚心向人学习，比如像开发学习，像DBA学习，等等。构建完善的知识体系。一个技术不会到会其实有时候就是一个月的事，根本没有大家想的那么恐怖，不要怕，大胆的去问。 换位思考，自身作则 上面的任务怎么说话去分派下去。怎么安排任务， 流程制度 流程化，制度化为了便于管理，减少出错的概率。因此要有流程和制度 新员工刚进来，可以适当的较少压力，因为有 分配任务的时候，要求下面的人去重复描述下，确保正确无误 优秀的思维去分享给团队，让团队一起成长 比如烧开水理论， 优秀的团队应该是一列高铁 个人职业规划个人现阶段的努力方向是能够快速解决问题这个要求就非常高，需要具备一定的开发能力。比如开发开发出来的程序，在测试上正常，但是一到生产上，服务器的负载就持续飙升，CPU资源被消耗殆尽，这个时候要能够快速的定位到进程。然后要能分析进程内部的资源消耗情况，比如调用内核的哪些系统调用的情况引起的异常等等，找到之后能不能定位到相应的程序代码，这样才能解决问题，而不是找到进程之后，简单的重启。【这一阶段基本上就是资深运维开发工程师级别，预计3年时间】 在这之后下一个阶段目标是未雨绸缪，在源头将问题遏制住因此需要具备开发能力，在软件需求评审和软件设计阶段就要参与进来。【在这一阶段基本上就达到了架构师的水平】 补充HTTP协议POST与GET的区别 GET是从服务器上获取数据，POST是向服务器传送数据 GET是通过发送HTTP协议通过URl参数传递进行接收，而POST是实体数据，通过表单提交 GET传送的数据量较小，不能大于2KB。POST传送的数据量较大，一般被默认为不受限制。 GET安全性非常低，POST安全性较高]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>职场</category>
        <category>简历内容应答</category>
      </categories>
      <tags>
        <tag>简历内容应答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win10添加指定程序到开机自启动]]></title>
    <url>%2F2018%2F04%2F03%2FWin10%E6%B7%BB%E5%8A%A0%E6%8C%87%E5%AE%9A%E7%A8%8B%E5%BA%8F%E5%88%B0%E5%BC%80%E6%9C%BA%E8%87%AA%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[打开运行对话框（win键+R），输入命令 shell:startup 会直接弹出启动项对应的目录，然后像把应用程序快捷方式(需要对该执行文件右键创建快捷方式)复制或者剪切到启动目录 注意：该方式的启动项对应的目录是个人目录，也就是说不是针对系统上的所有用户。]]></content>
      <categories>
        <category>IT基础知识</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>Win10</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http Server 网络处理模型的进化之路]]></title>
    <url>%2F2018%2F04%2F02%2FHttp-Server-%E7%BD%91%E7%BB%9C%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%BF%9B%E5%8C%96%E4%B9%8B%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[缘起我刚毕业那会儿，国家还是包分配工作的，我的死党小明被分配到了一个叫数据库的大城市，天天都可以坐在高端大气上档次的机房里，在那里专门执行 SQL查询优化，工作稳定又舒适； 隔壁宿舍的小白被送到了编译器镇，在那里专门把 C 源文件编译成 EXE 程序，虽然累，但是技术含量非常高，工资高，假期多。 我成绩不太好，典型的差生，四级补考了两次才过，被发配到了一个不知道什么名字的村庄，据说要处理什么 HTTP请求，这个村庄其实就是一个破旧的电脑，令我欣慰的是可以上网，时不时能和死党们通个信什么的。 不过辅导员说了，我们都有光明的前途。 Http Server 1.0HTTP是个新鲜的事物，能够激起我一点点工作的兴趣，不至于沉沦下去。 一上班，操作系统老大扔给我一大堆文档： “这是 HTTP协议， 两天看完！” 我这样的英文水平，这几十页的英文 HTTP协议我不吃不喝不睡两天也看不完， 死猪不怕开水烫，慢慢磨吧。 两个星期以后，我终于大概明白了这 HTTP是怎么回事：无非是有些电脑上的浏览器向我这个破电脑发送一个预先定义好的文本（Http request）, 然后我这边处理一下（通常是从硬盘上取一个后缀名是 html的文件，然后再把这个文件通过文本方式发回去（http response），就这么简单。 唯一麻烦的实现，我得请操作系统给我建立 Http 层下面的 TCP 连接通道， 因为所有的文本数据都得通过这些 TCP通道接收和发送，这个通道是用 socket建立的。 弄明白了原理，我很快就搞出了第一版程序，这个程序长这个样子： 看看， 这些 socket, bind, listen , accept… 都是操作系统老大提供的接口， 我能做的也就是把他们组装起来：先在 80端口监听，然后进入无限循环，如果有连接请求来了，就接受 (accept)，创建新的 socket，最后才可以通过这个 socket来接收，发送 http 数据。 老大给我的程序起了个名称，Http Server 版本 1.0 。 这个名字听起来挺高端的，我喜欢。 我兴冲冲的拿来实验，程序启动了，在 80端口“蹲守”，过了一会儿就有连接请求了， 赶紧 Accept ,建立新的 socket ，成功 ！接下来就需要从 socket 中读取 Http Request 了。 可是这个 receive 调用好慢，我足足等了 100 毫秒还没有响应！我被阻塞 (block) 住了！ 操作系统老大说：“别急啊，我也在等着从网卡那里读数据，读完以后就会复制给你。” 我乐的清闲，可以休息一下。 可是操作系统老大说：“别介啊，后边还有很多浏览器要发起连接，你不能在这儿歇着啊。” 我说不歇着怎么办？receive调用在你这里阻塞着，我除了加入阻塞队列，让出 CPU 让别人用还能干什么？ 老大说： “唉，大学里没听说过多进程吗？你现在很明显是单进程，一旦阻塞就完蛋了，想办法用下多进程，每个进程处理一个请求！” 老大教训的是，我忘了多进程并发编程了。 Http Server 2.0 ：多进程多进程的思路非常简单，当 accept连接以后，对于这个新的 socket ，不在主进程里处理，而是新创建子进程来接管。这样主进程就不会阻塞在 receive 上，可以继续接受新的连接了。 我改写了代码，把 Http server 升级为 V2.0，这次运行顺畅了很多，能并发的处理很多连接了。 这个时候 Web 刚刚兴起，我这个 Http Server 访问的人还不多，每分钟也就那么几十个连接发过来，我轻松应对。 由于是新鲜事物，我还有资本给搞数据库的小明和做编译的小白吹吹牛，告诉他们我可是网络高手。 没过几年，Web迅速发展，我所在的破旧机器也不行了，换成了一个性能强悍的服务器，也搬到了四季如春的机房里。 现在每秒中都有上百个连接请求了，有些连接持续的时间还相当的长，所以我经常得创建成百上千的进程来处理他们，每个进程都得耗费大量的系统资源，很明显操作系统老大已经不堪重负了。 他说：“咱们不能这么干了，这么多进程，光是做进程切换就把我累死了。” “要不对每个 Socket 连接我不用进程了，使用线程？ ” “可能好一点，但我还是得切换线程啊，你想想办法限制一下数量吧。” 我怎么限制？我只能说同一时刻，我只能支持 x个连接，其他的连接只能排队等待了。 这肯定不是一个好的办法。 Http Server 3.0 : Select模型老大说：“我们仔细合计合计，对我来说，一个 Socket连接就是一个所谓的文件描述符（File Descriptor ,简称 fd , 是个整数），这个 fd 背后是一个简单的数据结构，但是我们用了一个非常重量级的东西 – 进程 –来表示对它的读写操作，有点浪费啊。” 我说：“要不咱们还切换回单进程模型？但是又会回到老路上去，一个 receive 的阻塞就什么事都干不了了。” “单进程也不是不可以，但是我们要改变一下工作方式。” “改成什么？” 我想不透老大在卖什么关子。 “你想想你阻塞的本质原因，还不是因为人家浏览器还没有把数据发过来，我自然也没法给你，而你又迫不及待的想去读，我只好把你阻塞。在单进程情况下，一阻塞，别的事儿都干不了。“ “对，就是这样” “所以你接受了客户端连接以后，不能那么着急的去读，咱们这么办，你的每个 socket fd 都有编号，你把这些编号告诉我，就可以阻塞休息了 。” 我问道：“这不和以前一样吗？原来是调用 receive 时阻塞，现在还是阻塞。” “听我说完，我会在后台检查这些编号的 socket，如果发现这些 socket 可以读写，我会把对应的 socket 做个标记，把你唤醒去处理这些 socket 的数据，你处理完了，再把你的那些 socket fd 告诉我，再次进入阻塞，如此循环往复。” 我有点明白了：“ 这是我们俩的一种通信方式，我告诉你我要等待什么东西，然后阻塞，如果事件发生了，你就把我唤醒，让我做事情。” “对，关键点是你等我的通知，我把你从阻塞状态唤醒后，你一定要去遍历一遍所有的 socket fd，看看谁有标记，有标记的做相应处理。我把这种方式叫做 select 。” 我用 select 的方式改写了 Http server，抛弃了一个 socket 请求对于一个进程的模式，现在我用一个进程就可以处理所有的 socket了。 Http Server4.0 : epoll这种称为 select 的方式运行了一段时间，效果还不错，我只管把 socket fd 告诉老大，然后等着他通知我就行了。 有一次我无意中问老大：“我每次最多可以告诉你多少个 socket fd？” “1024个。” “那就是说我一个进程最多只能监控 1024 个 socket 了？ ” “是的，你可以考虑多用几个进程啊！” 这倒是一个办法，不过”select”的方式用的多了，我就发现了弊端，最大的问题就是我从阻塞中恢复以后，需要遍历这 1000 多个 socket fd，看看有没有标志位需要处理。 实际的情况是， 很多 socket 并不活跃， 在一段时间内浏览器并没有数据发过来， 这 1000 多个 socket 可能只有那么几十个需要真正的处理，但是我不得不查看所有的 socket fd，这挺烦人的。 难道老大不能把那些发生了变化的 socket 告诉我吗？ 我把这个想法给老大说了下，他说：“嗯，现在访问量越来越大， select 方式已经不满足要求，我们需要与时俱进了，我想了一个新的方式，叫做 epoll。” “看到没有，使用 epoll 和 select 其实类似“ 老大接着说 ：”不同的地方是第 3 步和第 4 步，我只会告诉你那些可以读写的 socket , 你呢只需要处理这些 ‘ready’ 的 socket 就可以了“ “看来老大想的很周全， 这种方式对我来说就简单的多了。 ” 我用 epoll 把 Http Server 再次升级，由于不需要遍历全部集合，只需要处理哪些有变化的，活跃的 socket 文件描述符，系统的处理能力有了飞跃的提升。 我的 Http Server 受到了广泛的欢迎，全世界有无数人在使用，最后死党数据库小明也知道了，他问我：“ 大家都说你能轻松的支持好几万的并发连接， 真是这样吗？ ” 我谦虚的说：“过奖，其实还得做系统的优化啦。” 他说：“厉害啊，你小子走了狗屎运了啊。” 我回答： “毕业那会儿辅导员不是说过吗， 每个人都有光明的前途。”]]></content>
      <categories>
        <category>IT基础知识</category>
        <category>网络编程</category>
        <category>epoll模型</category>
      </categories>
      <tags>
        <tag>epoll模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[终端常用快捷键]]></title>
    <url>%2F2018%2F04%2F01%2F%E7%BB%88%E7%AB%AF%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[常用快捷键Tab键： 命令、文件名等自动补全功能。 Ctrl+a： 光标回到命令行首。 （a：ahead） Ctrl+e： 光标回到命令行尾。 （e：end） Ctrl+b： 光标向行首移动一个字符。 （b：backwards） Ctrl+f： 光标向行尾移动一个字符。 （f：forwards） Ctrl+w： 删除光标处到行首的字符，也就是删除光标前面的所有内容。 Ctrl+k： 删除光标处到行尾的字符，也就是删除光标后面的所有内容。 Ctrl+u： 删除整个命令行文本字符，删除整行命令。 Ctrl+h： 向行首删除一个字符，向前删除一个字符，相当于Backspace。 Ctrl+d： 向行尾删除一个字符，向后删除一个字符，相当于Delete。 Ctrl+y： 粘贴Ctrl+u，Ctrl+k，Ctrl+w删除的文本。 Ctrl+p： 上一个使用的历史命令。 （p：previous） Ctrl+n： 下一个使用的历史命令。（n：next ） Ctrl+t： 交换光标所在字符和其前的字符。 Ctrl+i： 相当于Tab键。 Shift+Insert： 粘贴鼠标所复制的内容 Ctrl+d: 在空命令行的情况下可以退出终端。 Shift+c： 删除之后的所有内容并进入编辑模式 Ctrl+c： 中断终端中正在执行的任务。 Ctrl+z： 使正在运行在终端的任务，运行于后台。 （可用fg恢复到前台） 非常用快捷键Ctrl+s： 使终端发呆，静止，可以使快速输出的终端屏幕停下来。 Ctrl+q： 退出Ctrl+s引起的发呆。 Ctrl+[： 相当于Esc键。 Esc键： 连续按3次显示所有的支持的终端命令，相当于Tab键。 Ctrl+r： 快速检索历史命令。（r：retrieve）。 Ctrl+o： =Ctrl+m：相当Enter键。]]></content>
      <categories>
        <category>Linux基础知识</category>
        <category>终端常用快捷键</category>
      </categories>
      <tags>
        <tag>终端常用快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师面试常见问题]]></title>
    <url>%2F2018%2F03%2F28%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[IT基础知识（偏linux）redhat、centos、suse、ubuntu等发行版本的区别这些发行版本本质上没有什么区别，都是类unix系统。redhat的系统本身是免费的，但是它的服务和一些特定的组件是收费的而centos是redhat社区版本，国内使用较多，社区相当活跃。SUSE也是分为两种，一种企业版本的SLES，一种是opensuse，sles主要是一些金融国企在使用，安全性较好，opensuse是社区版本，suse使用起来和centos相差不多，软件包形式使用源自redhat的rpm，但是管理工具使用的是zypper。ubuntu源自于debain，国外使用的较多，也是相当热门的一个发型版本，在桌面领域有绝对技术优势，适合开发人员使用。 OSI7层模型和TCP/IP模型的区别联系OSI7层模型OSI 7层模式主要是由国际标准化组织（ISO）创建的，是一个国际通用的标准，它被开发出作为一个参照标准，用于指导如何设计网络通信系统。说的简单一点就是统一网络设备商的协议标准，实现多网络设备商环境（主机，路由器，交换机等等都是网络设置，都要遵循同一套的通信标准）它一共分为7层，每一层在网络通信数据传输过程中都定义了不同的功能。 OSI7层模型主要分为(从下到上)：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。每一层说明： layer function Application data flow；离用户最近的一层，它使一个网络应用能和另一个网络应用相互通信 Presentation 定义数据格式；数据压缩、加解密等。 Session 定义如何建立和终止连接，是告诉4层怎么做，4层只管被动的接受然后去做。 Transport 数据段；将上层的数据流进行分段；建立和终止网络连接；常用于流量控制和数据恢复 Network 数据包；使用IP地址在Internet上唯一确定一台设备；定义设备路由，寻址 Data link 数据帧；将上层数据封装成数据帧，其中包含源目MAC地址以及帧校验字段（用于检测传输错误）；它包含2个子层（LLC和MAC） Physical 比特流；定义了比特流如何在两台设备之间流通；主要涉及线缆，网卡， 下面是每一层常见的对应协议 layer protocol Application HTTP,FTP,Telnet,SMTP,SNMP Presentation MIME,TIFF,GIF,JPEG,PICT,ASCII,EBCDIC,encryption,MPEG,MIDI,HTML Session SSl/TLS,NetBIOS,RPC Transport TCP,UDP Network IP,ICMP,ARP,RARP Data link PPP,HDLC,IEEE 802.3/802.2,FDDI,ATM,IEEE 802.5/802.2 Physical Ethernet TCP/IP协议族TCP/IP模型类似OSI模型，作用也是描述一套指导标准，实现网络设备之间的通信，它被设计成4层 Application Transport Internet Network Access 其对应关系为： TCP/IP model OSI model Application Application Presentation Session Transport Transport Internet Network Network Access Data link Physical 区别除了层数的区别之外，它们之间最大的区别就是： OSI模型规定了在一个网络上传输数据所需要的步骤，并且它是非常具体的，定义了每一层使用什么协议以及如何使用；而TCP/IP模型是不特定的。另外一个区别就是，目前TCP/IP是所有网络设备上既定的协议事实，一般分析问题使用OSI模型。 路由，交换技术的基本原理路由技术我们在这里说的路由技术一般是指，路由转发。主要涉及设备为路由器或者三层交换机。这些设备上会维护一张路由表，其中的信息可以是通过动态路由协议（例如OSPF，EIGRP，ISIS，RIP，BGP，静态路由，默认路由等）获取组成路由表的内容是：出口接口和对应网段 路由设备接收到一个数据包之后，会解封装，获取其中的目的IP地址信息（网段信息），然后查找路由表，选择最优路由去转发。路由设备上也会有一张ARP表，根据广播域 交换技术在一个局域网内，也就是一个广播域内使用的技术。通常会涉及到的设备就是交换机。交换机上会维护一张MAC地址转发表，其中的信息是MAC地址和端口的映射关系。交换机根据数据帧中的目的MAC地址进行数据包的转发 注意：在一个广播域内的数据流动是依靠二层MAC来实现的，因为在第一次会涉及到ARP，有了记录之后，交换机会记录他的MAC地址表，后续的速度就会非常快 PS：有关网络模型和路由技术可以结合一个小案例在白板上演示一下，效果会更好，也就是将上述两部分的内容有机的整合成为一个整体 运维角度看软件开发生命周期软件开发生命周期的本源是人的需求以及满足需求的关系。人的抽象产品就是需求。而开发出来的产品运行态的进程就是具体的具象表达。 问题定义及规划，需求分析，软件设计，软件开发，测试，部署 问题定义及规划 1确定软件的开发目标及可行性 需求分析 12前提：确定软件开发可行对软件需要实现的各个功能进行详细分析 软件设计主要依据需求分析的结果 对整个软件系统进行设计，例如系统框架设计，数据库设计等。 软件设计一般分为总体设计和详细设计 脚本部分运维知识优化运维思想运维核心稳定性-网站/平台不宕机【核心】集群 负载均衡 高可用 解耦，微服务 数据不丢失【核心】数据备份，异地容灾 避免人为错误 避免人为错误，主要分为两个方面，一个是开发不严谨产生的错误，这部分通过流程可以控制。【比如测试不严谨，开发人员的代码有问题，直接把服务器资源跑没了】 一个是自己操作产生的问题，这部分通过一些智能化的自动化工具来尽量避免【避免在执行命令的时候误操作等等】 解决：建立完善的流程制度，对运维来说，包括标准化，对开发测试来说，包括上线的流程化 运维效率管理平台运维脚本化，工具化，自动化，人工智能化 如何做好运维工作-运维核心主动性运维职业规划问题解析面试官主要想了解的是个人定位问题。从事IT这一行，只有有非常清晰的目标，才能保证持续高效的产出。 因此，回答这种问题，主要从以下几点来回应 的 范例其他相关问题你为什么离职你对加班的看法个人最大的优点和缺点]]></content>
      <categories>
        <category>个人知识体系</category>
        <category>职场</category>
        <category>Linux运维面试问题</category>
      </categories>
      <tags>
        <tag>Linux运维面试问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker常用命令记录]]></title>
    <url>%2F2018%2F03%2F19%2Fdocker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[镜像命令下载/获取镜像运行镜像查看镜像信息images命令使用docker images命令可以列出本地主机上已有镜像的基本信息。 1$ docker images [option] 常用参数如下： -a –all=true|false 列出所有的镜像文件（包括临时文件），默认为否 –digests=true|false 列出镜像的数字摘要值，默认为否 -f –filter=[] 过滤列出的镜像 具体可以通过man docker-images 进行查看。 inspect命令镜像操作tag命令删除镜像]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>虚拟化</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix的历史数据与趋势数据]]></title>
    <url>%2F2018%2F02%2F06%2Fzabbix%E7%9A%84%E5%8E%86%E5%8F%B2%E6%95%B0%E6%8D%AE%E4%B8%8E%E8%B6%8B%E5%8A%BF%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[参考链接官方文档 zabbix history trends历史与趋势数据详解 zabbix配置操作详解（三） Zabbix系统中的历史数据和趋势数据 正文历史与趋势历史数据和趋势数据是Zabbix系统中对采集到的监控项数据进行存储的两种方式。 历史根据设定的时间间隔保持每个收集的值， 而趋势是每个小时产生一个值（一条信息），内容为历史数据在一个小时内的平均值、最大值、最小值以及这一个小时内该监控项目所采集到的数据的个数。 在zabbix中的配置在监控项配置页面进行定义，在这里，我的配置是历史数据保留15天，趋势数据保留90天。如下图所示： 区别联系详解历史和趋势数据它们既有区别又有联系。 历史数据： Zabbix系统针对每个监控项目在每次采集时所收集到的数据，这个数据保存Zabbix系统数据库的历史表中，这就是所谓的历史数据。 因为每次所采集到的数据都保存在历史表中，所以如果监控项目的更新间隔越小，则在固定时间内所保存到历史表中的数据就越多。如果每个监控项目的更新间隔是30秒的话，则两个小时，该监控项目在Zabbix数据库的历史表中就会产生240条记录，一天就会产生2880条记录。 如果我们的Zabbix系统只监控一台被监控主机，且这台被监控主机只有一个被监控项目，那么每天产生2880条记录确实不值得一提的。但是，当我们监控系统所监控的项目比较多时，则这个数据量是非常大的。 比如说，如果我们监控系统监控1000个监控项目，且每个监控项目的更新间隔都是30秒，则每天历史表中就会产生2880*1000=2880000条记录，也即近300万条记录。而1000个监控项目可以监控多少主机呢？我们以48口的交换机为例，单监控每台交换机的每个端口的流量，则一台48口的交换机就有96个监控项目。所以，如果我们仅监控这样的48口的交换机，1000个监控项目只差不多只够监控10台这样交换机。由此可见，如果我们所监控主机的数量稍微多一点，或者更确切的来说，我们所监控的项目稍微多点，则Zabbix系统每天在其数据库中所产生的记录是非常大的。 因此，我们建议，如非必须的，我们在配置监控项目时，应尽量减小历史数据的保留天数，以免给数据库系统带来很大的压力。 趋势数据： 而趋势数据则不同，对于相同的更新间隔，系统所产生的趋势数据的数量远远没有历史数据那么庞大。对同一个监控项目，之所以趋势数据的数据量要远远小于历史数据的数据量，是由趋势数据的取值方式决定的。 趋势数据取值方式是，它取对应监控项目的历史数据在一个小时内的平均值、最大值、最小值以及这一个小时内该监控项目所采集到的数据的个数。 因此，不管一个监控项目的更新间隔是多少，它所对应的趋势数据在数据库中的记录都只有一条。更新间隔越小，仅可能导致数据个数增大，而不会影响该监控项目在趋势表里的记录条数的。 由此，或许你觉得趋势数据很不准确，你还是愿意保留更长时间的历史数据，以便查看较长时间的数据图。其实不是这样的，因为在Zabbix系统数据库的趋势表里不但保留一个小时内历史数据的最大值、最小值和平均值，而还保存这一个小时内所采集到的数据个数。因此，在要求并不是很高的场合，使用趋势数据绘出的监控项目的数据图的走势与用历史数据绘出的数据图的走势差别不会很大的。 不管是历史数据还是趋势数据，都会周期性被Zabbix服务器端一种称之为“主妇（housekeeper）”进程进行清理，它会周期性的删除过期的历史数据和趋势数据。 也正是因为这个进程的存在，才会使Zabbix系统数据的数据量不会一直的彭胀下去。而实际上，如果我们在保持Zabbix系统的被监控主机和被监控项目不变，且不更改监控项目的更新间隔的情况下，Zabbix系统的数据库的数据量会在增长到一定的数据量后不再增长，而是基本维持在这个数据量上不变。 “主妇”进程清理历史数据和趋势数据的频率可以在Zabbix服务器端组件(或服务器代理组件)的配置文件zabbix_server.conf中进行配置，它的配置项是HousekeepingFrequency。 特别注意： 1、 如果监控项目的“保留历史数据(天)”配置项被设置成0时，则数据库历史表中仅保留该监控项目所采集的最后一条数据，其它历史数据将不会被会保留。而且，引用该监控项目的触发器也只能使用该项目所采集的最后数据。因此，此时如果在触发器里引用该项目时使用max、avg、min等函数，其将没有意义。 2、 如果监控项目的“保留趋势数据(天)”配置项被设置成0时，则该项目在系统数据库的趋势表里将不保留任何数据。 配置建议具体该配置成什么样的周期，需要根据监控项以及数据库的配置以及对数据查看的要求程度来决定。这里只给出相关建议。 历史数据配置首先我们需要知道当前mysql的存储情况。在zabbix的前端页面上，我们可以看到如下图所示信息： 这个数值就是NVPS，也就是每秒处理平均数量（Number of processed values per second) 计算公式如下： 历史数据大小=NVPSx3600x24x365(天数)x50B 每个监控项大小约为50B，每秒条数为NVPS，一小时3600秒，一天24小时，一年365年。 具体单个监控项大小取决于数据库引擎，通常为50B 例如： 假设有6W个监控项，刷新周期都为60秒（我这里为30秒），那么每秒将会产生1000条数据，也就是每秒会向数据库写入1000条数据。如果我的历史数据保留天数为90天，那么需要的空间大小如下： 1000x3600x24x90x50=388 800 000 000(B) (约为362G，如果保存一年则为：362x4=1448G) 趋势数据配置因为趋势数据是每小时每个监控项一条记录，因此可以计算出大致所占的空间，其计算公式如下： 趋势数据大小=监控项个数x24x365(天数)x128B 每一个监控项的大小约为128B，每小时产生一条记录，一天24小时，一年365天 具体单个监控项大小取决于数据库引擎，通常为128B 例如： 假设有6W个监控项，保存一年的趋势数据，那么需要的空间如下： 60000x24x265x128=67 276 800 000(B) （约为67GB） 总结通过上面的计算对比，相信可以很直观的看到差别，在同样一年的情况下，历史与趋势所占存储空间的比例为：1448/67。 所以，具体选择什么周期需要根据公司的业务及实际情况（硬件配置等）来决定，并没有一个统一的标准，遵循这个公式，都可以很明确的计算预估出数据量情况。]]></content>
      <categories>
        <category>IT科学技术知识体系结构-Linux运维方向</category>
        <category>运维监控体系</category>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[autohotkeye常用操作]]></title>
    <url>%2F2018%2F02%2F06%2Fautohotkeye%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言AutoHotkey是一个windows下的开源、免费、自动化软件工具。它由最初旨在提供键盘快捷键的脚本语言驱动(称为：热键)，随着时间的推移演变成一个完整的脚本语言。但你不需要把它想得太深，你只需要知道它可以简化你的重复性工作，一键自动化启动或运行程序等等；以此提高我们的工作效率，改善生活品质；通过按键映射，鼠标模拟，定义宏等。 参考资料官方https://autohotkey.com/docs/AutoHotkey.htm 民间https://jeffjade.com/2016/03/11/2016-03-11-autohotkey/https://ahkcn.github.io/docs/AutoHotkey.htm 下载安装下载地址autohotkey下载地址 使用说明 AutoHotkey doesn’t do anything on its own; it needs a script to tell it what to do. A script is simply a plain text file with the .ahk filename extension containing instructions for the program, like a configuration file, but much more powerful. A script can do as little as performing a single action and then exiting, but most scripts define a number of hotkeys, with each hotkey followed by one or more actions to take when the hotkey is pressed. 也就是说，在实际使用的时候，是通过autohotkey去调用脚本，然后再去执行一系列的操作 脚本是自己定义个一个后缀为.ahk的文件 然后双击启动Ahk2Exe.exe，选择自己编写的这个ahk文件，执行convert，之后会生成一个ahk.exe的可执行文件。启动这个ahk.exe文件，就将配置加载，之后就可以使用这些热键进行一系列的操作 一个脚本中对应一系列热键 脚本符号这里简单说明下脚本中常用符号代表的含义： # 号 代表 Win 键； ! 号 代表 Alt 键； ^ 号 代表 Ctrl 键； + 号 代表 shift 键； :: 号(两个英文冒号)起分隔作用； run， 非常常用 的 AHK 命令之一; ; 号 代表注释后面一行内容； *通配符 即使附加的修饰键被按住也能激发热键. 这常与 重映射 按键或按钮组合使用. 例如: *#c::Run Calc.exe 表示：Win+C、Shift+Win+C、Ctrl+Win+C 等都会触发此热键。 run它的后面是要运行的程序完整路径（比如我的Sublime的完整路径是：D:\Program Files (x86)\Sublime Text 3\sublime_text.exe）或网址。为什么第一行代码只是写着“notepad”，没有写上完整路径？因为“notepad”是“运行”对话框中的命令之一。 如果你想按下“Ctrl + Alt + Shift + Win + Q”（这个快捷键真拉风啊。(￣▽￣)）来启动 QQ 的话，可以这样写： ^!+#q::run QQ所在完整路径地址。 AutoHotKey的强大，有类似Mac下的Alfred2之风，可以自我定制(当然啦，后者还是强大太多)。所以可以说，它强大与否，在于使用者的你爱或者不爱折腾。学以致用，如果简单的折腾下，可以使得我们工作效率大幅提升，何乐不为？况且，在见识的增长中，这可以给我们思维带来极大的营养。以下是笔者常用功能的脚本配置： 温馨提示： 以下几个系统默认的 Win 快捷键，请自行确认是否覆盖 Win + E：打开资源管理器； Win + D：显示桌面； Win + F：打开查找对话框； Win + R：打开运行对话框； Win + L：锁定电脑； Win + PauseBreak：打开系统属性对话框; Win + Q: 本地文件/网页等搜索; Win + U: 打开控制面板－轻松使用设置中心; 配置使用这是我自行编写的脚本的内容 #q::Run https://wx.qq.com/ #w::Run http://watchmen.xin/ #e::Run E:\software\tcmd\totalcmd\TOTALCMD64.EXE #r::Run, E:\software\ss\Shadowsocks.exe #t::Run, E:\software\Snipaste\Snipaste.exe #y::Run, E:\software\TIMqq\Bin\QQScLauncher.exe #u::Run, E:\software\foxmail\Foxmail.exe #i::Run, E:\software\xmanager\Xshell.exe 进阶单热键多命令类似下面的这种设置被称为单行热键, 因为它们只包含单个命令. #n::Run Notepad ^!c::Run calc.exe 要在一个热键中执行多个命令，请把首行放在热键定义的下面，且在最后行命令的下一行添加 return。例如： #n:: Run http://www.google.com Run Notepad.exe return 如果要运行的程序或文档没有在环境变量中, 那么需要指定它的完整路径才能运行: Run %A_ProgramFiles%\Winamp\Winamp.exe 在上面的例子中, %A_ProgramFiles% 是 内置变量. 使用它而不使用像 C:\Program Files 这样的, 脚本可以有更好的移植性, 这表示它在其他电脑上能执行的可能性更大. 注意: 命令和变量的名称是不区分大小写的. 例如, “Run” 等同于 “run”, 而 “A_ProgramFiles” 等同于 “a_programfiles”. 要让脚本等到程序或文档关闭后才继续执行, 请使用 RunWait 代替 Run. 在下面的例子中, 一直到用户关闭记事本后 MsgBox 命令才会继续执行. RunWait Notepad MsgBox The user has finished (Notepad has been closed).]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>AutoHotKey</category>
      </categories>
      <tags>
        <tag>autohotkey</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七牛云-qshell工具常用命令]]></title>
    <url>%2F2018%2F02%2F05%2F%E4%B8%83%E7%89%9B%E4%BA%91-qshell%E5%B7%A5%E5%85%B7%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[前言/简介qshell是利用七牛文档上公开的API实现的一个方便开发者测试和使用七牛API服务的命令行工具。 该工具设计和开发的主要目的就是帮助开发者快速解决问题。 目前该工具融合了七牛存储，CDN，以及其他的一些七牛服务中经常使用到的方法对应的便捷命令，比如b64decode，就是用来解码七牛的URL安全的Base64编码用的，所以这是一个面向开发者的工具。 官方资料文档https://developer.qiniu.com/kodo/tools/1302/qshell 视频教程http://notdelete.echohu.top/spjc/qshell-win.mp4 安装/环境准备目前在windows上使用qshell需要执行以下几个步骤添加命令到系统 下载qshell，存储到指定文件夹，例如我这里是：E:\software\qshell 重命名，将qshell_windows_x64.exe重命名为qshell.exe 添加系统环境变量，将E:\software\qshell追加到环境变量中 命令选项参数 描述 -d 设置是否输出DEBUG日志，如果指定这个选项，则输出DEBUG级别的日志 -m 切换到多用户模式，这样所有的临时文件写入都在命令运行的目录下 -h 打印命令列表帮助信息，遇到参数忘记的情况下，可以使用该命令 -v 打印工具版本，反馈问题的时候，请提前告知工具对应版本号 命令列表 实际操作我们使用qupload来进行文件的管理 官方文档 命令参数展示 命令语法： 1qshell qupload [&lt;ThreadCount&gt;] &lt;LocalUploadConfig&gt; 命令参数： 配置参数展示qupload 功能需要配置文件的支持，配置文件支持的全部参数如下： { &quot;src_dir&quot; : &quot;&lt;LocalPath&gt;&quot;, &quot;bucket&quot; : &quot;&lt;Bucket&gt;&quot;, &quot;file_list&quot; : &quot;&lt;FileList&gt;&quot;, &quot;key_prefix&quot; : &quot;&lt;Key Prefix&gt;&quot;, &quot;up_host&quot; : &quot;&lt;Upload Host&gt;&quot;, &quot;ignore_dir&quot; : false, &quot;overwrite&quot; : false, &quot;check_exists&quot; : false, &quot;check_hash&quot; : false, &quot;check_size&quot; : false, &quot;rescan_local&quot; : true, &quot;skip_file_prefixes&quot; : &quot;test,demo,&quot;, &quot;skip_path_prefixes&quot; : &quot;hello/,temp/&quot;, &quot;skip_fixed_strings&quot; : &quot;.svn,.git&quot;, &quot;skip_suffixes&quot; : &quot;.DS_Store,.exe&quot;, &quot;log_file&quot; : &quot;upload.log&quot;, &quot;log_level&quot; : &quot;info&quot;, &quot;log_rotate&quot; : 1, &quot;log_stdout&quot; : false, &quot;file_type&quot; : 0 } 参数具体含义如下： 密钥设置单用户 1qshell account ak sk 多用户 1qshell -m account ak sk 这里的ak、sk在个人面板中的密钥管理中查看，点击显示，然后进行复制粘贴 如下图所示： 上传图片这里我们选择qupload方式来进行图片的上传，在windows本地创建一个文件夹用户放置图片数据，每次同步该文件夹即可，不用再单独每张上传 步骤1：创建本地图片文件夹如下图所示，在指定位置下创建一个文件夹用于存放图片，在这里，我把它和我的博客文件夹放在同级 步骤2：创建配置文件如下图所示，在指定目录下创建配置文件，注意，这里需要使用编辑打开，不要用notpad++这些编辑器 步骤3：执行命令进行上传准备工作都做好后，执行如下命令直接上传： qshell qupload 1 c:\Users\56810\blog\config.txt qshell qupload 1 C:\Users\Administrator\blog\config.txt 如下图所示 其他配置下载文件刷新缓存官方资料 使用七牛云提供的 qshell 命令行工具，参考使用文档，先设置密钥，然后执行 cdnrefresh 命令来刷新缓存。 具体操作为： 步骤1：修改配置文件 步骤2：执行命令]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>七牛云-qshell</category>
      </categories>
      <tags>
        <tag>qshell</tag>
        <tag>七牛云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RSS介绍及使用]]></title>
    <url>%2F2018%2F02%2F04%2FRSS%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[转载来源：http://www.ruanyifeng.com/blog/2006/01/rss.html RSS定义在解释RSS是什么之前，让我先来打一个比方。 读大学的时候，我有个习惯，就是每天要去看食堂后面的海报栏。在那里，会贴出各种各样最新的消息，比如哪个系要开讲座了、星期二晚上的电影放什么、二手货转让等等。只要看一下海报栏，就会对学校的各种活动心中有数。 如果没有海报栏的话，要想知道这些消息就会很麻烦。讲座消息会贴在各个系自己的公告栏里，电影排片表是贴在电影院里的，二手货消息则会贴在各幢宿舍的楼道里。我所在的大学有20几个系，一万多人，要想知道所有这些消息的话，即使是可能的话，也会相当的麻烦。 从这个例子出发，让我们来考虑一下互联网。 互联网是什么？最直观的说，就是一个杂乱无章的巨大信息源，其丰富和杂乱的程度，不仅是巨大的，而且几乎是无限的。 一个使用者，要想及时掌握的互联网上出现的最新信息，有办法吗？ 答案是没有办法，他只有一个网站一个网站的打开，去看有什么最新内容，就好比每天都必须去每一个系里走一遍，看有什么最新讲座。如果是几个网站，哪倒也不难，都去看一遍也花不了多少时间。但是随着你关注的网站数量上升，这项工作会迅速的变为”Mission Impossible”。想象一下，如果你每天关注几十个、甚至几百个网站，会是怎样的情景。光是打开它们的首页，就要花费多少时间啊，更别说浏览花去的时间了。 也许有人会说，普通人的话，谁会关心那么多网站啊？ 我要说，哪怕你只是一个网络的初级或最单纯的使用者，与你发生关系的网站数量也在急剧增加，因为Blog出现了。越来越多的人开始写作网络日志（Blog），把自己的想法和生活在网上展示，其中也必然包括你的朋友，或者其他你感兴趣的人。你想知道他/她的最新动向，就势必要留心他/她的Blog。所以，你的网站浏览清单总有一天会和你的电话本、MSN Message好友列表一样多，甚至更多。 那时，你会发现浏览网站会变成一种困难和低效率的行为。 有没有办法找到互联网上的”海报栏”，只去一个地方就知道你所想知道的所有最新内容？ 有，那就是RSS。 RSS内容和阅读器准确的说，RSS就像一个网站的海报，里面包括这个网站的最新内容，会自动更新。所以，我们只要订阅了RSS，就不会错过自己喜欢的网站的更新了。 但是光有海报还不行，还必须有海报栏，也就是说必须有RSS阅读器才行。因为RSS只是数据源，它本身是写给程序看的，必须经过阅读器转换，才能成为可以浏览的格式。 RSS阅读器多种多样，大致分为两种，一种是桌面型的，需要安装；另一种是在线型，直接使用浏览器进行阅读。 使用/订阅RSS在浏览器中订阅RSS，就必须先知道RSS的地址。一般来说，各个网站的首页都会用显著位置标明。名称可能会有些不同，比如RSS、XML、FEED，大家知道它们指的都是同样的东西就可以了。有时RSS后面还会带有版本号，比如2.0、1.0，甚至0.92，这个不必理会，它们只是内部格式不同，内容都是一样。 将RSS地址复制下来以后，你就可以在在线阅读器中添加。 以后，只用打开这一个网页，就可以看到所有你喜欢的网站的最新内容了。 推荐RSS阅读器个人目前在使用的RSS阅读器为：inoreader]]></content>
      <categories>
        <category>IT基础知识</category>
        <category>RSS</category>
      </categories>
      <tags>
        <tag>RSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown语法]]></title>
    <url>%2F2018%2F01%2F25%2FMarkdown%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Markdown介绍Markdown 是一种轻量级标记语言，它以纯文本形式(易读、易写、易更改)编写文档，常用的标记符号也不超过十个，并最终以HTML格式发布,让写作者专注于写作而不用关注样式。 划重点： 轻量级 标记语言 纯文本，所以兼容性极强，可以用所有文本编辑器打开。 让你专注于文字而不是排版。 格式式转换方便，Markdown 的文本你可以轻松转换为 html、电子书等。 Markdown 的标记语法有极好的可读性，常用的标记符号不过十来个 参考资料看完我这篇文章，再看完我下面推荐的这些内容，然后对比归纳总结，认真实践后，可以说在平常工作学习中完全够用。 官方资料 Markdown 语法说明 (简体中文版) Markdown 语法介绍 易读易写!-MarkDown语法说明 个人文章 献给写作者的 Markdown 新手指南 Markdown——入门指南 Markdown 基本语法 编辑器 个人在用的编辑器是MarkdownPad 2。各个工具之间相差不会很大，熟练掌握快捷键是提高效率的好方法 核心理念Markdown 的目标是实现「易读易写」，成为一种适用于网络的书写语言。。不管从任何角度来说，可读性，都是最重要的。Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像强调。 划重点： 语法是非常简单的符号 即写即读 兼容HTMLMarkdown 的构想不是要使得 HTML文档更容易书写。HTML 已经很容易写了。Markdown 的理念是，能让文档更容易读、写和随意改。 HTML是一种发布的格式，而Markdown 是一种书写的格式。也因此，Markdown 的格式语法只涵盖纯文本可以涵盖的范围。 常用操作标题（MarkdownPad中快捷键为Ctrl+1/2/3/4）：Markdown 支持两种标题的语法，类 Setext 和类 atx 形式。类 Setext 形式是用底线的形式，利用 = （最高阶标题）和 - （第二阶标题），例如： This is an H1 ============= This is an H2 ------------- 任何数量的 = 和 - 都可以有效果。但是这种形式只支持2层标题。 类 Atx 形式则是在行首插入 1 到 6 个 # ，对应到标题 1 到 6 阶，例如： # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 强调在Markdown中，可以使用 和 _ 来表示斜体和加粗。*单个为斜体，2个为加粗 加粗（MarkdownPad中快捷键为Ctrl+b）：加粗部分使用方式如下： **Coding，让开发更简单** __Coding，让开发更简单__ 实际展示效果如下： Coding，让开发更简单 Coding，让开发更简单 斜体（MarkdownPad中快捷键为Ctrl+l）：斜体部分的使用如下： *Coding，让开发更简单* _Coding，让开发更简单_ 实际展示效果展示如下： Coding，让开发更简单 Coding，让开发更简单 列表无序列表（MarkdownPad中快捷键为Ctrl+u）：* list1 前面使用*号 - list2 前面使用-号 + list3 前面使用+号 效果如下： list1 list2 list3 有序列表(MarkdownPad中快捷键为Ctrl+shift+o）：1. list1 使用数字+英文的点号，空格后接数据 2. list2 效果如下： list1 list2 区块引用（MarkdownPad中快捷键为Ctrl+q）&gt; 数据1 使用&gt;号 &gt; 数据2 &gt; &gt; 二级引用 注意区块引用可以包含多级引用 &gt; 实际效果展示： 数据1 数据2 这是二级引用 三级引用 代码区块（MarkdownPad中快捷键为Ctrl+k）：代码区块包括3种，文字内和单独一行以及指定代码格式的区块行 文字内加区块，不会加空白处底纹使用``（数字1左边，ESC下面的按键） 实际效果展示：在文件中含有代码区块是什么样子 整行的代码区块行，会加空白处底纹（快捷操作：全部选中然后敲Tab）缩进4个空格或者一个制表符（tab键）或者将代码块包裹在代码块包裹在 “/` 之间（避免无休止的缩进）。 实际效果展示 123require 'redcarpet'markdown = Redcarpet.new("Hello World!")puts markdown.to_html 实际效果展示： 现在的效果就是整整一个的区块行，如果这段代码比较长的话，那么markdown就会在下面生成一个查看条，供用户左右拉取调整，就是如现在所示。 指定代码格式的区块行 实际效果展示： 12$ line1-test1$ line2-test2 分割线/分隔线（MarkdownPad中快捷键为Ctrl+r）：一行中用三个以上的星号、减号、底线来建立一个分隔线，可以在字符之间加入空格，也可以不加空格 * * * *** ***** --- - - - 实际效果展示如下： 网页链接网页链接有2种方式，一种是直接显示链接，一种是通过文字进行跳转 直接显示&lt;https://www.baidu.com&gt; 用&lt;&gt;尖括号将内容包起来，markdown就会自动把它转成链接。网页链接、邮箱链接等都采用这种方式 实际效果展示如下：这段话中将要插入百度https://www.baidu.com的链接 文字跳转More info: [Server](https://hexo.io/docs/server.html) 前面是解释性说明，[]内是可以跳转的文字，()内是真正访问的地址。 实际效果展示如下： 请点击百度调整到百度页面 图片链接图片链接分为2部分，一种是在文字中，通过文字来链接到图片位置，用户需要点击这个文字链接去查看图片，优点是使文字更简约，缺点是无法直观的看到图。因此，第二种方式是直接在文章中显示图片。 我们把这两种方式分别称之为：行内式和参考式 行内式行内式的图片语法看起来像是： ![Alt text](/path/to/img.jpg) 参考案例：![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 详细叙述如下： 一个惊叹号 ! 接着一个方括号，里面放上图片的替代文字 接着一个普通括号，里面放上图片的网址， 最后还可以用引号包住并加上 选择性的 ‘title’ 文字。 参考式参考式的图片语法则长得像这样： ![Alt text][id] 「id」是图片参考的名称，图片参考的定义方式则和连结参考一样： 参考案例：[id]: url/to/image &quot;Optional title attribute&quot; 表格普通表格： First Header | Second Header | Third Header ------------ | ------------- | ------------ Content Cell | Content Cell | Content Cell Content Cell | Content Cell | Content Cell 设置表格两边内容对齐，中间内容居中，例如： First Header | Second Header | Third Header :----------- | :-----------: | -----------: Left | Center | Right Left | Center | Right 实际效果展示： First Header Second Header Third Header Left Center Right Left Center Right 文本居中居中使用html方式添加，格式如下： 1&lt;center&gt;这一行需要居中&lt;/center&gt; 文本居中的引用先看下实际效果： 主要用于主页等显示，和上面的文本场景有点不一样。 具体实现： &lt;!-- HTML方式: 直接在 Markdown 文件中编写 HTML 来调用 --&gt; &lt;!-- 其中 class=&quot;blockquote-center&quot; 是必须的 --&gt; &lt;blockquote class=&quot;blockquote-center&quot;&gt;blah blah blah&lt;/blockquote&gt; &lt;!-- 标签 方式，要求NexT版本在0.4.5或以上 --&gt; {% centerquote %} content {% endcenterquote %} &lt;!-- 标签别名 --&gt; {% cq %} content {% endcq %} 添加空行&lt;br /&gt; 使用该方法进行插入 反斜杠转义\*literal asterisks\* 使用这种方式来输出*号 实际效果展示： *literal asterisks* 字体颜色语法格式：&lt;font color=指定颜色的英文单词&gt;内容&lt;/font&gt;，例如 例如将字体颜色修改为红色： 代码为：&lt;font color=red&gt;内容&lt;/font&gt; 内容]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TotalCommander常用快捷键]]></title>
    <url>%2F2018%2F01%2F25%2FTotalCommander%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%2F</url>
    <content type="text"><![CDATA[基础知识参考资料可以先看下相关资料，这些资料对概念介绍等做的非常详细也写的非常好，因此这里不再赘述，本文主要是针对实际的运用。 官方资料 https://www.ghisler.com/官网上没有相对应的文档，需要额外去搜寻 优秀个人文章 TC学堂——最易读的Total Commander教程-强烈推荐通过该网站进行学习 Total Commander快捷键 实际操作常用目录这部分设置可以说是TC操作的精华，效率直接甩开windows资源管理器几条街。 快速添加ctrl+d，添加，然后a直接添加 常用目录高级配置通过自定义配置，可以自定义调整常用目录的名称、顺序等，后续的增删改查也在此页面进行。 ctrl+d，添加，进去之后按c进入常用目录配置对话框。在里面配置的时候，需要再最前面人为添加&amp;。 名称设置： &amp;1 test $b blog 命令参考设置： cd C:\Users\56810\blog\blog 直达组合键通过直达组合键，可以直接切换到指定目录下。 设置：alt+s 调出窗口，再按s进行配置。一共可以使用的个数是一般都是类似ctrl+alt+F1/F2..F11这么11个组合键 名称设置： &amp;1 desktop $b blog 命令参考设置： cd C:\Users\56810\blog\blog 配置完成之后，切换到桌面只需要：alt+s+1 切换磁盘分区Alt+F1调出分区选项之后，按D则进入D盘，E则进入E盘。 目录内容查看Alt+1 详细的列表信息 Alt+2 图形信息显示 Alt+3 目录树显示 多Tab标签操作ctrl+t 新建tab ctrl+上箭头 新建父目录tab ctrl+w 关闭标签 ctrl+shift+w 关闭所有非活动标签 ctrl+tab, ctrl+shift+tab 在同侧的tab间切换 改变tab排列顺序（包括在两个窗口间移动）：鼠标左键拖动。 自定义快捷键，直接切换到第N个标签可以在 wincmd.ini 中 [Shortcuts] 段，增加如下内容， C+1=cm_SrcActivateTab1 C+2=cm_SrcActivateTab2 C+3=cm_SrcActivateTab3 效果： ctrl+1～3 激活第 1～3 个标签，依次类推 压缩操作压缩： 选中文件之后，执行Alt+F5 查看压缩文件内容（不解压缩）： ctrl+右箭头或者直接回车 解压缩：Alt+F9 文件搜索Alt+F7 创建操作F7/Shift+F7 新建一个或多层文件夹。可以像DOS那样新建多层的目录，比如c:\file\a\b\c Shift+F4 新建文本文件，调用记事本编辑（自定义编辑器） 其他快捷键ctrl +e 进入资源管理器 alt + f1 选择第一个窗口的磁盘 +f2就是选择第二个窗口的磁盘 alt+下箭头 历史记录 alt+左箭头 返回上一个操作目录（历史目录） alt+右箭头 返回下一个操作目录（历史目录） ctrl+\ 返回到当前目录的根目录 Ctrl+Shift+Enter 查看当前的路径 shift+F10 右键 F3 文件内容预览 ctrl+M 批量重命名 Shift+F4 新建文本文件，调用记事本编辑（自定义编辑器） Ctrl+加号 全部选择同一类型的文件（例如压缩文件，目录文件） Ctrl+减号 全部取消同一类型的文件（例如压缩文件，目录文件）]]></content>
      <categories>
        <category>常用软件工具</category>
        <category>TotalCommander</category>
      </categories>
      <tags>
        <tag>TC操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F01%2F23%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is my first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask author on GitHub. 前言之前使用阿里云结合wordpress的方式搭博客，但是自己维护起来不是太方便，云服务器一旦攻击，数据是个问题。之后在51cto和csdn上写，但是要受到平台的限制。最近发现github有博客功能(几年前就推出了，竟然现在才发现)，完美解决这些问题。github提供空间，用户自行选择博客框架，专注于内容，大部分人应该还是喜欢这种简约风主题。目前这个博客使用github-pages+Hexo来实现。 参考资料搭建 https://zhuanlan.zhihu.com/p/26625249 http://eleveneat.com/2015/04/24/Hexo-a-blog/ 进阶 主要参考官方资料 Hexo文档 https://hexo.io/zh-cn/docs/ Next主题使用手册 http://theme-next.iissnan.com/ 根据官方资料，按图索骥，基本上都能很好的把所有功能实现出来。使用问题可以随时沟通交流 markdown语法 关于markdown的使用，可以看我的这篇博文 Markdown语法 Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
